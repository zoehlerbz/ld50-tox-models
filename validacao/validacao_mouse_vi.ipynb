{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73b79fa-1231-4a4e-8d80-bc72a54c3e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../code/Limpeza.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b92dcf-1e35-40fa-8351-5fd51e5e7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../code/Representacao.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e537f25-1270-415b-be6b-3fc5b473488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../code/Clusterizacao.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1302765-f887-4927-afff-107327d90f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------BASE-------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "#-------CHEM-------#\n",
    "from rdkit import RDLogger\n",
    "import cirpy\n",
    "#-------MACHINE LEARNING-------#\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3562a0ad-b012-4af5-ad0b-54b193ac6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desabilita os warnings do RDKit\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445dad04-f19e-4970-aa01-403cc9dd6f12",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003a4ac0-ac9d-47c9-a5e7-5c2ca5e1c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(fpSize: int):\n",
    "    \n",
    "    # Define o modelo ANN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(300, activation='relu', input_shape=(fpSize,)),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a352c3a-e8e6-450f-896f-661910e93cd5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659a83d-d515-4352-9adb-56cd3a1a2989",
   "metadata": {},
   "source": [
    "# MOUSE, INTRAVENOSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e800e7-9fbc-46af-a310-9cb12fa7cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_count = True\n",
    "fpSize = 8192\n",
    "radius = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95d5e5-a2c4-49f9-ba72-4792baee9629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,457,900</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │     \u001b[38;5;34m2,457,900\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,488,101</span> (9.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,488,101\u001b[0m (9.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,488,101</span> (9.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,488,101\u001b[0m (9.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 4.3661 - mae: 1.4896 - val_loss: 2.1115 - val_mae: 0.9453\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 1.1610 - mae: 0.7528 - val_loss: 1.7591 - val_mae: 0.8906\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.8006 - mae: 0.6084 - val_loss: 1.5977 - val_mae: 0.8361\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.5798 - mae: 0.5128 - val_loss: 1.6801 - val_mae: 0.8511\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.4731 - mae: 0.4630 - val_loss: 1.5491 - val_mae: 0.8338\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.4288 - mae: 0.4277 - val_loss: 1.5125 - val_mae: 0.8183\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.4005 - mae: 0.3979 - val_loss: 1.6969 - val_mae: 0.8237\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.2942 - mae: 0.3485 - val_loss: 1.5290 - val_mae: 0.8183\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.2427 - mae: 0.3262 - val_loss: 1.5335 - val_mae: 0.7982\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.2203 - mae: 0.3060 - val_loss: 1.4367 - val_mae: 0.8022\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.1954 - mae: 0.2933 - val_loss: 1.4150 - val_mae: 0.7865\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1826 - mae: 0.2835 - val_loss: 1.5013 - val_mae: 0.8021\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1773 - mae: 0.2834 - val_loss: 1.7164 - val_mae: 0.8190\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1832 - mae: 0.2776 - val_loss: 1.3638 - val_mae: 0.7736\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1598 - mae: 0.2630 - val_loss: 1.4210 - val_mae: 0.7913\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1621 - mae: 0.2651 - val_loss: 1.4909 - val_mae: 0.7725\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1539 - mae: 0.2510 - val_loss: 1.4476 - val_mae: 0.7714\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1254 - mae: 0.2278 - val_loss: 1.3938 - val_mae: 0.7765\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1424 - mae: 0.2367 - val_loss: 1.3431 - val_mae: 0.7585\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1260 - mae: 0.2265 - val_loss: 1.3349 - val_mae: 0.7659\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1136 - mae: 0.2243 - val_loss: 1.4592 - val_mae: 0.7720\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1284 - mae: 0.2243 - val_loss: 1.3924 - val_mae: 0.7933\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1142 - mae: 0.2122 - val_loss: 1.3228 - val_mae: 0.7632\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1169 - mae: 0.2184 - val_loss: 1.3502 - val_mae: 0.7596\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1016 - mae: 0.2075 - val_loss: 1.3624 - val_mae: 0.7600\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1487 - mae: 0.2264 - val_loss: 1.4344 - val_mae: 0.7643\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1142 - mae: 0.2067 - val_loss: 1.3131 - val_mae: 0.7543\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0849 - mae: 0.1906 - val_loss: 1.3666 - val_mae: 0.7706\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0860 - mae: 0.1884 - val_loss: 1.3775 - val_mae: 0.7653\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1087 - mae: 0.1942 - val_loss: 1.3672 - val_mae: 0.7595\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0803 - mae: 0.1786 - val_loss: 1.3303 - val_mae: 0.7617\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0734 - mae: 0.1813 - val_loss: 1.3502 - val_mae: 0.7541\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0743 - mae: 0.1763 - val_loss: 1.3283 - val_mae: 0.7529\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0703 - mae: 0.1737 - val_loss: 1.3143 - val_mae: 0.7491\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0715 - mae: 0.1699 - val_loss: 1.3649 - val_mae: 0.7742\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0763 - mae: 0.1776 - val_loss: 1.3304 - val_mae: 0.7583\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0689 - mae: 0.1674 - val_loss: 1.2918 - val_mae: 0.7581\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0794 - mae: 0.1770 - val_loss: 1.3762 - val_mae: 0.7606\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0685 - mae: 0.1724 - val_loss: 1.3400 - val_mae: 0.7576\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0723 - mae: 0.1609 - val_loss: 1.3033 - val_mae: 0.7501\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0705 - mae: 0.1622 - val_loss: 1.3127 - val_mae: 0.7422\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0741 - mae: 0.1597 - val_loss: 1.2977 - val_mae: 0.7459\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0606 - mae: 0.1482 - val_loss: 1.3173 - val_mae: 0.7472\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0579 - mae: 0.1464 - val_loss: 1.3171 - val_mae: 0.7485\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0460 - mae: 0.1368 - val_loss: 1.3416 - val_mae: 0.7530\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0536 - mae: 0.1384 - val_loss: 1.2967 - val_mae: 0.7431\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0554 - mae: 0.1398 - val_loss: 1.3099 - val_mae: 0.7428\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0489 - mae: 0.1362 - val_loss: 1.3159 - val_mae: 0.7414\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0496 - mae: 0.1438 - val_loss: 1.3240 - val_mae: 0.7530\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0486 - mae: 0.1452 - val_loss: 1.3335 - val_mae: 0.7440\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0538 - mae: 0.1446 - val_loss: 1.2928 - val_mae: 0.7423\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0506 - mae: 0.1376 - val_loss: 1.2954 - val_mae: 0.7490\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0472 - mae: 0.1376 - val_loss: 1.3046 - val_mae: 0.7455\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0502 - mae: 0.1432 - val_loss: 1.3228 - val_mae: 0.7488\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0564 - mae: 0.1365 - val_loss: 1.2869 - val_mae: 0.7430\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0468 - mae: 0.1340 - val_loss: 1.3001 - val_mae: 0.7374\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0460 - mae: 0.1323 - val_loss: 1.3434 - val_mae: 0.7502\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0433 - mae: 0.1236 - val_loss: 1.3194 - val_mae: 0.7449\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0440 - mae: 0.1294 - val_loss: 1.3363 - val_mae: 0.7514\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0428 - mae: 0.1261 - val_loss: 1.3208 - val_mae: 0.7444\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0420 - mae: 0.1253 - val_loss: 1.4227 - val_mae: 0.7673\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0480 - mae: 0.1337 - val_loss: 1.3059 - val_mae: 0.7389\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0337 - mae: 0.1166 - val_loss: 1.3401 - val_mae: 0.7477\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0370 - mae: 0.1196 - val_loss: 1.3039 - val_mae: 0.7444\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0477 - mae: 0.1211 - val_loss: 1.3405 - val_mae: 0.7462\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0358 - mae: 0.1209 - val_loss: 1.3205 - val_mae: 0.7429\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0350 - mae: 0.1135 - val_loss: 1.4101 - val_mae: 0.7499\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0366 - mae: 0.1213 - val_loss: 1.3014 - val_mae: 0.7438\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0366 - mae: 0.1189 - val_loss: 1.3278 - val_mae: 0.7438\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0387 - mae: 0.1198 - val_loss: 1.2829 - val_mae: 0.7353\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0310 - mae: 0.1093 - val_loss: 1.3272 - val_mae: 0.7438\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0333 - mae: 0.1142 - val_loss: 1.2988 - val_mae: 0.7374\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0290 - mae: 0.1100 - val_loss: 1.3376 - val_mae: 0.7485\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0337 - mae: 0.1135 - val_loss: 1.2905 - val_mae: 0.7371\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0328 - mae: 0.1086 - val_loss: 1.3147 - val_mae: 0.7398\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0265 - mae: 0.1029 - val_loss: 1.3270 - val_mae: 0.7473\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0356 - mae: 0.1145 - val_loss: 1.3034 - val_mae: 0.7374\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0303 - mae: 0.1088 - val_loss: 1.3190 - val_mae: 0.7366\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0305 - mae: 0.1092 - val_loss: 1.2932 - val_mae: 0.7418\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0271 - mae: 0.1047 - val_loss: 1.3274 - val_mae: 0.7382\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0306 - mae: 0.1065 - val_loss: 1.3067 - val_mae: 0.7420\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0333 - mae: 0.1053 - val_loss: 1.3144 - val_mae: 0.7390\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0321 - mae: 0.1076 - val_loss: 1.3081 - val_mae: 0.7369\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0248 - mae: 0.0988 - val_loss: 1.3429 - val_mae: 0.7437\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0282 - mae: 0.1054 - val_loss: 1.2726 - val_mae: 0.7321\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0281 - mae: 0.1004 - val_loss: 1.3011 - val_mae: 0.7413\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0277 - mae: 0.1043 - val_loss: 1.3041 - val_mae: 0.7350\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0265 - mae: 0.0997 - val_loss: 1.3117 - val_mae: 0.7415\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0255 - mae: 0.1008 - val_loss: 1.3101 - val_mae: 0.7468\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0274 - mae: 0.0990 - val_loss: 1.3308 - val_mae: 0.7414\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0229 - mae: 0.0967 - val_loss: 1.3255 - val_mae: 0.7422\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0275 - mae: 0.1036 - val_loss: 1.2980 - val_mae: 0.7364\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0267 - mae: 0.0978 - val_loss: 1.2921 - val_mae: 0.7350\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0248 - mae: 0.1016 - val_loss: 1.3274 - val_mae: 0.7387\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0244 - mae: 0.0965 - val_loss: 1.3046 - val_mae: 0.7358\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0230 - mae: 0.0951 - val_loss: 1.3094 - val_mae: 0.7375\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0385 - mae: 0.1029 - val_loss: 1.3077 - val_mae: 0.7419\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0212 - mae: 0.0925 - val_loss: 1.3518 - val_mae: 0.7455\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0252 - mae: 0.0961 - val_loss: 1.3024 - val_mae: 0.7352\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0230 - mae: 0.0962 - val_loss: 1.3110 - val_mae: 0.7360\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0191 - mae: 0.0876 - val_loss: 1.2926 - val_mae: 0.7364\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0230 - mae: 0.0940 - val_loss: 1.3096 - val_mae: 0.7435\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0197 - mae: 0.0897 - val_loss: 1.3155 - val_mae: 0.7410\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0223 - mae: 0.0938 - val_loss: 1.2984 - val_mae: 0.7352\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0210 - mae: 0.0896 - val_loss: 1.2940 - val_mae: 0.7347\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0196 - mae: 0.0886 - val_loss: 1.3283 - val_mae: 0.7415\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0223 - mae: 0.0890 - val_loss: 1.3205 - val_mae: 0.7391\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0215 - mae: 0.0917 - val_loss: 1.3522 - val_mae: 0.7473\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0204 - mae: 0.0924 - val_loss: 1.3213 - val_mae: 0.7364\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0208 - mae: 0.0896 - val_loss: 1.3226 - val_mae: 0.7358\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0157 - mae: 0.0807 - val_loss: 1.3471 - val_mae: 0.7378\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0218 - mae: 0.0866 - val_loss: 1.3032 - val_mae: 0.7348\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0204 - mae: 0.0849 - val_loss: 1.3068 - val_mae: 0.7410\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0242 - mae: 0.0923 - val_loss: 1.3161 - val_mae: 0.7397\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0200 - mae: 0.0865 - val_loss: 1.3195 - val_mae: 0.7392\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0205 - mae: 0.0841 - val_loss: 1.3443 - val_mae: 0.7422\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0160 - mae: 0.0774 - val_loss: 1.3177 - val_mae: 0.7471\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0164 - mae: 0.0813 - val_loss: 1.3286 - val_mae: 0.7388\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0227 - mae: 0.0879 - val_loss: 1.3273 - val_mae: 0.7448\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0170 - mae: 0.0809 - val_loss: 1.3437 - val_mae: 0.7404\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0234 - mae: 0.0877 - val_loss: 1.3200 - val_mae: 0.7377\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0180 - mae: 0.0853 - val_loss: 1.3309 - val_mae: 0.7412\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0187 - mae: 0.0839 - val_loss: 1.3185 - val_mae: 0.7420\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0176 - mae: 0.0851 - val_loss: 1.3419 - val_mae: 0.7408\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0188 - mae: 0.0810 - val_loss: 1.3170 - val_mae: 0.7389\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0157 - mae: 0.0771 - val_loss: 1.3111 - val_mae: 0.7405\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0178 - mae: 0.0823 - val_loss: 1.3664 - val_mae: 0.7457\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0191 - mae: 0.0840 - val_loss: 1.3400 - val_mae: 0.7440\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0150 - mae: 0.0786 - val_loss: 1.3220 - val_mae: 0.7381\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0150 - mae: 0.0749 - val_loss: 1.3458 - val_mae: 0.7447\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0175 - mae: 0.0714 - val_loss: 1.3337 - val_mae: 0.7384\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0179 - mae: 0.0745 - val_loss: 1.3349 - val_mae: 0.7430\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0170 - mae: 0.0813 - val_loss: 1.3330 - val_mae: 0.7468\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0199 - mae: 0.0834 - val_loss: 1.3239 - val_mae: 0.7433\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0200 - mae: 0.0818 - val_loss: 1.3268 - val_mae: 0.7406\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0136 - mae: 0.0724 - val_loss: 1.3383 - val_mae: 0.7387\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0141 - mae: 0.0728 - val_loss: 1.3223 - val_mae: 0.7411\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0139 - mae: 0.0715 - val_loss: 1.3285 - val_mae: 0.7385\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0144 - mae: 0.0766 - val_loss: 1.3325 - val_mae: 0.7390\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0147 - mae: 0.0775 - val_loss: 1.3113 - val_mae: 0.7412\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0202 - mae: 0.0817 - val_loss: 1.3445 - val_mae: 0.7399\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0161 - mae: 0.0755 - val_loss: 1.3392 - val_mae: 0.7398\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0124 - mae: 0.0691 - val_loss: 1.3504 - val_mae: 0.7447\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0177 - mae: 0.0744 - val_loss: 1.3089 - val_mae: 0.7430\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0208 - mae: 0.0792 - val_loss: 1.3352 - val_mae: 0.7422\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0148 - mae: 0.0730 - val_loss: 1.2807 - val_mae: 0.7382\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0154 - mae: 0.0759 - val_loss: 1.3587 - val_mae: 0.7436\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0121 - mae: 0.0703 - val_loss: 1.3256 - val_mae: 0.7397\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0143 - mae: 0.0720 - val_loss: 1.3447 - val_mae: 0.7423\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0181 - mae: 0.0784 - val_loss: 1.2958 - val_mae: 0.7333\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0173 - mae: 0.0786 - val_loss: 1.2965 - val_mae: 0.7363\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0162 - mae: 0.0721 - val_loss: 1.3371 - val_mae: 0.7460\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0159 - mae: 0.0703 - val_loss: 1.3069 - val_mae: 0.7408\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0164 - mae: 0.0773 - val_loss: 1.3156 - val_mae: 0.7409\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0168 - mae: 0.0717 - val_loss: 1.3114 - val_mae: 0.7405\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0144 - mae: 0.0711 - val_loss: 1.3102 - val_mae: 0.7379\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0145 - mae: 0.0705 - val_loss: 1.3044 - val_mae: 0.7378\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0160 - mae: 0.0731 - val_loss: 1.3180 - val_mae: 0.7389\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0124 - mae: 0.0681 - val_loss: 1.3501 - val_mae: 0.7466\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0122 - mae: 0.0650 - val_loss: 1.3327 - val_mae: 0.7433\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0118 - mae: 0.0696 - val_loss: 1.3292 - val_mae: 0.7395\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0167 - mae: 0.0751 - val_loss: 1.3408 - val_mae: 0.7387\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0152 - mae: 0.0731 - val_loss: 1.3149 - val_mae: 0.7396\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0200 - mae: 0.0729 - val_loss: 1.3368 - val_mae: 0.7398\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0170 - mae: 0.0749 - val_loss: 1.3580 - val_mae: 0.7382\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0157 - mae: 0.0730 - val_loss: 1.2883 - val_mae: 0.7367\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0143 - mae: 0.0728 - val_loss: 1.3321 - val_mae: 0.7389\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0155 - mae: 0.0712 - val_loss: 1.3041 - val_mae: 0.7373\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0152 - mae: 0.0693 - val_loss: 1.3275 - val_mae: 0.7403\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0121 - mae: 0.0667 - val_loss: 1.3170 - val_mae: 0.7380\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0118 - mae: 0.0668 - val_loss: 1.3136 - val_mae: 0.7329\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0163 - mae: 0.0699 - val_loss: 1.3316 - val_mae: 0.7390\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0107 - mae: 0.0636 - val_loss: 1.3141 - val_mae: 0.7341\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0106 - mae: 0.0636 - val_loss: 1.3302 - val_mae: 0.7391\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0139 - mae: 0.0675 - val_loss: 1.3466 - val_mae: 0.7410\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0198 - mae: 0.0755 - val_loss: 1.3266 - val_mae: 0.7334\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0105 - mae: 0.0637 - val_loss: 1.3059 - val_mae: 0.7325\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0115 - mae: 0.0662 - val_loss: 1.3276 - val_mae: 0.7401\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0172 - mae: 0.0686 - val_loss: 1.3194 - val_mae: 0.7431\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0146 - mae: 0.0668 - val_loss: 1.3229 - val_mae: 0.7406\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0145 - mae: 0.0693 - val_loss: 1.3428 - val_mae: 0.7376\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0120 - mae: 0.0658 - val_loss: 1.3156 - val_mae: 0.7435\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0116 - mae: 0.0652 - val_loss: 1.3242 - val_mae: 0.7363\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0158 - mae: 0.0615 - val_loss: 1.3146 - val_mae: 0.7406\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0127 - mae: 0.0664 - val_loss: 1.3152 - val_mae: 0.7396\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0136 - mae: 0.0629 - val_loss: 1.2881 - val_mae: 0.7355\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0100 - mae: 0.0624 - val_loss: 1.3449 - val_mae: 0.7350\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0127 - mae: 0.0663 - val_loss: 1.3460 - val_mae: 0.7365\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0161 - mae: 0.0693 - val_loss: 1.3038 - val_mae: 0.7384\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0154 - mae: 0.0683 - val_loss: 1.3502 - val_mae: 0.7415\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0109 - mae: 0.0591 - val_loss: 1.3170 - val_mae: 0.7363\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0105 - mae: 0.0598 - val_loss: 1.3128 - val_mae: 0.7387\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0112 - mae: 0.0650 - val_loss: 1.3451 - val_mae: 0.7427\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0117 - mae: 0.0639 - val_loss: 1.3331 - val_mae: 0.7404\n",
      "Epoch 195/200\n",
      "\u001b[1m449/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0154 - mae: 0.0706"
     ]
    }
   ],
   "source": [
    "# Obtem os dados\n",
    "mouse_vi = pd.read_csv('../dados/mouse_vi.csv', usecols=['mouse_vi', 'smiles'])\n",
    "\n",
    "# Converter valores da coluna 'valor' para float\n",
    "mouse_vi['mouse_vi'] = pd.to_numeric(mouse_vi['mouse_vi'], errors='coerce')\n",
    "\n",
    "# Remove NaN\n",
    "mouse_vi.dropna(subset=['mouse_vi', 'smiles'], inplace=True, ignore_index=True)\n",
    "\n",
    "# Normaliza LD50\n",
    "mouse_vi['log_ld50'] = -np.log(mouse_vi['mouse_vi'])\n",
    "\n",
    "# Realiza a limpeza dos dados\n",
    "limpeza = Limpeza(dataframe=mouse_vi)\n",
    "mouse_vi = limpeza.dados_limpos(col_smiles='smiles', col_valor='mouse_vi', sanitize=True, cutoff=.05, fragmento=False)\n",
    "\n",
    "# Define a representação fingerprint\n",
    "representacao = Representacao(dataframe=mouse_vi)\n",
    "mouse_vi = representacao.fingerprint(col_smiles='smiles', fingerprint='morgan', use_count=use_count, fpSize=fpSize, radius=radius)\n",
    "\n",
    "# Define os conjuntos de treinamento e teste\n",
    "X = np.array(mouse_vi['Features'].to_list())\n",
    "y = mouse_vi['log_ld50'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplica ANN\n",
    "model = ANN(fpSize=fpSize)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=200, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df86989-adf7-4cac-8b52-8ebd5838f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0e047-03c4-4a8d-886e-d75b71e08b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtem as métricas do modelo\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "\n",
    "# R-squared\n",
    "predictions = model.predict(X_test)\n",
    "y_true = np.array(y_test)\n",
    "y_pred = np.array(predictions)\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f'loss: {loss}')\n",
    "print(f'mae: {mae}')\n",
    "print(f'r2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f1058-4c00-454b-8db2-72a0db579191",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e6751-17f5-4f2f-84f3-be8d366c96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ld50(log_ld50):\n",
    "    return float(np.exp(-log_ld50))\n",
    "\n",
    "def ghs_category(ld_50):\n",
    "    if ld_50 <= 5:\n",
    "        return 1\n",
    "    elif ld_50 > 5 and ld_50 <= 50:\n",
    "        return 2\n",
    "    elif ld_50 > 50 and ld_50 <= 300:\n",
    "        return 3\n",
    "    elif ld_50 > 300 and ld_50 <= 2000:\n",
    "        return 4\n",
    "    elif ld_50 >= 2000:\n",
    "        return 5\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def classe_eh_a_mesma(ghs_observada, ghs_predita):\n",
    "    return ghs_observada == ghs_predita\n",
    "\n",
    "def reduz_animais(ghs_observada, ghs_predita):\n",
    "    if ghs_observada > 3 and ghs_observada > ghs_predita:\n",
    "        return True\n",
    "    elif ghs_observada < 3 and ghs_observada < ghs_predita:\n",
    "        return True\n",
    "    elif ghs_observada == ghs_predita and ghs_observada != 3:\n",
    "        return True\n",
    "    elif ghs_predita == 3:\n",
    "        return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aac4ab-afa1-4468-b0ba-f9b70d2d7430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghs = pd.DataFrame({\n",
    "    'observado':y_true,\n",
    "    'predito': [pred[0] for pred in y_pred]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc3f74-49f9-49ad-908c-31d76a1f3af6",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# ATC method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3be33a-0992-4a2e-be64-328c9c3de827",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghs['ld50_observado'] = ghs['observado'].apply(ld50)\n",
    "ghs['ld50_predito'] = ghs['predito'].apply(ld50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33aa2d-fa14-41bb-9adf-9c184dc5d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghs['ghs_observada'] = ghs['ld50_observado'].apply(ghs_category)\n",
    "ghs['ghs_predita'] = ghs['ld50_predito'].apply(ghs_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7421fa-3dbc-4598-81b6-7f3ca004f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghs['mesma_classe'] = ghs.apply(lambda row: classe_eh_a_mesma(row['ghs_observada'], row['ghs_predita']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e60f46-c892-4f2f-9a96-2a0a8fdfc86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghs['reduz_animais'] = ghs.apply(lambda row: reduz_animais(row['ghs_observada'], row['ghs_predita']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d565f-2a42-4017-a88c-175610efb571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Predição da classe correta: {(ghs['mesma_classe'].sum() * 100) / ghs.shape[0]}')\n",
    "print(f'Redução de animais: {(ghs['reduz_animais'].sum() * 100) / ghs.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed34ab2-8278-4f55-a4c7-4f945023cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f33c6-7e0c-473a-85f3-a0b74311840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghs.to_excel('validacao_mouse_vi.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
