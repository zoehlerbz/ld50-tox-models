{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3efdec8c-6e0a-4ec4-a6a5-6a6322b40ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run code/Limpeza.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc356b9-5254-4e7c-8833-eacd190138ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run code/Representacao.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641c3dd1-11a7-4f5c-92f4-bcde6db35f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run code/Clusterizacao.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e21f635-92ad-4fd2-9645-3825b3b58a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------BASE-------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "#-------RDKIT WARNINGS-------#\n",
    "from rdkit import RDLogger\n",
    "#-------MACHINE LEARNING-------#\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8470fa-c86a-4559-ac84-3a84d5528a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desabilita os warnings do RDKit\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b0dc4-6bf9-4ff0-b8fe-ca0a4b4dedb3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3040a91b-a169-44cc-9672-1c85442576de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(fpSize: int):\n",
    "    \n",
    "    # Define o modelo ANN\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(300, activation='relu', input_shape=(fpSize,)),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fc57f-7fb8-4679-b972-c145f873e817",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9a893-5f4d-4f50-a330-f534768a8170",
   "metadata": {},
   "source": [
    "## Opções de grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f02b95-0895-493e-8993-00d88f42487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_count_option = [False, True]\n",
    "fpSize_option = [2048, 4096, 8192]\n",
    "radius_option = [2, 3, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79595b67-e215-4a05-bac2-a157c89591be",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c877fb6c-725a-4229-b134-a885bbca7ac4",
   "metadata": {},
   "source": [
    "# MOUSE, INTRAVENOSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97fc4e1b-d9b9-4de4-9f8b-ace7654ee15b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.3299 - mae: 1.3188 - val_loss: 1.6867 - val_mae: 0.9213\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.0127 - mae: 0.7204 - val_loss: 1.4144 - val_mae: 0.8400\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6933 - mae: 0.5842 - val_loss: 1.3129 - val_mae: 0.8020\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4654 - mae: 0.4756 - val_loss: 1.3361 - val_mae: 0.8046\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3458 - mae: 0.4063 - val_loss: 1.3220 - val_mae: 0.8003\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2948 - mae: 0.3751 - val_loss: 1.2986 - val_mae: 0.8003\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2250 - mae: 0.3287 - val_loss: 1.3161 - val_mae: 0.8153\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2220 - mae: 0.3237 - val_loss: 1.2823 - val_mae: 0.7951\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1886 - mae: 0.2998 - val_loss: 1.3024 - val_mae: 0.7960\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1855 - mae: 0.2922 - val_loss: 1.2763 - val_mae: 0.7858\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1752 - mae: 0.2795 - val_loss: 1.3490 - val_mae: 0.8158\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1907 - mae: 0.2973 - val_loss: 1.2856 - val_mae: 0.7866\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1593 - mae: 0.2707 - val_loss: 1.2897 - val_mae: 0.7788\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1527 - mae: 0.2638 - val_loss: 1.2926 - val_mae: 0.8020\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1303 - mae: 0.2488 - val_loss: 1.3032 - val_mae: 0.7757\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1459 - mae: 0.2546 - val_loss: 1.2577 - val_mae: 0.7672\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1276 - mae: 0.2353 - val_loss: 1.2820 - val_mae: 0.7816\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1241 - mae: 0.2282 - val_loss: 1.2354 - val_mae: 0.7732\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1127 - mae: 0.2245 - val_loss: 1.2368 - val_mae: 0.7663\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1051 - mae: 0.2178 - val_loss: 1.2471 - val_mae: 0.7694\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1188 - mae: 0.2263 - val_loss: 1.2754 - val_mae: 0.7718\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1108 - mae: 0.2188 - val_loss: 1.2663 - val_mae: 0.7646\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0903 - mae: 0.2024 - val_loss: 1.2899 - val_mae: 0.7783\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0972 - mae: 0.2054 - val_loss: 1.2977 - val_mae: 0.7690\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0870 - mae: 0.1944 - val_loss: 1.2354 - val_mae: 0.7610\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0920 - mae: 0.2005 - val_loss: 1.2824 - val_mae: 0.7633\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0848 - mae: 0.1897 - val_loss: 1.2739 - val_mae: 0.7703\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0755 - mae: 0.1855 - val_loss: 1.2763 - val_mae: 0.7646\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0817 - mae: 0.1902 - val_loss: 1.2531 - val_mae: 0.7631\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0700 - mae: 0.1768 - val_loss: 1.2873 - val_mae: 0.7618\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0732 - mae: 0.1788 - val_loss: 1.2917 - val_mae: 0.7722\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0753 - mae: 0.1804 - val_loss: 1.2612 - val_mae: 0.7659\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0710 - mae: 0.1746 - val_loss: 1.2425 - val_mae: 0.7553\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0787 - mae: 0.1799 - val_loss: 1.2584 - val_mae: 0.7634\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0658 - mae: 0.1679 - val_loss: 1.2524 - val_mae: 0.7587\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0607 - mae: 0.1636 - val_loss: 1.2804 - val_mae: 0.7580\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0683 - mae: 0.1694 - val_loss: 1.2896 - val_mae: 0.7756\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0677 - mae: 0.1687 - val_loss: 1.2874 - val_mae: 0.7636\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0643 - mae: 0.1581 - val_loss: 1.2635 - val_mae: 0.7653\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0634 - mae: 0.1586 - val_loss: 1.2760 - val_mae: 0.7668\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0561 - mae: 0.1517 - val_loss: 1.2699 - val_mae: 0.7666\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0616 - mae: 0.1582 - val_loss: 1.2610 - val_mae: 0.7525\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0620 - mae: 0.1581 - val_loss: 1.2656 - val_mae: 0.7606\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0610 - mae: 0.1532 - val_loss: 1.2479 - val_mae: 0.7522\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0577 - mae: 0.1480 - val_loss: 1.2659 - val_mae: 0.7589\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0517 - mae: 0.1455 - val_loss: 1.2938 - val_mae: 0.7652\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0543 - mae: 0.1406 - val_loss: 1.2607 - val_mae: 0.7576\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0505 - mae: 0.1398 - val_loss: 1.2899 - val_mae: 0.7664\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0617 - mae: 0.1498 - val_loss: 1.2773 - val_mae: 0.7590\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0436 - mae: 0.1349 - val_loss: 1.2571 - val_mae: 0.7535\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0496 - mae: 0.1419 - val_loss: 1.2880 - val_mae: 0.7626\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0554 - mae: 0.1458 - val_loss: 1.2764 - val_mae: 0.7570\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0511 - mae: 0.1456 - val_loss: 1.3061 - val_mae: 0.7652\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0522 - mae: 0.1369 - val_loss: 1.2878 - val_mae: 0.7612\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0526 - mae: 0.1367 - val_loss: 1.2836 - val_mae: 0.7580\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0476 - mae: 0.1350 - val_loss: 1.2706 - val_mae: 0.7549\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0458 - mae: 0.1321 - val_loss: 1.2604 - val_mae: 0.7569\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0470 - mae: 0.1294 - val_loss: 1.2659 - val_mae: 0.7526\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0423 - mae: 0.1268 - val_loss: 1.2648 - val_mae: 0.7508\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0488 - mae: 0.1408 - val_loss: 1.3072 - val_mae: 0.7572\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0419 - mae: 0.1288 - val_loss: 1.2905 - val_mae: 0.7610\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0422 - mae: 0.1279 - val_loss: 1.2693 - val_mae: 0.7566\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.1193 - val_loss: 1.3339 - val_mae: 0.7719\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0424 - mae: 0.1237 - val_loss: 1.2535 - val_mae: 0.7485\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0480 - mae: 0.1239 - val_loss: 1.2887 - val_mae: 0.7552\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1177 - val_loss: 1.2944 - val_mae: 0.7593\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0442 - mae: 0.1255 - val_loss: 1.2504 - val_mae: 0.7517\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0420 - mae: 0.1215 - val_loss: 1.3055 - val_mae: 0.7606\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1156 - val_loss: 1.2770 - val_mae: 0.7548\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0432 - mae: 0.1232 - val_loss: 1.2672 - val_mae: 0.7569\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0395 - mae: 0.1168 - val_loss: 1.2840 - val_mae: 0.7534\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0373 - mae: 0.1136 - val_loss: 1.2837 - val_mae: 0.7580\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0384 - mae: 0.1112 - val_loss: 1.3143 - val_mae: 0.7642\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0389 - mae: 0.1166 - val_loss: 1.2796 - val_mae: 0.7513\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0349 - mae: 0.1168 - val_loss: 1.2905 - val_mae: 0.7571\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0360 - mae: 0.1119 - val_loss: 1.2924 - val_mae: 0.7532\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0329 - mae: 0.1081 - val_loss: 1.3189 - val_mae: 0.7569\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1120 - val_loss: 1.2790 - val_mae: 0.7532\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0327 - mae: 0.1103 - val_loss: 1.3078 - val_mae: 0.7669\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.1131 - val_loss: 1.3101 - val_mae: 0.7573\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1104 - val_loss: 1.3192 - val_mae: 0.7579\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0389 - mae: 0.1113 - val_loss: 1.3222 - val_mae: 0.7561\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0314 - mae: 0.1081 - val_loss: 1.3010 - val_mae: 0.7528\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0348 - mae: 0.1079 - val_loss: 1.2946 - val_mae: 0.7547\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0333 - mae: 0.1074 - val_loss: 1.2965 - val_mae: 0.7563\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0346 - mae: 0.1115 - val_loss: 1.2788 - val_mae: 0.7483\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.1005 - val_loss: 1.3029 - val_mae: 0.7607\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0327 - mae: 0.1036 - val_loss: 1.2862 - val_mae: 0.7486\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0314 - mae: 0.1012 - val_loss: 1.2709 - val_mae: 0.7488\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0335 - mae: 0.1069 - val_loss: 1.2897 - val_mae: 0.7569\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0387 - mae: 0.1073 - val_loss: 1.2806 - val_mae: 0.7513\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0365 - mae: 0.1058 - val_loss: 1.2940 - val_mae: 0.7570\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0282 - mae: 0.0965 - val_loss: 1.3091 - val_mae: 0.7527\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.0985 - val_loss: 1.2973 - val_mae: 0.7498\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.0982 - val_loss: 1.2867 - val_mae: 0.7508\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0299 - mae: 0.0991 - val_loss: 1.3095 - val_mae: 0.7551\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0255 - mae: 0.0963 - val_loss: 1.3037 - val_mae: 0.7575\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0291 - mae: 0.0953 - val_loss: 1.2934 - val_mae: 0.7548\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1014 - val_loss: 1.2893 - val_mae: 0.7548\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0311 - mae: 0.1014 - val_loss: 1.3151 - val_mae: 0.7583\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0306 - mae: 0.0995 - val_loss: 1.3032 - val_mae: 0.7575\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0274 - mae: 0.0977 - val_loss: 1.3055 - val_mae: 0.7534\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.0941 - val_loss: 1.2988 - val_mae: 0.7575\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0269 - mae: 0.0924 - val_loss: 1.2941 - val_mae: 0.7540\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0324 - mae: 0.0995 - val_loss: 1.2783 - val_mae: 0.7548\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0307 - mae: 0.0992 - val_loss: 1.2865 - val_mae: 0.7507\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0274 - mae: 0.0940 - val_loss: 1.3141 - val_mae: 0.7563\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0299 - mae: 0.0941 - val_loss: 1.3235 - val_mae: 0.7501\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0287 - mae: 0.0973 - val_loss: 1.3014 - val_mae: 0.7533\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0290 - mae: 0.0971 - val_loss: 1.3165 - val_mae: 0.7568\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0279 - mae: 0.0931 - val_loss: 1.3154 - val_mae: 0.7535\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0296 - mae: 0.0931 - val_loss: 1.3058 - val_mae: 0.7516\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0270 - mae: 0.0908 - val_loss: 1.3009 - val_mae: 0.7530\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0270 - mae: 0.0915 - val_loss: 1.2916 - val_mae: 0.7535\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0262 - mae: 0.0906 - val_loss: 1.2977 - val_mae: 0.7496\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.0927 - val_loss: 1.2808 - val_mae: 0.7478\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.0918 - val_loss: 1.2948 - val_mae: 0.7524\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0255 - mae: 0.0872 - val_loss: 1.3277 - val_mae: 0.7574\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0276 - mae: 0.0907 - val_loss: 1.3317 - val_mae: 0.7537\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - mae: 0.0899 - val_loss: 1.2998 - val_mae: 0.7584\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0310 - mae: 0.0935 - val_loss: 1.2920 - val_mae: 0.7512\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0258 - mae: 0.0875 - val_loss: 1.3028 - val_mae: 0.7535\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.0863 - val_loss: 1.2691 - val_mae: 0.7493\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0259 - mae: 0.0871 - val_loss: 1.2843 - val_mae: 0.7503\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0257 - mae: 0.0858 - val_loss: 1.3160 - val_mae: 0.7566\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0279 - mae: 0.0872 - val_loss: 1.3014 - val_mae: 0.7508\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0254 - mae: 0.0865 - val_loss: 1.2943 - val_mae: 0.7512\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.0899 - val_loss: 1.3234 - val_mae: 0.7549\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0825 - val_loss: 1.3003 - val_mae: 0.7515\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0236 - mae: 0.0828 - val_loss: 1.3496 - val_mae: 0.7629\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0268 - mae: 0.0918 - val_loss: 1.2943 - val_mae: 0.7506\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0243 - mae: 0.0865 - val_loss: 1.3119 - val_mae: 0.7538\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0289 - mae: 0.0823 - val_loss: 1.2950 - val_mae: 0.7502\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0257 - mae: 0.0841 - val_loss: 1.3375 - val_mae: 0.7548\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0210 - mae: 0.0797 - val_loss: 1.2885 - val_mae: 0.7531\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0261 - mae: 0.0835 - val_loss: 1.3062 - val_mae: 0.7502\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0244 - mae: 0.0844 - val_loss: 1.3123 - val_mae: 0.7561\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0261 - mae: 0.0883 - val_loss: 1.3200 - val_mae: 0.7546\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0849 - val_loss: 1.2845 - val_mae: 0.7509\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.0824 - val_loss: 1.2782 - val_mae: 0.7481\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.0830 - val_loss: 1.3353 - val_mae: 0.7571\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0233 - mae: 0.0818 - val_loss: 1.2994 - val_mae: 0.7493\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0231 - mae: 0.0784 - val_loss: 1.3237 - val_mae: 0.7561\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0823 - val_loss: 1.3028 - val_mae: 0.7578\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0819 - val_loss: 1.3134 - val_mae: 0.7555\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0240 - mae: 0.0829 - val_loss: 1.2881 - val_mae: 0.7494\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.0791 - val_loss: 1.3254 - val_mae: 0.7588\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0793 - val_loss: 1.3348 - val_mae: 0.7564\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0261 - mae: 0.0801 - val_loss: 1.2785 - val_mae: 0.7508\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0297 - mae: 0.0845 - val_loss: 1.3308 - val_mae: 0.7587\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0213 - mae: 0.0808 - val_loss: 1.3039 - val_mae: 0.7522\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0228 - mae: 0.0782 - val_loss: 1.3333 - val_mae: 0.7575\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0271 - mae: 0.0788 - val_loss: 1.3055 - val_mae: 0.7556\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.0815 - val_loss: 1.3358 - val_mae: 0.7566\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0240 - mae: 0.0823 - val_loss: 1.2971 - val_mae: 0.7537\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0210 - mae: 0.0794 - val_loss: 1.3491 - val_mae: 0.7580\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0757 - val_loss: 1.2942 - val_mae: 0.7509\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0234 - mae: 0.0795 - val_loss: 1.2742 - val_mae: 0.7476\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0249 - mae: 0.0824 - val_loss: 1.3143 - val_mae: 0.7582\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0204 - mae: 0.0745 - val_loss: 1.3146 - val_mae: 0.7507\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0226 - mae: 0.0760 - val_loss: 1.3109 - val_mae: 0.7557\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0236 - mae: 0.0793 - val_loss: 1.3456 - val_mae: 0.7583\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0224 - mae: 0.0763 - val_loss: 1.2861 - val_mae: 0.7524\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0234 - mae: 0.0787 - val_loss: 1.3258 - val_mae: 0.7527\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0233 - mae: 0.0814 - val_loss: 1.3517 - val_mae: 0.7594\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0244 - mae: 0.0807 - val_loss: 1.3007 - val_mae: 0.7542\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0253 - mae: 0.0750 - val_loss: 1.3213 - val_mae: 0.7587\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0254 - mae: 0.0765 - val_loss: 1.3081 - val_mae: 0.7538\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0206 - mae: 0.0738 - val_loss: 1.3170 - val_mae: 0.7546\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0759 - val_loss: 1.2974 - val_mae: 0.7515\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0248 - mae: 0.0764 - val_loss: 1.3235 - val_mae: 0.7600\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0224 - mae: 0.0767 - val_loss: 1.2865 - val_mae: 0.7522\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - mae: 0.0781 - val_loss: 1.3432 - val_mae: 0.7644\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.0789 - val_loss: 1.2848 - val_mae: 0.7487\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0242 - mae: 0.0730 - val_loss: 1.2995 - val_mae: 0.7608\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0747 - val_loss: 1.3196 - val_mae: 0.7540\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0751 - val_loss: 1.2944 - val_mae: 0.7532\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0228 - mae: 0.0738 - val_loss: 1.3243 - val_mae: 0.7518\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0738 - val_loss: 1.2997 - val_mae: 0.7559\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0242 - mae: 0.0785 - val_loss: 1.3407 - val_mae: 0.7642\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0240 - mae: 0.0777 - val_loss: 1.2828 - val_mae: 0.7505\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0695 - val_loss: 1.2864 - val_mae: 0.7508\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0231 - mae: 0.0766 - val_loss: 1.3067 - val_mae: 0.7542\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0728 - val_loss: 1.3105 - val_mae: 0.7560\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0228 - mae: 0.0723 - val_loss: 1.3068 - val_mae: 0.7524\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0239 - mae: 0.0756 - val_loss: 1.3008 - val_mae: 0.7517\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0231 - mae: 0.0736 - val_loss: 1.3343 - val_mae: 0.7538\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0705 - val_loss: 1.2834 - val_mae: 0.7485\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0239 - mae: 0.0735 - val_loss: 1.3348 - val_mae: 0.7532\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0227 - mae: 0.0758 - val_loss: 1.2965 - val_mae: 0.7526\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0217 - mae: 0.0727 - val_loss: 1.2903 - val_mae: 0.7502\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0698 - val_loss: 1.2878 - val_mae: 0.7509\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0722 - val_loss: 1.3270 - val_mae: 0.7532\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0700 - val_loss: 1.2842 - val_mae: 0.7517\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0749 - val_loss: 1.3212 - val_mae: 0.7510\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0708 - val_loss: 1.2916 - val_mae: 0.7488\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0699 - val_loss: 1.3398 - val_mae: 0.7565\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0682 - val_loss: 1.2860 - val_mae: 0.7530\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0233 - mae: 0.0751 - val_loss: 1.3208 - val_mae: 0.7532\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0225 - mae: 0.0737 - val_loss: 1.2934 - val_mae: 0.7484\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2723 - mae: 0.7346\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\AppData\\Local\\Temp\\ipykernel_31464\\1639649307.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.9556 - mae: 1.4160 - val_loss: 1.6599 - val_mae: 0.9107\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9908 - mae: 0.7058 - val_loss: 1.5553 - val_mae: 0.8728\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6102 - mae: 0.5475 - val_loss: 1.4604 - val_mae: 0.8506\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4044 - mae: 0.4434 - val_loss: 1.4862 - val_mae: 0.8541\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3079 - mae: 0.3854 - val_loss: 1.4501 - val_mae: 0.8576\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2729 - mae: 0.3582 - val_loss: 1.3482 - val_mae: 0.8183\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2100 - mae: 0.3125 - val_loss: 1.3891 - val_mae: 0.8149\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2015 - mae: 0.3131 - val_loss: 1.3676 - val_mae: 0.8180\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1811 - mae: 0.2963 - val_loss: 1.4817 - val_mae: 0.8462\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1761 - mae: 0.2808 - val_loss: 1.3731 - val_mae: 0.8219\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1611 - mae: 0.2747 - val_loss: 1.3762 - val_mae: 0.8167\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1615 - mae: 0.2727 - val_loss: 1.3552 - val_mae: 0.8142\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1551 - mae: 0.2635 - val_loss: 1.4015 - val_mae: 0.8183\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1416 - mae: 0.2538 - val_loss: 1.3818 - val_mae: 0.8085\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1223 - mae: 0.2362 - val_loss: 1.4137 - val_mae: 0.8215\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1160 - mae: 0.2362 - val_loss: 1.3645 - val_mae: 0.8067\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1178 - mae: 0.2376 - val_loss: 1.3883 - val_mae: 0.8114\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1140 - mae: 0.2280 - val_loss: 1.3842 - val_mae: 0.8189\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1140 - mae: 0.2282 - val_loss: 1.3695 - val_mae: 0.8086\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1053 - mae: 0.2176 - val_loss: 1.3706 - val_mae: 0.8057\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1006 - mae: 0.2105 - val_loss: 1.3506 - val_mae: 0.8037\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0965 - mae: 0.2066 - val_loss: 1.3501 - val_mae: 0.8098\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0844 - mae: 0.1974 - val_loss: 1.3637 - val_mae: 0.7964\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0848 - mae: 0.1924 - val_loss: 1.3712 - val_mae: 0.8016\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0795 - mae: 0.1938 - val_loss: 1.3493 - val_mae: 0.8015\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0861 - mae: 0.2009 - val_loss: 1.3453 - val_mae: 0.8022\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0784 - mae: 0.1886 - val_loss: 1.3620 - val_mae: 0.8058\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0734 - mae: 0.1835 - val_loss: 1.3327 - val_mae: 0.7951\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0789 - mae: 0.1817 - val_loss: 1.3499 - val_mae: 0.7923\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0718 - mae: 0.1815 - val_loss: 1.3496 - val_mae: 0.8055\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0782 - mae: 0.1834 - val_loss: 1.3545 - val_mae: 0.7939\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0585 - mae: 0.1679 - val_loss: 1.3275 - val_mae: 0.7897\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0699 - mae: 0.1691 - val_loss: 1.3392 - val_mae: 0.7985\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0614 - mae: 0.1624 - val_loss: 1.3471 - val_mae: 0.7938\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0548 - mae: 0.1549 - val_loss: 1.3513 - val_mae: 0.7991\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0584 - mae: 0.1622 - val_loss: 1.3327 - val_mae: 0.7928\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0522 - mae: 0.1554 - val_loss: 1.3460 - val_mae: 0.7893\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0515 - mae: 0.1558 - val_loss: 1.3561 - val_mae: 0.7908\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0602 - mae: 0.1564 - val_loss: 1.3332 - val_mae: 0.7866\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0502 - mae: 0.1490 - val_loss: 1.3099 - val_mae: 0.7756\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0556 - mae: 0.1524 - val_loss: 1.3439 - val_mae: 0.7995\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0565 - mae: 0.1518 - val_loss: 1.3288 - val_mae: 0.7850\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0533 - mae: 0.1456 - val_loss: 1.3151 - val_mae: 0.7825\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0465 - mae: 0.1417 - val_loss: 1.3418 - val_mae: 0.7886\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0479 - mae: 0.1406 - val_loss: 1.3438 - val_mae: 0.8003\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0513 - mae: 0.1426 - val_loss: 1.3215 - val_mae: 0.7862\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0454 - mae: 0.1368 - val_loss: 1.3433 - val_mae: 0.7854\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0453 - mae: 0.1380 - val_loss: 1.3416 - val_mae: 0.7843\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0437 - mae: 0.1325 - val_loss: 1.3569 - val_mae: 0.7965\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0464 - mae: 0.1375 - val_loss: 1.3369 - val_mae: 0.7874\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0404 - mae: 0.1286 - val_loss: 1.3593 - val_mae: 0.7910\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0385 - mae: 0.1294 - val_loss: 1.3372 - val_mae: 0.7895\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0424 - mae: 0.1334 - val_loss: 1.3616 - val_mae: 0.7937\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0364 - mae: 0.1293 - val_loss: 1.3110 - val_mae: 0.7819\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0385 - mae: 0.1285 - val_loss: 1.3419 - val_mae: 0.7841\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.1255 - val_loss: 1.3403 - val_mae: 0.7871\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0381 - mae: 0.1271 - val_loss: 1.3479 - val_mae: 0.7889\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0406 - mae: 0.1261 - val_loss: 1.3320 - val_mae: 0.7867\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0407 - mae: 0.1283 - val_loss: 1.3459 - val_mae: 0.7856\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0328 - mae: 0.1221 - val_loss: 1.3307 - val_mae: 0.7924\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1205 - val_loss: 1.3510 - val_mae: 0.7880\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.1142 - val_loss: 1.3393 - val_mae: 0.7860\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0351 - mae: 0.1144 - val_loss: 1.3400 - val_mae: 0.7814\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0303 - mae: 0.1088 - val_loss: 1.3441 - val_mae: 0.7861\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0295 - mae: 0.1105 - val_loss: 1.3419 - val_mae: 0.7860\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0307 - mae: 0.1157 - val_loss: 1.3594 - val_mae: 0.7871\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0343 - mae: 0.1152 - val_loss: 1.3321 - val_mae: 0.7772\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0303 - mae: 0.1120 - val_loss: 1.3437 - val_mae: 0.7800\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0307 - mae: 0.1140 - val_loss: 1.3263 - val_mae: 0.7815\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0308 - mae: 0.1128 - val_loss: 1.3600 - val_mae: 0.7775\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0275 - mae: 0.1075 - val_loss: 1.3474 - val_mae: 0.7873\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0270 - mae: 0.1043 - val_loss: 1.3203 - val_mae: 0.7749\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0267 - mae: 0.1047 - val_loss: 1.3276 - val_mae: 0.7799\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0296 - mae: 0.1105 - val_loss: 1.3481 - val_mae: 0.7949\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0254 - mae: 0.1060 - val_loss: 1.3213 - val_mae: 0.7771\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0286 - mae: 0.1036 - val_loss: 1.3329 - val_mae: 0.7832\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0301 - mae: 0.1066 - val_loss: 1.3220 - val_mae: 0.7811\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.1007 - val_loss: 1.3248 - val_mae: 0.7761\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0239 - mae: 0.0964 - val_loss: 1.3478 - val_mae: 0.7876\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0283 - mae: 0.1066 - val_loss: 1.3218 - val_mae: 0.7807\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0288 - mae: 0.1014 - val_loss: 1.3143 - val_mae: 0.7757\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0291 - mae: 0.1043 - val_loss: 1.3119 - val_mae: 0.7801\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0269 - mae: 0.1004 - val_loss: 1.3316 - val_mae: 0.7772\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0236 - mae: 0.0936 - val_loss: 1.3247 - val_mae: 0.7817\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0255 - mae: 0.0955 - val_loss: 1.3375 - val_mae: 0.7779\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0265 - mae: 0.0988 - val_loss: 1.3097 - val_mae: 0.7796\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0241 - mae: 0.0982 - val_loss: 1.3209 - val_mae: 0.7768\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0278 - mae: 0.0993 - val_loss: 1.3302 - val_mae: 0.7830\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0222 - mae: 0.0950 - val_loss: 1.3372 - val_mae: 0.7828\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0259 - mae: 0.0958 - val_loss: 1.3253 - val_mae: 0.7791\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0218 - mae: 0.0924 - val_loss: 1.3257 - val_mae: 0.7801\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0244 - mae: 0.0949 - val_loss: 1.3299 - val_mae: 0.7829\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0207 - mae: 0.0916 - val_loss: 1.3371 - val_mae: 0.7778\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0219 - mae: 0.0913 - val_loss: 1.3170 - val_mae: 0.7800\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0227 - mae: 0.0913 - val_loss: 1.3458 - val_mae: 0.7851\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0204 - mae: 0.0898 - val_loss: 1.3283 - val_mae: 0.7810\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0252 - mae: 0.0933 - val_loss: 1.3278 - val_mae: 0.7867\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0222 - mae: 0.0941 - val_loss: 1.3276 - val_mae: 0.7785\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.0942 - val_loss: 1.3339 - val_mae: 0.7849\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0905 - val_loss: 1.3339 - val_mae: 0.7843\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0222 - mae: 0.0895 - val_loss: 1.3531 - val_mae: 0.7863\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0200 - mae: 0.0873 - val_loss: 1.3209 - val_mae: 0.7830\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0229 - mae: 0.0883 - val_loss: 1.3240 - val_mae: 0.7812\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0186 - mae: 0.0850 - val_loss: 1.3303 - val_mae: 0.7852\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0230 - mae: 0.0901 - val_loss: 1.3531 - val_mae: 0.7852\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0313 - mae: 0.0962 - val_loss: 1.3305 - val_mae: 0.7825\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0214 - mae: 0.0867 - val_loss: 1.3360 - val_mae: 0.7848\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0866 - val_loss: 1.3402 - val_mae: 0.7825\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0859 - val_loss: 1.3381 - val_mae: 0.7812\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0854 - val_loss: 1.3419 - val_mae: 0.7822\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0166 - mae: 0.0822 - val_loss: 1.3205 - val_mae: 0.7801\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0221 - mae: 0.0867 - val_loss: 1.3275 - val_mae: 0.7854\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0182 - mae: 0.0856 - val_loss: 1.3156 - val_mae: 0.7783\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0170 - mae: 0.0805 - val_loss: 1.3413 - val_mae: 0.7850\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0197 - mae: 0.0844 - val_loss: 1.3196 - val_mae: 0.7771\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0186 - mae: 0.0870 - val_loss: 1.3264 - val_mae: 0.7737\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163 - mae: 0.0804 - val_loss: 1.3521 - val_mae: 0.7895\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162 - mae: 0.0815 - val_loss: 1.3283 - val_mae: 0.7775\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0151 - mae: 0.0755 - val_loss: 1.3271 - val_mae: 0.7855\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0807 - val_loss: 1.3433 - val_mae: 0.7811\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0181 - mae: 0.0834 - val_loss: 1.3262 - val_mae: 0.7861\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0227 - mae: 0.0879 - val_loss: 1.3414 - val_mae: 0.7810\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0201 - mae: 0.0808 - val_loss: 1.3235 - val_mae: 0.7814\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0185 - mae: 0.0783 - val_loss: 1.3406 - val_mae: 0.7755\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0202 - mae: 0.0769 - val_loss: 1.3319 - val_mae: 0.7822\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0176 - mae: 0.0824 - val_loss: 1.3478 - val_mae: 0.7805\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0832 - val_loss: 1.3225 - val_mae: 0.7783\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0829 - val_loss: 1.3391 - val_mae: 0.7730\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0761 - val_loss: 1.3251 - val_mae: 0.7801\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0759 - val_loss: 1.3432 - val_mae: 0.7813\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0166 - mae: 0.0767 - val_loss: 1.3337 - val_mae: 0.7808\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0152 - mae: 0.0751 - val_loss: 1.3458 - val_mae: 0.7788\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0179 - mae: 0.0814 - val_loss: 1.3217 - val_mae: 0.7776\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0207 - mae: 0.0760 - val_loss: 1.3280 - val_mae: 0.7832\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0191 - mae: 0.0804 - val_loss: 1.3336 - val_mae: 0.7790\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0214 - mae: 0.0807 - val_loss: 1.3342 - val_mae: 0.7835\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0148 - mae: 0.0734 - val_loss: 1.3333 - val_mae: 0.7816\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0701 - val_loss: 1.3296 - val_mae: 0.7803\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0736 - val_loss: 1.3202 - val_mae: 0.7761\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0148 - mae: 0.0734 - val_loss: 1.3273 - val_mae: 0.7759\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0762 - val_loss: 1.3215 - val_mae: 0.7744\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0768 - val_loss: 1.3506 - val_mae: 0.7784\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0161 - mae: 0.0726 - val_loss: 1.3378 - val_mae: 0.7768\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0729 - val_loss: 1.3387 - val_mae: 0.7784\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0690 - val_loss: 1.3311 - val_mae: 0.7781\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0723 - val_loss: 1.3367 - val_mae: 0.7793\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0744 - val_loss: 1.3335 - val_mae: 0.7821\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0690 - val_loss: 1.3339 - val_mae: 0.7822\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0751 - val_loss: 1.3310 - val_mae: 0.7812\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0166 - mae: 0.0731 - val_loss: 1.3241 - val_mae: 0.7770\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0159 - mae: 0.0717 - val_loss: 1.3348 - val_mae: 0.7810\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0159 - mae: 0.0703 - val_loss: 1.3297 - val_mae: 0.7775\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0729 - val_loss: 1.3423 - val_mae: 0.7810\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0157 - mae: 0.0723 - val_loss: 1.3240 - val_mae: 0.7721\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0685 - val_loss: 1.3428 - val_mae: 0.7835\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0689 - val_loss: 1.3275 - val_mae: 0.7791\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0217 - mae: 0.0715 - val_loss: 1.3301 - val_mae: 0.7772\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0695 - val_loss: 1.3393 - val_mae: 0.7796\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0680 - val_loss: 1.3470 - val_mae: 0.7785\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0218 - mae: 0.0721 - val_loss: 1.3343 - val_mae: 0.7821\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0172 - mae: 0.0727 - val_loss: 1.3204 - val_mae: 0.7749\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0158 - mae: 0.0699 - val_loss: 1.3433 - val_mae: 0.7840\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0156 - mae: 0.0693 - val_loss: 1.3348 - val_mae: 0.7783\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0154 - mae: 0.0662 - val_loss: 1.3311 - val_mae: 0.7754\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0680 - val_loss: 1.3574 - val_mae: 0.7798\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0687 - val_loss: 1.3371 - val_mae: 0.7743\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0148 - mae: 0.0732 - val_loss: 1.3467 - val_mae: 0.7783\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0738 - val_loss: 1.3239 - val_mae: 0.7734\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163 - mae: 0.0660 - val_loss: 1.3337 - val_mae: 0.7820\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0646 - val_loss: 1.3459 - val_mae: 0.7812\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0164 - mae: 0.0644 - val_loss: 1.3328 - val_mae: 0.7777\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0170 - mae: 0.0690 - val_loss: 1.3512 - val_mae: 0.7823\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0661 - val_loss: 1.3324 - val_mae: 0.7717\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0672 - val_loss: 1.3395 - val_mae: 0.7811\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0630 - val_loss: 1.3202 - val_mae: 0.7785\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0646 - val_loss: 1.3348 - val_mae: 0.7752\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0671 - val_loss: 1.3274 - val_mae: 0.7778\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0698 - val_loss: 1.3403 - val_mae: 0.7817\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0181 - mae: 0.0703 - val_loss: 1.3221 - val_mae: 0.7731\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0664 - val_loss: 1.3324 - val_mae: 0.7778\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0620 - val_loss: 1.3452 - val_mae: 0.7793\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0638 - val_loss: 1.3302 - val_mae: 0.7743\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0659 - val_loss: 1.3260 - val_mae: 0.7761\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0651 - val_loss: 1.3292 - val_mae: 0.7771\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0689 - val_loss: 1.3273 - val_mae: 0.7748\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0623 - val_loss: 1.3300 - val_mae: 0.7766\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0613 - val_loss: 1.3427 - val_mae: 0.7781\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0157 - mae: 0.0609 - val_loss: 1.3391 - val_mae: 0.7787\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0644 - val_loss: 1.3380 - val_mae: 0.7788\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0666 - val_loss: 1.3566 - val_mae: 0.7798\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0180 - mae: 0.0704 - val_loss: 1.3176 - val_mae: 0.7717\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0646 - val_loss: 1.3457 - val_mae: 0.7773\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0589 - val_loss: 1.3381 - val_mae: 0.7747\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0564 - val_loss: 1.3411 - val_mae: 0.7775\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0629 - val_loss: 1.3371 - val_mae: 0.7793\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0596 - val_loss: 1.3380 - val_mae: 0.7777\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0638 - val_loss: 1.3459 - val_mae: 0.7782\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0659 - val_loss: 1.3294 - val_mae: 0.7780\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0681 - val_loss: 1.3405 - val_mae: 0.7760\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0144 - mae: 0.0656 - val_loss: 1.3370 - val_mae: 0.7775\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3791 - mae: 0.7631\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3.8414 - mae: 1.4104 - val_loss: 1.7929 - val_mae: 0.9322\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.0556 - mae: 0.7298 - val_loss: 1.5801 - val_mae: 0.8733\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5719 - mae: 0.5353 - val_loss: 1.5304 - val_mae: 0.8731\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3783 - mae: 0.4320 - val_loss: 1.4846 - val_mae: 0.8545\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3092 - mae: 0.3853 - val_loss: 1.5272 - val_mae: 0.8575\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2557 - mae: 0.3467 - val_loss: 1.5106 - val_mae: 0.8430\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1972 - mae: 0.3121 - val_loss: 1.5533 - val_mae: 0.8744\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2086 - mae: 0.3121 - val_loss: 1.4149 - val_mae: 0.8305\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1666 - mae: 0.2844 - val_loss: 1.4988 - val_mae: 0.8353\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1465 - mae: 0.2666 - val_loss: 1.4307 - val_mae: 0.8284\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1564 - mae: 0.2620 - val_loss: 1.4138 - val_mae: 0.8251\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1295 - mae: 0.2506 - val_loss: 1.4326 - val_mae: 0.8321\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1244 - mae: 0.2500 - val_loss: 1.3949 - val_mae: 0.8229\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1361 - mae: 0.2566 - val_loss: 1.4051 - val_mae: 0.8152\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1173 - mae: 0.2365 - val_loss: 1.3881 - val_mae: 0.8031\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1215 - mae: 0.2418 - val_loss: 1.4371 - val_mae: 0.8378\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1098 - mae: 0.2283 - val_loss: 1.3994 - val_mae: 0.8066\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1051 - mae: 0.2300 - val_loss: 1.4314 - val_mae: 0.8114\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1180 - mae: 0.2285 - val_loss: 1.3705 - val_mae: 0.7988\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0841 - mae: 0.2045 - val_loss: 1.3904 - val_mae: 0.8047\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0883 - mae: 0.2049 - val_loss: 1.3707 - val_mae: 0.7971\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0846 - mae: 0.2016 - val_loss: 1.3744 - val_mae: 0.7976\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0935 - mae: 0.2060 - val_loss: 1.3805 - val_mae: 0.8152\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0765 - mae: 0.1911 - val_loss: 1.3546 - val_mae: 0.7981\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0702 - mae: 0.1845 - val_loss: 1.3621 - val_mae: 0.7921\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0708 - mae: 0.1812 - val_loss: 1.3637 - val_mae: 0.7984\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0668 - mae: 0.1806 - val_loss: 1.3748 - val_mae: 0.7986\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0749 - mae: 0.1845 - val_loss: 1.3795 - val_mae: 0.7989\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0636 - mae: 0.1748 - val_loss: 1.3565 - val_mae: 0.7902\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0618 - mae: 0.1714 - val_loss: 1.4122 - val_mae: 0.8161\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0610 - mae: 0.1689 - val_loss: 1.3931 - val_mae: 0.8018\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0554 - mae: 0.1651 - val_loss: 1.4043 - val_mae: 0.8082\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0595 - mae: 0.1662 - val_loss: 1.3977 - val_mae: 0.7996\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0538 - mae: 0.1583 - val_loss: 1.3673 - val_mae: 0.7976\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0490 - mae: 0.1540 - val_loss: 1.4083 - val_mae: 0.8010\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0492 - mae: 0.1546 - val_loss: 1.3770 - val_mae: 0.8080\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0520 - mae: 0.1521 - val_loss: 1.3510 - val_mae: 0.7937\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0524 - mae: 0.1583 - val_loss: 1.3737 - val_mae: 0.7933\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0485 - mae: 0.1562 - val_loss: 1.3581 - val_mae: 0.7985\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0434 - mae: 0.1453 - val_loss: 1.3553 - val_mae: 0.7826\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0420 - mae: 0.1408 - val_loss: 1.3627 - val_mae: 0.7876\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0433 - mae: 0.1425 - val_loss: 1.3690 - val_mae: 0.7901\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0458 - mae: 0.1468 - val_loss: 1.4077 - val_mae: 0.7961\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0451 - mae: 0.1458 - val_loss: 1.3669 - val_mae: 0.7881\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0393 - mae: 0.1360 - val_loss: 1.4054 - val_mae: 0.8019\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0417 - mae: 0.1392 - val_loss: 1.3413 - val_mae: 0.7904\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0364 - mae: 0.1316 - val_loss: 1.3891 - val_mae: 0.7960\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.1257 - val_loss: 1.3690 - val_mae: 0.7924\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0335 - mae: 0.1250 - val_loss: 1.3617 - val_mae: 0.7832\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1282 - val_loss: 1.3500 - val_mae: 0.7834\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0343 - mae: 0.1251 - val_loss: 1.3559 - val_mae: 0.7844\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0342 - mae: 0.1257 - val_loss: 1.3767 - val_mae: 0.7883\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0318 - mae: 0.1225 - val_loss: 1.3461 - val_mae: 0.7844\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0326 - mae: 0.1238 - val_loss: 1.3620 - val_mae: 0.7906\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0309 - mae: 0.1227 - val_loss: 1.3618 - val_mae: 0.7865\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0353 - mae: 0.1259 - val_loss: 1.3834 - val_mae: 0.8010\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1256 - val_loss: 1.3609 - val_mae: 0.7884\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0269 - mae: 0.1146 - val_loss: 1.3779 - val_mae: 0.7882\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0285 - mae: 0.1164 - val_loss: 1.3481 - val_mae: 0.7822\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0298 - mae: 0.1177 - val_loss: 1.3494 - val_mae: 0.7854\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0273 - mae: 0.1158 - val_loss: 1.3541 - val_mae: 0.7802\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0284 - mae: 0.1148 - val_loss: 1.3851 - val_mae: 0.7852\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0269 - mae: 0.1121 - val_loss: 1.3496 - val_mae: 0.7836\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0278 - mae: 0.1154 - val_loss: 1.3605 - val_mae: 0.7844\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0266 - mae: 0.1105 - val_loss: 1.3703 - val_mae: 0.7856\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0247 - mae: 0.1069 - val_loss: 1.3514 - val_mae: 0.7850\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.1032 - val_loss: 1.3711 - val_mae: 0.7919\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0261 - mae: 0.1076 - val_loss: 1.3728 - val_mae: 0.7891\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0251 - mae: 0.1113 - val_loss: 1.3540 - val_mae: 0.7819\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0233 - mae: 0.1027 - val_loss: 1.3671 - val_mae: 0.7838\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0247 - mae: 0.1062 - val_loss: 1.3653 - val_mae: 0.7857\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0223 - mae: 0.1017 - val_loss: 1.3485 - val_mae: 0.7853\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.1009 - val_loss: 1.3610 - val_mae: 0.7879\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0249 - mae: 0.1053 - val_loss: 1.3807 - val_mae: 0.7890\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.1025 - val_loss: 1.3545 - val_mae: 0.7867\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0219 - mae: 0.0975 - val_loss: 1.3525 - val_mae: 0.7830\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0975 - val_loss: 1.3790 - val_mae: 0.7870\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0212 - mae: 0.0987 - val_loss: 1.3778 - val_mae: 0.7931\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0233 - mae: 0.1039 - val_loss: 1.3829 - val_mae: 0.7842\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0202 - mae: 0.0978 - val_loss: 1.3609 - val_mae: 0.7803\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.1008 - val_loss: 1.3744 - val_mae: 0.7868\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0951 - val_loss: 1.3634 - val_mae: 0.7823\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0211 - mae: 0.0960 - val_loss: 1.3786 - val_mae: 0.7845\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0206 - mae: 0.0948 - val_loss: 1.3784 - val_mae: 0.7879\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0915 - val_loss: 1.3905 - val_mae: 0.7830\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0922 - val_loss: 1.3710 - val_mae: 0.7897\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184 - mae: 0.0935 - val_loss: 1.3694 - val_mae: 0.7867\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0928 - val_loss: 1.3833 - val_mae: 0.7867\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0176 - mae: 0.0919 - val_loss: 1.3667 - val_mae: 0.7819\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0916 - val_loss: 1.3811 - val_mae: 0.7849\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0169 - mae: 0.0858 - val_loss: 1.3448 - val_mae: 0.7783\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0910 - val_loss: 1.3730 - val_mae: 0.7854\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0202 - mae: 0.0939 - val_loss: 1.3668 - val_mae: 0.7851\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0869 - val_loss: 1.3549 - val_mae: 0.7815\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0885 - val_loss: 1.3600 - val_mae: 0.7798\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.0882 - val_loss: 1.3905 - val_mae: 0.7891\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0899 - val_loss: 1.3531 - val_mae: 0.7822\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0859 - val_loss: 1.3529 - val_mae: 0.7822\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0857 - val_loss: 1.3568 - val_mae: 0.7825\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0146 - mae: 0.0831 - val_loss: 1.3619 - val_mae: 0.7835\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0152 - mae: 0.0841 - val_loss: 1.3536 - val_mae: 0.7799\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0154 - mae: 0.0851 - val_loss: 1.3598 - val_mae: 0.7784\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0153 - mae: 0.0839 - val_loss: 1.3815 - val_mae: 0.7843\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0784 - val_loss: 1.3588 - val_mae: 0.7821\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0810 - val_loss: 1.3814 - val_mae: 0.7856\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0159 - mae: 0.0813 - val_loss: 1.3636 - val_mae: 0.7834\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178 - mae: 0.0888 - val_loss: 1.3788 - val_mae: 0.7844\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0152 - mae: 0.0814 - val_loss: 1.3624 - val_mae: 0.7832\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0798 - val_loss: 1.3671 - val_mae: 0.7839\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0812 - val_loss: 1.3649 - val_mae: 0.7860\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162 - mae: 0.0831 - val_loss: 1.3629 - val_mae: 0.7860\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0809 - val_loss: 1.3806 - val_mae: 0.7862\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0808 - val_loss: 1.3808 - val_mae: 0.7878\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0805 - val_loss: 1.3780 - val_mae: 0.7878\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0139 - mae: 0.0767 - val_loss: 1.3625 - val_mae: 0.7824\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0739 - val_loss: 1.3686 - val_mae: 0.7825\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0116 - mae: 0.0732 - val_loss: 1.3666 - val_mae: 0.7863\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0777 - val_loss: 1.3748 - val_mae: 0.7827\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0150 - mae: 0.0812 - val_loss: 1.3651 - val_mae: 0.7802\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0797 - val_loss: 1.3841 - val_mae: 0.7863\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0138 - mae: 0.0768 - val_loss: 1.3736 - val_mae: 0.7818\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0123 - mae: 0.0735 - val_loss: 1.3829 - val_mae: 0.7853\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0766 - val_loss: 1.3784 - val_mae: 0.7813\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0754 - val_loss: 1.3793 - val_mae: 0.7840\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0726 - val_loss: 1.3829 - val_mae: 0.7822\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0746 - val_loss: 1.3636 - val_mae: 0.7848\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0771 - val_loss: 1.3837 - val_mae: 0.7819\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0822 - val_loss: 1.3709 - val_mae: 0.7835\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0776 - val_loss: 1.3689 - val_mae: 0.7858\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0721 - val_loss: 1.3786 - val_mae: 0.7821\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0717 - val_loss: 1.3668 - val_mae: 0.7833\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0700 - val_loss: 1.3752 - val_mae: 0.7813\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0689 - val_loss: 1.3758 - val_mae: 0.7826\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0681 - val_loss: 1.3669 - val_mae: 0.7807\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0745 - val_loss: 1.3823 - val_mae: 0.7835\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0760 - val_loss: 1.3787 - val_mae: 0.7818\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0745 - val_loss: 1.3742 - val_mae: 0.7826\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0709 - val_loss: 1.3668 - val_mae: 0.7879\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0113 - mae: 0.0698 - val_loss: 1.3741 - val_mae: 0.7820\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0754 - val_loss: 1.3827 - val_mae: 0.7851\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0743 - val_loss: 1.3661 - val_mae: 0.7843\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0692 - val_loss: 1.3870 - val_mae: 0.7861\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0109 - mae: 0.0708 - val_loss: 1.3636 - val_mae: 0.7779\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0666 - val_loss: 1.3616 - val_mae: 0.7780\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0692 - val_loss: 1.3617 - val_mae: 0.7787\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0697 - val_loss: 1.3545 - val_mae: 0.7781\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0693 - val_loss: 1.3718 - val_mae: 0.7820\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0706 - val_loss: 1.3858 - val_mae: 0.7885\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0673 - val_loss: 1.3723 - val_mae: 0.7823\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0686 - val_loss: 1.3679 - val_mae: 0.7821\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0111 - mae: 0.0687 - val_loss: 1.3821 - val_mae: 0.7847\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0668 - val_loss: 1.3716 - val_mae: 0.7844\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0694 - val_loss: 1.3816 - val_mae: 0.7825\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0698 - val_loss: 1.3665 - val_mae: 0.7817\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0104 - mae: 0.0675 - val_loss: 1.3828 - val_mae: 0.7820\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0106 - mae: 0.0692 - val_loss: 1.3732 - val_mae: 0.7788\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0649 - val_loss: 1.3789 - val_mae: 0.7823\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0659 - val_loss: 1.3721 - val_mae: 0.7824\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0705 - val_loss: 1.3888 - val_mae: 0.7851\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0648 - val_loss: 1.3680 - val_mae: 0.7807\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0631 - val_loss: 1.3737 - val_mae: 0.7842\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0675 - val_loss: 1.3728 - val_mae: 0.7800\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0675 - val_loss: 1.3929 - val_mae: 0.7879\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0691 - val_loss: 1.3665 - val_mae: 0.7813\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0671 - val_loss: 1.3862 - val_mae: 0.7850\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0644 - val_loss: 1.3678 - val_mae: 0.7818\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0605 - val_loss: 1.3705 - val_mae: 0.7819\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0611 - val_loss: 1.3884 - val_mae: 0.7829\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0634 - val_loss: 1.3832 - val_mae: 0.7814\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0660 - val_loss: 1.3876 - val_mae: 0.7853\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0681 - val_loss: 1.3732 - val_mae: 0.7815\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0651 - val_loss: 1.3724 - val_mae: 0.7798\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0620 - val_loss: 1.3757 - val_mae: 0.7829\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0651 - val_loss: 1.3845 - val_mae: 0.7867\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0614 - val_loss: 1.3668 - val_mae: 0.7780\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - mae: 0.0597 - val_loss: 1.3771 - val_mae: 0.7804\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0619 - val_loss: 1.3676 - val_mae: 0.7803\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0075 - mae: 0.0584 - val_loss: 1.3718 - val_mae: 0.7814\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0616 - val_loss: 1.3660 - val_mae: 0.7795\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0630 - val_loss: 1.4002 - val_mae: 0.7933\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0660 - val_loss: 1.3660 - val_mae: 0.7801\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0632 - val_loss: 1.3687 - val_mae: 0.7821\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0636 - val_loss: 1.3870 - val_mae: 0.7845\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0634 - val_loss: 1.3791 - val_mae: 0.7816\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0625 - val_loss: 1.3743 - val_mae: 0.7834\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0604 - val_loss: 1.3692 - val_mae: 0.7797\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - mae: 0.0597 - val_loss: 1.3765 - val_mae: 0.7811\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0623 - val_loss: 1.3625 - val_mae: 0.7756\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0609 - val_loss: 1.3738 - val_mae: 0.7827\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0607 - val_loss: 1.3658 - val_mae: 0.7805\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0075 - mae: 0.0585 - val_loss: 1.3790 - val_mae: 0.7801\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0089 - mae: 0.0597 - val_loss: 1.3709 - val_mae: 0.7820\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0612 - val_loss: 1.3754 - val_mae: 0.7801\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0642 - val_loss: 1.3715 - val_mae: 0.7813\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0085 - mae: 0.0607 - val_loss: 1.3664 - val_mae: 0.7796\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0079 - mae: 0.0585 - val_loss: 1.3722 - val_mae: 0.7829\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0087 - mae: 0.0604 - val_loss: 1.3768 - val_mae: 0.7822\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0079 - mae: 0.0588 - val_loss: 1.3857 - val_mae: 0.7814\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0074 - mae: 0.0586 - val_loss: 1.3645 - val_mae: 0.7775\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0595 - val_loss: 1.3614 - val_mae: 0.7775\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3487 - mae: 0.7678\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 3.8301 - mae: 1.3981 - val_loss: 1.5791 - val_mae: 0.8754\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.9783 - mae: 0.6993 - val_loss: 1.4639 - val_mae: 0.8492\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.6435 - mae: 0.5542 - val_loss: 1.3802 - val_mae: 0.8238\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4581 - mae: 0.4695 - val_loss: 1.3857 - val_mae: 0.8406\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.3643 - mae: 0.4133 - val_loss: 1.3538 - val_mae: 0.8125\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2986 - mae: 0.3669 - val_loss: 1.3196 - val_mae: 0.7958\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2428 - mae: 0.3352 - val_loss: 1.3808 - val_mae: 0.8316\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2132 - mae: 0.3124 - val_loss: 1.3232 - val_mae: 0.7787\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1829 - mae: 0.2932 - val_loss: 1.3522 - val_mae: 0.7918\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1952 - mae: 0.2925 - val_loss: 1.2768 - val_mae: 0.7709\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1783 - mae: 0.2868 - val_loss: 1.2859 - val_mae: 0.7758\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1690 - mae: 0.2817 - val_loss: 1.3505 - val_mae: 0.7827\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1466 - mae: 0.2622 - val_loss: 1.3083 - val_mae: 0.7786\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1307 - mae: 0.2428 - val_loss: 1.3248 - val_mae: 0.7782\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1328 - mae: 0.2429 - val_loss: 1.3135 - val_mae: 0.7737\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1311 - mae: 0.2461 - val_loss: 1.3106 - val_mae: 0.7681\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1237 - mae: 0.2360 - val_loss: 1.2966 - val_mae: 0.7681\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1200 - mae: 0.2344 - val_loss: 1.3126 - val_mae: 0.7798\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1034 - mae: 0.2207 - val_loss: 1.2494 - val_mae: 0.7530\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1029 - mae: 0.2152 - val_loss: 1.3208 - val_mae: 0.7754\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1098 - mae: 0.2230 - val_loss: 1.2989 - val_mae: 0.7644\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1054 - mae: 0.2169 - val_loss: 1.3138 - val_mae: 0.7751\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0955 - mae: 0.2041 - val_loss: 1.2853 - val_mae: 0.7539\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0793 - mae: 0.1898 - val_loss: 1.3009 - val_mae: 0.7579\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0908 - mae: 0.1983 - val_loss: 1.2944 - val_mae: 0.7578\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0846 - mae: 0.1947 - val_loss: 1.2643 - val_mae: 0.7524\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0791 - mae: 0.1927 - val_loss: 1.3641 - val_mae: 0.7799\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0864 - mae: 0.1947 - val_loss: 1.2932 - val_mae: 0.7536\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0869 - mae: 0.1922 - val_loss: 1.2875 - val_mae: 0.7572\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0705 - mae: 0.1722 - val_loss: 1.3265 - val_mae: 0.7584\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0772 - mae: 0.1774 - val_loss: 1.2997 - val_mae: 0.7615\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0747 - mae: 0.1777 - val_loss: 1.2887 - val_mae: 0.7552\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0660 - mae: 0.1680 - val_loss: 1.3002 - val_mae: 0.7581\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0646 - mae: 0.1682 - val_loss: 1.2888 - val_mae: 0.7534\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0660 - mae: 0.1671 - val_loss: 1.2693 - val_mae: 0.7545\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0645 - mae: 0.1647 - val_loss: 1.3041 - val_mae: 0.7699\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0653 - mae: 0.1661 - val_loss: 1.3043 - val_mae: 0.7547\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0670 - mae: 0.1598 - val_loss: 1.2854 - val_mae: 0.7570\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0604 - mae: 0.1563 - val_loss: 1.2706 - val_mae: 0.7466\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0580 - mae: 0.1577 - val_loss: 1.2944 - val_mae: 0.7613\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0602 - mae: 0.1515 - val_loss: 1.2687 - val_mae: 0.7531\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0559 - mae: 0.1504 - val_loss: 1.2798 - val_mae: 0.7568\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0549 - mae: 0.1476 - val_loss: 1.2819 - val_mae: 0.7529\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0567 - mae: 0.1446 - val_loss: 1.2661 - val_mae: 0.7540\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0475 - mae: 0.1404 - val_loss: 1.2675 - val_mae: 0.7455\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0568 - mae: 0.1426 - val_loss: 1.2697 - val_mae: 0.7469\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0459 - mae: 0.1360 - val_loss: 1.2892 - val_mae: 0.7558\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0491 - mae: 0.1373 - val_loss: 1.2698 - val_mae: 0.7439\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0518 - mae: 0.1420 - val_loss: 1.2925 - val_mae: 0.7618\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0540 - mae: 0.1395 - val_loss: 1.2717 - val_mae: 0.7462\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0475 - mae: 0.1369 - val_loss: 1.2900 - val_mae: 0.7562\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0491 - mae: 0.1383 - val_loss: 1.2862 - val_mae: 0.7479\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1298 - val_loss: 1.2975 - val_mae: 0.7582\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0460 - mae: 0.1277 - val_loss: 1.2962 - val_mae: 0.7545\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1262 - val_loss: 1.2917 - val_mae: 0.7540\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0460 - mae: 0.1323 - val_loss: 1.2676 - val_mae: 0.7488\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0414 - mae: 0.1276 - val_loss: 1.2916 - val_mae: 0.7524\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0427 - mae: 0.1260 - val_loss: 1.2988 - val_mae: 0.7510\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0463 - mae: 0.1269 - val_loss: 1.3064 - val_mae: 0.7516\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0431 - mae: 0.1261 - val_loss: 1.2786 - val_mae: 0.7506\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0399 - mae: 0.1186 - val_loss: 1.2502 - val_mae: 0.7403\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0475 - mae: 0.1257 - val_loss: 1.2953 - val_mae: 0.7569\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1227 - val_loss: 1.2977 - val_mae: 0.7515\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0365 - mae: 0.1171 - val_loss: 1.2883 - val_mae: 0.7491\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0389 - mae: 0.1207 - val_loss: 1.2786 - val_mae: 0.7441\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0360 - mae: 0.1177 - val_loss: 1.3148 - val_mae: 0.7590\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0361 - mae: 0.1154 - val_loss: 1.2860 - val_mae: 0.7549\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0457 - mae: 0.1249 - val_loss: 1.3041 - val_mae: 0.7508\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0374 - mae: 0.1182 - val_loss: 1.3078 - val_mae: 0.7571\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0297 - mae: 0.1092 - val_loss: 1.2643 - val_mae: 0.7397\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0351 - mae: 0.1115 - val_loss: 1.3145 - val_mae: 0.7508\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0358 - mae: 0.1093 - val_loss: 1.2876 - val_mae: 0.7498\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0319 - mae: 0.1070 - val_loss: 1.3175 - val_mae: 0.7502\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0328 - mae: 0.1084 - val_loss: 1.3034 - val_mae: 0.7520\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0356 - mae: 0.1091 - val_loss: 1.2782 - val_mae: 0.7466\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0316 - mae: 0.1071 - val_loss: 1.3144 - val_mae: 0.7499\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0355 - mae: 0.1142 - val_loss: 1.3213 - val_mae: 0.7503\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0416 - mae: 0.1143 - val_loss: 1.2774 - val_mae: 0.7485\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0291 - mae: 0.1041 - val_loss: 1.3125 - val_mae: 0.7485\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0316 - mae: 0.1035 - val_loss: 1.3035 - val_mae: 0.7488\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0304 - mae: 0.1039 - val_loss: 1.2858 - val_mae: 0.7441\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0327 - mae: 0.1073 - val_loss: 1.2872 - val_mae: 0.7524\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0333 - mae: 0.1079 - val_loss: 1.3104 - val_mae: 0.7481\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0315 - mae: 0.1054 - val_loss: 1.3053 - val_mae: 0.7495\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0314 - mae: 0.1050 - val_loss: 1.3161 - val_mae: 0.7527\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0331 - mae: 0.1058 - val_loss: 1.2977 - val_mae: 0.7465\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0273 - mae: 0.0988 - val_loss: 1.2969 - val_mae: 0.7534\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0276 - mae: 0.1012 - val_loss: 1.3044 - val_mae: 0.7477\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0350 - mae: 0.1050 - val_loss: 1.3063 - val_mae: 0.7463\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0302 - mae: 0.0998 - val_loss: 1.2892 - val_mae: 0.7484\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0330 - mae: 0.0988 - val_loss: 1.3727 - val_mae: 0.7577\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0353 - mae: 0.1046 - val_loss: 1.2919 - val_mae: 0.7503\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0294 - mae: 0.0979 - val_loss: 1.3076 - val_mae: 0.7448\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0286 - mae: 0.0987 - val_loss: 1.3042 - val_mae: 0.7481\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0318 - mae: 0.0994 - val_loss: 1.3131 - val_mae: 0.7546\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0281 - mae: 0.0937 - val_loss: 1.3034 - val_mae: 0.7520\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0298 - mae: 0.0993 - val_loss: 1.2857 - val_mae: 0.7429\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0280 - mae: 0.0946 - val_loss: 1.3008 - val_mae: 0.7481\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0313 - mae: 0.1005 - val_loss: 1.2999 - val_mae: 0.7525\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0261 - mae: 0.0955 - val_loss: 1.2876 - val_mae: 0.7448\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0293 - mae: 0.0988 - val_loss: 1.3048 - val_mae: 0.7556\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0298 - mae: 0.0995 - val_loss: 1.3140 - val_mae: 0.7460\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0258 - mae: 0.0914 - val_loss: 1.3526 - val_mae: 0.7511\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0307 - mae: 0.0969 - val_loss: 1.2890 - val_mae: 0.7450\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0290 - mae: 0.0938 - val_loss: 1.3015 - val_mae: 0.7457\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0277 - mae: 0.0875 - val_loss: 1.3059 - val_mae: 0.7528\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0277 - mae: 0.0907 - val_loss: 1.2976 - val_mae: 0.7470\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0285 - mae: 0.0919 - val_loss: 1.2866 - val_mae: 0.7485\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0280 - mae: 0.0928 - val_loss: 1.3107 - val_mae: 0.7485\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0275 - mae: 0.0899 - val_loss: 1.2870 - val_mae: 0.7491\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0269 - mae: 0.0861 - val_loss: 1.2933 - val_mae: 0.7436\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0265 - mae: 0.0877 - val_loss: 1.2855 - val_mae: 0.7473\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0280 - mae: 0.0931 - val_loss: 1.3471 - val_mae: 0.7476\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0283 - mae: 0.0922 - val_loss: 1.2830 - val_mae: 0.7450\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0288 - mae: 0.0911 - val_loss: 1.3245 - val_mae: 0.7502\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0256 - mae: 0.0882 - val_loss: 1.2755 - val_mae: 0.7448\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0247 - mae: 0.0904 - val_loss: 1.3037 - val_mae: 0.7475\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0280 - mae: 0.0903 - val_loss: 1.2789 - val_mae: 0.7413\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0243 - mae: 0.0864 - val_loss: 1.3138 - val_mae: 0.7470\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0269 - mae: 0.0853 - val_loss: 1.2881 - val_mae: 0.7436\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0275 - mae: 0.0868 - val_loss: 1.3179 - val_mae: 0.7537\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0282 - mae: 0.0889 - val_loss: 1.2996 - val_mae: 0.7460\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0257 - mae: 0.0847 - val_loss: 1.2785 - val_mae: 0.7412\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0307 - mae: 0.0860 - val_loss: 1.3160 - val_mae: 0.7482\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0235 - mae: 0.0810 - val_loss: 1.2763 - val_mae: 0.7408\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0265 - mae: 0.0892 - val_loss: 1.3038 - val_mae: 0.7504\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0274 - mae: 0.0839 - val_loss: 1.2946 - val_mae: 0.7457\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0251 - mae: 0.0860 - val_loss: 1.3217 - val_mae: 0.7520\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0262 - mae: 0.0859 - val_loss: 1.2832 - val_mae: 0.7414\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0210 - mae: 0.0795 - val_loss: 1.3474 - val_mae: 0.7550\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0225 - mae: 0.0836 - val_loss: 1.3440 - val_mae: 0.7519\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0256 - mae: 0.0812 - val_loss: 1.2948 - val_mae: 0.7450\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.0844 - val_loss: 1.3329 - val_mae: 0.7529\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0225 - mae: 0.0841 - val_loss: 1.2929 - val_mae: 0.7474\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0257 - mae: 0.0810 - val_loss: 1.3034 - val_mae: 0.7470\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0210 - mae: 0.0801 - val_loss: 1.2796 - val_mae: 0.7420\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0238 - mae: 0.0828 - val_loss: 1.3516 - val_mae: 0.7569\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0215 - mae: 0.0796 - val_loss: 1.2862 - val_mae: 0.7474\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0246 - mae: 0.0825 - val_loss: 1.3318 - val_mae: 0.7518\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0234 - mae: 0.0800 - val_loss: 1.2871 - val_mae: 0.7456\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0324 - mae: 0.0817 - val_loss: 1.3049 - val_mae: 0.7469\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.0799 - val_loss: 1.3046 - val_mae: 0.7469\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0221 - mae: 0.0792 - val_loss: 1.3141 - val_mae: 0.7493\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0238 - mae: 0.0808 - val_loss: 1.2864 - val_mae: 0.7447\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0246 - mae: 0.0808 - val_loss: 1.3298 - val_mae: 0.7502\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0241 - mae: 0.0812 - val_loss: 1.2868 - val_mae: 0.7427\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0236 - mae: 0.0786 - val_loss: 1.2945 - val_mae: 0.7460\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0243 - mae: 0.0762 - val_loss: 1.3314 - val_mae: 0.7498\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0211 - mae: 0.0778 - val_loss: 1.2921 - val_mae: 0.7480\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0200 - mae: 0.0773 - val_loss: 1.3511 - val_mae: 0.7490\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0224 - mae: 0.0802 - val_loss: 1.3250 - val_mae: 0.7464\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0259 - mae: 0.0850 - val_loss: 1.2938 - val_mae: 0.7471\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0236 - mae: 0.0791 - val_loss: 1.3418 - val_mae: 0.7490\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0262 - mae: 0.0811 - val_loss: 1.2784 - val_mae: 0.7448\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0273 - mae: 0.0808 - val_loss: 1.3170 - val_mae: 0.7502\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0212 - mae: 0.0775 - val_loss: 1.2959 - val_mae: 0.7444\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0223 - mae: 0.0761 - val_loss: 1.2952 - val_mae: 0.7425\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0246 - mae: 0.0744 - val_loss: 1.2986 - val_mae: 0.7475\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0225 - mae: 0.0747 - val_loss: 1.2852 - val_mae: 0.7391\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0233 - mae: 0.0797 - val_loss: 1.3036 - val_mae: 0.7430\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0203 - mae: 0.0766 - val_loss: 1.2771 - val_mae: 0.7415\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0236 - mae: 0.0753 - val_loss: 1.2975 - val_mae: 0.7400\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0196 - mae: 0.0771 - val_loss: 1.3178 - val_mae: 0.7491\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0260 - mae: 0.0802 - val_loss: 1.2995 - val_mae: 0.7463\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0276 - mae: 0.0817 - val_loss: 1.3016 - val_mae: 0.7417\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0212 - mae: 0.0737 - val_loss: 1.2958 - val_mae: 0.7427\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0205 - mae: 0.0720 - val_loss: 1.3101 - val_mae: 0.7439\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0276 - mae: 0.0800 - val_loss: 1.2830 - val_mae: 0.7413\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0241 - mae: 0.0758 - val_loss: 1.3561 - val_mae: 0.7531\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0223 - mae: 0.0788 - val_loss: 1.2845 - val_mae: 0.7436\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0203 - mae: 0.0757 - val_loss: 1.3269 - val_mae: 0.7489\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0198 - mae: 0.0721 - val_loss: 1.2892 - val_mae: 0.7464\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0165 - mae: 0.0690 - val_loss: 1.3393 - val_mae: 0.7509\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0219 - mae: 0.0759 - val_loss: 1.3052 - val_mae: 0.7469\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0212 - mae: 0.0760 - val_loss: 1.2873 - val_mae: 0.7418\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0196 - mae: 0.0713 - val_loss: 1.3170 - val_mae: 0.7491\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0240 - mae: 0.0737 - val_loss: 1.3009 - val_mae: 0.7458\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0228 - mae: 0.0725 - val_loss: 1.2815 - val_mae: 0.7427\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0232 - mae: 0.0727 - val_loss: 1.3407 - val_mae: 0.7508\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0221 - mae: 0.0766 - val_loss: 1.2862 - val_mae: 0.7412\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0204 - mae: 0.0716 - val_loss: 1.3016 - val_mae: 0.7544\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0240 - mae: 0.0759 - val_loss: 1.2992 - val_mae: 0.7472\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0234 - mae: 0.0732 - val_loss: 1.3118 - val_mae: 0.7463\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0202 - mae: 0.0736 - val_loss: 1.2971 - val_mae: 0.7468\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0253 - mae: 0.0694 - val_loss: 1.3133 - val_mae: 0.7486\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0220 - mae: 0.0728 - val_loss: 1.2901 - val_mae: 0.7442\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0210 - mae: 0.0722 - val_loss: 1.2804 - val_mae: 0.7403\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0212 - mae: 0.0708 - val_loss: 1.3091 - val_mae: 0.7485\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0231 - mae: 0.0706 - val_loss: 1.2758 - val_mae: 0.7402\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0171 - mae: 0.0668 - val_loss: 1.3264 - val_mae: 0.7463\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0229 - mae: 0.0750 - val_loss: 1.2765 - val_mae: 0.7421\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0203 - mae: 0.0707 - val_loss: 1.3213 - val_mae: 0.7492\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0205 - mae: 0.0718 - val_loss: 1.2851 - val_mae: 0.7449\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0217 - mae: 0.0672 - val_loss: 1.2971 - val_mae: 0.7427\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0205 - mae: 0.0708 - val_loss: 1.2747 - val_mae: 0.7427\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0178 - mae: 0.0710 - val_loss: 1.3081 - val_mae: 0.7429\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0203 - mae: 0.0715 - val_loss: 1.2897 - val_mae: 0.7429\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0181 - mae: 0.0684 - val_loss: 1.2876 - val_mae: 0.7508\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0257 - mae: 0.0818 - val_loss: 1.3154 - val_mae: 0.7475\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0229 - mae: 0.0721 - val_loss: 1.2859 - val_mae: 0.7440\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3274 - mae: 0.7540\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 3.6293 - mae: 1.3821 - val_loss: 1.6468 - val_mae: 0.9084\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.9494 - mae: 0.6844 - val_loss: 1.5527 - val_mae: 0.8819\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5785 - mae: 0.5224 - val_loss: 1.4787 - val_mae: 0.8551\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.4038 - mae: 0.4376 - val_loss: 1.4081 - val_mae: 0.8412\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.3085 - mae: 0.3845 - val_loss: 1.4957 - val_mae: 0.8583\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2332 - mae: 0.3362 - val_loss: 1.4090 - val_mae: 0.8300\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2038 - mae: 0.3113 - val_loss: 1.4760 - val_mae: 0.8421\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1963 - mae: 0.2951 - val_loss: 1.4553 - val_mae: 0.8360\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1795 - mae: 0.2861 - val_loss: 1.4539 - val_mae: 0.8261\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1688 - mae: 0.2802 - val_loss: 1.4350 - val_mae: 0.8238\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1579 - mae: 0.2665 - val_loss: 1.3986 - val_mae: 0.8124\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1587 - mae: 0.2686 - val_loss: 1.4634 - val_mae: 0.8178\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1420 - mae: 0.2549 - val_loss: 1.4263 - val_mae: 0.8239\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1213 - mae: 0.2393 - val_loss: 1.4983 - val_mae: 0.8315\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1225 - mae: 0.2340 - val_loss: 1.4007 - val_mae: 0.8104\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1114 - mae: 0.2297 - val_loss: 1.4235 - val_mae: 0.8270\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1223 - mae: 0.2325 - val_loss: 1.3753 - val_mae: 0.7979\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1103 - mae: 0.2211 - val_loss: 1.3559 - val_mae: 0.7917\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1013 - mae: 0.2137 - val_loss: 1.3735 - val_mae: 0.7978\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0981 - mae: 0.2078 - val_loss: 1.4134 - val_mae: 0.8091\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0911 - mae: 0.2058 - val_loss: 1.3764 - val_mae: 0.8033\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0881 - mae: 0.2039 - val_loss: 1.3656 - val_mae: 0.7918\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0897 - mae: 0.1976 - val_loss: 1.3899 - val_mae: 0.7965\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0802 - mae: 0.1895 - val_loss: 1.4019 - val_mae: 0.8035\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0801 - mae: 0.1837 - val_loss: 1.3543 - val_mae: 0.8010\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0748 - mae: 0.1823 - val_loss: 1.3842 - val_mae: 0.8015\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0777 - mae: 0.1845 - val_loss: 1.3727 - val_mae: 0.7958\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0800 - mae: 0.1842 - val_loss: 1.3678 - val_mae: 0.7929\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0590 - mae: 0.1641 - val_loss: 1.3631 - val_mae: 0.7957\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0641 - mae: 0.1679 - val_loss: 1.3836 - val_mae: 0.7945\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0590 - mae: 0.1631 - val_loss: 1.4293 - val_mae: 0.8006\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0682 - mae: 0.1727 - val_loss: 1.3630 - val_mae: 0.7944\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0641 - mae: 0.1654 - val_loss: 1.3986 - val_mae: 0.8037\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0558 - mae: 0.1530 - val_loss: 1.3786 - val_mae: 0.7955\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0546 - mae: 0.1529 - val_loss: 1.3596 - val_mae: 0.7922\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0553 - mae: 0.1541 - val_loss: 1.3539 - val_mae: 0.7860\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0527 - mae: 0.1511 - val_loss: 1.3826 - val_mae: 0.7969\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0498 - mae: 0.1443 - val_loss: 1.3703 - val_mae: 0.7925\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0539 - mae: 0.1472 - val_loss: 1.4001 - val_mae: 0.7964\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0529 - mae: 0.1457 - val_loss: 1.3806 - val_mae: 0.7893\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0517 - mae: 0.1447 - val_loss: 1.3663 - val_mae: 0.7866\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0498 - mae: 0.1416 - val_loss: 1.3785 - val_mae: 0.7849\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0474 - mae: 0.1384 - val_loss: 1.3449 - val_mae: 0.7824\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0452 - mae: 0.1365 - val_loss: 1.3705 - val_mae: 0.7891\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0388 - mae: 0.1296 - val_loss: 1.3883 - val_mae: 0.7873\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0558 - mae: 0.1402 - val_loss: 1.3609 - val_mae: 0.7887\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0429 - mae: 0.1306 - val_loss: 1.3683 - val_mae: 0.7847\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0383 - mae: 0.1265 - val_loss: 1.3666 - val_mae: 0.7837\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.1284 - val_loss: 1.3825 - val_mae: 0.7911\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0385 - mae: 0.1312 - val_loss: 1.3534 - val_mae: 0.7846\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0395 - mae: 0.1268 - val_loss: 1.3811 - val_mae: 0.7831\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0374 - mae: 0.1255 - val_loss: 1.3737 - val_mae: 0.7848\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0401 - mae: 0.1298 - val_loss: 1.3868 - val_mae: 0.7852\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0350 - mae: 0.1235 - val_loss: 1.4004 - val_mae: 0.8014\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0360 - mae: 0.1235 - val_loss: 1.3836 - val_mae: 0.7888\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0334 - mae: 0.1164 - val_loss: 1.3600 - val_mae: 0.7808\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0372 - mae: 0.1203 - val_loss: 1.4023 - val_mae: 0.7874\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0328 - mae: 0.1107 - val_loss: 1.3754 - val_mae: 0.7934\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0303 - mae: 0.1129 - val_loss: 1.3736 - val_mae: 0.7874\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0299 - mae: 0.1151 - val_loss: 1.3520 - val_mae: 0.7794\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0369 - mae: 0.1181 - val_loss: 1.3670 - val_mae: 0.7842\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0316 - mae: 0.1120 - val_loss: 1.3833 - val_mae: 0.7883\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0340 - mae: 0.1127 - val_loss: 1.3741 - val_mae: 0.7878\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0319 - mae: 0.1120 - val_loss: 1.3923 - val_mae: 0.7849\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0325 - mae: 0.1116 - val_loss: 1.3512 - val_mae: 0.7789\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0277 - mae: 0.1046 - val_loss: 1.3485 - val_mae: 0.7771\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0312 - mae: 0.1113 - val_loss: 1.3565 - val_mae: 0.7796\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0294 - mae: 0.1091 - val_loss: 1.3942 - val_mae: 0.7909\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0250 - mae: 0.1043 - val_loss: 1.3521 - val_mae: 0.7807\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0266 - mae: 0.1024 - val_loss: 1.3651 - val_mae: 0.7798\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0289 - mae: 0.1043 - val_loss: 1.3498 - val_mae: 0.7780\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0280 - mae: 0.1041 - val_loss: 1.3641 - val_mae: 0.7871\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0260 - mae: 0.1028 - val_loss: 1.3659 - val_mae: 0.7763\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0292 - mae: 0.1049 - val_loss: 1.3670 - val_mae: 0.7846\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0252 - mae: 0.0994 - val_loss: 1.3550 - val_mae: 0.7802\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0283 - mae: 0.1018 - val_loss: 1.3591 - val_mae: 0.7784\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0286 - mae: 0.1008 - val_loss: 1.3350 - val_mae: 0.7712\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0259 - mae: 0.0967 - val_loss: 1.3539 - val_mae: 0.7795\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0276 - mae: 0.0997 - val_loss: 1.3486 - val_mae: 0.7763\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0277 - mae: 0.0995 - val_loss: 1.3737 - val_mae: 0.7835\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0231 - mae: 0.0953 - val_loss: 1.3492 - val_mae: 0.7753\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0242 - mae: 0.0985 - val_loss: 1.3527 - val_mae: 0.7786\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0278 - mae: 0.0991 - val_loss: 1.3409 - val_mae: 0.7770\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0247 - mae: 0.0952 - val_loss: 1.3765 - val_mae: 0.7868\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0251 - mae: 0.0957 - val_loss: 1.3530 - val_mae: 0.7770\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0238 - mae: 0.0907 - val_loss: 1.3543 - val_mae: 0.7766\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0235 - mae: 0.0978 - val_loss: 1.3552 - val_mae: 0.7764\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0226 - mae: 0.0915 - val_loss: 1.3890 - val_mae: 0.7823\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0239 - mae: 0.0927 - val_loss: 1.3541 - val_mae: 0.7764\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0267 - mae: 0.0911 - val_loss: 1.3548 - val_mae: 0.7789\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0198 - mae: 0.0882 - val_loss: 1.3571 - val_mae: 0.7752\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0232 - mae: 0.0933 - val_loss: 1.3792 - val_mae: 0.7824\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0216 - mae: 0.0907 - val_loss: 1.3555 - val_mae: 0.7798\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0246 - mae: 0.0907 - val_loss: 1.3689 - val_mae: 0.7812\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0240 - mae: 0.0872 - val_loss: 1.3613 - val_mae: 0.7788\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0237 - mae: 0.0896 - val_loss: 1.3554 - val_mae: 0.7781\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0196 - mae: 0.0856 - val_loss: 1.3563 - val_mae: 0.7760\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0191 - mae: 0.0857 - val_loss: 1.3407 - val_mae: 0.7763\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0219 - mae: 0.0877 - val_loss: 1.3605 - val_mae: 0.7784\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0180 - mae: 0.0850 - val_loss: 1.3749 - val_mae: 0.7792\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0193 - mae: 0.0857 - val_loss: 1.3425 - val_mae: 0.7716\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0185 - mae: 0.0835 - val_loss: 1.3770 - val_mae: 0.7793\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0240 - mae: 0.0928 - val_loss: 1.3554 - val_mae: 0.7770\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0175 - mae: 0.0809 - val_loss: 1.3760 - val_mae: 0.7830\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0176 - mae: 0.0814 - val_loss: 1.3453 - val_mae: 0.7716\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0182 - mae: 0.0824 - val_loss: 1.3486 - val_mae: 0.7721\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.0818 - val_loss: 1.3657 - val_mae: 0.7776\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0217 - mae: 0.0849 - val_loss: 1.3473 - val_mae: 0.7721\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0187 - mae: 0.0812 - val_loss: 1.3739 - val_mae: 0.7830\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0184 - mae: 0.0817 - val_loss: 1.3550 - val_mae: 0.7807\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0195 - mae: 0.0824 - val_loss: 1.4103 - val_mae: 0.7812\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0206 - mae: 0.0863 - val_loss: 1.3502 - val_mae: 0.7785\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0198 - mae: 0.0800 - val_loss: 1.3683 - val_mae: 0.7772\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0199 - mae: 0.0805 - val_loss: 1.3880 - val_mae: 0.7824\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0167 - mae: 0.0763 - val_loss: 1.3706 - val_mae: 0.7785\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0145 - mae: 0.0762 - val_loss: 1.3684 - val_mae: 0.7757\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0156 - mae: 0.0755 - val_loss: 1.3564 - val_mae: 0.7758\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0146 - mae: 0.0744 - val_loss: 1.3595 - val_mae: 0.7747\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0155 - mae: 0.0763 - val_loss: 1.3694 - val_mae: 0.7831\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0200 - mae: 0.0789 - val_loss: 1.3691 - val_mae: 0.7758\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0182 - mae: 0.0775 - val_loss: 1.3836 - val_mae: 0.7804\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0177 - mae: 0.0752 - val_loss: 1.3632 - val_mae: 0.7799\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0154 - mae: 0.0768 - val_loss: 1.3800 - val_mae: 0.7802\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0152 - mae: 0.0750 - val_loss: 1.3773 - val_mae: 0.7788\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0172 - mae: 0.0749 - val_loss: 1.3386 - val_mae: 0.7704\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0161 - mae: 0.0740 - val_loss: 1.3575 - val_mae: 0.7753\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0162 - mae: 0.0749 - val_loss: 1.3588 - val_mae: 0.7726\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0155 - mae: 0.0732 - val_loss: 1.3528 - val_mae: 0.7739\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0160 - mae: 0.0751 - val_loss: 1.3709 - val_mae: 0.7773\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0163 - mae: 0.0738 - val_loss: 1.3584 - val_mae: 0.7738\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0692 - val_loss: 1.3715 - val_mae: 0.7804\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0130 - mae: 0.0702 - val_loss: 1.3595 - val_mae: 0.7762\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0145 - mae: 0.0697 - val_loss: 1.3565 - val_mae: 0.7716\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0705 - val_loss: 1.3840 - val_mae: 0.7810\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0169 - mae: 0.0732 - val_loss: 1.4022 - val_mae: 0.7820\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0202 - mae: 0.0765 - val_loss: 1.3649 - val_mae: 0.7757\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0172 - mae: 0.0714 - val_loss: 1.3737 - val_mae: 0.7767\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0138 - mae: 0.0675 - val_loss: 1.3567 - val_mae: 0.7725\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0169 - mae: 0.0684 - val_loss: 1.3707 - val_mae: 0.7766\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0137 - mae: 0.0645 - val_loss: 1.3588 - val_mae: 0.7774\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0201 - mae: 0.0773 - val_loss: 1.3785 - val_mae: 0.7784\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0140 - mae: 0.0720 - val_loss: 1.3571 - val_mae: 0.7740\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0160 - mae: 0.0731 - val_loss: 1.3705 - val_mae: 0.7780\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0153 - mae: 0.0669 - val_loss: 1.3823 - val_mae: 0.7787\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0673 - val_loss: 1.3624 - val_mae: 0.7730\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0129 - mae: 0.0695 - val_loss: 1.3695 - val_mae: 0.7762\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0162 - mae: 0.0710 - val_loss: 1.3749 - val_mae: 0.7785\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0153 - mae: 0.0735 - val_loss: 1.3631 - val_mae: 0.7731\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0142 - mae: 0.0708 - val_loss: 1.3672 - val_mae: 0.7803\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0117 - mae: 0.0651 - val_loss: 1.3737 - val_mae: 0.7760\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0180 - mae: 0.0712 - val_loss: 1.3560 - val_mae: 0.7780\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0111 - mae: 0.0644 - val_loss: 1.4037 - val_mae: 0.7809\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0165 - mae: 0.0661 - val_loss: 1.3551 - val_mae: 0.7767\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0157 - mae: 0.0670 - val_loss: 1.3799 - val_mae: 0.7742\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0159 - mae: 0.0702 - val_loss: 1.3657 - val_mae: 0.7777\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0142 - mae: 0.0692 - val_loss: 1.3703 - val_mae: 0.7757\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0657 - val_loss: 1.3600 - val_mae: 0.7771\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0157 - mae: 0.0643 - val_loss: 1.3735 - val_mae: 0.7769\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0137 - mae: 0.0644 - val_loss: 1.3621 - val_mae: 0.7766\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0163 - mae: 0.0641 - val_loss: 1.3675 - val_mae: 0.7771\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0136 - mae: 0.0679 - val_loss: 1.3740 - val_mae: 0.7800\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0131 - mae: 0.0638 - val_loss: 1.3563 - val_mae: 0.7769\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0115 - mae: 0.0626 - val_loss: 1.3867 - val_mae: 0.7796\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0144 - mae: 0.0642 - val_loss: 1.3622 - val_mae: 0.7780\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0151 - mae: 0.0677 - val_loss: 1.3928 - val_mae: 0.7811\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0148 - mae: 0.0679 - val_loss: 1.3498 - val_mae: 0.7738\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0613 - val_loss: 1.3565 - val_mae: 0.7763\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0135 - mae: 0.0606 - val_loss: 1.3775 - val_mae: 0.7796\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0112 - mae: 0.0598 - val_loss: 1.3703 - val_mae: 0.7774\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0150 - mae: 0.0660 - val_loss: 1.3663 - val_mae: 0.7784\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0117 - mae: 0.0616 - val_loss: 1.3797 - val_mae: 0.7778\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0141 - mae: 0.0627 - val_loss: 1.3679 - val_mae: 0.7764\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0608 - val_loss: 1.3867 - val_mae: 0.7794\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0136 - mae: 0.0638 - val_loss: 1.3505 - val_mae: 0.7737\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0168 - mae: 0.0660 - val_loss: 1.3613 - val_mae: 0.7756\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0118 - mae: 0.0628 - val_loss: 1.3813 - val_mae: 0.7787\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0130 - mae: 0.0621 - val_loss: 1.3669 - val_mae: 0.7761\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0133 - mae: 0.0620 - val_loss: 1.3677 - val_mae: 0.7748\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0103 - mae: 0.0585 - val_loss: 1.3707 - val_mae: 0.7773\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0210 - mae: 0.0622 - val_loss: 1.3838 - val_mae: 0.7759\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0117 - mae: 0.0621 - val_loss: 1.3605 - val_mae: 0.7761\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0115 - mae: 0.0583 - val_loss: 1.3692 - val_mae: 0.7763\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0100 - mae: 0.0589 - val_loss: 1.3716 - val_mae: 0.7781\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0104 - mae: 0.0598 - val_loss: 1.3739 - val_mae: 0.7774\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0594 - val_loss: 1.3740 - val_mae: 0.7765\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0629 - val_loss: 1.4023 - val_mae: 0.7832\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0107 - mae: 0.0597 - val_loss: 1.3949 - val_mae: 0.7788\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0602 - val_loss: 1.3595 - val_mae: 0.7786\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0154 - mae: 0.0615 - val_loss: 1.3790 - val_mae: 0.7769\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0175 - mae: 0.0600 - val_loss: 1.3530 - val_mae: 0.7743\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0113 - mae: 0.0576 - val_loss: 1.3763 - val_mae: 0.7771\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0116 - mae: 0.0570 - val_loss: 1.3535 - val_mae: 0.7768\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0117 - mae: 0.0584 - val_loss: 1.3759 - val_mae: 0.7763\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0144 - mae: 0.0609 - val_loss: 1.3645 - val_mae: 0.7781\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0138 - mae: 0.0610 - val_loss: 1.3807 - val_mae: 0.7763\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0121 - mae: 0.0582 - val_loss: 1.3682 - val_mae: 0.7758\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0120 - mae: 0.0590 - val_loss: 1.3723 - val_mae: 0.7762\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0559 - val_loss: 1.3708 - val_mae: 0.7800\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0142 - mae: 0.0622 - val_loss: 1.3752 - val_mae: 0.7762\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0096 - mae: 0.0581 - val_loss: 1.3531 - val_mae: 0.7716\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3684 - mae: 0.7700\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 3.8606 - mae: 1.4346 - val_loss: 1.7779 - val_mae: 0.9339\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.9198 - mae: 0.6790 - val_loss: 1.5701 - val_mae: 0.8990\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.5320 - mae: 0.5104 - val_loss: 1.5638 - val_mae: 0.8945\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.3924 - mae: 0.4303 - val_loss: 1.5319 - val_mae: 0.8857\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2783 - mae: 0.3652 - val_loss: 1.6518 - val_mae: 0.8752\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2418 - mae: 0.3373 - val_loss: 1.5566 - val_mae: 0.8891\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.2004 - mae: 0.3041 - val_loss: 1.5246 - val_mae: 0.8662\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1661 - mae: 0.2817 - val_loss: 1.4768 - val_mae: 0.8602\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1715 - mae: 0.2863 - val_loss: 1.4777 - val_mae: 0.8515\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1589 - mae: 0.2810 - val_loss: 1.4902 - val_mae: 0.8552\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1570 - mae: 0.2697 - val_loss: 1.4447 - val_mae: 0.8420\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1305 - mae: 0.2539 - val_loss: 1.4360 - val_mae: 0.8421\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1334 - mae: 0.2529 - val_loss: 1.4194 - val_mae: 0.8322\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1277 - mae: 0.2451 - val_loss: 1.4378 - val_mae: 0.8402\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1193 - mae: 0.2379 - val_loss: 1.4650 - val_mae: 0.8278\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1055 - mae: 0.2193 - val_loss: 1.4489 - val_mae: 0.8315\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0943 - mae: 0.2130 - val_loss: 1.4376 - val_mae: 0.8339\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.1045 - mae: 0.2237 - val_loss: 1.4335 - val_mae: 0.8197\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0877 - mae: 0.2049 - val_loss: 1.4392 - val_mae: 0.8322\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0844 - mae: 0.2026 - val_loss: 1.4199 - val_mae: 0.8174\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0886 - mae: 0.2012 - val_loss: 1.3859 - val_mae: 0.8086\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0840 - mae: 0.2024 - val_loss: 1.4207 - val_mae: 0.8188\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0802 - mae: 0.1917 - val_loss: 1.4491 - val_mae: 0.8247\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0859 - mae: 0.1989 - val_loss: 1.3667 - val_mae: 0.8067\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0727 - mae: 0.1852 - val_loss: 1.4443 - val_mae: 0.8221\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0668 - mae: 0.1776 - val_loss: 1.3874 - val_mae: 0.8098\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0605 - mae: 0.1686 - val_loss: 1.3807 - val_mae: 0.8088\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0706 - mae: 0.1729 - val_loss: 1.3923 - val_mae: 0.8098\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0583 - mae: 0.1656 - val_loss: 1.3728 - val_mae: 0.8049\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0544 - mae: 0.1611 - val_loss: 1.4347 - val_mae: 0.8226\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0609 - mae: 0.1653 - val_loss: 1.3629 - val_mae: 0.7995\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0541 - mae: 0.1583 - val_loss: 1.3704 - val_mae: 0.8039\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0510 - mae: 0.1559 - val_loss: 1.3754 - val_mae: 0.8020\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0503 - mae: 0.1576 - val_loss: 1.3989 - val_mae: 0.8030\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0520 - mae: 0.1516 - val_loss: 1.3433 - val_mae: 0.7925\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0448 - mae: 0.1453 - val_loss: 1.3966 - val_mae: 0.8131\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0490 - mae: 0.1483 - val_loss: 1.3667 - val_mae: 0.7961\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0422 - mae: 0.1422 - val_loss: 1.3620 - val_mae: 0.7996\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0428 - mae: 0.1391 - val_loss: 1.3664 - val_mae: 0.7952\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0436 - mae: 0.1387 - val_loss: 1.3785 - val_mae: 0.7966\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0412 - mae: 0.1391 - val_loss: 1.3839 - val_mae: 0.8112\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0385 - mae: 0.1357 - val_loss: 1.3831 - val_mae: 0.8019\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0409 - mae: 0.1389 - val_loss: 1.3906 - val_mae: 0.8047\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0392 - mae: 0.1356 - val_loss: 1.3813 - val_mae: 0.7975\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0362 - mae: 0.1306 - val_loss: 1.3605 - val_mae: 0.7919\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0339 - mae: 0.1236 - val_loss: 1.3568 - val_mae: 0.7928\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0309 - mae: 0.1186 - val_loss: 1.3521 - val_mae: 0.7928\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0326 - mae: 0.1236 - val_loss: 1.3837 - val_mae: 0.7988\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0329 - mae: 0.1226 - val_loss: 1.3757 - val_mae: 0.7938\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0392 - mae: 0.1283 - val_loss: 1.3607 - val_mae: 0.7974\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0326 - mae: 0.1244 - val_loss: 1.3474 - val_mae: 0.7931\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0307 - mae: 0.1177 - val_loss: 1.3756 - val_mae: 0.7953\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0316 - mae: 0.1199 - val_loss: 1.3524 - val_mae: 0.7910\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0281 - mae: 0.1123 - val_loss: 1.3686 - val_mae: 0.7986\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0275 - mae: 0.1136 - val_loss: 1.3645 - val_mae: 0.7952\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0282 - mae: 0.1157 - val_loss: 1.3600 - val_mae: 0.7922\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0259 - mae: 0.1103 - val_loss: 1.3512 - val_mae: 0.7924\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0286 - mae: 0.1138 - val_loss: 1.3836 - val_mae: 0.8030\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0272 - mae: 0.1107 - val_loss: 1.3584 - val_mae: 0.7875\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0326 - mae: 0.1201 - val_loss: 1.3819 - val_mae: 0.7986\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0279 - mae: 0.1119 - val_loss: 1.3633 - val_mae: 0.7942\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0252 - mae: 0.1057 - val_loss: 1.3621 - val_mae: 0.7916\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0224 - mae: 0.1030 - val_loss: 1.3552 - val_mae: 0.7969\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0234 - mae: 0.1026 - val_loss: 1.3575 - val_mae: 0.7938\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0240 - mae: 0.1026 - val_loss: 1.3535 - val_mae: 0.7907\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0242 - mae: 0.1023 - val_loss: 1.3477 - val_mae: 0.7924\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0275 - mae: 0.1080 - val_loss: 1.3534 - val_mae: 0.7936\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0239 - mae: 0.1016 - val_loss: 1.3627 - val_mae: 0.7946\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0237 - mae: 0.1046 - val_loss: 1.3462 - val_mae: 0.7908\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0211 - mae: 0.0982 - val_loss: 1.3298 - val_mae: 0.7832\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0209 - mae: 0.0963 - val_loss: 1.3384 - val_mae: 0.7876\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0204 - mae: 0.0946 - val_loss: 1.3492 - val_mae: 0.7932\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0217 - mae: 0.0994 - val_loss: 1.3560 - val_mae: 0.7926\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0232 - mae: 0.1033 - val_loss: 1.3312 - val_mae: 0.7840\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0241 - mae: 0.1008 - val_loss: 1.3584 - val_mae: 0.7917\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.0988 - val_loss: 1.3414 - val_mae: 0.7815\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0200 - mae: 0.0939 - val_loss: 1.3485 - val_mae: 0.7869\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0195 - mae: 0.0906 - val_loss: 1.3581 - val_mae: 0.7906\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0191 - mae: 0.0903 - val_loss: 1.3410 - val_mae: 0.7834\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0206 - mae: 0.0939 - val_loss: 1.3482 - val_mae: 0.7839\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0194 - mae: 0.0939 - val_loss: 1.3368 - val_mae: 0.7849\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0210 - mae: 0.0953 - val_loss: 1.3641 - val_mae: 0.7942\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0188 - mae: 0.0928 - val_loss: 1.3343 - val_mae: 0.7831\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0177 - mae: 0.0878 - val_loss: 1.3425 - val_mae: 0.7856\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0175 - mae: 0.0888 - val_loss: 1.3454 - val_mae: 0.7838\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0176 - mae: 0.0859 - val_loss: 1.3376 - val_mae: 0.7868\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0180 - mae: 0.0887 - val_loss: 1.3536 - val_mae: 0.7869\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0860 - val_loss: 1.3445 - val_mae: 0.7878\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0175 - mae: 0.0872 - val_loss: 1.3388 - val_mae: 0.7790\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0180 - mae: 0.0875 - val_loss: 1.3411 - val_mae: 0.7898\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0181 - mae: 0.0892 - val_loss: 1.3396 - val_mae: 0.7851\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0164 - mae: 0.0851 - val_loss: 1.3335 - val_mae: 0.7812\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0191 - mae: 0.0911 - val_loss: 1.3429 - val_mae: 0.7834\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0145 - mae: 0.0795 - val_loss: 1.3454 - val_mae: 0.7842\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0151 - mae: 0.0811 - val_loss: 1.3392 - val_mae: 0.7832\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0147 - mae: 0.0793 - val_loss: 1.3404 - val_mae: 0.7832\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0145 - mae: 0.0807 - val_loss: 1.3570 - val_mae: 0.7895\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0155 - mae: 0.0810 - val_loss: 1.3469 - val_mae: 0.7873\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0170 - mae: 0.0846 - val_loss: 1.3383 - val_mae: 0.7837\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0143 - mae: 0.0810 - val_loss: 1.3440 - val_mae: 0.7806\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0172 - mae: 0.0859 - val_loss: 1.3397 - val_mae: 0.7852\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.0821 - val_loss: 1.3545 - val_mae: 0.7853\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0149 - mae: 0.0806 - val_loss: 1.3249 - val_mae: 0.7796\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0135 - mae: 0.0761 - val_loss: 1.3550 - val_mae: 0.7884\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0139 - mae: 0.0798 - val_loss: 1.3353 - val_mae: 0.7822\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0153 - mae: 0.0797 - val_loss: 1.3375 - val_mae: 0.7820\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0769 - val_loss: 1.3333 - val_mae: 0.7802\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0762 - val_loss: 1.3494 - val_mae: 0.7865\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0157 - mae: 0.0809 - val_loss: 1.3464 - val_mae: 0.7840\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0131 - mae: 0.0757 - val_loss: 1.3469 - val_mae: 0.7831\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0131 - mae: 0.0724 - val_loss: 1.3512 - val_mae: 0.7799\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0146 - mae: 0.0781 - val_loss: 1.3365 - val_mae: 0.7822\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0121 - mae: 0.0733 - val_loss: 1.3354 - val_mae: 0.7834\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0743 - val_loss: 1.3418 - val_mae: 0.7807\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0132 - mae: 0.0751 - val_loss: 1.3426 - val_mae: 0.7818\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0153 - mae: 0.0814 - val_loss: 1.3332 - val_mae: 0.7790\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0135 - mae: 0.0756 - val_loss: 1.3577 - val_mae: 0.7841\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0139 - mae: 0.0746 - val_loss: 1.3414 - val_mae: 0.7828\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0118 - mae: 0.0715 - val_loss: 1.3442 - val_mae: 0.7848\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0111 - mae: 0.0697 - val_loss: 1.3489 - val_mae: 0.7831\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0110 - mae: 0.0691 - val_loss: 1.3517 - val_mae: 0.7838\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0733 - val_loss: 1.3509 - val_mae: 0.7825\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0699 - val_loss: 1.3508 - val_mae: 0.7839\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0105 - mae: 0.0677 - val_loss: 1.3479 - val_mae: 0.7829\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0739 - val_loss: 1.3468 - val_mae: 0.7834\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0115 - mae: 0.0712 - val_loss: 1.3426 - val_mae: 0.7800\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0118 - mae: 0.0724 - val_loss: 1.3482 - val_mae: 0.7855\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0723 - val_loss: 1.3346 - val_mae: 0.7829\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0121 - mae: 0.0699 - val_loss: 1.3582 - val_mae: 0.7851\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0112 - mae: 0.0682 - val_loss: 1.3449 - val_mae: 0.7836\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0721 - val_loss: 1.3492 - val_mae: 0.7870\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0116 - mae: 0.0706 - val_loss: 1.3279 - val_mae: 0.7812\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0682 - val_loss: 1.3498 - val_mae: 0.7855\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0116 - mae: 0.0698 - val_loss: 1.3343 - val_mae: 0.7790\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0106 - mae: 0.0681 - val_loss: 1.3450 - val_mae: 0.7863\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0119 - mae: 0.0709 - val_loss: 1.3494 - val_mae: 0.7832\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0092 - mae: 0.0633 - val_loss: 1.3551 - val_mae: 0.7859\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0138 - mae: 0.0753 - val_loss: 1.3449 - val_mae: 0.7841\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0687 - val_loss: 1.3520 - val_mae: 0.7829\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0108 - mae: 0.0657 - val_loss: 1.3533 - val_mae: 0.7856\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0635 - val_loss: 1.3356 - val_mae: 0.7801\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0098 - mae: 0.0646 - val_loss: 1.3535 - val_mae: 0.7849\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0088 - mae: 0.0631 - val_loss: 1.3328 - val_mae: 0.7790\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0099 - mae: 0.0651 - val_loss: 1.3565 - val_mae: 0.7872\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0102 - mae: 0.0639 - val_loss: 1.3449 - val_mae: 0.7815\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0104 - mae: 0.0668 - val_loss: 1.3495 - val_mae: 0.7879\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0710 - val_loss: 1.3468 - val_mae: 0.7813\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0639 - val_loss: 1.3450 - val_mae: 0.7836\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0088 - mae: 0.0626 - val_loss: 1.3690 - val_mae: 0.7901\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0115 - mae: 0.0669 - val_loss: 1.3440 - val_mae: 0.7844\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0104 - mae: 0.0646 - val_loss: 1.3511 - val_mae: 0.7850\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0102 - mae: 0.0642 - val_loss: 1.3578 - val_mae: 0.7868\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0107 - mae: 0.0655 - val_loss: 1.3569 - val_mae: 0.7873\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0594 - val_loss: 1.3612 - val_mae: 0.7915\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0107 - mae: 0.0644 - val_loss: 1.3425 - val_mae: 0.7853\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0085 - mae: 0.0612 - val_loss: 1.3574 - val_mae: 0.7880\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0095 - mae: 0.0639 - val_loss: 1.3453 - val_mae: 0.7855\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0094 - mae: 0.0641 - val_loss: 1.3551 - val_mae: 0.7850\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0097 - mae: 0.0645 - val_loss: 1.3423 - val_mae: 0.7833\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0097 - mae: 0.0632 - val_loss: 1.3446 - val_mae: 0.7860\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0099 - mae: 0.0648 - val_loss: 1.3494 - val_mae: 0.7855\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0084 - mae: 0.0610 - val_loss: 1.3545 - val_mae: 0.7860\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0083 - mae: 0.0604 - val_loss: 1.3615 - val_mae: 0.7860\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0609 - val_loss: 1.3444 - val_mae: 0.7876\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0624 - val_loss: 1.3552 - val_mae: 0.7829\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0096 - mae: 0.0609 - val_loss: 1.3449 - val_mae: 0.7848\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0077 - mae: 0.0581 - val_loss: 1.3591 - val_mae: 0.7886\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0078 - mae: 0.0583 - val_loss: 1.3546 - val_mae: 0.7897\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0090 - mae: 0.0603 - val_loss: 1.3578 - val_mae: 0.7868\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0602 - val_loss: 1.3521 - val_mae: 0.7867\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0090 - mae: 0.0627 - val_loss: 1.3560 - val_mae: 0.7845\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.0578 - val_loss: 1.3455 - val_mae: 0.7853\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.0550 - val_loss: 1.3569 - val_mae: 0.7847\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0081 - mae: 0.0585 - val_loss: 1.3415 - val_mae: 0.7865\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0078 - mae: 0.0571 - val_loss: 1.3617 - val_mae: 0.7863\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0087 - mae: 0.0602 - val_loss: 1.3457 - val_mae: 0.7845\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0077 - mae: 0.0584 - val_loss: 1.3653 - val_mae: 0.7925\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0095 - mae: 0.0627 - val_loss: 1.3474 - val_mae: 0.7868\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0077 - mae: 0.0582 - val_loss: 1.3522 - val_mae: 0.7831\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0071 - mae: 0.0558 - val_loss: 1.3615 - val_mae: 0.7900\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0069 - mae: 0.0545 - val_loss: 1.3541 - val_mae: 0.7855\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0071 - mae: 0.0541 - val_loss: 1.3518 - val_mae: 0.7879\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0584 - val_loss: 1.3652 - val_mae: 0.7870\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0089 - mae: 0.0602 - val_loss: 1.3503 - val_mae: 0.7853\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.0571 - val_loss: 1.3521 - val_mae: 0.7842\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0070 - mae: 0.0556 - val_loss: 1.3624 - val_mae: 0.7891\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0073 - mae: 0.0556 - val_loss: 1.3529 - val_mae: 0.7888\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0074 - mae: 0.0562 - val_loss: 1.3718 - val_mae: 0.7902\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0067 - mae: 0.0541 - val_loss: 1.3590 - val_mae: 0.7873\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0070 - mae: 0.0550 - val_loss: 1.3627 - val_mae: 0.7892\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0081 - mae: 0.0599 - val_loss: 1.3443 - val_mae: 0.7837\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0071 - mae: 0.0545 - val_loss: 1.3572 - val_mae: 0.7877\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0537 - val_loss: 1.3616 - val_mae: 0.7864\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0076 - mae: 0.0558 - val_loss: 1.3549 - val_mae: 0.7870\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0063 - mae: 0.0519 - val_loss: 1.3616 - val_mae: 0.7884\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0534 - val_loss: 1.3526 - val_mae: 0.7867\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0075 - mae: 0.0550 - val_loss: 1.3634 - val_mae: 0.7887\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0087 - mae: 0.0574 - val_loss: 1.3541 - val_mae: 0.7848\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0077 - mae: 0.0546 - val_loss: 1.3473 - val_mae: 0.7833\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0073 - mae: 0.0559 - val_loss: 1.3570 - val_mae: 0.7870\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3633 - mae: 0.7700\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 3.7627 - mae: 1.4100 - val_loss: 1.6451 - val_mae: 0.9106\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 1.0008 - mae: 0.6976 - val_loss: 1.4965 - val_mae: 0.8525\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.6338 - mae: 0.5478 - val_loss: 1.4717 - val_mae: 0.8547\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.4617 - mae: 0.4704 - val_loss: 1.4490 - val_mae: 0.8485\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.3618 - mae: 0.4160 - val_loss: 1.3701 - val_mae: 0.8123\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.2818 - mae: 0.3643 - val_loss: 1.4004 - val_mae: 0.8117\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2668 - mae: 0.3495 - val_loss: 1.3612 - val_mae: 0.8041\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.2226 - mae: 0.3270 - val_loss: 1.3579 - val_mae: 0.8010\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.2073 - mae: 0.3087 - val_loss: 1.3504 - val_mae: 0.7961\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1791 - mae: 0.2935 - val_loss: 1.4051 - val_mae: 0.8182\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1841 - mae: 0.2898 - val_loss: 1.3928 - val_mae: 0.8043\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1559 - mae: 0.2740 - val_loss: 1.3387 - val_mae: 0.7902\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1690 - mae: 0.2668 - val_loss: 1.3482 - val_mae: 0.7855\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1388 - mae: 0.2580 - val_loss: 1.3556 - val_mae: 0.7913\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1510 - mae: 0.2589 - val_loss: 1.3844 - val_mae: 0.7898\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1496 - mae: 0.2477 - val_loss: 1.3427 - val_mae: 0.7801\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1202 - mae: 0.2296 - val_loss: 1.3220 - val_mae: 0.7835\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1173 - mae: 0.2270 - val_loss: 1.3268 - val_mae: 0.7711\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1185 - mae: 0.2286 - val_loss: 1.3439 - val_mae: 0.7870\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0973 - mae: 0.2128 - val_loss: 1.3745 - val_mae: 0.7838\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1084 - mae: 0.2123 - val_loss: 1.2694 - val_mae: 0.7605\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1002 - mae: 0.2049 - val_loss: 1.3376 - val_mae: 0.7852\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1013 - mae: 0.2077 - val_loss: 1.3054 - val_mae: 0.7634\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0870 - mae: 0.1988 - val_loss: 1.3026 - val_mae: 0.7611\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0839 - mae: 0.1972 - val_loss: 1.3708 - val_mae: 0.7816\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1014 - mae: 0.2028 - val_loss: 1.3103 - val_mae: 0.7608\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0849 - mae: 0.1843 - val_loss: 1.3031 - val_mae: 0.7634\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0968 - mae: 0.1814 - val_loss: 1.3114 - val_mae: 0.7586\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0801 - mae: 0.1791 - val_loss: 1.3139 - val_mae: 0.7611\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0729 - mae: 0.1788 - val_loss: 1.2803 - val_mae: 0.7562\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0731 - mae: 0.1772 - val_loss: 1.3313 - val_mae: 0.7641\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0751 - mae: 0.1731 - val_loss: 1.3082 - val_mae: 0.7599\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0695 - mae: 0.1708 - val_loss: 1.2731 - val_mae: 0.7506\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0717 - mae: 0.1674 - val_loss: 1.2902 - val_mae: 0.7561\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0715 - mae: 0.1671 - val_loss: 1.2854 - val_mae: 0.7562\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0598 - mae: 0.1575 - val_loss: 1.3039 - val_mae: 0.7591\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0596 - mae: 0.1558 - val_loss: 1.2999 - val_mae: 0.7559\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0598 - mae: 0.1534 - val_loss: 1.3122 - val_mae: 0.7562\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0624 - mae: 0.1602 - val_loss: 1.2839 - val_mae: 0.7503\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0586 - mae: 0.1541 - val_loss: 1.2956 - val_mae: 0.7491\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0550 - mae: 0.1506 - val_loss: 1.3058 - val_mae: 0.7553\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0632 - mae: 0.1554 - val_loss: 1.2827 - val_mae: 0.7523\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0581 - mae: 0.1507 - val_loss: 1.2967 - val_mae: 0.7531\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0549 - mae: 0.1436 - val_loss: 1.3125 - val_mae: 0.7590\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0473 - mae: 0.1368 - val_loss: 1.3115 - val_mae: 0.7627\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0483 - mae: 0.1379 - val_loss: 1.3040 - val_mae: 0.7514\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0521 - mae: 0.1388 - val_loss: 1.3041 - val_mae: 0.7536\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0516 - mae: 0.1374 - val_loss: 1.2944 - val_mae: 0.7568\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0510 - mae: 0.1390 - val_loss: 1.2998 - val_mae: 0.7537\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0538 - mae: 0.1371 - val_loss: 1.2926 - val_mae: 0.7493\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0499 - mae: 0.1329 - val_loss: 1.2903 - val_mae: 0.7571\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0466 - mae: 0.1317 - val_loss: 1.2847 - val_mae: 0.7460\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0477 - mae: 0.1321 - val_loss: 1.2803 - val_mae: 0.7546\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0448 - mae: 0.1317 - val_loss: 1.3155 - val_mae: 0.7561\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0453 - mae: 0.1295 - val_loss: 1.2973 - val_mae: 0.7496\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0437 - mae: 0.1312 - val_loss: 1.2735 - val_mae: 0.7460\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0478 - mae: 0.1269 - val_loss: 1.2971 - val_mae: 0.7580\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0404 - mae: 0.1205 - val_loss: 1.2833 - val_mae: 0.7488\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0402 - mae: 0.1219 - val_loss: 1.3142 - val_mae: 0.7571\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0404 - mae: 0.1230 - val_loss: 1.2876 - val_mae: 0.7533\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0385 - mae: 0.1225 - val_loss: 1.3237 - val_mae: 0.7587\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0391 - mae: 0.1235 - val_loss: 1.2973 - val_mae: 0.7493\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0388 - mae: 0.1201 - val_loss: 1.3028 - val_mae: 0.7492\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0418 - mae: 0.1177 - val_loss: 1.3017 - val_mae: 0.7507\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0352 - mae: 0.1106 - val_loss: 1.2766 - val_mae: 0.7467\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0405 - mae: 0.1168 - val_loss: 1.3046 - val_mae: 0.7444\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0376 - mae: 0.1181 - val_loss: 1.2805 - val_mae: 0.7436\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0355 - mae: 0.1101 - val_loss: 1.3180 - val_mae: 0.7531\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0416 - mae: 0.1154 - val_loss: 1.3212 - val_mae: 0.7606\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0410 - mae: 0.1166 - val_loss: 1.2985 - val_mae: 0.7512\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0349 - mae: 0.1089 - val_loss: 1.3079 - val_mae: 0.7519\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0413 - mae: 0.1174 - val_loss: 1.3406 - val_mae: 0.7558\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0359 - mae: 0.1109 - val_loss: 1.2809 - val_mae: 0.7493\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0284 - mae: 0.1021 - val_loss: 1.3122 - val_mae: 0.7501\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0357 - mae: 0.1079 - val_loss: 1.3273 - val_mae: 0.7559\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0331 - mae: 0.1082 - val_loss: 1.2956 - val_mae: 0.7498\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0370 - mae: 0.1108 - val_loss: 1.2923 - val_mae: 0.7462\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0348 - mae: 0.1066 - val_loss: 1.2972 - val_mae: 0.7491\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0333 - mae: 0.1073 - val_loss: 1.3104 - val_mae: 0.7523\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0326 - mae: 0.1101 - val_loss: 1.2972 - val_mae: 0.7494\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0324 - mae: 0.1051 - val_loss: 1.3063 - val_mae: 0.7514\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0332 - mae: 0.1057 - val_loss: 1.2982 - val_mae: 0.7492\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0326 - mae: 0.1043 - val_loss: 1.2883 - val_mae: 0.7555\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0319 - mae: 0.1037 - val_loss: 1.2992 - val_mae: 0.7506\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0316 - mae: 0.1002 - val_loss: 1.2970 - val_mae: 0.7474\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0320 - mae: 0.1016 - val_loss: 1.3000 - val_mae: 0.7558\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0334 - mae: 0.1062 - val_loss: 1.3158 - val_mae: 0.7537\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0344 - mae: 0.1028 - val_loss: 1.2768 - val_mae: 0.7480\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0270 - mae: 0.0951 - val_loss: 1.3357 - val_mae: 0.7560\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0318 - mae: 0.1019 - val_loss: 1.2903 - val_mae: 0.7503\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0323 - mae: 0.0970 - val_loss: 1.2931 - val_mae: 0.7467\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0288 - mae: 0.0970 - val_loss: 1.3027 - val_mae: 0.7543\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0340 - mae: 0.1016 - val_loss: 1.3005 - val_mae: 0.7511\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0287 - mae: 0.0981 - val_loss: 1.3157 - val_mae: 0.7491\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0290 - mae: 0.0982 - val_loss: 1.3149 - val_mae: 0.7543\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0247 - mae: 0.0931 - val_loss: 1.3044 - val_mae: 0.7527\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0290 - mae: 0.0928 - val_loss: 1.2941 - val_mae: 0.7462\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0261 - mae: 0.0932 - val_loss: 1.3092 - val_mae: 0.7517\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0284 - mae: 0.0932 - val_loss: 1.2954 - val_mae: 0.7455\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0319 - mae: 0.0973 - val_loss: 1.3108 - val_mae: 0.7543\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0268 - mae: 0.0921 - val_loss: 1.2932 - val_mae: 0.7475\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0307 - mae: 0.0934 - val_loss: 1.3172 - val_mae: 0.7478\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0391 - mae: 0.0990 - val_loss: 1.2963 - val_mae: 0.7461\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0284 - mae: 0.0925 - val_loss: 1.3026 - val_mae: 0.7502\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0259 - mae: 0.0905 - val_loss: 1.2921 - val_mae: 0.7475\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0293 - mae: 0.0906 - val_loss: 1.3387 - val_mae: 0.7533\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0246 - mae: 0.0912 - val_loss: 1.3025 - val_mae: 0.7500\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0299 - mae: 0.0956 - val_loss: 1.3047 - val_mae: 0.7503\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0286 - mae: 0.0926 - val_loss: 1.3106 - val_mae: 0.7510\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0259 - mae: 0.0902 - val_loss: 1.3009 - val_mae: 0.7501\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0304 - mae: 0.0924 - val_loss: 1.3060 - val_mae: 0.7503\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0266 - mae: 0.0894 - val_loss: 1.3123 - val_mae: 0.7495\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0277 - mae: 0.0851 - val_loss: 1.3137 - val_mae: 0.7492\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0240 - mae: 0.0844 - val_loss: 1.2981 - val_mae: 0.7458\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0311 - mae: 0.0943 - val_loss: 1.3319 - val_mae: 0.7553\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0255 - mae: 0.0868 - val_loss: 1.3118 - val_mae: 0.7498\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0248 - mae: 0.0852 - val_loss: 1.2887 - val_mae: 0.7462\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0230 - mae: 0.0852 - val_loss: 1.3166 - val_mae: 0.7489\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0284 - mae: 0.0887 - val_loss: 1.3241 - val_mae: 0.7540\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0256 - mae: 0.0824 - val_loss: 1.2867 - val_mae: 0.7435\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0233 - mae: 0.0812 - val_loss: 1.3094 - val_mae: 0.7531\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0261 - mae: 0.0819 - val_loss: 1.3186 - val_mae: 0.7547\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0226 - mae: 0.0840 - val_loss: 1.3164 - val_mae: 0.7510\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0287 - mae: 0.0913 - val_loss: 1.3154 - val_mae: 0.7529\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0261 - mae: 0.0844 - val_loss: 1.3124 - val_mae: 0.7471\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0255 - mae: 0.0830 - val_loss: 1.2969 - val_mae: 0.7501\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0235 - mae: 0.0797 - val_loss: 1.3254 - val_mae: 0.7544\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0270 - mae: 0.0839 - val_loss: 1.2831 - val_mae: 0.7442\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0247 - mae: 0.0823 - val_loss: 1.2988 - val_mae: 0.7503\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0239 - mae: 0.0825 - val_loss: 1.3085 - val_mae: 0.7508\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0228 - mae: 0.0794 - val_loss: 1.2959 - val_mae: 0.7490\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0264 - mae: 0.0811 - val_loss: 1.3058 - val_mae: 0.7497\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0232 - mae: 0.0811 - val_loss: 1.2950 - val_mae: 0.7458\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0239 - mae: 0.0796 - val_loss: 1.3036 - val_mae: 0.7491\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0236 - mae: 0.0798 - val_loss: 1.3086 - val_mae: 0.7537\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0300 - mae: 0.0849 - val_loss: 1.3125 - val_mae: 0.7496\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0233 - mae: 0.0796 - val_loss: 1.2962 - val_mae: 0.7465\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0207 - mae: 0.0752 - val_loss: 1.3013 - val_mae: 0.7460\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0235 - mae: 0.0770 - val_loss: 1.2908 - val_mae: 0.7479\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0220 - mae: 0.0766 - val_loss: 1.2867 - val_mae: 0.7438\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0220 - mae: 0.0769 - val_loss: 1.3138 - val_mae: 0.7511\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0255 - mae: 0.0794 - val_loss: 1.2866 - val_mae: 0.7464\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0207 - mae: 0.0802 - val_loss: 1.2910 - val_mae: 0.7441\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0245 - mae: 0.0758 - val_loss: 1.3068 - val_mae: 0.7490\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0220 - mae: 0.0752 - val_loss: 1.2996 - val_mae: 0.7448\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0199 - mae: 0.0730 - val_loss: 1.3077 - val_mae: 0.7501\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0249 - mae: 0.0752 - val_loss: 1.3046 - val_mae: 0.7456\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0228 - mae: 0.0740 - val_loss: 1.3016 - val_mae: 0.7505\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0239 - mae: 0.0739 - val_loss: 1.3298 - val_mae: 0.7582\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0235 - mae: 0.0790 - val_loss: 1.2934 - val_mae: 0.7422\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0213 - mae: 0.0769 - val_loss: 1.3152 - val_mae: 0.7503\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0258 - mae: 0.0768 - val_loss: 1.3148 - val_mae: 0.7489\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0221 - mae: 0.0793 - val_loss: 1.2952 - val_mae: 0.7505\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0216 - mae: 0.0738 - val_loss: 1.3165 - val_mae: 0.7505\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0231 - mae: 0.0759 - val_loss: 1.3042 - val_mae: 0.7483\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0248 - mae: 0.0775 - val_loss: 1.3091 - val_mae: 0.7472\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0240 - mae: 0.0743 - val_loss: 1.3092 - val_mae: 0.7452\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0175 - mae: 0.0692 - val_loss: 1.3048 - val_mae: 0.7502\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0213 - mae: 0.0757 - val_loss: 1.2938 - val_mae: 0.7470\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0250 - mae: 0.0803 - val_loss: 1.2994 - val_mae: 0.7483\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0203 - mae: 0.0743 - val_loss: 1.3185 - val_mae: 0.7545\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0239 - mae: 0.0732 - val_loss: 1.3330 - val_mae: 0.7535\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0180 - mae: 0.0688 - val_loss: 1.3144 - val_mae: 0.7506\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0212 - mae: 0.0701 - val_loss: 1.3028 - val_mae: 0.7468\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0232 - mae: 0.0720 - val_loss: 1.3115 - val_mae: 0.7487\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0272 - mae: 0.0746 - val_loss: 1.3282 - val_mae: 0.7522\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0225 - mae: 0.0727 - val_loss: 1.3018 - val_mae: 0.7479\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0216 - mae: 0.0736 - val_loss: 1.2968 - val_mae: 0.7485\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0211 - mae: 0.0728 - val_loss: 1.3026 - val_mae: 0.7451\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0232 - mae: 0.0719 - val_loss: 1.3061 - val_mae: 0.7459\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0264 - mae: 0.0749 - val_loss: 1.3213 - val_mae: 0.7510\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0222 - mae: 0.0734 - val_loss: 1.3169 - val_mae: 0.7520\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0228 - mae: 0.0733 - val_loss: 1.3091 - val_mae: 0.7465\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0283 - mae: 0.0709 - val_loss: 1.3202 - val_mae: 0.7517\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0218 - mae: 0.0722 - val_loss: 1.2876 - val_mae: 0.7406\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0192 - mae: 0.0729 - val_loss: 1.3141 - val_mae: 0.7514\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0196 - mae: 0.0732 - val_loss: 1.2975 - val_mae: 0.7445\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0172 - mae: 0.0700 - val_loss: 1.3137 - val_mae: 0.7488\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0262 - mae: 0.0715 - val_loss: 1.3156 - val_mae: 0.7484\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0212 - mae: 0.0699 - val_loss: 1.3135 - val_mae: 0.7491\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0209 - mae: 0.0693 - val_loss: 1.3041 - val_mae: 0.7457\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0185 - mae: 0.0692 - val_loss: 1.3099 - val_mae: 0.7505\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0214 - mae: 0.0685 - val_loss: 1.3024 - val_mae: 0.7444\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0183 - mae: 0.0662 - val_loss: 1.2958 - val_mae: 0.7553\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0193 - mae: 0.0723 - val_loss: 1.3038 - val_mae: 0.7461\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0218 - mae: 0.0689 - val_loss: 1.3004 - val_mae: 0.7483\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0225 - mae: 0.0747 - val_loss: 1.3108 - val_mae: 0.7465\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0221 - mae: 0.0719 - val_loss: 1.2854 - val_mae: 0.7439\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0230 - mae: 0.0757 - val_loss: 1.2942 - val_mae: 0.7444\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0217 - mae: 0.0711 - val_loss: 1.2961 - val_mae: 0.7480\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0219 - mae: 0.0681 - val_loss: 1.3019 - val_mae: 0.7487\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0180 - mae: 0.0653 - val_loss: 1.2887 - val_mae: 0.7427\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0198 - mae: 0.0674 - val_loss: 1.3018 - val_mae: 0.7494\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0196 - mae: 0.0682 - val_loss: 1.2963 - val_mae: 0.7489\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0181 - mae: 0.0680 - val_loss: 1.2901 - val_mae: 0.7466\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0267 - mae: 0.0733 - val_loss: 1.3184 - val_mae: 0.7487\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0197 - mae: 0.0690 - val_loss: 1.3064 - val_mae: 0.7477\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0234 - mae: 0.0659 - val_loss: 1.3084 - val_mae: 0.7477\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0219 - mae: 0.0685 - val_loss: 1.2976 - val_mae: 0.7449\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0207 - mae: 0.0682 - val_loss: 1.3073 - val_mae: 0.7509\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3013 - mae: 0.7458\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 3.6857 - mae: 1.3979 - val_loss: 1.6378 - val_mae: 0.8945\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.9022 - mae: 0.6671 - val_loss: 1.6120 - val_mae: 0.9038\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.5482 - mae: 0.5146 - val_loss: 1.5161 - val_mae: 0.8664\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.3868 - mae: 0.4249 - val_loss: 1.4723 - val_mae: 0.8444\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.3043 - mae: 0.3763 - val_loss: 1.4677 - val_mae: 0.8530\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2966 - mae: 0.3683 - val_loss: 1.4626 - val_mae: 0.8298\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2170 - mae: 0.3190 - val_loss: 1.4556 - val_mae: 0.8353\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1965 - mae: 0.3001 - val_loss: 1.4019 - val_mae: 0.8087\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1768 - mae: 0.2909 - val_loss: 1.3797 - val_mae: 0.8021\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1557 - mae: 0.2701 - val_loss: 1.4183 - val_mae: 0.8114\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1538 - mae: 0.2695 - val_loss: 1.3978 - val_mae: 0.7972\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1297 - mae: 0.2478 - val_loss: 1.3629 - val_mae: 0.8037\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1348 - mae: 0.2546 - val_loss: 1.4255 - val_mae: 0.8094\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1270 - mae: 0.2425 - val_loss: 1.3547 - val_mae: 0.7902\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1161 - mae: 0.2359 - val_loss: 1.3863 - val_mae: 0.7987\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1185 - mae: 0.2363 - val_loss: 1.3606 - val_mae: 0.7884\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1238 - mae: 0.2351 - val_loss: 1.3787 - val_mae: 0.7944\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1075 - mae: 0.2226 - val_loss: 1.3429 - val_mae: 0.7893\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0882 - mae: 0.2015 - val_loss: 1.3606 - val_mae: 0.7892\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0957 - mae: 0.2062 - val_loss: 1.3527 - val_mae: 0.7862\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0906 - mae: 0.1984 - val_loss: 1.3352 - val_mae: 0.7796\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0842 - mae: 0.1889 - val_loss: 1.3768 - val_mae: 0.7940\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0807 - mae: 0.1940 - val_loss: 1.3654 - val_mae: 0.7855\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0785 - mae: 0.1868 - val_loss: 1.3538 - val_mae: 0.7825\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0759 - mae: 0.1861 - val_loss: 1.3786 - val_mae: 0.7980\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0693 - mae: 0.1795 - val_loss: 1.3635 - val_mae: 0.7860\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0754 - mae: 0.1860 - val_loss: 1.3236 - val_mae: 0.7753\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0715 - mae: 0.1798 - val_loss: 1.3642 - val_mae: 0.7861\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0701 - mae: 0.1752 - val_loss: 1.3453 - val_mae: 0.7713\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0664 - mae: 0.1666 - val_loss: 1.3238 - val_mae: 0.7718\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0642 - mae: 0.1614 - val_loss: 1.3531 - val_mae: 0.7820\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0595 - mae: 0.1571 - val_loss: 1.3494 - val_mae: 0.7748\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0539 - mae: 0.1547 - val_loss: 1.3563 - val_mae: 0.7829\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0564 - mae: 0.1519 - val_loss: 1.3306 - val_mae: 0.7705\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0624 - mae: 0.1573 - val_loss: 1.3325 - val_mae: 0.7701\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0578 - mae: 0.1550 - val_loss: 1.3475 - val_mae: 0.7727\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0535 - mae: 0.1510 - val_loss: 1.3148 - val_mae: 0.7697\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0539 - mae: 0.1515 - val_loss: 1.3544 - val_mae: 0.7745\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0503 - mae: 0.1460 - val_loss: 1.3283 - val_mae: 0.7754\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0515 - mae: 0.1424 - val_loss: 1.3288 - val_mae: 0.7746\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0465 - mae: 0.1420 - val_loss: 1.3694 - val_mae: 0.7849\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0520 - mae: 0.1485 - val_loss: 1.3077 - val_mae: 0.7621\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0440 - mae: 0.1331 - val_loss: 1.3580 - val_mae: 0.7801\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0440 - mae: 0.1345 - val_loss: 1.3164 - val_mae: 0.7659\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0454 - mae: 0.1325 - val_loss: 1.3614 - val_mae: 0.7736\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0466 - mae: 0.1344 - val_loss: 1.3501 - val_mae: 0.7798\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0410 - mae: 0.1327 - val_loss: 1.3296 - val_mae: 0.7692\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0424 - mae: 0.1270 - val_loss: 1.3398 - val_mae: 0.7709\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0335 - mae: 0.1216 - val_loss: 1.3129 - val_mae: 0.7700\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0394 - mae: 0.1272 - val_loss: 1.3588 - val_mae: 0.7800\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0381 - mae: 0.1262 - val_loss: 1.3335 - val_mae: 0.7691\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0390 - mae: 0.1243 - val_loss: 1.3228 - val_mae: 0.7659\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0327 - mae: 0.1192 - val_loss: 1.3388 - val_mae: 0.7696\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0390 - mae: 0.1233 - val_loss: 1.3213 - val_mae: 0.7651\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0379 - mae: 0.1267 - val_loss: 1.3503 - val_mae: 0.7729\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0423 - mae: 0.1252 - val_loss: 1.3001 - val_mae: 0.7645\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0321 - mae: 0.1130 - val_loss: 1.3413 - val_mae: 0.7701\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0330 - mae: 0.1158 - val_loss: 1.3494 - val_mae: 0.7746\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0319 - mae: 0.1131 - val_loss: 1.2913 - val_mae: 0.7596\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0317 - mae: 0.1152 - val_loss: 1.3516 - val_mae: 0.7773\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0317 - mae: 0.1160 - val_loss: 1.3280 - val_mae: 0.7698\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0342 - mae: 0.1156 - val_loss: 1.3276 - val_mae: 0.7680\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0337 - mae: 0.1180 - val_loss: 1.3088 - val_mae: 0.7646\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0323 - mae: 0.1071 - val_loss: 1.3260 - val_mae: 0.7696\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0288 - mae: 0.1043 - val_loss: 1.3189 - val_mae: 0.7678\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0304 - mae: 0.1083 - val_loss: 1.3397 - val_mae: 0.7726\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0279 - mae: 0.1045 - val_loss: 1.3287 - val_mae: 0.7710\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0282 - mae: 0.1053 - val_loss: 1.3318 - val_mae: 0.7711\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0271 - mae: 0.1066 - val_loss: 1.3233 - val_mae: 0.7640\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0288 - mae: 0.1043 - val_loss: 1.3300 - val_mae: 0.7680\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0289 - mae: 0.1054 - val_loss: 1.3295 - val_mae: 0.7690\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0308 - mae: 0.1061 - val_loss: 1.3353 - val_mae: 0.7733\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0284 - mae: 0.1054 - val_loss: 1.3270 - val_mae: 0.7680\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0262 - mae: 0.0997 - val_loss: 1.3213 - val_mae: 0.7657\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0261 - mae: 0.0990 - val_loss: 1.3248 - val_mae: 0.7662\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0258 - mae: 0.0978 - val_loss: 1.3227 - val_mae: 0.7637\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0248 - mae: 0.0963 - val_loss: 1.3009 - val_mae: 0.7589\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0260 - mae: 0.0998 - val_loss: 1.3243 - val_mae: 0.7633\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0242 - mae: 0.0972 - val_loss: 1.3265 - val_mae: 0.7756\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0255 - mae: 0.1000 - val_loss: 1.3201 - val_mae: 0.7602\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0265 - mae: 0.0941 - val_loss: 1.3177 - val_mae: 0.7602\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0233 - mae: 0.0954 - val_loss: 1.3335 - val_mae: 0.7715\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0229 - mae: 0.0942 - val_loss: 1.3054 - val_mae: 0.7614\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0241 - mae: 0.0966 - val_loss: 1.3159 - val_mae: 0.7653\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0217 - mae: 0.0888 - val_loss: 1.3295 - val_mae: 0.7693\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0217 - mae: 0.0910 - val_loss: 1.3064 - val_mae: 0.7647\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0281 - mae: 0.0975 - val_loss: 1.3371 - val_mae: 0.7691\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0242 - mae: 0.0905 - val_loss: 1.3120 - val_mae: 0.7689\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0224 - mae: 0.0914 - val_loss: 1.3534 - val_mae: 0.7698\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0214 - mae: 0.0883 - val_loss: 1.3286 - val_mae: 0.7668\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0204 - mae: 0.0865 - val_loss: 1.3197 - val_mae: 0.7669\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0192 - mae: 0.0864 - val_loss: 1.3076 - val_mae: 0.7630\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0253 - mae: 0.0906 - val_loss: 1.3198 - val_mae: 0.7681\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0309 - mae: 0.0917 - val_loss: 1.3128 - val_mae: 0.7612\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0189 - mae: 0.0839 - val_loss: 1.3364 - val_mae: 0.7682\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0182 - mae: 0.0820 - val_loss: 1.3304 - val_mae: 0.7650\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0206 - mae: 0.0813 - val_loss: 1.3075 - val_mae: 0.7658\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0227 - mae: 0.0884 - val_loss: 1.3298 - val_mae: 0.7665\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0182 - mae: 0.0851 - val_loss: 1.2950 - val_mae: 0.7562\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0185 - mae: 0.0873 - val_loss: 1.3402 - val_mae: 0.7724\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0206 - mae: 0.0889 - val_loss: 1.3150 - val_mae: 0.7623\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0196 - mae: 0.0843 - val_loss: 1.3069 - val_mae: 0.7601\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0150 - mae: 0.0779 - val_loss: 1.3033 - val_mae: 0.7605\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0233 - mae: 0.0876 - val_loss: 1.3154 - val_mae: 0.7648\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0215 - mae: 0.0856 - val_loss: 1.3074 - val_mae: 0.7624\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0223 - mae: 0.0804 - val_loss: 1.3219 - val_mae: 0.7632\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0172 - mae: 0.0802 - val_loss: 1.3279 - val_mae: 0.7663\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0156 - mae: 0.0750 - val_loss: 1.3147 - val_mae: 0.7610\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0784 - val_loss: 1.3187 - val_mae: 0.7643\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0166 - mae: 0.0799 - val_loss: 1.3114 - val_mae: 0.7615\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0259 - mae: 0.0864 - val_loss: 1.3038 - val_mae: 0.7601\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0220 - mae: 0.0807 - val_loss: 1.3195 - val_mae: 0.7655\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0194 - mae: 0.0838 - val_loss: 1.3116 - val_mae: 0.7645\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0178 - mae: 0.0795 - val_loss: 1.3120 - val_mae: 0.7624\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0200 - mae: 0.0783 - val_loss: 1.2956 - val_mae: 0.7580\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0180 - mae: 0.0764 - val_loss: 1.3082 - val_mae: 0.7607\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0147 - mae: 0.0746 - val_loss: 1.3353 - val_mae: 0.7671\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0200 - mae: 0.0783 - val_loss: 1.2986 - val_mae: 0.7602\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0160 - mae: 0.0770 - val_loss: 1.3148 - val_mae: 0.7644\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0161 - mae: 0.0764 - val_loss: 1.3182 - val_mae: 0.7610\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0764 - val_loss: 1.3203 - val_mae: 0.7605\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0178 - mae: 0.0794 - val_loss: 1.3175 - val_mae: 0.7632\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0176 - mae: 0.0771 - val_loss: 1.3103 - val_mae: 0.7606\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0175 - mae: 0.0753 - val_loss: 1.3051 - val_mae: 0.7610\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0167 - mae: 0.0746 - val_loss: 1.3065 - val_mae: 0.7612\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0149 - mae: 0.0748 - val_loss: 1.2954 - val_mae: 0.7573\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0141 - mae: 0.0706 - val_loss: 1.3120 - val_mae: 0.7599\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0165 - mae: 0.0719 - val_loss: 1.3180 - val_mae: 0.7633\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0741 - val_loss: 1.3381 - val_mae: 0.7640\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0208 - mae: 0.0788 - val_loss: 1.3087 - val_mae: 0.7624\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0169 - mae: 0.0759 - val_loss: 1.3178 - val_mae: 0.7584\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0178 - mae: 0.0718 - val_loss: 1.3156 - val_mae: 0.7602\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0168 - mae: 0.0711 - val_loss: 1.3244 - val_mae: 0.7636\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0181 - mae: 0.0735 - val_loss: 1.3245 - val_mae: 0.7653\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0700 - val_loss: 1.3212 - val_mae: 0.7612\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0146 - mae: 0.0711 - val_loss: 1.3158 - val_mae: 0.7635\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0153 - mae: 0.0716 - val_loss: 1.3076 - val_mae: 0.7602\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0757 - val_loss: 1.3233 - val_mae: 0.7611\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0176 - mae: 0.0771 - val_loss: 1.3138 - val_mae: 0.7600\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0178 - mae: 0.0725 - val_loss: 1.3066 - val_mae: 0.7606\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0156 - mae: 0.0688 - val_loss: 1.3077 - val_mae: 0.7607\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0677 - val_loss: 1.3144 - val_mae: 0.7604\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0181 - mae: 0.0708 - val_loss: 1.3162 - val_mae: 0.7639\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0148 - mae: 0.0709 - val_loss: 1.3078 - val_mae: 0.7605\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0129 - mae: 0.0666 - val_loss: 1.3232 - val_mae: 0.7639\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0176 - mae: 0.0710 - val_loss: 1.3098 - val_mae: 0.7617\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0689 - val_loss: 1.3183 - val_mae: 0.7652\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0149 - mae: 0.0708 - val_loss: 1.3088 - val_mae: 0.7609\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0139 - mae: 0.0678 - val_loss: 1.3245 - val_mae: 0.7614\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0213 - mae: 0.0750 - val_loss: 1.3143 - val_mae: 0.7614\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0150 - mae: 0.0688 - val_loss: 1.3165 - val_mae: 0.7607\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0149 - mae: 0.0665 - val_loss: 1.3117 - val_mae: 0.7586\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0647 - val_loss: 1.3160 - val_mae: 0.7625\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0136 - mae: 0.0673 - val_loss: 1.3168 - val_mae: 0.7612\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0198 - mae: 0.0722 - val_loss: 1.3166 - val_mae: 0.7603\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0172 - mae: 0.0725 - val_loss: 1.3106 - val_mae: 0.7600\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0184 - mae: 0.0731 - val_loss: 1.3176 - val_mae: 0.7592\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0652 - val_loss: 1.3140 - val_mae: 0.7585\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0142 - mae: 0.0630 - val_loss: 1.3017 - val_mae: 0.7581\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0136 - mae: 0.0642 - val_loss: 1.3333 - val_mae: 0.7628\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0642 - val_loss: 1.3089 - val_mae: 0.7576\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0138 - mae: 0.0659 - val_loss: 1.3152 - val_mae: 0.7608\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0183 - mae: 0.0692 - val_loss: 1.3106 - val_mae: 0.7574\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0140 - mae: 0.0674 - val_loss: 1.2988 - val_mae: 0.7578\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0679 - val_loss: 1.3173 - val_mae: 0.7603\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0137 - mae: 0.0642 - val_loss: 1.3050 - val_mae: 0.7577\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0165 - mae: 0.0645 - val_loss: 1.3123 - val_mae: 0.7596\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0143 - mae: 0.0624 - val_loss: 1.3204 - val_mae: 0.7615\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0115 - mae: 0.0604 - val_loss: 1.3151 - val_mae: 0.7598\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0605 - val_loss: 1.3144 - val_mae: 0.7616\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0663 - val_loss: 1.3037 - val_mae: 0.7565\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0124 - mae: 0.0654 - val_loss: 1.3202 - val_mae: 0.7594\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0663 - val_loss: 1.3102 - val_mae: 0.7597\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0159 - mae: 0.0675 - val_loss: 1.3084 - val_mae: 0.7611\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0136 - mae: 0.0618 - val_loss: 1.3040 - val_mae: 0.7574\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0613 - val_loss: 1.3049 - val_mae: 0.7548\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0101 - mae: 0.0587 - val_loss: 1.3152 - val_mae: 0.7625\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0650 - val_loss: 1.3074 - val_mae: 0.7604\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0113 - mae: 0.0620 - val_loss: 1.3112 - val_mae: 0.7602\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0141 - mae: 0.0638 - val_loss: 1.2968 - val_mae: 0.7553\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0104 - mae: 0.0613 - val_loss: 1.3177 - val_mae: 0.7602\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0133 - mae: 0.0631 - val_loss: 1.3118 - val_mae: 0.7610\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0646 - val_loss: 1.3294 - val_mae: 0.7638\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0167 - mae: 0.0665 - val_loss: 1.3149 - val_mae: 0.7606\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0124 - mae: 0.0626 - val_loss: 1.3312 - val_mae: 0.7672\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0136 - mae: 0.0598 - val_loss: 1.3132 - val_mae: 0.7604\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0126 - mae: 0.0622 - val_loss: 1.3077 - val_mae: 0.7601\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0138 - mae: 0.0578 - val_loss: 1.3168 - val_mae: 0.7596\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0619 - val_loss: 1.3124 - val_mae: 0.7591\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0171 - mae: 0.0640 - val_loss: 1.2962 - val_mae: 0.7571\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0105 - mae: 0.0608 - val_loss: 1.3226 - val_mae: 0.7641\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0108 - mae: 0.0586 - val_loss: 1.3097 - val_mae: 0.7595\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0157 - mae: 0.0652 - val_loss: 1.3141 - val_mae: 0.7571\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0595 - val_loss: 1.3095 - val_mae: 0.7605\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0634 - val_loss: 1.3187 - val_mae: 0.7604\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0590 - val_loss: 1.3073 - val_mae: 0.7591\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0127 - mae: 0.0570 - val_loss: 1.3091 - val_mae: 0.7550\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0111 - mae: 0.0587 - val_loss: 1.3025 - val_mae: 0.7545\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0643 - val_loss: 1.3251 - val_mae: 0.7564\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0160 - mae: 0.0614 - val_loss: 1.3074 - val_mae: 0.7562\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3619 - mae: 0.7593\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 4.0100 - mae: 1.4623 - val_loss: 1.7819 - val_mae: 0.9225\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.8635 - mae: 0.6517 - val_loss: 1.5833 - val_mae: 0.8847\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.5637 - mae: 0.5107 - val_loss: 1.6140 - val_mae: 0.8914\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.3976 - mae: 0.4258 - val_loss: 1.5433 - val_mae: 0.8595\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.3006 - mae: 0.3797 - val_loss: 1.5681 - val_mae: 0.8660\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.2397 - mae: 0.3265 - val_loss: 1.5365 - val_mae: 0.8701\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.2157 - mae: 0.3095 - val_loss: 1.4663 - val_mae: 0.8420\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1893 - mae: 0.2986 - val_loss: 1.5210 - val_mae: 0.8622\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1619 - mae: 0.2756 - val_loss: 1.5004 - val_mae: 0.8322\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1881 - mae: 0.2833 - val_loss: 1.5193 - val_mae: 0.8393\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1467 - mae: 0.2608 - val_loss: 1.4824 - val_mae: 0.8269\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1245 - mae: 0.2441 - val_loss: 1.4188 - val_mae: 0.8157\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1207 - mae: 0.2373 - val_loss: 1.5122 - val_mae: 0.8394\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1262 - mae: 0.2421 - val_loss: 1.4746 - val_mae: 0.8255\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1151 - mae: 0.2372 - val_loss: 1.4851 - val_mae: 0.8194\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1044 - mae: 0.2216 - val_loss: 1.4528 - val_mae: 0.8187\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1081 - mae: 0.2223 - val_loss: 1.4749 - val_mae: 0.8243\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1019 - mae: 0.2241 - val_loss: 1.4651 - val_mae: 0.8073\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1007 - mae: 0.2193 - val_loss: 1.4409 - val_mae: 0.8114\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0857 - mae: 0.1980 - val_loss: 1.4479 - val_mae: 0.8115\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0864 - mae: 0.1980 - val_loss: 1.4383 - val_mae: 0.8064\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0860 - mae: 0.2031 - val_loss: 1.4415 - val_mae: 0.7980\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0771 - mae: 0.1939 - val_loss: 1.4331 - val_mae: 0.8053\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0787 - mae: 0.1921 - val_loss: 1.4080 - val_mae: 0.7904\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0709 - mae: 0.1766 - val_loss: 1.4307 - val_mae: 0.8083\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0662 - mae: 0.1736 - val_loss: 1.4266 - val_mae: 0.7948\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0645 - mae: 0.1742 - val_loss: 1.4115 - val_mae: 0.7921\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0598 - mae: 0.1682 - val_loss: 1.3898 - val_mae: 0.7855\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0600 - mae: 0.1682 - val_loss: 1.4222 - val_mae: 0.7949\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0600 - mae: 0.1617 - val_loss: 1.4491 - val_mae: 0.7978\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0795 - mae: 0.1725 - val_loss: 1.3907 - val_mae: 0.7815\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0562 - mae: 0.1567 - val_loss: 1.4065 - val_mae: 0.7843\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0465 - mae: 0.1502 - val_loss: 1.4000 - val_mae: 0.7846\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0514 - mae: 0.1534 - val_loss: 1.3879 - val_mae: 0.7831\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0471 - mae: 0.1487 - val_loss: 1.4085 - val_mae: 0.7900\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0428 - mae: 0.1407 - val_loss: 1.3839 - val_mae: 0.7789\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0399 - mae: 0.1364 - val_loss: 1.3923 - val_mae: 0.7815\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0420 - mae: 0.1390 - val_loss: 1.3962 - val_mae: 0.7881\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0411 - mae: 0.1400 - val_loss: 1.4075 - val_mae: 0.7950\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0406 - mae: 0.1413 - val_loss: 1.4090 - val_mae: 0.7847\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0431 - mae: 0.1455 - val_loss: 1.3929 - val_mae: 0.7861\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0411 - mae: 0.1341 - val_loss: 1.4229 - val_mae: 0.7874\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0342 - mae: 0.1239 - val_loss: 1.3951 - val_mae: 0.7889\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0329 - mae: 0.1212 - val_loss: 1.4150 - val_mae: 0.7787\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0357 - mae: 0.1270 - val_loss: 1.3978 - val_mae: 0.7845\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0382 - mae: 0.1326 - val_loss: 1.3939 - val_mae: 0.7790\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0359 - mae: 0.1268 - val_loss: 1.4094 - val_mae: 0.7796\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0314 - mae: 0.1216 - val_loss: 1.4125 - val_mae: 0.7838\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0350 - mae: 0.1256 - val_loss: 1.3955 - val_mae: 0.7794\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0351 - mae: 0.1219 - val_loss: 1.3965 - val_mae: 0.7815\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0317 - mae: 0.1192 - val_loss: 1.3610 - val_mae: 0.7766\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0307 - mae: 0.1146 - val_loss: 1.4131 - val_mae: 0.7855\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0286 - mae: 0.1114 - val_loss: 1.3800 - val_mae: 0.7701\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0281 - mae: 0.1108 - val_loss: 1.3812 - val_mae: 0.7797\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0298 - mae: 0.1138 - val_loss: 1.3741 - val_mae: 0.7782\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0295 - mae: 0.1153 - val_loss: 1.4032 - val_mae: 0.7841\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0290 - mae: 0.1131 - val_loss: 1.3919 - val_mae: 0.7774\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0308 - mae: 0.1141 - val_loss: 1.3804 - val_mae: 0.7746\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0277 - mae: 0.1114 - val_loss: 1.3831 - val_mae: 0.7722\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0297 - mae: 0.1154 - val_loss: 1.3795 - val_mae: 0.7735\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0263 - mae: 0.1055 - val_loss: 1.3807 - val_mae: 0.7782\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0245 - mae: 0.1043 - val_loss: 1.3791 - val_mae: 0.7759\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0229 - mae: 0.1008 - val_loss: 1.4083 - val_mae: 0.7808\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0261 - mae: 0.1045 - val_loss: 1.3964 - val_mae: 0.7798\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0249 - mae: 0.1032 - val_loss: 1.3776 - val_mae: 0.7753\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0229 - mae: 0.0994 - val_loss: 1.3737 - val_mae: 0.7698\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0229 - mae: 0.0992 - val_loss: 1.3912 - val_mae: 0.7774\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0218 - mae: 0.0984 - val_loss: 1.3808 - val_mae: 0.7778\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0231 - mae: 0.0973 - val_loss: 1.3991 - val_mae: 0.7723\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0254 - mae: 0.1016 - val_loss: 1.3846 - val_mae: 0.7783\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0251 - mae: 0.1065 - val_loss: 1.3776 - val_mae: 0.7700\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0216 - mae: 0.0955 - val_loss: 1.3871 - val_mae: 0.7764\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0206 - mae: 0.0933 - val_loss: 1.3858 - val_mae: 0.7729\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0251 - mae: 0.0989 - val_loss: 1.3686 - val_mae: 0.7751\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0204 - mae: 0.0926 - val_loss: 1.3695 - val_mae: 0.7666\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0210 - mae: 0.0935 - val_loss: 1.3814 - val_mae: 0.7699\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0177 - mae: 0.0870 - val_loss: 1.3819 - val_mae: 0.7707\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0201 - mae: 0.0929 - val_loss: 1.3909 - val_mae: 0.7740\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0199 - mae: 0.0934 - val_loss: 1.3989 - val_mae: 0.7764\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0190 - mae: 0.0918 - val_loss: 1.3736 - val_mae: 0.7683\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0175 - mae: 0.0874 - val_loss: 1.3898 - val_mae: 0.7733\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0172 - mae: 0.0861 - val_loss: 1.3811 - val_mae: 0.7715\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0174 - mae: 0.0866 - val_loss: 1.3877 - val_mae: 0.7733\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0182 - mae: 0.0888 - val_loss: 1.3940 - val_mae: 0.7744\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0179 - mae: 0.0875 - val_loss: 1.3722 - val_mae: 0.7680\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0162 - mae: 0.0830 - val_loss: 1.3929 - val_mae: 0.7751\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0174 - mae: 0.0855 - val_loss: 1.3750 - val_mae: 0.7704\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0162 - mae: 0.0815 - val_loss: 1.3961 - val_mae: 0.7728\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0164 - mae: 0.0844 - val_loss: 1.3736 - val_mae: 0.7692\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0176 - mae: 0.0840 - val_loss: 1.4068 - val_mae: 0.7775\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0173 - mae: 0.0875 - val_loss: 1.3645 - val_mae: 0.7630\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0181 - mae: 0.0868 - val_loss: 1.3910 - val_mae: 0.7704\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0170 - mae: 0.0823 - val_loss: 1.3623 - val_mae: 0.7674\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0159 - mae: 0.0822 - val_loss: 1.3856 - val_mae: 0.7703\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0157 - mae: 0.0808 - val_loss: 1.3635 - val_mae: 0.7670\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0856 - val_loss: 1.3885 - val_mae: 0.7721\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0150 - mae: 0.0811 - val_loss: 1.3779 - val_mae: 0.7704\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0154 - mae: 0.0828 - val_loss: 1.3895 - val_mae: 0.7718\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0164 - mae: 0.0834 - val_loss: 1.3849 - val_mae: 0.7698\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0161 - mae: 0.0804 - val_loss: 1.3865 - val_mae: 0.7715\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0148 - mae: 0.0791 - val_loss: 1.3768 - val_mae: 0.7671\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0143 - mae: 0.0762 - val_loss: 1.3981 - val_mae: 0.7721\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0149 - mae: 0.0803 - val_loss: 1.3870 - val_mae: 0.7725\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0162 - mae: 0.0803 - val_loss: 1.3801 - val_mae: 0.7665\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0769 - val_loss: 1.3837 - val_mae: 0.7727\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0138 - mae: 0.0750 - val_loss: 1.3937 - val_mae: 0.7720\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0155 - mae: 0.0792 - val_loss: 1.4005 - val_mae: 0.7733\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0127 - mae: 0.0733 - val_loss: 1.3897 - val_mae: 0.7698\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0128 - mae: 0.0750 - val_loss: 1.3938 - val_mae: 0.7735\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0717 - val_loss: 1.3990 - val_mae: 0.7720\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0133 - mae: 0.0727 - val_loss: 1.3763 - val_mae: 0.7698\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0124 - mae: 0.0718 - val_loss: 1.3892 - val_mae: 0.7696\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0725 - val_loss: 1.3706 - val_mae: 0.7693\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0746 - val_loss: 1.3857 - val_mae: 0.7736\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0133 - mae: 0.0746 - val_loss: 1.3828 - val_mae: 0.7744\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0137 - mae: 0.0768 - val_loss: 1.3854 - val_mae: 0.7740\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0754 - val_loss: 1.3863 - val_mae: 0.7691\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0704 - val_loss: 1.4017 - val_mae: 0.7755\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0710 - val_loss: 1.3852 - val_mae: 0.7723\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0106 - mae: 0.0681 - val_loss: 1.3912 - val_mae: 0.7712\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0720 - val_loss: 1.3713 - val_mae: 0.7663\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0678 - val_loss: 1.3941 - val_mae: 0.7710\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0115 - mae: 0.0708 - val_loss: 1.3811 - val_mae: 0.7695\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0702 - val_loss: 1.4010 - val_mae: 0.7717\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0128 - mae: 0.0740 - val_loss: 1.3885 - val_mae: 0.7743\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0707 - val_loss: 1.3767 - val_mae: 0.7706\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0107 - mae: 0.0673 - val_loss: 1.3978 - val_mae: 0.7800\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0716 - val_loss: 1.3837 - val_mae: 0.7709\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0682 - val_loss: 1.3880 - val_mae: 0.7679\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0714 - val_loss: 1.3831 - val_mae: 0.7702\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0117 - mae: 0.0699 - val_loss: 1.3811 - val_mae: 0.7721\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0130 - mae: 0.0681 - val_loss: 1.3838 - val_mae: 0.7681\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0097 - mae: 0.0634 - val_loss: 1.3903 - val_mae: 0.7704\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0088 - mae: 0.0627 - val_loss: 1.3937 - val_mae: 0.7727\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0106 - mae: 0.0670 - val_loss: 1.3941 - val_mae: 0.7745\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0689 - val_loss: 1.3928 - val_mae: 0.7728\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0104 - mae: 0.0682 - val_loss: 1.4060 - val_mae: 0.7721\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0111 - mae: 0.0690 - val_loss: 1.3926 - val_mae: 0.7695\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0659 - val_loss: 1.3810 - val_mae: 0.7663\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0658 - val_loss: 1.3913 - val_mae: 0.7709\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0099 - mae: 0.0643 - val_loss: 1.3807 - val_mae: 0.7665\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 0.0101 - mae: 0.0668 - val_loss: 1.3813 - val_mae: 0.7682\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 0.0123 - mae: 0.0706 - val_loss: 1.3929 - val_mae: 0.7702\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0097 - mae: 0.0635 - val_loss: 1.3921 - val_mae: 0.7686\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0112 - mae: 0.0652 - val_loss: 1.3896 - val_mae: 0.7691\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0093 - mae: 0.0627 - val_loss: 1.3967 - val_mae: 0.7724\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0087 - mae: 0.0608 - val_loss: 1.4001 - val_mae: 0.7719\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0097 - mae: 0.0627 - val_loss: 1.3919 - val_mae: 0.7703\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0104 - mae: 0.0660 - val_loss: 1.3979 - val_mae: 0.7730\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0101 - mae: 0.0635 - val_loss: 1.3947 - val_mae: 0.7712\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0104 - mae: 0.0651 - val_loss: 1.3893 - val_mae: 0.7704\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0098 - mae: 0.0636 - val_loss: 1.3895 - val_mae: 0.7659\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0113 - mae: 0.0666 - val_loss: 1.3788 - val_mae: 0.7682\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0102 - mae: 0.0656 - val_loss: 1.3928 - val_mae: 0.7695\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0090 - mae: 0.0610 - val_loss: 1.3939 - val_mae: 0.7704\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0083 - mae: 0.0596 - val_loss: 1.3898 - val_mae: 0.7703\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0077 - mae: 0.0563 - val_loss: 1.3839 - val_mae: 0.7662\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0082 - mae: 0.0584 - val_loss: 1.3837 - val_mae: 0.7679\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0081 - mae: 0.0595 - val_loss: 1.3975 - val_mae: 0.7696\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0090 - mae: 0.0620 - val_loss: 1.3922 - val_mae: 0.7704\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0086 - mae: 0.0628 - val_loss: 1.4003 - val_mae: 0.7685\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0107 - mae: 0.0667 - val_loss: 1.3903 - val_mae: 0.7686\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0091 - mae: 0.0629 - val_loss: 1.3762 - val_mae: 0.7666\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0088 - mae: 0.0599 - val_loss: 1.3906 - val_mae: 0.7696\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0102 - mae: 0.0634 - val_loss: 1.3867 - val_mae: 0.7692\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0101 - mae: 0.0626 - val_loss: 1.4004 - val_mae: 0.7732\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0082 - mae: 0.0611 - val_loss: 1.3948 - val_mae: 0.7697\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0081 - mae: 0.0576 - val_loss: 1.3941 - val_mae: 0.7687\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0075 - mae: 0.0535 - val_loss: 1.3932 - val_mae: 0.7712\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0087 - mae: 0.0595 - val_loss: 1.3969 - val_mae: 0.7701\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0081 - mae: 0.0589 - val_loss: 1.3903 - val_mae: 0.7709\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0088 - mae: 0.0610 - val_loss: 1.3996 - val_mae: 0.7720\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0096 - mae: 0.0617 - val_loss: 1.4103 - val_mae: 0.7733\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0105 - mae: 0.0643 - val_loss: 1.3900 - val_mae: 0.7673\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0622 - val_loss: 1.4024 - val_mae: 0.7688\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0090 - mae: 0.0593 - val_loss: 1.4079 - val_mae: 0.7723\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0085 - mae: 0.0566 - val_loss: 1.3992 - val_mae: 0.7703\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0083 - mae: 0.0573 - val_loss: 1.4074 - val_mae: 0.7719\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0070 - mae: 0.0568 - val_loss: 1.4019 - val_mae: 0.7696\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0077 - mae: 0.0562 - val_loss: 1.3962 - val_mae: 0.7688\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0070 - mae: 0.0535 - val_loss: 1.4085 - val_mae: 0.7746\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0084 - mae: 0.0577 - val_loss: 1.4002 - val_mae: 0.7692\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0083 - mae: 0.0584 - val_loss: 1.4063 - val_mae: 0.7756\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0076 - mae: 0.0577 - val_loss: 1.4062 - val_mae: 0.7718\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0079 - mae: 0.0577 - val_loss: 1.4007 - val_mae: 0.7702\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0082 - mae: 0.0580 - val_loss: 1.3988 - val_mae: 0.7699\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0067 - mae: 0.0537 - val_loss: 1.4173 - val_mae: 0.7728\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0064 - mae: 0.0517 - val_loss: 1.4101 - val_mae: 0.7745\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0076 - mae: 0.0582 - val_loss: 1.4114 - val_mae: 0.7731\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0074 - mae: 0.0567 - val_loss: 1.3923 - val_mae: 0.7736\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0081 - mae: 0.0589 - val_loss: 1.4068 - val_mae: 0.7719\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0069 - mae: 0.0524 - val_loss: 1.4011 - val_mae: 0.7706\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0063 - mae: 0.0521 - val_loss: 1.3956 - val_mae: 0.7695\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0080 - mae: 0.0551 - val_loss: 1.4166 - val_mae: 0.7746\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0098 - mae: 0.0627 - val_loss: 1.4017 - val_mae: 0.7680\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0083 - mae: 0.0594 - val_loss: 1.3979 - val_mae: 0.7681\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0065 - mae: 0.0539 - val_loss: 1.3977 - val_mae: 0.7668\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0066 - mae: 0.0531 - val_loss: 1.4207 - val_mae: 0.7744\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0066 - mae: 0.0538 - val_loss: 1.4043 - val_mae: 0.7724\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0071 - mae: 0.0540 - val_loss: 1.4045 - val_mae: 0.7692\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4100 - mae: 0.7669\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 5.4558 - mae: 1.6383 - val_loss: 2.2575 - val_mae: 1.0094\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3820 - mae: 0.8348 - val_loss: 2.1087 - val_mae: 0.9224\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.2946 - mae: 0.7155 - val_loss: 1.4931 - val_mae: 0.8349\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6816 - mae: 0.5735 - val_loss: 1.5883 - val_mae: 0.8600\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5032 - mae: 0.4902 - val_loss: 1.7099 - val_mae: 0.8311\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4152 - mae: 0.4383 - val_loss: 1.4496 - val_mae: 0.8078\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3430 - mae: 0.3981 - val_loss: 1.5859 - val_mae: 0.8375\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3444 - mae: 0.3853 - val_loss: 1.4312 - val_mae: 0.7906\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2719 - mae: 0.3429 - val_loss: 1.4106 - val_mae: 0.7965\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2330 - mae: 0.3179 - val_loss: 1.5240 - val_mae: 0.8171\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2372 - mae: 0.3263 - val_loss: 1.4338 - val_mae: 0.8017\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2469 - mae: 0.3211 - val_loss: 1.3566 - val_mae: 0.7793\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1849 - mae: 0.2861 - val_loss: 1.3911 - val_mae: 0.7807\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1643 - mae: 0.2726 - val_loss: 1.4855 - val_mae: 0.7974\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1702 - mae: 0.2748 - val_loss: 1.3932 - val_mae: 0.7877\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1974 - mae: 0.2800 - val_loss: 1.3777 - val_mae: 0.7706\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1784 - mae: 0.2802 - val_loss: 1.5057 - val_mae: 0.7886\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1612 - mae: 0.2573 - val_loss: 1.3598 - val_mae: 0.7790\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1475 - mae: 0.2441 - val_loss: 1.4318 - val_mae: 0.7816\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1464 - mae: 0.2464 - val_loss: 1.3779 - val_mae: 0.7663\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1317 - mae: 0.2288 - val_loss: 1.3289 - val_mae: 0.7564\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1222 - mae: 0.2218 - val_loss: 1.3772 - val_mae: 0.7814\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1486 - mae: 0.2482 - val_loss: 1.3323 - val_mae: 0.7652\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1297 - mae: 0.2319 - val_loss: 1.3312 - val_mae: 0.7663\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0945 - mae: 0.2028 - val_loss: 1.3340 - val_mae: 0.7631\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1149 - mae: 0.2150 - val_loss: 1.3557 - val_mae: 0.7529\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0968 - mae: 0.2024 - val_loss: 1.3310 - val_mae: 0.7528\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1130 - mae: 0.2114 - val_loss: 1.3106 - val_mae: 0.7601\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1013 - mae: 0.2011 - val_loss: 1.2683 - val_mae: 0.7486\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1276 - mae: 0.2034 - val_loss: 1.2995 - val_mae: 0.7469\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0960 - mae: 0.1932 - val_loss: 1.2550 - val_mae: 0.7502\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0844 - mae: 0.1861 - val_loss: 1.3256 - val_mae: 0.7660\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0935 - mae: 0.1943 - val_loss: 1.2524 - val_mae: 0.7477\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0794 - mae: 0.1850 - val_loss: 1.3134 - val_mae: 0.7579\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0746 - mae: 0.1793 - val_loss: 1.2757 - val_mae: 0.7512\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0871 - mae: 0.1807 - val_loss: 1.2846 - val_mae: 0.7562\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0669 - mae: 0.1693 - val_loss: 1.3173 - val_mae: 0.7562\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0711 - mae: 0.1702 - val_loss: 1.3292 - val_mae: 0.7571\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0735 - mae: 0.1752 - val_loss: 1.3144 - val_mae: 0.7552\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0804 - mae: 0.1723 - val_loss: 1.3045 - val_mae: 0.7563\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0785 - mae: 0.1743 - val_loss: 1.2841 - val_mae: 0.7534\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0623 - mae: 0.1651 - val_loss: 1.3275 - val_mae: 0.7593\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0598 - mae: 0.1575 - val_loss: 1.2305 - val_mae: 0.7412\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0765 - mae: 0.1693 - val_loss: 1.2695 - val_mae: 0.7499\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0623 - mae: 0.1573 - val_loss: 1.3014 - val_mae: 0.7476\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0571 - mae: 0.1546 - val_loss: 1.2800 - val_mae: 0.7455\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0506 - mae: 0.1477 - val_loss: 1.2473 - val_mae: 0.7394\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0566 - mae: 0.1532 - val_loss: 1.3031 - val_mae: 0.7441\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0688 - mae: 0.1623 - val_loss: 1.2845 - val_mae: 0.7516\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0558 - mae: 0.1507 - val_loss: 1.2424 - val_mae: 0.7392\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0491 - mae: 0.1434 - val_loss: 1.2992 - val_mae: 0.7462\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0490 - mae: 0.1455 - val_loss: 1.3064 - val_mae: 0.7500\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0472 - mae: 0.1396 - val_loss: 1.2762 - val_mae: 0.7488\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0592 - mae: 0.1523 - val_loss: 1.2892 - val_mae: 0.7509\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0488 - mae: 0.1432 - val_loss: 1.3186 - val_mae: 0.7515\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0535 - mae: 0.1463 - val_loss: 1.3172 - val_mae: 0.7470\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0423 - mae: 0.1343 - val_loss: 1.2681 - val_mae: 0.7417\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0397 - mae: 0.1306 - val_loss: 1.2852 - val_mae: 0.7498\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0455 - mae: 0.1330 - val_loss: 1.3064 - val_mae: 0.7537\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0441 - mae: 0.1354 - val_loss: 1.2824 - val_mae: 0.7455\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0521 - mae: 0.1448 - val_loss: 1.2885 - val_mae: 0.7509\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0447 - mae: 0.1321 - val_loss: 1.3246 - val_mae: 0.7487\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0443 - mae: 0.1280 - val_loss: 1.2930 - val_mae: 0.7458\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0442 - mae: 0.1256 - val_loss: 1.2884 - val_mae: 0.7450\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0388 - mae: 0.1299 - val_loss: 1.3292 - val_mae: 0.7494\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0520 - mae: 0.1355 - val_loss: 1.2548 - val_mae: 0.7486\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.1225 - val_loss: 1.2573 - val_mae: 0.7417\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0380 - mae: 0.1230 - val_loss: 1.2962 - val_mae: 0.7471\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0386 - mae: 0.1186 - val_loss: 1.2914 - val_mae: 0.7428\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0436 - mae: 0.1252 - val_loss: 1.3135 - val_mae: 0.7477\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0317 - mae: 0.1156 - val_loss: 1.3191 - val_mae: 0.7547\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0412 - mae: 0.1269 - val_loss: 1.3212 - val_mae: 0.7462\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0395 - mae: 0.1235 - val_loss: 1.2986 - val_mae: 0.7482\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0416 - mae: 0.1300 - val_loss: 1.3144 - val_mae: 0.7491\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0542 - mae: 0.1315 - val_loss: 1.3653 - val_mae: 0.7552\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0394 - mae: 0.1197 - val_loss: 1.3191 - val_mae: 0.7500\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0353 - mae: 0.1175 - val_loss: 1.2980 - val_mae: 0.7427\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0326 - mae: 0.1120 - val_loss: 1.3628 - val_mae: 0.7476\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0258 - mae: 0.1039 - val_loss: 1.3795 - val_mae: 0.7479\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0324 - mae: 0.1135 - val_loss: 1.3120 - val_mae: 0.7521\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0281 - mae: 0.1079 - val_loss: 1.3294 - val_mae: 0.7486\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0373 - mae: 0.1085 - val_loss: 1.3406 - val_mae: 0.7506\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0292 - mae: 0.1123 - val_loss: 1.4520 - val_mae: 0.7605\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0515 - mae: 0.1221 - val_loss: 1.3044 - val_mae: 0.7459\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0336 - mae: 0.1138 - val_loss: 1.3433 - val_mae: 0.7596\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0283 - mae: 0.1081 - val_loss: 1.2720 - val_mae: 0.7424\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0283 - mae: 0.1076 - val_loss: 1.3683 - val_mae: 0.7572\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0620 - mae: 0.1392 - val_loss: 1.3176 - val_mae: 0.7512\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0309 - mae: 0.1102 - val_loss: 1.3026 - val_mae: 0.7412\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0286 - mae: 0.1026 - val_loss: 1.3236 - val_mae: 0.7418\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0351 - mae: 0.1122 - val_loss: 1.2992 - val_mae: 0.7411\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0257 - mae: 0.0986 - val_loss: 1.3340 - val_mae: 0.7437\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0223 - mae: 0.0986 - val_loss: 1.3441 - val_mae: 0.7444\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.0963 - val_loss: 1.3031 - val_mae: 0.7460\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.0979 - val_loss: 1.2629 - val_mae: 0.7434\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0312 - mae: 0.1056 - val_loss: 1.3139 - val_mae: 0.7413\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.1036 - val_loss: 1.3039 - val_mae: 0.7394\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0274 - mae: 0.1060 - val_loss: 1.2776 - val_mae: 0.7409\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0395 - mae: 0.1120 - val_loss: 1.3108 - val_mae: 0.7428\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0259 - mae: 0.1027 - val_loss: 1.3031 - val_mae: 0.7412\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0216 - mae: 0.0981 - val_loss: 1.3247 - val_mae: 0.7469\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0929 - val_loss: 1.2613 - val_mae: 0.7413\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0243 - mae: 0.0986 - val_loss: 1.3397 - val_mae: 0.7482\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0231 - mae: 0.1001 - val_loss: 1.2998 - val_mae: 0.7410\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0265 - mae: 0.1040 - val_loss: 1.2920 - val_mae: 0.7415\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0239 - mae: 0.1010 - val_loss: 1.3217 - val_mae: 0.7459\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0268 - mae: 0.0982 - val_loss: 1.2938 - val_mae: 0.7431\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0358 - mae: 0.1022 - val_loss: 1.3319 - val_mae: 0.7440\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0314 - mae: 0.1018 - val_loss: 1.2952 - val_mae: 0.7437\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0267 - mae: 0.0950 - val_loss: 1.3460 - val_mae: 0.7452\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0283 - mae: 0.1050 - val_loss: 1.3128 - val_mae: 0.7409\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0257 - mae: 0.0957 - val_loss: 1.3259 - val_mae: 0.7433\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0225 - mae: 0.0970 - val_loss: 1.2867 - val_mae: 0.7436\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0253 - mae: 0.0971 - val_loss: 1.3080 - val_mae: 0.7465\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0254 - mae: 0.0919 - val_loss: 1.3261 - val_mae: 0.7419\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.0858 - val_loss: 1.3213 - val_mae: 0.7441\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0869 - val_loss: 1.3095 - val_mae: 0.7430\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0863 - val_loss: 1.3520 - val_mae: 0.7445\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0920 - val_loss: 1.3055 - val_mae: 0.7476\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0259 - mae: 0.0962 - val_loss: 1.3908 - val_mae: 0.7489\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.0925 - val_loss: 1.3304 - val_mae: 0.7479\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0873 - val_loss: 1.3670 - val_mae: 0.7485\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0883 - val_loss: 1.3388 - val_mae: 0.7433\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0227 - mae: 0.0914 - val_loss: 1.3451 - val_mae: 0.7418\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0873 - val_loss: 1.3164 - val_mae: 0.7362\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0845 - val_loss: 1.3368 - val_mae: 0.7474\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0866 - val_loss: 1.3544 - val_mae: 0.7414\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0917 - val_loss: 1.3579 - val_mae: 0.7428\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0874 - val_loss: 1.3563 - val_mae: 0.7482\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0224 - mae: 0.0947 - val_loss: 1.3422 - val_mae: 0.7398\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0159 - mae: 0.0782 - val_loss: 1.3578 - val_mae: 0.7443\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0267 - mae: 0.0877 - val_loss: 1.3784 - val_mae: 0.7500\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0204 - mae: 0.0867 - val_loss: 1.3213 - val_mae: 0.7380\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167 - mae: 0.0794 - val_loss: 1.3745 - val_mae: 0.7473\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0867 - val_loss: 1.3129 - val_mae: 0.7413\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - mae: 0.0823 - val_loss: 1.3402 - val_mae: 0.7448\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0815 - val_loss: 1.3545 - val_mae: 0.7414\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0919 - val_loss: 1.3457 - val_mae: 0.7458\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0212 - mae: 0.0855 - val_loss: 1.2971 - val_mae: 0.7358\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0850 - val_loss: 1.3473 - val_mae: 0.7451\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0845 - val_loss: 1.3217 - val_mae: 0.7409\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.0816 - val_loss: 1.3194 - val_mae: 0.7407\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184 - mae: 0.0834 - val_loss: 1.4145 - val_mae: 0.7461\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0867 - val_loss: 1.3124 - val_mae: 0.7331\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0855 - val_loss: 1.3525 - val_mae: 0.7404\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163 - mae: 0.0798 - val_loss: 1.3075 - val_mae: 0.7364\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0211 - mae: 0.0857 - val_loss: 1.3285 - val_mae: 0.7423\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0755 - val_loss: 1.3296 - val_mae: 0.7420\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0152 - mae: 0.0746 - val_loss: 1.3229 - val_mae: 0.7353\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0149 - mae: 0.0726 - val_loss: 1.2831 - val_mae: 0.7395\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0768 - val_loss: 1.3475 - val_mae: 0.7395\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0823 - val_loss: 1.3157 - val_mae: 0.7399\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0158 - mae: 0.0804 - val_loss: 1.3286 - val_mae: 0.7396\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0157 - mae: 0.0761 - val_loss: 1.3338 - val_mae: 0.7408\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0814 - val_loss: 1.3344 - val_mae: 0.7458\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163 - mae: 0.0769 - val_loss: 1.3056 - val_mae: 0.7339\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0159 - mae: 0.0775 - val_loss: 1.4368 - val_mae: 0.7448\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0247 - mae: 0.0851 - val_loss: 1.3289 - val_mae: 0.7377\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0790 - val_loss: 1.3627 - val_mae: 0.7416\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0780 - val_loss: 1.3634 - val_mae: 0.7393\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0146 - mae: 0.0763 - val_loss: 1.3258 - val_mae: 0.7433\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0778 - val_loss: 1.3332 - val_mae: 0.7406\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0730 - val_loss: 1.3204 - val_mae: 0.7380\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0727 - val_loss: 1.2850 - val_mae: 0.7323\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0706 - val_loss: 1.3712 - val_mae: 0.7413\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0799 - val_loss: 1.3276 - val_mae: 0.7401\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0794 - val_loss: 1.3539 - val_mae: 0.7418\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167 - mae: 0.0800 - val_loss: 1.2932 - val_mae: 0.7360\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0772 - val_loss: 1.3532 - val_mae: 0.7374\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0789 - val_loss: 1.2923 - val_mae: 0.7398\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0705 - val_loss: 1.3058 - val_mae: 0.7387\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0728 - val_loss: 1.3541 - val_mae: 0.7400\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0149 - mae: 0.0714 - val_loss: 1.3003 - val_mae: 0.7381\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0718 - val_loss: 1.3191 - val_mae: 0.7409\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0714 - val_loss: 1.3058 - val_mae: 0.7388\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0762 - val_loss: 1.3177 - val_mae: 0.7365\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0743 - val_loss: 1.2878 - val_mae: 0.7390\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0714 - val_loss: 1.3376 - val_mae: 0.7423\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0787 - val_loss: 1.2865 - val_mae: 0.7297\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0724 - val_loss: 1.3321 - val_mae: 0.7428\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167 - mae: 0.0770 - val_loss: 1.3055 - val_mae: 0.7337\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162 - mae: 0.0776 - val_loss: 1.3027 - val_mae: 0.7351\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0169 - mae: 0.0727 - val_loss: 1.2900 - val_mae: 0.7382\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0683 - val_loss: 1.3009 - val_mae: 0.7365\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0682 - val_loss: 1.3178 - val_mae: 0.7385\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0698 - val_loss: 1.3211 - val_mae: 0.7347\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0729 - val_loss: 1.3330 - val_mae: 0.7346\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0688 - val_loss: 1.2905 - val_mae: 0.7308\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0641 - val_loss: 1.3500 - val_mae: 0.7345\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0750 - val_loss: 1.2717 - val_mae: 0.7282\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0768 - val_loss: 1.3217 - val_mae: 0.7375\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0712 - val_loss: 1.2856 - val_mae: 0.7346\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0716 - val_loss: 1.2731 - val_mae: 0.7328\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0705 - val_loss: 1.3473 - val_mae: 0.7366\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0699 - val_loss: 1.2941 - val_mae: 0.7330\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0725 - val_loss: 1.3332 - val_mae: 0.7372\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0665 - val_loss: 1.2966 - val_mae: 0.7351\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0639 - val_loss: 1.3721 - val_mae: 0.7393\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0687 - val_loss: 1.4126 - val_mae: 0.7359\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0740 - val_loss: 1.3097 - val_mae: 0.7375\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3129 - mae: 0.7300\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 4.4512 - mae: 1.5289 - val_loss: 2.4253 - val_mae: 1.0507\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3204 - mae: 0.8151 - val_loss: 1.9505 - val_mae: 0.9276\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.9497 - mae: 0.6665 - val_loss: 1.7578 - val_mae: 0.8686\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6404 - mae: 0.5606 - val_loss: 1.7936 - val_mae: 0.8689\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.4502 - mae: 0.4644 - val_loss: 2.4725 - val_mae: 0.8913\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3954 - mae: 0.4197 - val_loss: 1.6109 - val_mae: 0.8382\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3348 - mae: 0.3775 - val_loss: 1.7261 - val_mae: 0.8315\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2541 - mae: 0.3300 - val_loss: 1.7633 - val_mae: 0.8806\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2616 - mae: 0.3348 - val_loss: 1.6619 - val_mae: 0.8222\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2161 - mae: 0.3037 - val_loss: 1.5898 - val_mae: 0.8046\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2072 - mae: 0.2964 - val_loss: 1.6449 - val_mae: 0.8111\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1988 - mae: 0.2849 - val_loss: 1.5616 - val_mae: 0.8090\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1834 - mae: 0.2821 - val_loss: 1.6019 - val_mae: 0.8004\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1679 - mae: 0.2690 - val_loss: 1.6125 - val_mae: 0.8139\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1796 - mae: 0.2690 - val_loss: 1.5227 - val_mae: 0.8017\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1738 - mae: 0.2602 - val_loss: 1.5211 - val_mae: 0.8029\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1444 - mae: 0.2485 - val_loss: 1.5924 - val_mae: 0.8138\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2272 - mae: 0.2785 - val_loss: 1.6421 - val_mae: 0.7979\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1462 - mae: 0.2443 - val_loss: 1.6491 - val_mae: 0.7992\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1205 - mae: 0.2287 - val_loss: 1.5513 - val_mae: 0.8020\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1169 - mae: 0.2159 - val_loss: 1.5643 - val_mae: 0.7860\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1022 - mae: 0.2021 - val_loss: 1.4951 - val_mae: 0.7826\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0972 - mae: 0.2030 - val_loss: 1.5804 - val_mae: 0.8012\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1203 - mae: 0.2146 - val_loss: 1.5175 - val_mae: 0.7918\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0926 - mae: 0.2005 - val_loss: 1.4816 - val_mae: 0.7736\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0947 - mae: 0.2030 - val_loss: 1.4600 - val_mae: 0.7793\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0940 - mae: 0.1965 - val_loss: 1.4233 - val_mae: 0.7707\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0917 - mae: 0.1936 - val_loss: 1.4744 - val_mae: 0.7796\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0997 - mae: 0.1961 - val_loss: 1.4855 - val_mae: 0.7846\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0908 - mae: 0.1883 - val_loss: 1.4353 - val_mae: 0.7718\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0847 - mae: 0.1843 - val_loss: 1.4658 - val_mae: 0.7810\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0805 - mae: 0.1815 - val_loss: 1.4092 - val_mae: 0.7702\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0834 - mae: 0.1850 - val_loss: 1.4612 - val_mae: 0.7838\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0766 - mae: 0.1786 - val_loss: 1.4916 - val_mae: 0.7663\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0751 - mae: 0.1771 - val_loss: 1.4449 - val_mae: 0.7787\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0707 - mae: 0.1686 - val_loss: 1.4563 - val_mae: 0.7764\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0733 - mae: 0.1755 - val_loss: 1.4473 - val_mae: 0.7711\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0643 - mae: 0.1648 - val_loss: 1.5091 - val_mae: 0.7732\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0743 - mae: 0.1689 - val_loss: 1.4460 - val_mae: 0.7753\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0677 - mae: 0.1631 - val_loss: 1.4260 - val_mae: 0.7698\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0608 - mae: 0.1612 - val_loss: 1.4737 - val_mae: 0.7813\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0584 - mae: 0.1586 - val_loss: 1.4608 - val_mae: 0.7728\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0885 - mae: 0.1733 - val_loss: 1.4113 - val_mae: 0.7729\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0724 - mae: 0.1574 - val_loss: 1.4571 - val_mae: 0.7754\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0573 - mae: 0.1479 - val_loss: 1.4174 - val_mae: 0.7679\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0515 - mae: 0.1458 - val_loss: 1.4969 - val_mae: 0.7705\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0512 - mae: 0.1414 - val_loss: 1.3778 - val_mae: 0.7666\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0526 - mae: 0.1483 - val_loss: 1.4018 - val_mae: 0.7706\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0669 - mae: 0.1544 - val_loss: 1.4754 - val_mae: 0.7746\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0521 - mae: 0.1493 - val_loss: 1.4998 - val_mae: 0.7761\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0529 - mae: 0.1468 - val_loss: 1.4676 - val_mae: 0.7807\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0443 - mae: 0.1350 - val_loss: 1.4785 - val_mae: 0.7754\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0430 - mae: 0.1357 - val_loss: 1.4714 - val_mae: 0.7746\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0466 - mae: 0.1337 - val_loss: 1.4579 - val_mae: 0.7695\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0558 - mae: 0.1375 - val_loss: 1.4521 - val_mae: 0.7797\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0459 - mae: 0.1384 - val_loss: 1.4529 - val_mae: 0.7726\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0466 - mae: 0.1328 - val_loss: 1.4738 - val_mae: 0.7747\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0476 - mae: 0.1365 - val_loss: 1.3959 - val_mae: 0.7625\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0409 - mae: 0.1331 - val_loss: 1.4638 - val_mae: 0.7760\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0458 - mae: 0.1378 - val_loss: 1.4212 - val_mae: 0.7712\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0409 - mae: 0.1280 - val_loss: 1.4582 - val_mae: 0.7794\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.1255 - val_loss: 1.4216 - val_mae: 0.7681\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0379 - mae: 0.1242 - val_loss: 1.4619 - val_mae: 0.7716\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0363 - mae: 0.1249 - val_loss: 1.4149 - val_mae: 0.7677\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.1214 - val_loss: 1.4420 - val_mae: 0.7706\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0399 - mae: 0.1305 - val_loss: 1.3958 - val_mae: 0.7689\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0371 - mae: 0.1186 - val_loss: 1.4274 - val_mae: 0.7768\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0406 - mae: 0.1224 - val_loss: 1.4184 - val_mae: 0.7658\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0347 - mae: 0.1154 - val_loss: 1.4242 - val_mae: 0.7706\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0375 - mae: 0.1217 - val_loss: 1.4440 - val_mae: 0.7700\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0389 - mae: 0.1235 - val_loss: 1.4758 - val_mae: 0.7712\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0324 - mae: 0.1168 - val_loss: 1.4124 - val_mae: 0.7678\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.1160 - val_loss: 1.3981 - val_mae: 0.7624\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0341 - mae: 0.1184 - val_loss: 1.4406 - val_mae: 0.7679\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0382 - mae: 0.1201 - val_loss: 1.4372 - val_mae: 0.7709\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0328 - mae: 0.1092 - val_loss: 1.4075 - val_mae: 0.7647\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0286 - mae: 0.1063 - val_loss: 1.4285 - val_mae: 0.7716\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1106 - val_loss: 1.4570 - val_mae: 0.7779\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0276 - mae: 0.1129 - val_loss: 1.3911 - val_mae: 0.7697\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1144 - val_loss: 1.4436 - val_mae: 0.7731\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.1086 - val_loss: 1.4363 - val_mae: 0.7702\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0309 - mae: 0.1106 - val_loss: 1.4311 - val_mae: 0.7682\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0275 - mae: 0.1040 - val_loss: 1.4395 - val_mae: 0.7665\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0305 - mae: 0.1044 - val_loss: 1.4339 - val_mae: 0.7655\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.1105 - val_loss: 1.4457 - val_mae: 0.7684\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0267 - mae: 0.1031 - val_loss: 1.4494 - val_mae: 0.7708\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.1042 - val_loss: 1.4510 - val_mae: 0.7712\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0266 - mae: 0.1044 - val_loss: 1.4522 - val_mae: 0.7729\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0252 - mae: 0.1006 - val_loss: 1.4063 - val_mae: 0.7648\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0268 - mae: 0.1032 - val_loss: 1.4468 - val_mae: 0.7680\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0331 - mae: 0.1132 - val_loss: 1.4163 - val_mae: 0.7652\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0295 - mae: 0.1042 - val_loss: 1.3867 - val_mae: 0.7660\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0273 - mae: 0.1016 - val_loss: 1.4313 - val_mae: 0.7644\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.0962 - val_loss: 1.4133 - val_mae: 0.7662\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1163 - val_loss: 1.4168 - val_mae: 0.7608\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0233 - mae: 0.0987 - val_loss: 1.4493 - val_mae: 0.7746\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0228 - mae: 0.0956 - val_loss: 1.4258 - val_mae: 0.7676\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0244 - mae: 0.0913 - val_loss: 1.4301 - val_mae: 0.7682\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.0945 - val_loss: 1.3896 - val_mae: 0.7600\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.1010 - val_loss: 1.5231 - val_mae: 0.7745\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0256 - mae: 0.1005 - val_loss: 1.4385 - val_mae: 0.7680\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0255 - mae: 0.0948 - val_loss: 1.4555 - val_mae: 0.7635\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0218 - mae: 0.0939 - val_loss: 1.4142 - val_mae: 0.7624\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0224 - mae: 0.0909 - val_loss: 1.4088 - val_mae: 0.7677\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0263 - mae: 0.0917 - val_loss: 1.4310 - val_mae: 0.7625\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0234 - mae: 0.0949 - val_loss: 1.4017 - val_mae: 0.7663\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0224 - mae: 0.0971 - val_loss: 1.4315 - val_mae: 0.7605\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0206 - mae: 0.0924 - val_loss: 1.4163 - val_mae: 0.7616\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0905 - val_loss: 1.3992 - val_mae: 0.7598\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0893 - val_loss: 1.4212 - val_mae: 0.7698\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0249 - mae: 0.0996 - val_loss: 1.4027 - val_mae: 0.7677\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0249 - mae: 0.0954 - val_loss: 1.4761 - val_mae: 0.7674\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0211 - mae: 0.0917 - val_loss: 1.4287 - val_mae: 0.7693\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0850 - val_loss: 1.4571 - val_mae: 0.7654\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - mae: 0.0821 - val_loss: 1.4250 - val_mae: 0.7609\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0838 - val_loss: 1.4125 - val_mae: 0.7684\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0900 - val_loss: 1.4068 - val_mae: 0.7591\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0884 - val_loss: 1.4427 - val_mae: 0.7663\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0891 - val_loss: 1.4113 - val_mae: 0.7627\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0159 - mae: 0.0790 - val_loss: 1.4293 - val_mae: 0.7640\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0830 - val_loss: 1.4463 - val_mae: 0.7706\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0918 - val_loss: 1.4064 - val_mae: 0.7606\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0210 - mae: 0.0871 - val_loss: 1.4784 - val_mae: 0.7685\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0241 - mae: 0.0916 - val_loss: 1.4094 - val_mae: 0.7622\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0202 - mae: 0.0869 - val_loss: 1.4212 - val_mae: 0.7621\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0795 - val_loss: 1.4218 - val_mae: 0.7641\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0755 - val_loss: 1.4387 - val_mae: 0.7670\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0154 - mae: 0.0805 - val_loss: 1.4490 - val_mae: 0.7666\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0899 - val_loss: 1.4185 - val_mae: 0.7646\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0810 - val_loss: 1.4148 - val_mae: 0.7629\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0852 - val_loss: 1.4364 - val_mae: 0.7657\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0816 - val_loss: 1.4018 - val_mae: 0.7611\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0213 - mae: 0.0913 - val_loss: 1.4359 - val_mae: 0.7664\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0149 - mae: 0.0794 - val_loss: 1.3821 - val_mae: 0.7590\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0869 - val_loss: 1.4666 - val_mae: 0.7645\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0216 - mae: 0.0868 - val_loss: 1.4207 - val_mae: 0.7630\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0801 - val_loss: 1.4407 - val_mae: 0.7646\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0157 - mae: 0.0771 - val_loss: 1.4838 - val_mae: 0.7698\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0154 - mae: 0.0763 - val_loss: 1.4134 - val_mae: 0.7588\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0737 - val_loss: 1.4163 - val_mae: 0.7634\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0762 - val_loss: 1.4342 - val_mae: 0.7648\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0818 - val_loss: 1.4191 - val_mae: 0.7647\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199 - mae: 0.0894 - val_loss: 1.4080 - val_mae: 0.7648\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0815 - val_loss: 1.4351 - val_mae: 0.7667\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0160 - mae: 0.0792 - val_loss: 1.4033 - val_mae: 0.7596\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0139 - mae: 0.0764 - val_loss: 1.4362 - val_mae: 0.7627\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0758 - val_loss: 1.4189 - val_mae: 0.7619\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0720 - val_loss: 1.4078 - val_mae: 0.7617\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0725 - val_loss: 1.4405 - val_mae: 0.7640\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0169 - mae: 0.0834 - val_loss: 1.4236 - val_mae: 0.7637\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0793 - val_loss: 1.4522 - val_mae: 0.7639\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0146 - mae: 0.0748 - val_loss: 1.4180 - val_mae: 0.7673\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0757 - val_loss: 1.4313 - val_mae: 0.7647\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0736 - val_loss: 1.4124 - val_mae: 0.7598\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0705 - val_loss: 1.4356 - val_mae: 0.7621\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0728 - val_loss: 1.4034 - val_mae: 0.7565\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0812 - val_loss: 1.4441 - val_mae: 0.7698\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0743 - val_loss: 1.4185 - val_mae: 0.7607\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0151 - mae: 0.0764 - val_loss: 1.4095 - val_mae: 0.7657\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0743 - val_loss: 1.4484 - val_mae: 0.7665\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0759 - val_loss: 1.4005 - val_mae: 0.7562\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0158 - mae: 0.0753 - val_loss: 1.4211 - val_mae: 0.7636\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0144 - mae: 0.0728 - val_loss: 1.4141 - val_mae: 0.7607\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0693 - val_loss: 1.4579 - val_mae: 0.7631\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0693 - val_loss: 1.4080 - val_mae: 0.7573\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0707 - val_loss: 1.4517 - val_mae: 0.7592\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0156 - mae: 0.0774 - val_loss: 1.4288 - val_mae: 0.7642\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0777 - val_loss: 1.4728 - val_mae: 0.7628\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0211 - mae: 0.0835 - val_loss: 1.4212 - val_mae: 0.7605\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0729 - val_loss: 1.4188 - val_mae: 0.7588\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0663 - val_loss: 1.4222 - val_mae: 0.7605\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0665 - val_loss: 1.4485 - val_mae: 0.7654\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0763 - val_loss: 1.4534 - val_mae: 0.7637\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0757 - val_loss: 1.4455 - val_mae: 0.7597\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184 - mae: 0.0755 - val_loss: 1.4105 - val_mae: 0.7637\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0685 - val_loss: 1.4130 - val_mae: 0.7629\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0668 - val_loss: 1.4215 - val_mae: 0.7593\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0663 - val_loss: 1.4446 - val_mae: 0.7629\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0732 - val_loss: 1.4080 - val_mae: 0.7586\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0686 - val_loss: 1.4177 - val_mae: 0.7597\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167 - mae: 0.0726 - val_loss: 1.4257 - val_mae: 0.7624\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178 - mae: 0.0755 - val_loss: 1.4356 - val_mae: 0.7623\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0723 - val_loss: 1.4140 - val_mae: 0.7558\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0659 - val_loss: 1.4287 - val_mae: 0.7607\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0690 - val_loss: 1.4013 - val_mae: 0.7598\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0709 - val_loss: 1.4464 - val_mae: 0.7604\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0676 - val_loss: 1.4128 - val_mae: 0.7610\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0113 - mae: 0.0693 - val_loss: 1.3983 - val_mae: 0.7568\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0668 - val_loss: 1.4449 - val_mae: 0.7605\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0703 - val_loss: 1.4158 - val_mae: 0.7596\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162 - mae: 0.0720 - val_loss: 1.4283 - val_mae: 0.7597\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0684 - val_loss: 1.4180 - val_mae: 0.7594\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0660 - val_loss: 1.4167 - val_mae: 0.7583\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0648 - val_loss: 1.4495 - val_mae: 0.7604\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0698 - val_loss: 1.3958 - val_mae: 0.7551\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0656 - val_loss: 1.4438 - val_mae: 0.7666\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0148 - mae: 0.0763 - val_loss: 1.4211 - val_mae: 0.7561\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0116 - mae: 0.0661 - val_loss: 1.4128 - val_mae: 0.7624\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0681 - val_loss: 1.4364 - val_mae: 0.7610\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0677 - val_loss: 1.3921 - val_mae: 0.7563\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3576 - mae: 0.7519\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 5.0330 - mae: 1.5550 - val_loss: 2.4296 - val_mae: 1.0438\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.3852 - mae: 0.8440 - val_loss: 2.0253 - val_mae: 0.9477\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.8441 - mae: 0.6494 - val_loss: 1.9700 - val_mae: 0.9170\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6302 - mae: 0.5540 - val_loss: 1.6564 - val_mae: 0.8463\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5089 - mae: 0.4803 - val_loss: 1.5898 - val_mae: 0.8498\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3472 - mae: 0.3961 - val_loss: 1.7451 - val_mae: 0.8423\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2894 - mae: 0.3599 - val_loss: 1.5639 - val_mae: 0.8481\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2583 - mae: 0.3322 - val_loss: 1.5932 - val_mae: 0.8369\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2152 - mae: 0.3120 - val_loss: 1.5856 - val_mae: 0.8539\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2271 - mae: 0.3020 - val_loss: 1.6144 - val_mae: 0.8273\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2094 - mae: 0.2866 - val_loss: 1.5677 - val_mae: 0.8413\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1873 - mae: 0.2851 - val_loss: 1.6159 - val_mae: 0.8360\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2219 - mae: 0.2913 - val_loss: 1.5652 - val_mae: 0.8281\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1604 - mae: 0.2634 - val_loss: 1.4642 - val_mae: 0.8296\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1582 - mae: 0.2555 - val_loss: 1.4537 - val_mae: 0.8201\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1394 - mae: 0.2451 - val_loss: 1.4786 - val_mae: 0.8265\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1359 - mae: 0.2448 - val_loss: 1.6043 - val_mae: 0.8182\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1384 - mae: 0.2527 - val_loss: 1.5256 - val_mae: 0.8144\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1262 - mae: 0.2385 - val_loss: 1.5441 - val_mae: 0.8094\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1529 - mae: 0.2538 - val_loss: 1.5554 - val_mae: 0.8097\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1300 - mae: 0.2328 - val_loss: 1.5364 - val_mae: 0.8089\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1386 - mae: 0.2258 - val_loss: 1.5152 - val_mae: 0.8096\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1206 - mae: 0.2292 - val_loss: 1.5108 - val_mae: 0.8119\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1117 - mae: 0.2132 - val_loss: 1.5778 - val_mae: 0.8100\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0870 - mae: 0.1967 - val_loss: 1.4151 - val_mae: 0.7965\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0870 - mae: 0.1901 - val_loss: 1.4939 - val_mae: 0.8054\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0777 - mae: 0.1802 - val_loss: 1.5310 - val_mae: 0.8032\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0836 - mae: 0.1872 - val_loss: 1.4538 - val_mae: 0.8035\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0862 - mae: 0.1926 - val_loss: 1.4700 - val_mae: 0.7925\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1044 - mae: 0.1997 - val_loss: 1.5289 - val_mae: 0.8031\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0928 - mae: 0.1923 - val_loss: 1.4557 - val_mae: 0.7972\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0736 - mae: 0.1770 - val_loss: 1.4364 - val_mae: 0.7969\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0839 - mae: 0.1815 - val_loss: 1.5055 - val_mae: 0.8058\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0675 - mae: 0.1718 - val_loss: 1.4574 - val_mae: 0.7965\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0708 - mae: 0.1727 - val_loss: 1.4714 - val_mae: 0.7926\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0649 - mae: 0.1651 - val_loss: 1.4451 - val_mae: 0.7866\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0615 - mae: 0.1612 - val_loss: 1.5167 - val_mae: 0.8004\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0637 - mae: 0.1627 - val_loss: 1.4919 - val_mae: 0.7985\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0650 - mae: 0.1609 - val_loss: 1.4833 - val_mae: 0.7981\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0605 - mae: 0.1634 - val_loss: 1.4176 - val_mae: 0.7935\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0589 - mae: 0.1582 - val_loss: 1.5006 - val_mae: 0.7993\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0714 - mae: 0.1717 - val_loss: 1.4948 - val_mae: 0.7939\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0512 - mae: 0.1480 - val_loss: 1.4639 - val_mae: 0.7897\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0512 - mae: 0.1456 - val_loss: 1.5073 - val_mae: 0.7942\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0480 - mae: 0.1437 - val_loss: 1.4528 - val_mae: 0.7918\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0472 - mae: 0.1401 - val_loss: 1.4871 - val_mae: 0.7942\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0495 - mae: 0.1443 - val_loss: 1.4431 - val_mae: 0.7890\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0956 - mae: 0.1755 - val_loss: 1.4945 - val_mae: 0.7969\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0535 - mae: 0.1493 - val_loss: 1.4945 - val_mae: 0.8020\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0405 - mae: 0.1347 - val_loss: 1.4931 - val_mae: 0.7910\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0376 - mae: 0.1256 - val_loss: 1.4650 - val_mae: 0.7943\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1218 - val_loss: 1.4515 - val_mae: 0.7945\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0440 - mae: 0.1338 - val_loss: 1.4810 - val_mae: 0.7936\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0499 - mae: 0.1413 - val_loss: 1.4609 - val_mae: 0.7882\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0443 - mae: 0.1386 - val_loss: 1.5299 - val_mae: 0.7973\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0420 - mae: 0.1299 - val_loss: 1.4690 - val_mae: 0.7971\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0439 - mae: 0.1322 - val_loss: 1.5060 - val_mae: 0.7955\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0405 - mae: 0.1245 - val_loss: 1.4661 - val_mae: 0.7945\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0431 - mae: 0.1219 - val_loss: 1.4501 - val_mae: 0.7933\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1181 - val_loss: 1.4361 - val_mae: 0.7831\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0346 - mae: 0.1220 - val_loss: 1.4653 - val_mae: 0.7920\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1210 - val_loss: 1.4564 - val_mae: 0.7912\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0350 - mae: 0.1234 - val_loss: 1.4814 - val_mae: 0.7922\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0455 - mae: 0.1288 - val_loss: 1.4368 - val_mae: 0.7878\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0357 - mae: 0.1221 - val_loss: 1.4911 - val_mae: 0.7915\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0318 - mae: 0.1147 - val_loss: 1.4416 - val_mae: 0.7876\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0394 - mae: 0.1194 - val_loss: 1.4489 - val_mae: 0.7909\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0303 - mae: 0.1133 - val_loss: 1.4574 - val_mae: 0.7887\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0338 - mae: 0.1183 - val_loss: 1.4595 - val_mae: 0.7999\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0328 - mae: 0.1154 - val_loss: 1.4821 - val_mae: 0.7876\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1222 - val_loss: 1.4639 - val_mae: 0.7912\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0322 - mae: 0.1091 - val_loss: 1.4368 - val_mae: 0.7830\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0314 - mae: 0.1137 - val_loss: 1.4578 - val_mae: 0.7857\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0298 - mae: 0.1109 - val_loss: 1.4822 - val_mae: 0.7821\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0257 - mae: 0.1061 - val_loss: 1.4306 - val_mae: 0.7809\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0329 - mae: 0.1106 - val_loss: 1.4749 - val_mae: 0.7903\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0376 - mae: 0.1187 - val_loss: 1.4298 - val_mae: 0.7822\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0296 - mae: 0.1085 - val_loss: 1.4798 - val_mae: 0.7907\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0319 - mae: 0.1101 - val_loss: 1.4534 - val_mae: 0.7881\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0227 - mae: 0.0983 - val_loss: 1.4808 - val_mae: 0.7894\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0242 - mae: 0.0998 - val_loss: 1.4506 - val_mae: 0.7881\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0254 - mae: 0.1025 - val_loss: 1.4609 - val_mae: 0.7884\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0244 - mae: 0.1023 - val_loss: 1.4569 - val_mae: 0.7859\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0254 - mae: 0.1040 - val_loss: 1.4813 - val_mae: 0.7870\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0223 - mae: 0.0991 - val_loss: 1.4914 - val_mae: 0.7937\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0260 - mae: 0.1046 - val_loss: 1.4591 - val_mae: 0.7841\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0228 - mae: 0.0995 - val_loss: 1.4776 - val_mae: 0.7875\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0225 - mae: 0.0966 - val_loss: 1.4796 - val_mae: 0.7864\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.0983 - val_loss: 1.4622 - val_mae: 0.7851\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0959 - val_loss: 1.4484 - val_mae: 0.7854\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0203 - mae: 0.0945 - val_loss: 1.4592 - val_mae: 0.7829\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0233 - mae: 0.0979 - val_loss: 1.4266 - val_mae: 0.7829\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0214 - mae: 0.0971 - val_loss: 1.4572 - val_mae: 0.7850\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0205 - mae: 0.0915 - val_loss: 1.4424 - val_mae: 0.7862\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0913 - val_loss: 1.4361 - val_mae: 0.7861\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0946 - val_loss: 1.4346 - val_mae: 0.7813\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0239 - mae: 0.0991 - val_loss: 1.4734 - val_mae: 0.7868\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0945 - val_loss: 1.4686 - val_mae: 0.7855\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0887 - val_loss: 1.4338 - val_mae: 0.7889\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0232 - mae: 0.0991 - val_loss: 1.4458 - val_mae: 0.7835\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0888 - val_loss: 1.4457 - val_mae: 0.7853\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0890 - val_loss: 1.4911 - val_mae: 0.7891\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0892 - val_loss: 1.4601 - val_mae: 0.7820\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0913 - val_loss: 1.4621 - val_mae: 0.7876\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0855 - val_loss: 1.4950 - val_mae: 0.7925\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0213 - mae: 0.0960 - val_loss: 1.4494 - val_mae: 0.7841\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0861 - val_loss: 1.4547 - val_mae: 0.7871\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0851 - val_loss: 1.4709 - val_mae: 0.7833\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0874 - val_loss: 1.4747 - val_mae: 0.7914\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0845 - val_loss: 1.4487 - val_mae: 0.7825\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0834 - val_loss: 1.4776 - val_mae: 0.7866\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0153 - mae: 0.0823 - val_loss: 1.4732 - val_mae: 0.7859\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0899 - val_loss: 1.4519 - val_mae: 0.7831\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178 - mae: 0.0851 - val_loss: 1.4913 - val_mae: 0.7887\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170 - mae: 0.0842 - val_loss: 1.5051 - val_mae: 0.7905\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0903 - val_loss: 1.4609 - val_mae: 0.7802\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0793 - val_loss: 1.4595 - val_mae: 0.7830\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175 - mae: 0.0859 - val_loss: 1.4841 - val_mae: 0.7859\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0915 - val_loss: 1.4612 - val_mae: 0.7836\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0768 - val_loss: 1.4758 - val_mae: 0.7838\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - mae: 0.0847 - val_loss: 1.4725 - val_mae: 0.7854\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184 - mae: 0.0853 - val_loss: 1.4503 - val_mae: 0.7816\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0856 - val_loss: 1.4576 - val_mae: 0.7848\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0158 - mae: 0.0806 - val_loss: 1.4896 - val_mae: 0.7881\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0810 - val_loss: 1.4505 - val_mae: 0.7853\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0843 - val_loss: 1.4755 - val_mae: 0.7844\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0741 - val_loss: 1.4393 - val_mae: 0.7791\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0742 - val_loss: 1.4623 - val_mae: 0.7813\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0139 - mae: 0.0770 - val_loss: 1.4454 - val_mae: 0.7809\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0139 - mae: 0.0753 - val_loss: 1.4735 - val_mae: 0.7813\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0147 - mae: 0.0797 - val_loss: 1.4642 - val_mae: 0.7854\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0164 - mae: 0.0808 - val_loss: 1.4406 - val_mae: 0.7785\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0149 - mae: 0.0808 - val_loss: 1.4760 - val_mae: 0.7846\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0148 - mae: 0.0785 - val_loss: 1.4747 - val_mae: 0.7858\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0754 - val_loss: 1.4488 - val_mae: 0.7852\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0732 - val_loss: 1.4650 - val_mae: 0.7844\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0769 - val_loss: 1.4522 - val_mae: 0.7823\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0809 - val_loss: 1.4537 - val_mae: 0.7819\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0773 - val_loss: 1.4489 - val_mae: 0.7838\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0738 - val_loss: 1.4672 - val_mae: 0.7852\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0149 - mae: 0.0789 - val_loss: 1.4580 - val_mae: 0.7803\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0730 - val_loss: 1.4644 - val_mae: 0.7813\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0721 - val_loss: 1.4563 - val_mae: 0.7847\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0728 - val_loss: 1.4683 - val_mae: 0.7849\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0735 - val_loss: 1.4505 - val_mae: 0.7819\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0694 - val_loss: 1.4433 - val_mae: 0.7773\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0739 - val_loss: 1.4504 - val_mae: 0.7834\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0776 - val_loss: 1.4363 - val_mae: 0.7827\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0146 - mae: 0.0772 - val_loss: 1.4493 - val_mae: 0.7813\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0687 - val_loss: 1.4451 - val_mae: 0.7812\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0107 - mae: 0.0683 - val_loss: 1.4525 - val_mae: 0.7842\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0691 - val_loss: 1.4567 - val_mae: 0.7829\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0680 - val_loss: 1.4393 - val_mae: 0.7795\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0713 - val_loss: 1.4502 - val_mae: 0.7819\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0718 - val_loss: 1.4430 - val_mae: 0.7795\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0694 - val_loss: 1.4834 - val_mae: 0.7866\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0709 - val_loss: 1.4406 - val_mae: 0.7817\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0775 - val_loss: 1.4628 - val_mae: 0.7816\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0744 - val_loss: 1.4587 - val_mae: 0.7791\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0692 - val_loss: 1.4719 - val_mae: 0.7828\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0626 - val_loss: 1.4539 - val_mae: 0.7787\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0681 - val_loss: 1.4278 - val_mae: 0.7772\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0135 - mae: 0.0739 - val_loss: 1.4713 - val_mae: 0.7839\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0116 - mae: 0.0695 - val_loss: 1.4503 - val_mae: 0.7840\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0648 - val_loss: 1.4412 - val_mae: 0.7772\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0648 - val_loss: 1.4719 - val_mae: 0.7824\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0776 - val_loss: 1.4691 - val_mae: 0.7807\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0121 - mae: 0.0717 - val_loss: 1.4594 - val_mae: 0.7806\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0670 - val_loss: 1.4689 - val_mae: 0.7814\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0620 - val_loss: 1.4181 - val_mae: 0.7791\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0128 - mae: 0.0700 - val_loss: 1.4723 - val_mae: 0.7846\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0680 - val_loss: 1.4574 - val_mae: 0.7813\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0096 - mae: 0.0644 - val_loss: 1.4613 - val_mae: 0.7855\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0762 - val_loss: 1.4668 - val_mae: 0.7785\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0671 - val_loss: 1.4566 - val_mae: 0.7851\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0664 - val_loss: 1.4589 - val_mae: 0.7853\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0101 - mae: 0.0649 - val_loss: 1.4431 - val_mae: 0.7808\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0662 - val_loss: 1.4440 - val_mae: 0.7799\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0661 - val_loss: 1.4776 - val_mae: 0.7804\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0123 - mae: 0.0701 - val_loss: 1.4554 - val_mae: 0.7837\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0672 - val_loss: 1.4397 - val_mae: 0.7816\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0636 - val_loss: 1.4512 - val_mae: 0.7809\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0673 - val_loss: 1.4447 - val_mae: 0.7759\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0092 - mae: 0.0607 - val_loss: 1.4510 - val_mae: 0.7804\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0628 - val_loss: 1.4570 - val_mae: 0.7763\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0714 - val_loss: 1.4531 - val_mae: 0.7792\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0641 - val_loss: 1.4365 - val_mae: 0.7798\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0653 - val_loss: 1.4399 - val_mae: 0.7785\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0634 - val_loss: 1.4313 - val_mae: 0.7786\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0100 - mae: 0.0638 - val_loss: 1.4368 - val_mae: 0.7770\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0621 - val_loss: 1.4229 - val_mae: 0.7794\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0095 - mae: 0.0621 - val_loss: 1.4385 - val_mae: 0.7799\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0090 - mae: 0.0627 - val_loss: 1.4137 - val_mae: 0.7781\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0629 - val_loss: 1.4388 - val_mae: 0.7780\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0644 - val_loss: 1.4250 - val_mae: 0.7755\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0084 - mae: 0.0606 - val_loss: 1.4380 - val_mae: 0.7757\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0094 - mae: 0.0621 - val_loss: 1.4097 - val_mae: 0.7758\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0645 - val_loss: 1.4203 - val_mae: 0.7785\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0629 - val_loss: 1.5041 - val_mae: 0.7859\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0663 - val_loss: 1.4522 - val_mae: 0.7809\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4203 - mae: 0.7700\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 4.5496 - mae: 1.5083 - val_loss: 2.3134 - val_mae: 0.9758\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 1.3872 - mae: 0.8082 - val_loss: 2.1940 - val_mae: 0.9319\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.8073 - mae: 0.6231 - val_loss: 1.5895 - val_mae: 0.8444\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.6112 - mae: 0.5425 - val_loss: 1.5936 - val_mae: 0.8262\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.4487 - mae: 0.4573 - val_loss: 1.5126 - val_mae: 0.8154\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3961 - mae: 0.4121 - val_loss: 1.6072 - val_mae: 0.8472\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3549 - mae: 0.4007 - val_loss: 1.4680 - val_mae: 0.8145\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2826 - mae: 0.3470 - val_loss: 1.5290 - val_mae: 0.8155\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2742 - mae: 0.3436 - val_loss: 1.5364 - val_mae: 0.7929\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2230 - mae: 0.3140 - val_loss: 1.6388 - val_mae: 0.8082\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2325 - mae: 0.3056 - val_loss: 1.4441 - val_mae: 0.7932\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1931 - mae: 0.2943 - val_loss: 1.5140 - val_mae: 0.7965\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2016 - mae: 0.2937 - val_loss: 1.4465 - val_mae: 0.7909\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1759 - mae: 0.2771 - val_loss: 1.5343 - val_mae: 0.8101\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1511 - mae: 0.2632 - val_loss: 1.5380 - val_mae: 0.7795\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1681 - mae: 0.2633 - val_loss: 1.4137 - val_mae: 0.7901\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1429 - mae: 0.2411 - val_loss: 1.3580 - val_mae: 0.7824\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1705 - mae: 0.2629 - val_loss: 1.4644 - val_mae: 0.7971\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1438 - mae: 0.2490 - val_loss: 1.6160 - val_mae: 0.7978\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2426 - mae: 0.2434 - val_loss: 1.3349 - val_mae: 0.7660\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1219 - mae: 0.2256 - val_loss: 1.3906 - val_mae: 0.7669\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1127 - mae: 0.2216 - val_loss: 1.3905 - val_mae: 0.7717\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0940 - mae: 0.2055 - val_loss: 1.3429 - val_mae: 0.7615\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1019 - mae: 0.2111 - val_loss: 1.3888 - val_mae: 0.7648\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1022 - mae: 0.2050 - val_loss: 1.3612 - val_mae: 0.7572\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0900 - mae: 0.1987 - val_loss: 1.3484 - val_mae: 0.7745\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1058 - mae: 0.2126 - val_loss: 1.3697 - val_mae: 0.7590\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1110 - mae: 0.2095 - val_loss: 1.3655 - val_mae: 0.7587\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0982 - mae: 0.1953 - val_loss: 1.3602 - val_mae: 0.7610\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0807 - mae: 0.1882 - val_loss: 1.4276 - val_mae: 0.7529\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0830 - mae: 0.1784 - val_loss: 1.3346 - val_mae: 0.7589\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0664 - mae: 0.1680 - val_loss: 1.3388 - val_mae: 0.7633\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0754 - mae: 0.1819 - val_loss: 1.3887 - val_mae: 0.7589\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0746 - mae: 0.1762 - val_loss: 1.3371 - val_mae: 0.7643\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0702 - mae: 0.1743 - val_loss: 1.3207 - val_mae: 0.7538\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0742 - mae: 0.1776 - val_loss: 1.3581 - val_mae: 0.7512\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0648 - mae: 0.1661 - val_loss: 1.3470 - val_mae: 0.7560\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0593 - mae: 0.1558 - val_loss: 1.3793 - val_mae: 0.7652\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0793 - mae: 0.1724 - val_loss: 1.3500 - val_mae: 0.7500\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0542 - mae: 0.1569 - val_loss: 1.3243 - val_mae: 0.7488\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0660 - mae: 0.1596 - val_loss: 1.3721 - val_mae: 0.7642\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0750 - mae: 0.1664 - val_loss: 1.2967 - val_mae: 0.7417\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0659 - mae: 0.1558 - val_loss: 1.3450 - val_mae: 0.7461\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0536 - mae: 0.1485 - val_loss: 1.3547 - val_mae: 0.7504\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0513 - mae: 0.1450 - val_loss: 1.2817 - val_mae: 0.7442\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0521 - mae: 0.1455 - val_loss: 1.3114 - val_mae: 0.7457\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0502 - mae: 0.1439 - val_loss: 1.3438 - val_mae: 0.7418\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0560 - mae: 0.1502 - val_loss: 1.4021 - val_mae: 0.7577\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0520 - mae: 0.1438 - val_loss: 1.3404 - val_mae: 0.7471\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0458 - mae: 0.1365 - val_loss: 1.3186 - val_mae: 0.7417\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0455 - mae: 0.1405 - val_loss: 1.3410 - val_mae: 0.7433\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0533 - mae: 0.1381 - val_loss: 1.3093 - val_mae: 0.7403\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0489 - mae: 0.1374 - val_loss: 1.3569 - val_mae: 0.7515\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0533 - mae: 0.1444 - val_loss: 1.2891 - val_mae: 0.7371\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0557 - mae: 0.1395 - val_loss: 1.3476 - val_mae: 0.7524\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0398 - mae: 0.1307 - val_loss: 1.3197 - val_mae: 0.7483\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0493 - mae: 0.1401 - val_loss: 1.3626 - val_mae: 0.7471\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0463 - mae: 0.1343 - val_loss: 1.3198 - val_mae: 0.7441\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0447 - mae: 0.1347 - val_loss: 1.3277 - val_mae: 0.7486\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0361 - mae: 0.1227 - val_loss: 1.3033 - val_mae: 0.7424\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0363 - mae: 0.1224 - val_loss: 1.3135 - val_mae: 0.7420\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0399 - mae: 0.1203 - val_loss: 1.2965 - val_mae: 0.7364\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0379 - mae: 0.1207 - val_loss: 1.3048 - val_mae: 0.7442\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0392 - mae: 0.1264 - val_loss: 1.2723 - val_mae: 0.7464\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0447 - mae: 0.1313 - val_loss: 1.3426 - val_mae: 0.7444\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0421 - mae: 0.1264 - val_loss: 1.3159 - val_mae: 0.7417\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0361 - mae: 0.1197 - val_loss: 1.3160 - val_mae: 0.7459\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0337 - mae: 0.1153 - val_loss: 1.3459 - val_mae: 0.7322\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0512 - mae: 0.1291 - val_loss: 1.3184 - val_mae: 0.7364\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0357 - mae: 0.1158 - val_loss: 1.3037 - val_mae: 0.7329\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0388 - mae: 0.1153 - val_loss: 1.3047 - val_mae: 0.7385\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0346 - mae: 0.1156 - val_loss: 1.3071 - val_mae: 0.7304\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0387 - mae: 0.1144 - val_loss: 1.3325 - val_mae: 0.7376\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0300 - mae: 0.1092 - val_loss: 1.3003 - val_mae: 0.7370\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0272 - mae: 0.1051 - val_loss: 1.3034 - val_mae: 0.7377\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0320 - mae: 0.1152 - val_loss: 1.3318 - val_mae: 0.7380\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0322 - mae: 0.1102 - val_loss: 1.3274 - val_mae: 0.7404\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0304 - mae: 0.1090 - val_loss: 1.3269 - val_mae: 0.7378\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0329 - mae: 0.1113 - val_loss: 1.3145 - val_mae: 0.7356\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0279 - mae: 0.1035 - val_loss: 1.3040 - val_mae: 0.7442\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0317 - mae: 0.1088 - val_loss: 1.3088 - val_mae: 0.7352\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0267 - mae: 0.1063 - val_loss: 1.3437 - val_mae: 0.7393\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0314 - mae: 0.1089 - val_loss: 1.3461 - val_mae: 0.7366\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0317 - mae: 0.1085 - val_loss: 1.3418 - val_mae: 0.7436\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0312 - mae: 0.1069 - val_loss: 1.3170 - val_mae: 0.7434\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0261 - mae: 0.1024 - val_loss: 1.3103 - val_mae: 0.7382\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0311 - mae: 0.1120 - val_loss: 1.3053 - val_mae: 0.7399\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0289 - mae: 0.1086 - val_loss: 1.3620 - val_mae: 0.7395\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0309 - mae: 0.1049 - val_loss: 1.3126 - val_mae: 0.7306\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0276 - mae: 0.0954 - val_loss: 1.3454 - val_mae: 0.7417\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0210 - mae: 0.0957 - val_loss: 1.3455 - val_mae: 0.7376\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0252 - mae: 0.0993 - val_loss: 1.3490 - val_mae: 0.7415\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0260 - mae: 0.1034 - val_loss: 1.3048 - val_mae: 0.7354\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0237 - mae: 0.1007 - val_loss: 1.2937 - val_mae: 0.7372\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0353 - mae: 0.1042 - val_loss: 1.3203 - val_mae: 0.7370\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0248 - mae: 0.0963 - val_loss: 1.3428 - val_mae: 0.7383\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0241 - mae: 0.0967 - val_loss: 1.3161 - val_mae: 0.7433\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0243 - mae: 0.0988 - val_loss: 1.3334 - val_mae: 0.7342\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0201 - mae: 0.0932 - val_loss: 1.2942 - val_mae: 0.7334\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0212 - mae: 0.0931 - val_loss: 1.3557 - val_mae: 0.7376\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0261 - mae: 0.0951 - val_loss: 1.3377 - val_mae: 0.7417\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0293 - mae: 0.1046 - val_loss: 1.3333 - val_mae: 0.7430\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0261 - mae: 0.1006 - val_loss: 1.3115 - val_mae: 0.7379\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0226 - mae: 0.0950 - val_loss: 1.3415 - val_mae: 0.7386\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0201 - mae: 0.0873 - val_loss: 1.3279 - val_mae: 0.7370\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0283 - mae: 0.0904 - val_loss: 1.3436 - val_mae: 0.7373\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0170 - mae: 0.0853 - val_loss: 1.3510 - val_mae: 0.7401\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0341 - mae: 0.1095 - val_loss: 1.2795 - val_mae: 0.7323\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0255 - mae: 0.1012 - val_loss: 1.3828 - val_mae: 0.7392\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0297 - mae: 0.0979 - val_loss: 1.3178 - val_mae: 0.7357\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0293 - mae: 0.0876 - val_loss: 1.3250 - val_mae: 0.7406\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0165 - mae: 0.0829 - val_loss: 1.3180 - val_mae: 0.7336\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0223 - mae: 0.0804 - val_loss: 1.3250 - val_mae: 0.7343\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0169 - mae: 0.0861 - val_loss: 1.3093 - val_mae: 0.7332\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0206 - mae: 0.0899 - val_loss: 1.3251 - val_mae: 0.7376\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0166 - mae: 0.0858 - val_loss: 1.3275 - val_mae: 0.7372\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0199 - mae: 0.0871 - val_loss: 1.3615 - val_mae: 0.7384\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0233 - mae: 0.0949 - val_loss: 1.2923 - val_mae: 0.7380\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0236 - mae: 0.0908 - val_loss: 1.3382 - val_mae: 0.7332\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0233 - mae: 0.0909 - val_loss: 1.2881 - val_mae: 0.7336\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.0822 - val_loss: 1.3470 - val_mae: 0.7301\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0203 - mae: 0.0805 - val_loss: 1.3257 - val_mae: 0.7433\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0138 - mae: 0.0746 - val_loss: 1.3158 - val_mae: 0.7315\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0835 - val_loss: 1.3124 - val_mae: 0.7345\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0165 - mae: 0.0847 - val_loss: 1.3187 - val_mae: 0.7325\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0189 - mae: 0.0853 - val_loss: 1.3001 - val_mae: 0.7272\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0209 - mae: 0.0873 - val_loss: 1.3612 - val_mae: 0.7384\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0170 - mae: 0.0809 - val_loss: 1.2796 - val_mae: 0.7288\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0176 - mae: 0.0815 - val_loss: 1.3365 - val_mae: 0.7410\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0178 - mae: 0.0828 - val_loss: 1.3169 - val_mae: 0.7312\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0156 - mae: 0.0756 - val_loss: 1.2840 - val_mae: 0.7344\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0158 - mae: 0.0816 - val_loss: 1.3170 - val_mae: 0.7355\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0189 - mae: 0.0812 - val_loss: 1.2964 - val_mae: 0.7292\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.0795 - val_loss: 1.3205 - val_mae: 0.7401\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0801 - val_loss: 1.3341 - val_mae: 0.7353\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0188 - mae: 0.0829 - val_loss: 1.2964 - val_mae: 0.7368\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0206 - mae: 0.0927 - val_loss: 1.3072 - val_mae: 0.7329\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0215 - mae: 0.0886 - val_loss: 1.3095 - val_mae: 0.7370\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0187 - mae: 0.0761 - val_loss: 1.3040 - val_mae: 0.7320\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0742 - val_loss: 1.3246 - val_mae: 0.7361\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0174 - mae: 0.0766 - val_loss: 1.2808 - val_mae: 0.7347\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0156 - mae: 0.0782 - val_loss: 1.3193 - val_mae: 0.7381\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0186 - mae: 0.0791 - val_loss: 1.2828 - val_mae: 0.7333\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0782 - val_loss: 1.2820 - val_mae: 0.7332\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0212 - mae: 0.0801 - val_loss: 1.3098 - val_mae: 0.7315\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0156 - mae: 0.0742 - val_loss: 1.2904 - val_mae: 0.7312\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0814 - val_loss: 1.2753 - val_mae: 0.7265\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0176 - mae: 0.0780 - val_loss: 1.3015 - val_mae: 0.7396\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0179 - mae: 0.0858 - val_loss: 1.2843 - val_mae: 0.7279\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.0750 - val_loss: 1.3130 - val_mae: 0.7334\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0125 - mae: 0.0678 - val_loss: 1.2803 - val_mae: 0.7300\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0685 - val_loss: 1.3248 - val_mae: 0.7354\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0152 - mae: 0.0710 - val_loss: 1.2997 - val_mae: 0.7313\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0760 - val_loss: 1.3500 - val_mae: 0.7449\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0164 - mae: 0.0813 - val_loss: 1.2935 - val_mae: 0.7296\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0170 - mae: 0.0751 - val_loss: 1.2818 - val_mae: 0.7297\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0170 - mae: 0.0759 - val_loss: 1.2983 - val_mae: 0.7303\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0119 - mae: 0.0681 - val_loss: 1.2857 - val_mae: 0.7293\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0154 - mae: 0.0744 - val_loss: 1.3274 - val_mae: 0.7354\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0156 - mae: 0.0770 - val_loss: 1.2902 - val_mae: 0.7335\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0727 - val_loss: 1.3136 - val_mae: 0.7363\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0735 - val_loss: 1.2813 - val_mae: 0.7339\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0152 - mae: 0.0715 - val_loss: 1.3073 - val_mae: 0.7337\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0822 - val_loss: 1.2930 - val_mae: 0.7291\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0156 - mae: 0.0715 - val_loss: 1.3045 - val_mae: 0.7329\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0174 - mae: 0.0747 - val_loss: 1.2969 - val_mae: 0.7320\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0159 - mae: 0.0713 - val_loss: 1.2846 - val_mae: 0.7349\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0152 - mae: 0.0730 - val_loss: 1.2897 - val_mae: 0.7319\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0735 - val_loss: 1.2811 - val_mae: 0.7327\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0131 - mae: 0.0695 - val_loss: 1.3082 - val_mae: 0.7356\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0117 - mae: 0.0682 - val_loss: 1.2882 - val_mae: 0.7329\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0128 - mae: 0.0679 - val_loss: 1.3341 - val_mae: 0.7335\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0140 - mae: 0.0735 - val_loss: 1.2895 - val_mae: 0.7302\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0234 - mae: 0.0841 - val_loss: 1.3227 - val_mae: 0.7370\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0146 - mae: 0.0736 - val_loss: 1.3047 - val_mae: 0.7369\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0672 - val_loss: 1.3257 - val_mae: 0.7374\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0628 - val_loss: 1.3072 - val_mae: 0.7361\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0135 - mae: 0.0640 - val_loss: 1.3195 - val_mae: 0.7376\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0145 - mae: 0.0715 - val_loss: 1.3196 - val_mae: 0.7362\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0142 - mae: 0.0682 - val_loss: 1.3346 - val_mae: 0.7399\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0675 - val_loss: 1.3289 - val_mae: 0.7365\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0128 - mae: 0.0690 - val_loss: 1.3092 - val_mae: 0.7355\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0213 - mae: 0.0768 - val_loss: 1.3194 - val_mae: 0.7380\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0165 - mae: 0.0709 - val_loss: 1.2937 - val_mae: 0.7351\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0113 - mae: 0.0676 - val_loss: 1.3375 - val_mae: 0.7383\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0113 - mae: 0.0659 - val_loss: 1.2963 - val_mae: 0.7345\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0659 - val_loss: 1.2946 - val_mae: 0.7340\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0120 - mae: 0.0679 - val_loss: 1.3167 - val_mae: 0.7349\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0120 - mae: 0.0637 - val_loss: 1.3180 - val_mae: 0.7350\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0670 - val_loss: 1.3397 - val_mae: 0.7362\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0109 - mae: 0.0671 - val_loss: 1.3232 - val_mae: 0.7375\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0146 - mae: 0.0731 - val_loss: 1.2860 - val_mae: 0.7315\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0117 - mae: 0.0646 - val_loss: 1.3237 - val_mae: 0.7326\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0649 - val_loss: 1.2970 - val_mae: 0.7343\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0669 - val_loss: 1.2922 - val_mae: 0.7291\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0107 - mae: 0.0646 - val_loss: 1.3059 - val_mae: 0.7360\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0118 - mae: 0.0663 - val_loss: 1.3092 - val_mae: 0.7345\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0634 - val_loss: 1.3056 - val_mae: 0.7327\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.0684 - val_loss: 1.3326 - val_mae: 0.7371\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0098 - mae: 0.0602 - val_loss: 1.2756 - val_mae: 0.7302\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3076 - mae: 0.7328\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 4.4316 - mae: 1.5115 - val_loss: 2.2583 - val_mae: 1.0191\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 1.3170 - mae: 0.8050 - val_loss: 2.1361 - val_mae: 0.9391\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.8381 - mae: 0.6265 - val_loss: 1.7751 - val_mae: 0.8690\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.5771 - mae: 0.5122 - val_loss: 1.7787 - val_mae: 0.8584\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.4085 - mae: 0.4304 - val_loss: 1.6951 - val_mae: 0.8503\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.3915 - mae: 0.4088 - val_loss: 1.5656 - val_mae: 0.8277\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.4171 - mae: 0.3659 - val_loss: 1.6896 - val_mae: 0.8430\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2812 - mae: 0.3398 - val_loss: 1.5267 - val_mae: 0.8160\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2700 - mae: 0.3185 - val_loss: 1.5788 - val_mae: 0.8233\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2236 - mae: 0.2972 - val_loss: 1.5797 - val_mae: 0.8119\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1794 - mae: 0.2712 - val_loss: 1.4989 - val_mae: 0.8098\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1771 - mae: 0.2735 - val_loss: 1.6379 - val_mae: 0.8154\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1796 - mae: 0.2825 - val_loss: 1.4673 - val_mae: 0.8064\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1595 - mae: 0.2625 - val_loss: 1.5352 - val_mae: 0.8009\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2599 - mae: 0.2808 - val_loss: 1.4935 - val_mae: 0.8080\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1470 - mae: 0.2482 - val_loss: 1.4929 - val_mae: 0.7964\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1672 - mae: 0.2501 - val_loss: 1.5003 - val_mae: 0.7962\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1350 - mae: 0.2348 - val_loss: 1.5566 - val_mae: 0.7939\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1236 - mae: 0.2196 - val_loss: 1.4861 - val_mae: 0.7867\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1192 - mae: 0.2122 - val_loss: 1.5200 - val_mae: 0.7891\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1174 - mae: 0.2142 - val_loss: 1.4883 - val_mae: 0.7896\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0991 - mae: 0.2062 - val_loss: 1.5431 - val_mae: 0.7897\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0981 - mae: 0.2015 - val_loss: 1.4406 - val_mae: 0.7844\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1003 - mae: 0.1993 - val_loss: 1.4636 - val_mae: 0.7835\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.1076 - mae: 0.1953 - val_loss: 1.4490 - val_mae: 0.7749\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0973 - mae: 0.2019 - val_loss: 1.4883 - val_mae: 0.7811\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0980 - mae: 0.1977 - val_loss: 1.3898 - val_mae: 0.7727\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0996 - mae: 0.1923 - val_loss: 1.4406 - val_mae: 0.7810\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0744 - mae: 0.1766 - val_loss: 1.4076 - val_mae: 0.7707\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0749 - mae: 0.1794 - val_loss: 1.4339 - val_mae: 0.7719\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0772 - mae: 0.1832 - val_loss: 1.4259 - val_mae: 0.7744\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0766 - mae: 0.1722 - val_loss: 1.4563 - val_mae: 0.7811\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0672 - mae: 0.1676 - val_loss: 1.4646 - val_mae: 0.7765\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0734 - mae: 0.1678 - val_loss: 1.4455 - val_mae: 0.7742\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0823 - mae: 0.1719 - val_loss: 1.4602 - val_mae: 0.7718\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0937 - mae: 0.1736 - val_loss: 1.3946 - val_mae: 0.7720\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0767 - mae: 0.1731 - val_loss: 1.4458 - val_mae: 0.7678\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0548 - mae: 0.1519 - val_loss: 1.4164 - val_mae: 0.7675\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0634 - mae: 0.1519 - val_loss: 1.4214 - val_mae: 0.7677\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0467 - mae: 0.1414 - val_loss: 1.4198 - val_mae: 0.7621\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0490 - mae: 0.1449 - val_loss: 1.4772 - val_mae: 0.7663\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0608 - mae: 0.1513 - val_loss: 1.3922 - val_mae: 0.7567\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0506 - mae: 0.1461 - val_loss: 1.4004 - val_mae: 0.7609\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0532 - mae: 0.1471 - val_loss: 1.4578 - val_mae: 0.7712\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0559 - mae: 0.1473 - val_loss: 1.4020 - val_mae: 0.7549\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0471 - mae: 0.1411 - val_loss: 1.4354 - val_mae: 0.7622\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0495 - mae: 0.1395 - val_loss: 1.3978 - val_mae: 0.7554\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0541 - mae: 0.1394 - val_loss: 1.3583 - val_mae: 0.7643\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0517 - mae: 0.1436 - val_loss: 1.4115 - val_mae: 0.7586\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0448 - mae: 0.1331 - val_loss: 1.4015 - val_mae: 0.7594\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0465 - mae: 0.1343 - val_loss: 1.3892 - val_mae: 0.7500\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0486 - mae: 0.1350 - val_loss: 1.3952 - val_mae: 0.7611\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0439 - mae: 0.1309 - val_loss: 1.4129 - val_mae: 0.7594\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0357 - mae: 0.1238 - val_loss: 1.4094 - val_mae: 0.7637\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0397 - mae: 0.1271 - val_loss: 1.4047 - val_mae: 0.7555\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0394 - mae: 0.1271 - val_loss: 1.4352 - val_mae: 0.7631\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0380 - mae: 0.1233 - val_loss: 1.4244 - val_mae: 0.7574\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0394 - mae: 0.1272 - val_loss: 1.4068 - val_mae: 0.7554\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0368 - mae: 0.1267 - val_loss: 1.3908 - val_mae: 0.7543\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0350 - mae: 0.1181 - val_loss: 1.4331 - val_mae: 0.7567\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0345 - mae: 0.1166 - val_loss: 1.3729 - val_mae: 0.7524\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0382 - mae: 0.1161 - val_loss: 1.4190 - val_mae: 0.7564\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0321 - mae: 0.1128 - val_loss: 1.4240 - val_mae: 0.7564\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0384 - mae: 0.1247 - val_loss: 1.4277 - val_mae: 0.7542\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0367 - mae: 0.1210 - val_loss: 1.4452 - val_mae: 0.7547\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0407 - mae: 0.1189 - val_loss: 1.4464 - val_mae: 0.7605\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0329 - mae: 0.1152 - val_loss: 1.4119 - val_mae: 0.7576\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0322 - mae: 0.1142 - val_loss: 1.4484 - val_mae: 0.7572\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0321 - mae: 0.1100 - val_loss: 1.4309 - val_mae: 0.7552\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0307 - mae: 0.1087 - val_loss: 1.3960 - val_mae: 0.7550\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0295 - mae: 0.1111 - val_loss: 1.4675 - val_mae: 0.7595\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0320 - mae: 0.1108 - val_loss: 1.4205 - val_mae: 0.7540\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0268 - mae: 0.1055 - val_loss: 1.4196 - val_mae: 0.7541\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0260 - mae: 0.1028 - val_loss: 1.4130 - val_mae: 0.7528\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0273 - mae: 0.1018 - val_loss: 1.4286 - val_mae: 0.7477\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0282 - mae: 0.1046 - val_loss: 1.3973 - val_mae: 0.7520\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0265 - mae: 0.1060 - val_loss: 1.4129 - val_mae: 0.7504\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0317 - mae: 0.1100 - val_loss: 1.4260 - val_mae: 0.7547\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0299 - mae: 0.1104 - val_loss: 1.4027 - val_mae: 0.7542\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0261 - mae: 0.1026 - val_loss: 1.4120 - val_mae: 0.7504\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0257 - mae: 0.1000 - val_loss: 1.4060 - val_mae: 0.7481\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0204 - mae: 0.0903 - val_loss: 1.4012 - val_mae: 0.7517\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0307 - mae: 0.1007 - val_loss: 1.4449 - val_mae: 0.7538\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0282 - mae: 0.0994 - val_loss: 1.4027 - val_mae: 0.7507\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0241 - mae: 0.1003 - val_loss: 1.4089 - val_mae: 0.7490\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0258 - mae: 0.0983 - val_loss: 1.4203 - val_mae: 0.7527\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0230 - mae: 0.0994 - val_loss: 1.4209 - val_mae: 0.7524\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0242 - mae: 0.0951 - val_loss: 1.4186 - val_mae: 0.7506\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0275 - mae: 0.1003 - val_loss: 1.4305 - val_mae: 0.7505\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0241 - mae: 0.0948 - val_loss: 1.3988 - val_mae: 0.7426\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0236 - mae: 0.0945 - val_loss: 1.4131 - val_mae: 0.7505\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0242 - mae: 0.0919 - val_loss: 1.4108 - val_mae: 0.7477\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0249 - mae: 0.0933 - val_loss: 1.3945 - val_mae: 0.7519\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0228 - mae: 0.0951 - val_loss: 1.4358 - val_mae: 0.7485\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0220 - mae: 0.0932 - val_loss: 1.4334 - val_mae: 0.7543\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0267 - mae: 0.1002 - val_loss: 1.3816 - val_mae: 0.7432\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0256 - mae: 0.1003 - val_loss: 1.4089 - val_mae: 0.7503\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0239 - mae: 0.0927 - val_loss: 1.4063 - val_mae: 0.7519\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.0923 - val_loss: 1.4159 - val_mae: 0.7504\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0194 - mae: 0.0840 - val_loss: 1.4026 - val_mae: 0.7489\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0193 - mae: 0.0859 - val_loss: 1.4354 - val_mae: 0.7530\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0180 - mae: 0.0838 - val_loss: 1.3770 - val_mae: 0.7440\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0264 - mae: 0.0959 - val_loss: 1.4267 - val_mae: 0.7549\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.0953 - val_loss: 1.3919 - val_mae: 0.7434\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0185 - mae: 0.0891 - val_loss: 1.3956 - val_mae: 0.7473\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0182 - mae: 0.0853 - val_loss: 1.4124 - val_mae: 0.7505\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0178 - mae: 0.0815 - val_loss: 1.3920 - val_mae: 0.7435\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0158 - mae: 0.0804 - val_loss: 1.4136 - val_mae: 0.7469\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0209 - mae: 0.0892 - val_loss: 1.4024 - val_mae: 0.7489\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0172 - mae: 0.0854 - val_loss: 1.3811 - val_mae: 0.7491\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0210 - mae: 0.0905 - val_loss: 1.3897 - val_mae: 0.7453\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0187 - mae: 0.0836 - val_loss: 1.3973 - val_mae: 0.7437\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0210 - mae: 0.0843 - val_loss: 1.3940 - val_mae: 0.7454\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0171 - mae: 0.0814 - val_loss: 1.4113 - val_mae: 0.7520\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0191 - mae: 0.0840 - val_loss: 1.4182 - val_mae: 0.7447\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0206 - mae: 0.0870 - val_loss: 1.4262 - val_mae: 0.7478\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0167 - mae: 0.0796 - val_loss: 1.3944 - val_mae: 0.7470\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0166 - mae: 0.0806 - val_loss: 1.3842 - val_mae: 0.7441\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0204 - mae: 0.0847 - val_loss: 1.4191 - val_mae: 0.7469\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0193 - mae: 0.0830 - val_loss: 1.3867 - val_mae: 0.7499\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0242 - mae: 0.0887 - val_loss: 1.4054 - val_mae: 0.7520\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0197 - mae: 0.0843 - val_loss: 1.4103 - val_mae: 0.7495\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0779 - val_loss: 1.3884 - val_mae: 0.7453\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0137 - mae: 0.0745 - val_loss: 1.3985 - val_mae: 0.7465\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.0788 - val_loss: 1.3845 - val_mae: 0.7415\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0165 - mae: 0.0796 - val_loss: 1.4023 - val_mae: 0.7478\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0142 - mae: 0.0736 - val_loss: 1.3959 - val_mae: 0.7460\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0139 - mae: 0.0750 - val_loss: 1.3942 - val_mae: 0.7482\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.0832 - val_loss: 1.4063 - val_mae: 0.7434\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0163 - mae: 0.0816 - val_loss: 1.3829 - val_mae: 0.7434\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0176 - mae: 0.0785 - val_loss: 1.3912 - val_mae: 0.7450\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0156 - mae: 0.0793 - val_loss: 1.3705 - val_mae: 0.7424\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0174 - mae: 0.0789 - val_loss: 1.4126 - val_mae: 0.7490\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0730 - val_loss: 1.4135 - val_mae: 0.7473\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0159 - mae: 0.0787 - val_loss: 1.3988 - val_mae: 0.7460\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0152 - mae: 0.0785 - val_loss: 1.3870 - val_mae: 0.7456\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0137 - mae: 0.0735 - val_loss: 1.3760 - val_mae: 0.7463\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0140 - mae: 0.0712 - val_loss: 1.3771 - val_mae: 0.7429\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0126 - mae: 0.0685 - val_loss: 1.3778 - val_mae: 0.7450\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0192 - mae: 0.0780 - val_loss: 1.3666 - val_mae: 0.7432\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0775 - val_loss: 1.4040 - val_mae: 0.7479\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0736 - val_loss: 1.3746 - val_mae: 0.7416\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0136 - mae: 0.0710 - val_loss: 1.3916 - val_mae: 0.7462\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0143 - mae: 0.0745 - val_loss: 1.3941 - val_mae: 0.7468\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0143 - mae: 0.0697 - val_loss: 1.4076 - val_mae: 0.7460\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0142 - mae: 0.0708 - val_loss: 1.3880 - val_mae: 0.7462\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0159 - mae: 0.0761 - val_loss: 1.4221 - val_mae: 0.7493\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0777 - val_loss: 1.3718 - val_mae: 0.7471\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0132 - mae: 0.0750 - val_loss: 1.4116 - val_mae: 0.7468\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0728 - val_loss: 1.3795 - val_mae: 0.7431\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0697 - val_loss: 1.4167 - val_mae: 0.7472\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0140 - mae: 0.0717 - val_loss: 1.3837 - val_mae: 0.7469\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0138 - mae: 0.0738 - val_loss: 1.4292 - val_mae: 0.7476\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0167 - mae: 0.0742 - val_loss: 1.3789 - val_mae: 0.7449\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0128 - mae: 0.0675 - val_loss: 1.4220 - val_mae: 0.7509\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0142 - mae: 0.0696 - val_loss: 1.4186 - val_mae: 0.7454\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0693 - val_loss: 1.3676 - val_mae: 0.7427\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0172 - mae: 0.0783 - val_loss: 1.3898 - val_mae: 0.7457\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0126 - mae: 0.0698 - val_loss: 1.4127 - val_mae: 0.7450\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0713 - val_loss: 1.4086 - val_mae: 0.7506\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0116 - mae: 0.0693 - val_loss: 1.4351 - val_mae: 0.7517\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0146 - mae: 0.0720 - val_loss: 1.3803 - val_mae: 0.7408\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0112 - mae: 0.0684 - val_loss: 1.3976 - val_mae: 0.7457\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0682 - val_loss: 1.3631 - val_mae: 0.7369\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0108 - mae: 0.0678 - val_loss: 1.4001 - val_mae: 0.7440\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0680 - val_loss: 1.3681 - val_mae: 0.7443\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0719 - val_loss: 1.3927 - val_mae: 0.7459\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0128 - mae: 0.0691 - val_loss: 1.4385 - val_mae: 0.7503\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0669 - val_loss: 1.3924 - val_mae: 0.7435\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0118 - mae: 0.0666 - val_loss: 1.3913 - val_mae: 0.7442\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0131 - mae: 0.0698 - val_loss: 1.3664 - val_mae: 0.7411\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0683 - val_loss: 1.3777 - val_mae: 0.7436\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0095 - mae: 0.0624 - val_loss: 1.3939 - val_mae: 0.7428\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0136 - mae: 0.0640 - val_loss: 1.3614 - val_mae: 0.7441\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0139 - mae: 0.0700 - val_loss: 1.3881 - val_mae: 0.7417\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0711 - val_loss: 1.3649 - val_mae: 0.7426\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0642 - val_loss: 1.3823 - val_mae: 0.7381\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0121 - mae: 0.0671 - val_loss: 1.3760 - val_mae: 0.7440\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0118 - mae: 0.0656 - val_loss: 1.3957 - val_mae: 0.7390\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0633 - val_loss: 1.3814 - val_mae: 0.7412\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0121 - mae: 0.0640 - val_loss: 1.3740 - val_mae: 0.7436\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0667 - val_loss: 1.3736 - val_mae: 0.7423\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0657 - val_loss: 1.4309 - val_mae: 0.7470\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0180 - mae: 0.0767 - val_loss: 1.3952 - val_mae: 0.7466\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0120 - mae: 0.0667 - val_loss: 1.3722 - val_mae: 0.7421\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0106 - mae: 0.0627 - val_loss: 1.3937 - val_mae: 0.7428\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0621 - val_loss: 1.3871 - val_mae: 0.7448\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0070 - mae: 0.0550 - val_loss: 1.3980 - val_mae: 0.7465\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0091 - mae: 0.0608 - val_loss: 1.3832 - val_mae: 0.7438\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0118 - mae: 0.0661 - val_loss: 1.3771 - val_mae: 0.7403\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0085 - mae: 0.0614 - val_loss: 1.4001 - val_mae: 0.7436\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0125 - mae: 0.0652 - val_loss: 1.3887 - val_mae: 0.7406\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0089 - mae: 0.0616 - val_loss: 1.4200 - val_mae: 0.7461\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0670 - val_loss: 1.4011 - val_mae: 0.7458\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0112 - mae: 0.0655 - val_loss: 1.4077 - val_mae: 0.7461\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0095 - mae: 0.0624 - val_loss: 1.3875 - val_mae: 0.7406\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0090 - mae: 0.0586 - val_loss: 1.3858 - val_mae: 0.7421\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0116 - mae: 0.0608 - val_loss: 1.4012 - val_mae: 0.7445\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0121 - mae: 0.0634 - val_loss: 1.3618 - val_mae: 0.7373\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0103 - mae: 0.0614 - val_loss: 1.3686 - val_mae: 0.7410\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3642 - mae: 0.7553\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 4.6969 - mae: 1.5661 - val_loss: 2.1175 - val_mae: 1.0096\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 1.2423 - mae: 0.7870 - val_loss: 1.7683 - val_mae: 0.9182\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.8420 - mae: 0.6032 - val_loss: 1.8798 - val_mae: 0.9178\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.5791 - mae: 0.5107 - val_loss: 1.6723 - val_mae: 0.8664\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.4009 - mae: 0.4204 - val_loss: 1.6342 - val_mae: 0.8580\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.3226 - mae: 0.3666 - val_loss: 1.6538 - val_mae: 0.8555\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2805 - mae: 0.3403 - val_loss: 1.6052 - val_mae: 0.8515\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2599 - mae: 0.3204 - val_loss: 1.5478 - val_mae: 0.8306\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1928 - mae: 0.2892 - val_loss: 2.4473 - val_mae: 0.8785\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2250 - mae: 0.2995 - val_loss: 1.5496 - val_mae: 0.8408\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1992 - mae: 0.2844 - val_loss: 1.5798 - val_mae: 0.8352\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1788 - mae: 0.2757 - val_loss: 1.5400 - val_mae: 0.8436\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.2527 - mae: 0.2907 - val_loss: 1.4828 - val_mae: 0.8090\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1750 - mae: 0.2658 - val_loss: 1.6008 - val_mae: 0.8292\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1367 - mae: 0.2415 - val_loss: 1.4631 - val_mae: 0.8020\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1545 - mae: 0.2389 - val_loss: 1.5554 - val_mae: 0.8058\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1480 - mae: 0.2372 - val_loss: 1.4477 - val_mae: 0.8071\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1244 - mae: 0.2290 - val_loss: 1.5356 - val_mae: 0.8137\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1247 - mae: 0.2252 - val_loss: 1.6032 - val_mae: 0.8244\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1285 - mae: 0.2224 - val_loss: 1.4716 - val_mae: 0.8073\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.1032 - mae: 0.2125 - val_loss: 1.5476 - val_mae: 0.8109\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1008 - mae: 0.2052 - val_loss: 1.4715 - val_mae: 0.8023\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0867 - mae: 0.1913 - val_loss: 1.4716 - val_mae: 0.8032\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0839 - mae: 0.1905 - val_loss: 1.4529 - val_mae: 0.8086\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0989 - mae: 0.1976 - val_loss: 1.4386 - val_mae: 0.7914\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0874 - mae: 0.1936 - val_loss: 1.4407 - val_mae: 0.7860\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0917 - mae: 0.1933 - val_loss: 1.4682 - val_mae: 0.8055\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0911 - mae: 0.1917 - val_loss: 1.4502 - val_mae: 0.7867\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0828 - mae: 0.1807 - val_loss: 1.4261 - val_mae: 0.7895\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0742 - mae: 0.1757 - val_loss: 1.4338 - val_mae: 0.7794\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0763 - mae: 0.1758 - val_loss: 1.4196 - val_mae: 0.7876\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0685 - mae: 0.1674 - val_loss: 1.3957 - val_mae: 0.7823\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0652 - mae: 0.1663 - val_loss: 1.4262 - val_mae: 0.7885\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0656 - mae: 0.1656 - val_loss: 1.3786 - val_mae: 0.7811\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0631 - mae: 0.1641 - val_loss: 1.4197 - val_mae: 0.7883\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0629 - mae: 0.1591 - val_loss: 1.4071 - val_mae: 0.7802\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0632 - mae: 0.1573 - val_loss: 1.4439 - val_mae: 0.7851\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0543 - mae: 0.1527 - val_loss: 1.4118 - val_mae: 0.7794\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0549 - mae: 0.1526 - val_loss: 1.4260 - val_mae: 0.7857\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0590 - mae: 0.1517 - val_loss: 1.4087 - val_mae: 0.7837\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0495 - mae: 0.1444 - val_loss: 1.3987 - val_mae: 0.7813\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0535 - mae: 0.1514 - val_loss: 1.3967 - val_mae: 0.7739\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0490 - mae: 0.1454 - val_loss: 1.3569 - val_mae: 0.7753\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0443 - mae: 0.1344 - val_loss: 1.4022 - val_mae: 0.7794\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0463 - mae: 0.1377 - val_loss: 1.3950 - val_mae: 0.7740\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0547 - mae: 0.1363 - val_loss: 1.4072 - val_mae: 0.7779\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0477 - mae: 0.1380 - val_loss: 1.4305 - val_mae: 0.7811\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0451 - mae: 0.1339 - val_loss: 1.4198 - val_mae: 0.7785\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0466 - mae: 0.1379 - val_loss: 1.4101 - val_mae: 0.7778\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0455 - mae: 0.1377 - val_loss: 1.4183 - val_mae: 0.7821\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0422 - mae: 0.1311 - val_loss: 1.4218 - val_mae: 0.7816\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0398 - mae: 0.1294 - val_loss: 1.4030 - val_mae: 0.7786\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0450 - mae: 0.1268 - val_loss: 1.4088 - val_mae: 0.7761\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0380 - mae: 0.1218 - val_loss: 1.4030 - val_mae: 0.7740\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0314 - mae: 0.1186 - val_loss: 1.3639 - val_mae: 0.7703\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0359 - mae: 0.1243 - val_loss: 1.4361 - val_mae: 0.7810\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0367 - mae: 0.1260 - val_loss: 1.4074 - val_mae: 0.7743\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0361 - mae: 0.1223 - val_loss: 1.3781 - val_mae: 0.7681\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0361 - mae: 0.1184 - val_loss: 1.3853 - val_mae: 0.7773\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0451 - mae: 0.1384 - val_loss: 1.4156 - val_mae: 0.7834\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0412 - mae: 0.1303 - val_loss: 1.3961 - val_mae: 0.7721\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0323 - mae: 0.1130 - val_loss: 1.3868 - val_mae: 0.7734\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0245 - mae: 0.1027 - val_loss: 1.4154 - val_mae: 0.7736\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0266 - mae: 0.1059 - val_loss: 1.3869 - val_mae: 0.7679\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0284 - mae: 0.1089 - val_loss: 1.4459 - val_mae: 0.7747\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0283 - mae: 0.1086 - val_loss: 1.4582 - val_mae: 0.7803\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0328 - mae: 0.1177 - val_loss: 1.3996 - val_mae: 0.7672\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0298 - mae: 0.1140 - val_loss: 1.4197 - val_mae: 0.7711\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0295 - mae: 0.1105 - val_loss: 1.4258 - val_mae: 0.7754\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0289 - mae: 0.1103 - val_loss: 1.3990 - val_mae: 0.7714\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0294 - mae: 0.1115 - val_loss: 1.4143 - val_mae: 0.7741\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0297 - mae: 0.1105 - val_loss: 1.4064 - val_mae: 0.7725\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0254 - mae: 0.1039 - val_loss: 1.4159 - val_mae: 0.7730\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0252 - mae: 0.0988 - val_loss: 1.4134 - val_mae: 0.7677\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0226 - mae: 0.0972 - val_loss: 1.4548 - val_mae: 0.7803\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0236 - mae: 0.0988 - val_loss: 1.3974 - val_mae: 0.7761\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0257 - mae: 0.1054 - val_loss: 1.4040 - val_mae: 0.7734\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0250 - mae: 0.1020 - val_loss: 1.4185 - val_mae: 0.7769\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0272 - mae: 0.1054 - val_loss: 1.4025 - val_mae: 0.7734\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0250 - mae: 0.0993 - val_loss: 1.4104 - val_mae: 0.7741\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0215 - mae: 0.0965 - val_loss: 1.4268 - val_mae: 0.7751\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0225 - mae: 0.0948 - val_loss: 1.4065 - val_mae: 0.7712\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0226 - mae: 0.0974 - val_loss: 1.4355 - val_mae: 0.7739\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0264 - mae: 0.1005 - val_loss: 1.4468 - val_mae: 0.7787\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0242 - mae: 0.1003 - val_loss: 1.4013 - val_mae: 0.7732\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0245 - mae: 0.1012 - val_loss: 1.4332 - val_mae: 0.7740\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0196 - mae: 0.0916 - val_loss: 1.4156 - val_mae: 0.7713\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0206 - mae: 0.0933 - val_loss: 1.4418 - val_mae: 0.7727\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0224 - mae: 0.0929 - val_loss: 1.4368 - val_mae: 0.7760\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0199 - mae: 0.0918 - val_loss: 1.3945 - val_mae: 0.7714\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0186 - mae: 0.0895 - val_loss: 1.4372 - val_mae: 0.7785\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0226 - mae: 0.0961 - val_loss: 1.3947 - val_mae: 0.7675\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0245 - mae: 0.0993 - val_loss: 1.4295 - val_mae: 0.7760\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0238 - mae: 0.0980 - val_loss: 1.3969 - val_mae: 0.7705\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0194 - mae: 0.0893 - val_loss: 1.4242 - val_mae: 0.7772\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0161 - mae: 0.0819 - val_loss: 1.4346 - val_mae: 0.7733\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0198 - mae: 0.0875 - val_loss: 1.3939 - val_mae: 0.7688\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.0816 - val_loss: 1.4040 - val_mae: 0.7701\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0182 - mae: 0.0878 - val_loss: 1.4070 - val_mae: 0.7734\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0169 - mae: 0.0850 - val_loss: 1.4291 - val_mae: 0.7759\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0186 - mae: 0.0891 - val_loss: 1.4306 - val_mae: 0.7752\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0185 - mae: 0.0871 - val_loss: 1.4164 - val_mae: 0.7728\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0173 - mae: 0.0834 - val_loss: 1.4135 - val_mae: 0.7711\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0140 - mae: 0.0792 - val_loss: 1.4183 - val_mae: 0.7742\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0178 - mae: 0.0867 - val_loss: 1.4318 - val_mae: 0.7778\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0197 - mae: 0.0923 - val_loss: 1.4323 - val_mae: 0.7754\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0187 - mae: 0.0896 - val_loss: 1.4180 - val_mae: 0.7743\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0196 - mae: 0.0894 - val_loss: 1.3962 - val_mae: 0.7691\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0149 - mae: 0.0778 - val_loss: 1.4158 - val_mae: 0.7743\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0130 - mae: 0.0737 - val_loss: 1.4100 - val_mae: 0.7693\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0166 - mae: 0.0813 - val_loss: 1.4307 - val_mae: 0.7740\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0842 - val_loss: 1.4167 - val_mae: 0.7700\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0167 - mae: 0.0853 - val_loss: 1.4117 - val_mae: 0.7710\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0788 - val_loss: 1.4418 - val_mae: 0.7730\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0189 - mae: 0.0841 - val_loss: 1.4107 - val_mae: 0.7730\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0154 - mae: 0.0791 - val_loss: 1.4059 - val_mae: 0.7712\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0156 - mae: 0.0834 - val_loss: 1.4139 - val_mae: 0.7726\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0131 - mae: 0.0756 - val_loss: 1.4249 - val_mae: 0.7736\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0160 - mae: 0.0803 - val_loss: 1.4075 - val_mae: 0.7734\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0136 - mae: 0.0765 - val_loss: 1.4001 - val_mae: 0.7662\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0750 - val_loss: 1.4281 - val_mae: 0.7741\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0764 - val_loss: 1.4299 - val_mae: 0.7754\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0149 - mae: 0.0796 - val_loss: 1.4071 - val_mae: 0.7748\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0190 - mae: 0.0864 - val_loss: 1.4458 - val_mae: 0.7783\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0178 - mae: 0.0817 - val_loss: 1.4212 - val_mae: 0.7711\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0801 - val_loss: 1.4264 - val_mae: 0.7719\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0138 - mae: 0.0748 - val_loss: 1.4224 - val_mae: 0.7722\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0133 - mae: 0.0730 - val_loss: 1.4260 - val_mae: 0.7711\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0112 - mae: 0.0698 - val_loss: 1.4225 - val_mae: 0.7718\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0130 - mae: 0.0731 - val_loss: 1.4259 - val_mae: 0.7727\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0739 - val_loss: 1.4134 - val_mae: 0.7782\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0167 - mae: 0.0831 - val_loss: 1.4202 - val_mae: 0.7703\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0156 - mae: 0.0773 - val_loss: 1.4200 - val_mae: 0.7707\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0138 - mae: 0.0720 - val_loss: 1.4208 - val_mae: 0.7744\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0724 - val_loss: 1.4230 - val_mae: 0.7726\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0733 - val_loss: 1.4535 - val_mae: 0.7783\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0132 - mae: 0.0723 - val_loss: 1.4248 - val_mae: 0.7730\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0133 - mae: 0.0717 - val_loss: 1.4032 - val_mae: 0.7660\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.0789 - val_loss: 1.4312 - val_mae: 0.7743\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0714 - val_loss: 1.4011 - val_mae: 0.7681\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0119 - mae: 0.0712 - val_loss: 1.4401 - val_mae: 0.7755\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0114 - mae: 0.0667 - val_loss: 1.4243 - val_mae: 0.7756\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0660 - val_loss: 1.4138 - val_mae: 0.7711\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0682 - val_loss: 1.4336 - val_mae: 0.7747\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0116 - mae: 0.0704 - val_loss: 1.4201 - val_mae: 0.7733\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0124 - mae: 0.0707 - val_loss: 1.4178 - val_mae: 0.7737\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0113 - mae: 0.0699 - val_loss: 1.4134 - val_mae: 0.7726\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0108 - mae: 0.0680 - val_loss: 1.4365 - val_mae: 0.7747\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0745 - val_loss: 1.4278 - val_mae: 0.7759\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0135 - mae: 0.0740 - val_loss: 1.4062 - val_mae: 0.7715\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0726 - val_loss: 1.4152 - val_mae: 0.7713\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0102 - mae: 0.0659 - val_loss: 1.4074 - val_mae: 0.7723\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0120 - mae: 0.0680 - val_loss: 1.4239 - val_mae: 0.7726\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0115 - mae: 0.0689 - val_loss: 1.4273 - val_mae: 0.7729\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0690 - val_loss: 1.4332 - val_mae: 0.7714\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0109 - mae: 0.0659 - val_loss: 1.4151 - val_mae: 0.7710\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0109 - mae: 0.0687 - val_loss: 1.4206 - val_mae: 0.7737\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0113 - mae: 0.0673 - val_loss: 1.4596 - val_mae: 0.7757\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0762 - val_loss: 1.4095 - val_mae: 0.7715\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0133 - mae: 0.0708 - val_loss: 1.4298 - val_mae: 0.7722\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0673 - val_loss: 1.4086 - val_mae: 0.7732\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0102 - mae: 0.0649 - val_loss: 1.3971 - val_mae: 0.7704\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0105 - mae: 0.0647 - val_loss: 1.4181 - val_mae: 0.7731\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0110 - mae: 0.0646 - val_loss: 1.4093 - val_mae: 0.7704\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0109 - mae: 0.0688 - val_loss: 1.4294 - val_mae: 0.7734\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0095 - mae: 0.0653 - val_loss: 1.4150 - val_mae: 0.7703\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0099 - mae: 0.0653 - val_loss: 1.4397 - val_mae: 0.7745\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0102 - mae: 0.0657 - val_loss: 1.4299 - val_mae: 0.7688\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0104 - mae: 0.0666 - val_loss: 1.4303 - val_mae: 0.7732\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0114 - mae: 0.0672 - val_loss: 1.4217 - val_mae: 0.7705\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0091 - mae: 0.0621 - val_loss: 1.4218 - val_mae: 0.7738\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0111 - mae: 0.0663 - val_loss: 1.4248 - val_mae: 0.7752\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0093 - mae: 0.0627 - val_loss: 1.3958 - val_mae: 0.7699\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0095 - mae: 0.0650 - val_loss: 1.4196 - val_mae: 0.7724\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0088 - mae: 0.0618 - val_loss: 1.4090 - val_mae: 0.7703\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0100 - mae: 0.0648 - val_loss: 1.4273 - val_mae: 0.7697\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0087 - mae: 0.0604 - val_loss: 1.4495 - val_mae: 0.7772\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0094 - mae: 0.0625 - val_loss: 1.4198 - val_mae: 0.7702\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0645 - val_loss: 1.4175 - val_mae: 0.7706\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0672 - val_loss: 1.4202 - val_mae: 0.7706\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0103 - mae: 0.0656 - val_loss: 1.4610 - val_mae: 0.7758\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0092 - mae: 0.0622 - val_loss: 1.4344 - val_mae: 0.7697\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0092 - mae: 0.0641 - val_loss: 1.4287 - val_mae: 0.7761\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0099 - mae: 0.0648 - val_loss: 1.4313 - val_mae: 0.7700\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0099 - mae: 0.0628 - val_loss: 1.4020 - val_mae: 0.7669\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0094 - mae: 0.0629 - val_loss: 1.4466 - val_mae: 0.7753\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0094 - mae: 0.0636 - val_loss: 1.4075 - val_mae: 0.7730\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0641 - val_loss: 1.4256 - val_mae: 0.7731\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0653 - val_loss: 1.4350 - val_mae: 0.7753\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0085 - mae: 0.0588 - val_loss: 1.4479 - val_mae: 0.7747\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0080 - mae: 0.0575 - val_loss: 1.4313 - val_mae: 0.7731\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0075 - mae: 0.0552 - val_loss: 1.4288 - val_mae: 0.7721\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0092 - mae: 0.0611 - val_loss: 1.4518 - val_mae: 0.7759\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0113 - mae: 0.0658 - val_loss: 1.4338 - val_mae: 0.7730\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0103 - mae: 0.0653 - val_loss: 1.4553 - val_mae: 0.7748\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0088 - mae: 0.0615 - val_loss: 1.4372 - val_mae: 0.7736\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0093 - mae: 0.0622 - val_loss: 1.4414 - val_mae: 0.7711\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0087 - mae: 0.0598 - val_loss: 1.4644 - val_mae: 0.7751\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0095 - mae: 0.0621 - val_loss: 1.4305 - val_mae: 0.7707\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0089 - mae: 0.0610 - val_loss: 1.4175 - val_mae: 0.7697\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3569 - mae: 0.7550\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 4.2620 - mae: 1.4934 - val_loss: 2.0811 - val_mae: 0.9619\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 1.1659 - mae: 0.7584 - val_loss: 1.8108 - val_mae: 0.8963\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.7259 - mae: 0.5847 - val_loss: 1.7163 - val_mae: 0.8738\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.5596 - mae: 0.5102 - val_loss: 1.4938 - val_mae: 0.8190\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.4326 - mae: 0.4363 - val_loss: 1.5978 - val_mae: 0.8360\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.3864 - mae: 0.4128 - val_loss: 1.5913 - val_mae: 0.8422\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.3208 - mae: 0.3782 - val_loss: 1.6893 - val_mae: 0.8289\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.2992 - mae: 0.3579 - val_loss: 1.5352 - val_mae: 0.8180\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.2515 - mae: 0.3284 - val_loss: 1.5463 - val_mae: 0.8196\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.2460 - mae: 0.3173 - val_loss: 1.4936 - val_mae: 0.8022\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1972 - mae: 0.2963 - val_loss: 1.4471 - val_mae: 0.7969\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.1861 - mae: 0.2783 - val_loss: 1.4086 - val_mae: 0.7870\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1703 - mae: 0.2710 - val_loss: 1.4590 - val_mae: 0.8077\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1581 - mae: 0.2633 - val_loss: 1.4348 - val_mae: 0.7827\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1709 - mae: 0.2738 - val_loss: 1.4104 - val_mae: 0.7850\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1493 - mae: 0.2560 - val_loss: 1.4101 - val_mae: 0.7823\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1369 - mae: 0.2398 - val_loss: 1.4105 - val_mae: 0.7759\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1247 - mae: 0.2357 - val_loss: 1.5733 - val_mae: 0.7978\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1398 - mae: 0.2401 - val_loss: 1.3690 - val_mae: 0.7693\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1191 - mae: 0.2251 - val_loss: 1.4208 - val_mae: 0.7844\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1349 - mae: 0.2422 - val_loss: 1.3791 - val_mae: 0.7769\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1160 - mae: 0.2271 - val_loss: 1.4087 - val_mae: 0.7708\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.1021 - mae: 0.2111 - val_loss: 1.3584 - val_mae: 0.7641\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1083 - mae: 0.2075 - val_loss: 1.3679 - val_mae: 0.7648\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1040 - mae: 0.1989 - val_loss: 1.3627 - val_mae: 0.7568\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0911 - mae: 0.1933 - val_loss: 1.3851 - val_mae: 0.7641\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0874 - mae: 0.1928 - val_loss: 1.3459 - val_mae: 0.7586\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0780 - mae: 0.1855 - val_loss: 1.4062 - val_mae: 0.7672\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0800 - mae: 0.1844 - val_loss: 1.3333 - val_mae: 0.7579\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0818 - mae: 0.1868 - val_loss: 1.3676 - val_mae: 0.7621\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0800 - mae: 0.1805 - val_loss: 1.3379 - val_mae: 0.7480\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0733 - mae: 0.1767 - val_loss: 1.3458 - val_mae: 0.7570\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0778 - mae: 0.1780 - val_loss: 1.5195 - val_mae: 0.7756\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0834 - mae: 0.1841 - val_loss: 1.3243 - val_mae: 0.7641\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0752 - mae: 0.1725 - val_loss: 1.3754 - val_mae: 0.7689\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0617 - mae: 0.1655 - val_loss: 1.3616 - val_mae: 0.7585\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0630 - mae: 0.1594 - val_loss: 1.3505 - val_mae: 0.7620\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0555 - mae: 0.1558 - val_loss: 1.3866 - val_mae: 0.7590\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0706 - mae: 0.1690 - val_loss: 1.3158 - val_mae: 0.7512\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0590 - mae: 0.1591 - val_loss: 1.3711 - val_mae: 0.7560\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0512 - mae: 0.1509 - val_loss: 1.3303 - val_mae: 0.7527\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0521 - mae: 0.1493 - val_loss: 1.3352 - val_mae: 0.7542\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0655 - mae: 0.1537 - val_loss: 1.3553 - val_mae: 0.7532\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0521 - mae: 0.1480 - val_loss: 1.3598 - val_mae: 0.7574\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0503 - mae: 0.1442 - val_loss: 1.3792 - val_mae: 0.7591\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0524 - mae: 0.1467 - val_loss: 1.3262 - val_mae: 0.7445\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0538 - mae: 0.1473 - val_loss: 1.3498 - val_mae: 0.7555\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0654 - mae: 0.1461 - val_loss: 1.3649 - val_mae: 0.7583\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0585 - mae: 0.1463 - val_loss: 1.3367 - val_mae: 0.7471\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0410 - mae: 0.1335 - val_loss: 1.3479 - val_mae: 0.7540\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0467 - mae: 0.1370 - val_loss: 1.3887 - val_mae: 0.7563\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0432 - mae: 0.1356 - val_loss: 1.4248 - val_mae: 0.7554\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0520 - mae: 0.1377 - val_loss: 1.3417 - val_mae: 0.7479\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0466 - mae: 0.1364 - val_loss: 1.3896 - val_mae: 0.7592\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0637 - mae: 0.1438 - val_loss: 1.3552 - val_mae: 0.7511\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0457 - mae: 0.1326 - val_loss: 1.3667 - val_mae: 0.7605\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0502 - mae: 0.1376 - val_loss: 1.3544 - val_mae: 0.7562\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0398 - mae: 0.1264 - val_loss: 1.3360 - val_mae: 0.7505\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0383 - mae: 0.1239 - val_loss: 1.3938 - val_mae: 0.7587\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0433 - mae: 0.1266 - val_loss: 1.3807 - val_mae: 0.7608\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0494 - mae: 0.1252 - val_loss: 1.3731 - val_mae: 0.7571\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0371 - mae: 0.1204 - val_loss: 1.3892 - val_mae: 0.7603\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0401 - mae: 0.1236 - val_loss: 1.3655 - val_mae: 0.7551\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0505 - mae: 0.1277 - val_loss: 1.3700 - val_mae: 0.7591\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0367 - mae: 0.1191 - val_loss: 1.3392 - val_mae: 0.7497\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0351 - mae: 0.1161 - val_loss: 1.3437 - val_mae: 0.7495\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0429 - mae: 0.1191 - val_loss: 1.3428 - val_mae: 0.7466\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0367 - mae: 0.1232 - val_loss: 1.4063 - val_mae: 0.7553\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0400 - mae: 0.1246 - val_loss: 1.3485 - val_mae: 0.7497\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0341 - mae: 0.1154 - val_loss: 1.3465 - val_mae: 0.7528\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0316 - mae: 0.1129 - val_loss: 1.3637 - val_mae: 0.7503\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0295 - mae: 0.1101 - val_loss: 1.3427 - val_mae: 0.7527\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0365 - mae: 0.1205 - val_loss: 1.3182 - val_mae: 0.7526\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0311 - mae: 0.1135 - val_loss: 1.2949 - val_mae: 0.7521\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0347 - mae: 0.1155 - val_loss: 1.3349 - val_mae: 0.7468\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0317 - mae: 0.1118 - val_loss: 1.3406 - val_mae: 0.7504\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0301 - mae: 0.1063 - val_loss: 1.3191 - val_mae: 0.7536\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0310 - mae: 0.1112 - val_loss: 1.3309 - val_mae: 0.7514\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0332 - mae: 0.1102 - val_loss: 1.3515 - val_mae: 0.7507\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0287 - mae: 0.1069 - val_loss: 1.3450 - val_mae: 0.7488\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0329 - mae: 0.1066 - val_loss: 1.3454 - val_mae: 0.7511\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0257 - mae: 0.0985 - val_loss: 1.4126 - val_mae: 0.7575\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0267 - mae: 0.1021 - val_loss: 1.3783 - val_mae: 0.7545\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0251 - mae: 0.1013 - val_loss: 1.3348 - val_mae: 0.7525\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0275 - mae: 0.1043 - val_loss: 1.3309 - val_mae: 0.7598\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0281 - mae: 0.1041 - val_loss: 1.3307 - val_mae: 0.7500\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0319 - mae: 0.1081 - val_loss: 1.3746 - val_mae: 0.7550\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0304 - mae: 0.1012 - val_loss: 1.3543 - val_mae: 0.7488\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0246 - mae: 0.0968 - val_loss: 1.3422 - val_mae: 0.7487\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0209 - mae: 0.0923 - val_loss: 1.3974 - val_mae: 0.7481\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0243 - mae: 0.0975 - val_loss: 1.3359 - val_mae: 0.7461\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0241 - mae: 0.0975 - val_loss: 1.3771 - val_mae: 0.7541\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0234 - mae: 0.0993 - val_loss: 1.3642 - val_mae: 0.7487\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0210 - mae: 0.0936 - val_loss: 1.3955 - val_mae: 0.7519\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0249 - mae: 0.0995 - val_loss: 1.3273 - val_mae: 0.7491\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0232 - mae: 0.0959 - val_loss: 1.3622 - val_mae: 0.7518\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0275 - mae: 0.1004 - val_loss: 1.3366 - val_mae: 0.7457\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0249 - mae: 0.0987 - val_loss: 1.3420 - val_mae: 0.7466\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0237 - mae: 0.0933 - val_loss: 1.3076 - val_mae: 0.7521\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0238 - mae: 0.0898 - val_loss: 1.3644 - val_mae: 0.7528\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0209 - mae: 0.0921 - val_loss: 1.3159 - val_mae: 0.7452\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0223 - mae: 0.0945 - val_loss: 1.3633 - val_mae: 0.7469\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0193 - mae: 0.0887 - val_loss: 1.3533 - val_mae: 0.7527\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0211 - mae: 0.0913 - val_loss: 1.3709 - val_mae: 0.7477\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0272 - mae: 0.0970 - val_loss: 1.3410 - val_mae: 0.7452\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0253 - mae: 0.0939 - val_loss: 1.3543 - val_mae: 0.7470\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0183 - mae: 0.0860 - val_loss: 1.3462 - val_mae: 0.7490\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0189 - mae: 0.0858 - val_loss: 1.3435 - val_mae: 0.7460\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0191 - mae: 0.0878 - val_loss: 1.3387 - val_mae: 0.7481\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0207 - mae: 0.0866 - val_loss: 1.3474 - val_mae: 0.7477\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0261 - mae: 0.0899 - val_loss: 1.3362 - val_mae: 0.7439\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0210 - mae: 0.0881 - val_loss: 1.3092 - val_mae: 0.7477\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0209 - mae: 0.0916 - val_loss: 1.3674 - val_mae: 0.7475\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0200 - mae: 0.0850 - val_loss: 1.3535 - val_mae: 0.7494\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0271 - mae: 0.0928 - val_loss: 1.3450 - val_mae: 0.7480\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0175 - mae: 0.0854 - val_loss: 1.3659 - val_mae: 0.7506\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0218 - mae: 0.0866 - val_loss: 1.3710 - val_mae: 0.7414\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0201 - mae: 0.0879 - val_loss: 1.3516 - val_mae: 0.7504\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0146 - mae: 0.0798 - val_loss: 1.3426 - val_mae: 0.7488\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0249 - mae: 0.0851 - val_loss: 1.3386 - val_mae: 0.7454\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0167 - mae: 0.0807 - val_loss: 1.3342 - val_mae: 0.7404\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0783 - val_loss: 1.3547 - val_mae: 0.7487\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0194 - mae: 0.0833 - val_loss: 1.3277 - val_mae: 0.7426\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0796 - val_loss: 1.3481 - val_mae: 0.7458\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0786 - val_loss: 1.3622 - val_mae: 0.7458\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0174 - mae: 0.0846 - val_loss: 1.3317 - val_mae: 0.7457\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0177 - mae: 0.0792 - val_loss: 1.3597 - val_mae: 0.7529\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0160 - mae: 0.0831 - val_loss: 1.3325 - val_mae: 0.7459\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0188 - mae: 0.0783 - val_loss: 1.3381 - val_mae: 0.7495\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0170 - mae: 0.0814 - val_loss: 1.3790 - val_mae: 0.7554\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0249 - mae: 0.0955 - val_loss: 1.3835 - val_mae: 0.7484\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0206 - mae: 0.0812 - val_loss: 1.4031 - val_mae: 0.7513\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0737 - val_loss: 1.3509 - val_mae: 0.7449\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0182 - mae: 0.0800 - val_loss: 1.3714 - val_mae: 0.7473\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0150 - mae: 0.0741 - val_loss: 1.3674 - val_mae: 0.7444\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0146 - mae: 0.0722 - val_loss: 1.3255 - val_mae: 0.7404\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0141 - mae: 0.0707 - val_loss: 1.3541 - val_mae: 0.7481\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0194 - mae: 0.0760 - val_loss: 1.3237 - val_mae: 0.7381\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0142 - mae: 0.0760 - val_loss: 1.3280 - val_mae: 0.7447\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0742 - val_loss: 1.3891 - val_mae: 0.7449\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0192 - mae: 0.0789 - val_loss: 1.3129 - val_mae: 0.7425\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0175 - mae: 0.0813 - val_loss: 1.3597 - val_mae: 0.7504\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0160 - mae: 0.0792 - val_loss: 1.3765 - val_mae: 0.7414\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0744 - val_loss: 1.3399 - val_mae: 0.7432\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0173 - mae: 0.0744 - val_loss: 1.3812 - val_mae: 0.7459\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0767 - val_loss: 1.3240 - val_mae: 0.7423\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0128 - mae: 0.0724 - val_loss: 1.3798 - val_mae: 0.7443\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0694 - val_loss: 1.3009 - val_mae: 0.7363\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0160 - mae: 0.0735 - val_loss: 1.3436 - val_mae: 0.7405\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0750 - val_loss: 1.3361 - val_mae: 0.7429\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0146 - mae: 0.0765 - val_loss: 1.4079 - val_mae: 0.7492\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0147 - mae: 0.0752 - val_loss: 1.3522 - val_mae: 0.7408\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0160 - mae: 0.0767 - val_loss: 1.3432 - val_mae: 0.7397\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0185 - mae: 0.0786 - val_loss: 1.3427 - val_mae: 0.7431\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0135 - mae: 0.0705 - val_loss: 1.3181 - val_mae: 0.7397\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0151 - mae: 0.0741 - val_loss: 1.3843 - val_mae: 0.7461\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0694 - val_loss: 1.3203 - val_mae: 0.7402\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0138 - mae: 0.0681 - val_loss: 1.3411 - val_mae: 0.7440\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0128 - mae: 0.0710 - val_loss: 1.3468 - val_mae: 0.7446\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0703 - val_loss: 1.3438 - val_mae: 0.7373\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0669 - val_loss: 1.3374 - val_mae: 0.7439\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0153 - mae: 0.0744 - val_loss: 1.3398 - val_mae: 0.7436\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0154 - mae: 0.0715 - val_loss: 1.3319 - val_mae: 0.7425\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0722 - val_loss: 1.3404 - val_mae: 0.7454\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0153 - mae: 0.0716 - val_loss: 1.3510 - val_mae: 0.7411\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0180 - mae: 0.0688 - val_loss: 1.3118 - val_mae: 0.7388\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0195 - mae: 0.0726 - val_loss: 1.3352 - val_mae: 0.7405\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0138 - mae: 0.0712 - val_loss: 1.3327 - val_mae: 0.7395\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0673 - val_loss: 1.3227 - val_mae: 0.7480\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0159 - mae: 0.0721 - val_loss: 1.3450 - val_mae: 0.7380\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0125 - mae: 0.0665 - val_loss: 1.3369 - val_mae: 0.7454\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0142 - mae: 0.0691 - val_loss: 1.3276 - val_mae: 0.7404\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0155 - mae: 0.0694 - val_loss: 1.3321 - val_mae: 0.7423\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0150 - mae: 0.0690 - val_loss: 1.3004 - val_mae: 0.7371\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0110 - mae: 0.0642 - val_loss: 1.3694 - val_mae: 0.7424\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0111 - mae: 0.0653 - val_loss: 1.3404 - val_mae: 0.7444\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0703 - val_loss: 1.3179 - val_mae: 0.7402\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0126 - mae: 0.0696 - val_loss: 1.3403 - val_mae: 0.7451\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0115 - mae: 0.0632 - val_loss: 1.3211 - val_mae: 0.7395\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0687 - val_loss: 1.3333 - val_mae: 0.7436\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0166 - mae: 0.0759 - val_loss: 1.3344 - val_mae: 0.7417\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0664 - val_loss: 1.3364 - val_mae: 0.7407\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0117 - mae: 0.0654 - val_loss: 1.3343 - val_mae: 0.7488\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0651 - val_loss: 1.3290 - val_mae: 0.7415\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0680 - val_loss: 1.3486 - val_mae: 0.7446\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0116 - mae: 0.0682 - val_loss: 1.3091 - val_mae: 0.7376\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0154 - mae: 0.0647 - val_loss: 1.3295 - val_mae: 0.7404\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0129 - mae: 0.0637 - val_loss: 1.3198 - val_mae: 0.7375\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0134 - mae: 0.0621 - val_loss: 1.3333 - val_mae: 0.7401\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0584 - val_loss: 1.3165 - val_mae: 0.7387\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0111 - mae: 0.0634 - val_loss: 1.3176 - val_mae: 0.7393\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0142 - mae: 0.0659 - val_loss: 1.3085 - val_mae: 0.7390\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0132 - mae: 0.0632 - val_loss: 1.3121 - val_mae: 0.7382\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0101 - mae: 0.0623 - val_loss: 1.3231 - val_mae: 0.7362\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0096 - mae: 0.0610 - val_loss: 1.3154 - val_mae: 0.7413\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0113 - mae: 0.0665 - val_loss: 1.3218 - val_mae: 0.7363\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0641 - val_loss: 1.3523 - val_mae: 0.7472\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0110 - mae: 0.0636 - val_loss: 1.3229 - val_mae: 0.7364\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0112 - mae: 0.0625 - val_loss: 1.3171 - val_mae: 0.7378\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0103 - mae: 0.0609 - val_loss: 1.3072 - val_mae: 0.7369\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3186 - mae: 0.7371\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 4.8911 - mae: 1.5957 - val_loss: 2.5714 - val_mae: 0.9840\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 1.1569 - mae: 0.7465 - val_loss: 2.0710 - val_mae: 0.9298\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.7295 - mae: 0.5859 - val_loss: 1.9985 - val_mae: 0.9455\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.5511 - mae: 0.4980 - val_loss: 1.8360 - val_mae: 0.8740\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.5380 - mae: 0.4416 - val_loss: 1.9224 - val_mae: 0.8814\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.3124 - mae: 0.3715 - val_loss: 1.7616 - val_mae: 0.8791\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2816 - mae: 0.3452 - val_loss: 1.9596 - val_mae: 0.8547\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2645 - mae: 0.3378 - val_loss: 1.7708 - val_mae: 0.8480\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.6099 - mae: 0.3556 - val_loss: 1.7434 - val_mae: 0.8454\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2281 - mae: 0.3015 - val_loss: 1.6508 - val_mae: 0.8356\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1744 - mae: 0.2752 - val_loss: 1.5801 - val_mae: 0.8270\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1612 - mae: 0.2670 - val_loss: 1.5850 - val_mae: 0.8241\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1521 - mae: 0.2562 - val_loss: 1.5844 - val_mae: 0.8259\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1484 - mae: 0.2627 - val_loss: 1.5950 - val_mae: 0.8226\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1339 - mae: 0.2428 - val_loss: 1.5650 - val_mae: 0.8146\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1399 - mae: 0.2434 - val_loss: 1.5877 - val_mae: 0.8167\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1583 - mae: 0.2492 - val_loss: 1.5497 - val_mae: 0.8136\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1374 - mae: 0.2410 - val_loss: 1.6690 - val_mae: 0.8279\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1194 - mae: 0.2271 - val_loss: 1.5360 - val_mae: 0.8071\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1058 - mae: 0.2118 - val_loss: 1.6903 - val_mae: 0.8171\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1075 - mae: 0.2112 - val_loss: 1.5708 - val_mae: 0.8042\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1173 - mae: 0.2167 - val_loss: 1.5727 - val_mae: 0.8097\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1083 - mae: 0.2117 - val_loss: 1.8060 - val_mae: 0.8221\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1689 - mae: 0.2304 - val_loss: 1.5669 - val_mae: 0.8137\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0957 - mae: 0.1934 - val_loss: 1.4722 - val_mae: 0.7943\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0831 - mae: 0.1849 - val_loss: 1.5915 - val_mae: 0.8050\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0914 - mae: 0.1893 - val_loss: 1.5172 - val_mae: 0.7998\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0867 - mae: 0.1825 - val_loss: 1.5026 - val_mae: 0.7946\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0825 - mae: 0.1795 - val_loss: 1.5231 - val_mae: 0.7950\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0688 - mae: 0.1723 - val_loss: 1.5048 - val_mae: 0.7891\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0740 - mae: 0.1740 - val_loss: 1.4502 - val_mae: 0.7897\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0810 - mae: 0.1799 - val_loss: 1.5615 - val_mae: 0.7954\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0842 - mae: 0.1871 - val_loss: 1.5509 - val_mae: 0.7976\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0726 - mae: 0.1691 - val_loss: 1.5699 - val_mae: 0.7961\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0713 - mae: 0.1599 - val_loss: 1.4411 - val_mae: 0.7953\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0698 - mae: 0.1655 - val_loss: 1.5245 - val_mae: 0.7947\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0552 - mae: 0.1498 - val_loss: 1.4958 - val_mae: 0.7937\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0584 - mae: 0.1516 - val_loss: 1.4441 - val_mae: 0.7832\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0586 - mae: 0.1561 - val_loss: 1.4953 - val_mae: 0.7903\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0595 - mae: 0.1510 - val_loss: 1.4441 - val_mae: 0.7804\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0493 - mae: 0.1393 - val_loss: 1.4737 - val_mae: 0.7840\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0445 - mae: 0.1355 - val_loss: 1.5088 - val_mae: 0.7866\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0524 - mae: 0.1446 - val_loss: 1.5345 - val_mae: 0.7888\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0640 - mae: 0.1549 - val_loss: 1.4437 - val_mae: 0.7772\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0511 - mae: 0.1438 - val_loss: 1.4927 - val_mae: 0.7838\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0505 - mae: 0.1397 - val_loss: 1.4590 - val_mae: 0.7753\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0489 - mae: 0.1428 - val_loss: 1.5372 - val_mae: 0.7911\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0494 - mae: 0.1441 - val_loss: 1.4706 - val_mae: 0.7825\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0480 - mae: 0.1370 - val_loss: 1.4776 - val_mae: 0.7805\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0510 - mae: 0.1323 - val_loss: 1.4527 - val_mae: 0.7741\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0600 - mae: 0.1416 - val_loss: 1.5158 - val_mae: 0.7830\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0432 - mae: 0.1274 - val_loss: 1.4653 - val_mae: 0.7763\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0453 - mae: 0.1283 - val_loss: 1.5735 - val_mae: 0.7865\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0496 - mae: 0.1356 - val_loss: 1.4856 - val_mae: 0.7852\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0423 - mae: 0.1270 - val_loss: 1.5062 - val_mae: 0.7802\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0374 - mae: 0.1212 - val_loss: 1.4669 - val_mae: 0.7814\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0431 - mae: 0.1261 - val_loss: 1.4739 - val_mae: 0.7783\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0406 - mae: 0.1229 - val_loss: 1.4807 - val_mae: 0.7856\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0383 - mae: 0.1200 - val_loss: 1.4900 - val_mae: 0.7725\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0409 - mae: 0.1213 - val_loss: 1.5136 - val_mae: 0.7828\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0346 - mae: 0.1187 - val_loss: 1.4466 - val_mae: 0.7719\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0325 - mae: 0.1152 - val_loss: 1.4350 - val_mae: 0.7758\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0397 - mae: 0.1135 - val_loss: 1.4690 - val_mae: 0.7730\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0308 - mae: 0.1099 - val_loss: 1.4851 - val_mae: 0.7835\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0377 - mae: 0.1166 - val_loss: 1.4856 - val_mae: 0.7757\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0321 - mae: 0.1140 - val_loss: 1.4782 - val_mae: 0.7757\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0346 - mae: 0.1137 - val_loss: 1.4731 - val_mae: 0.7791\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0283 - mae: 0.1078 - val_loss: 1.4189 - val_mae: 0.7737\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0333 - mae: 0.1115 - val_loss: 1.4866 - val_mae: 0.7789\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0323 - mae: 0.1106 - val_loss: 1.4300 - val_mae: 0.7734\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0309 - mae: 0.1042 - val_loss: 1.4616 - val_mae: 0.7725\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0315 - mae: 0.1048 - val_loss: 1.4926 - val_mae: 0.7806\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0399 - mae: 0.1140 - val_loss: 1.4828 - val_mae: 0.7757\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0298 - mae: 0.1079 - val_loss: 1.4748 - val_mae: 0.7793\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0314 - mae: 0.1050 - val_loss: 1.4802 - val_mae: 0.7813\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0310 - mae: 0.1070 - val_loss: 1.4641 - val_mae: 0.7810\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0308 - mae: 0.1095 - val_loss: 1.4632 - val_mae: 0.7808\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0290 - mae: 0.1046 - val_loss: 1.4359 - val_mae: 0.7749\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0246 - mae: 0.0980 - val_loss: 1.4775 - val_mae: 0.7803\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0272 - mae: 0.1010 - val_loss: 1.4664 - val_mae: 0.7723\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0264 - mae: 0.1013 - val_loss: 1.4783 - val_mae: 0.7752\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0252 - mae: 0.1010 - val_loss: 1.4786 - val_mae: 0.7766\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0244 - mae: 0.1000 - val_loss: 1.4548 - val_mae: 0.7788\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0315 - mae: 0.1089 - val_loss: 1.4674 - val_mae: 0.7768\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0252 - mae: 0.0912 - val_loss: 1.4765 - val_mae: 0.7761\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0230 - mae: 0.0915 - val_loss: 1.4566 - val_mae: 0.7761\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0242 - mae: 0.0940 - val_loss: 1.4433 - val_mae: 0.7712\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0255 - mae: 0.0984 - val_loss: 1.4947 - val_mae: 0.7770\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0289 - mae: 0.0998 - val_loss: 1.4444 - val_mae: 0.7706\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0332 - mae: 0.1024 - val_loss: 1.4299 - val_mae: 0.7744\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0196 - mae: 0.0891 - val_loss: 1.4553 - val_mae: 0.7740\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0203 - mae: 0.0873 - val_loss: 1.4709 - val_mae: 0.7779\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0202 - mae: 0.0896 - val_loss: 1.4719 - val_mae: 0.7765\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0235 - mae: 0.0931 - val_loss: 1.4625 - val_mae: 0.7742\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0271 - mae: 0.0978 - val_loss: 1.4713 - val_mae: 0.7782\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0250 - mae: 0.0913 - val_loss: 1.4817 - val_mae: 0.7779\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0180 - mae: 0.0824 - val_loss: 1.4741 - val_mae: 0.7735\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0219 - mae: 0.0907 - val_loss: 1.4718 - val_mae: 0.7773\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0246 - mae: 0.0925 - val_loss: 1.4532 - val_mae: 0.7744\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0250 - mae: 0.0932 - val_loss: 1.4670 - val_mae: 0.7765\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0180 - mae: 0.0836 - val_loss: 1.4510 - val_mae: 0.7769\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0237 - mae: 0.0904 - val_loss: 1.4862 - val_mae: 0.7737\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0172 - mae: 0.0824 - val_loss: 1.4578 - val_mae: 0.7758\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0260 - mae: 0.0920 - val_loss: 1.4731 - val_mae: 0.7752\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0173 - mae: 0.0830 - val_loss: 1.4623 - val_mae: 0.7732\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0191 - mae: 0.0896 - val_loss: 1.4636 - val_mae: 0.7727\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0203 - mae: 0.0860 - val_loss: 1.4523 - val_mae: 0.7751\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0158 - mae: 0.0773 - val_loss: 1.4729 - val_mae: 0.7754\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0165 - mae: 0.0787 - val_loss: 1.4905 - val_mae: 0.7745\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0186 - mae: 0.0835 - val_loss: 1.4650 - val_mae: 0.7790\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0298 - mae: 0.0900 - val_loss: 1.4464 - val_mae: 0.7753\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0217 - mae: 0.0868 - val_loss: 1.4255 - val_mae: 0.7751\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0199 - mae: 0.0809 - val_loss: 1.4545 - val_mae: 0.7742\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0199 - mae: 0.0830 - val_loss: 1.4631 - val_mae: 0.7718\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0168 - mae: 0.0813 - val_loss: 1.4850 - val_mae: 0.7747\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0177 - mae: 0.0818 - val_loss: 1.4748 - val_mae: 0.7782\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0198 - mae: 0.0845 - val_loss: 1.4592 - val_mae: 0.7726\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0214 - mae: 0.0818 - val_loss: 1.4591 - val_mae: 0.7743\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0170 - mae: 0.0796 - val_loss: 1.4791 - val_mae: 0.7786\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0206 - mae: 0.0795 - val_loss: 1.4493 - val_mae: 0.7749\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0164 - mae: 0.0782 - val_loss: 1.4671 - val_mae: 0.7748\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0214 - mae: 0.0855 - val_loss: 1.4420 - val_mae: 0.7727\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0188 - mae: 0.0773 - val_loss: 1.4716 - val_mae: 0.7746\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0183 - mae: 0.0829 - val_loss: 1.4201 - val_mae: 0.7685\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0177 - mae: 0.0779 - val_loss: 1.4609 - val_mae: 0.7760\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0169 - mae: 0.0754 - val_loss: 1.4374 - val_mae: 0.7731\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0143 - mae: 0.0747 - val_loss: 1.4564 - val_mae: 0.7732\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0184 - mae: 0.0773 - val_loss: 1.4259 - val_mae: 0.7683\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0157 - mae: 0.0785 - val_loss: 1.4544 - val_mae: 0.7720\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0158 - mae: 0.0791 - val_loss: 1.4403 - val_mae: 0.7735\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0744 - val_loss: 1.4709 - val_mae: 0.7700\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0143 - mae: 0.0727 - val_loss: 1.4364 - val_mae: 0.7694\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0139 - mae: 0.0734 - val_loss: 1.4630 - val_mae: 0.7758\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0189 - mae: 0.0805 - val_loss: 1.4477 - val_mae: 0.7688\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0143 - mae: 0.0740 - val_loss: 1.4405 - val_mae: 0.7717\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0136 - mae: 0.0739 - val_loss: 1.5103 - val_mae: 0.7806\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0178 - mae: 0.0833 - val_loss: 1.4344 - val_mae: 0.7693\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0151 - mae: 0.0752 - val_loss: 1.4296 - val_mae: 0.7719\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0161 - mae: 0.0716 - val_loss: 1.4367 - val_mae: 0.7717\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0155 - mae: 0.0751 - val_loss: 1.4532 - val_mae: 0.7771\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0169 - mae: 0.0757 - val_loss: 1.4297 - val_mae: 0.7725\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0146 - mae: 0.0715 - val_loss: 1.4734 - val_mae: 0.7758\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0144 - mae: 0.0725 - val_loss: 1.4613 - val_mae: 0.7728\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0683 - val_loss: 1.4464 - val_mae: 0.7743\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0156 - mae: 0.0728 - val_loss: 1.4449 - val_mae: 0.7713\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0147 - mae: 0.0738 - val_loss: 1.4441 - val_mae: 0.7727\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0196 - mae: 0.0811 - val_loss: 1.4540 - val_mae: 0.7719\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0130 - mae: 0.0698 - val_loss: 1.4342 - val_mae: 0.7719\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0705 - val_loss: 1.4769 - val_mae: 0.7715\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0719 - val_loss: 1.4407 - val_mae: 0.7695\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0177 - mae: 0.0707 - val_loss: 1.4797 - val_mae: 0.7753\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0136 - mae: 0.0718 - val_loss: 1.4539 - val_mae: 0.7733\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0166 - mae: 0.0706 - val_loss: 1.4610 - val_mae: 0.7755\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0125 - mae: 0.0711 - val_loss: 1.4581 - val_mae: 0.7711\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0704 - val_loss: 1.4714 - val_mae: 0.7732\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0640 - val_loss: 1.4507 - val_mae: 0.7730\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0136 - mae: 0.0699 - val_loss: 1.4426 - val_mae: 0.7743\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0130 - mae: 0.0723 - val_loss: 1.4549 - val_mae: 0.7697\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0146 - mae: 0.0687 - val_loss: 1.4418 - val_mae: 0.7731\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0641 - val_loss: 1.4321 - val_mae: 0.7709\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0133 - mae: 0.0651 - val_loss: 1.4431 - val_mae: 0.7708\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0110 - mae: 0.0637 - val_loss: 1.4564 - val_mae: 0.7752\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0127 - mae: 0.0684 - val_loss: 1.4488 - val_mae: 0.7710\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0138 - mae: 0.0688 - val_loss: 1.4313 - val_mae: 0.7725\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0691 - val_loss: 1.4545 - val_mae: 0.7693\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0108 - mae: 0.0638 - val_loss: 1.4262 - val_mae: 0.7718\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0130 - mae: 0.0654 - val_loss: 1.4594 - val_mae: 0.7738\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0127 - mae: 0.0674 - val_loss: 1.4202 - val_mae: 0.7670\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0644 - val_loss: 1.4471 - val_mae: 0.7716\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0672 - val_loss: 1.4397 - val_mae: 0.7730\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0107 - mae: 0.0655 - val_loss: 1.4183 - val_mae: 0.7671\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0110 - mae: 0.0636 - val_loss: 1.4322 - val_mae: 0.7723\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0648 - val_loss: 1.4429 - val_mae: 0.7686\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 0.0124 - mae: 0.0633 - val_loss: 1.4730 - val_mae: 0.7773\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0676 - val_loss: 1.4137 - val_mae: 0.7671\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0640 - val_loss: 1.4456 - val_mae: 0.7724\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0110 - mae: 0.0659 - val_loss: 1.4131 - val_mae: 0.7722\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0691 - val_loss: 1.4808 - val_mae: 0.7765\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0157 - mae: 0.0659 - val_loss: 1.4088 - val_mae: 0.7707\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0138 - mae: 0.0665 - val_loss: 1.4679 - val_mae: 0.7765\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0128 - mae: 0.0636 - val_loss: 1.4420 - val_mae: 0.7742\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0099 - mae: 0.0593 - val_loss: 1.4653 - val_mae: 0.7729\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0102 - mae: 0.0621 - val_loss: 1.4453 - val_mae: 0.7718\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0129 - mae: 0.0648 - val_loss: 1.4499 - val_mae: 0.7699\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0113 - mae: 0.0635 - val_loss: 1.4426 - val_mae: 0.7689\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0113 - mae: 0.0622 - val_loss: 1.4517 - val_mae: 0.7684\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0095 - mae: 0.0601 - val_loss: 1.4378 - val_mae: 0.7714\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0645 - val_loss: 1.4359 - val_mae: 0.7725\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0146 - mae: 0.0676 - val_loss: 1.4231 - val_mae: 0.7700\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0094 - mae: 0.0608 - val_loss: 1.4415 - val_mae: 0.7712\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0081 - mae: 0.0552 - val_loss: 1.4327 - val_mae: 0.7688\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0107 - mae: 0.0599 - val_loss: 1.4519 - val_mae: 0.7710\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0113 - mae: 0.0633 - val_loss: 1.4390 - val_mae: 0.7717\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0169 - mae: 0.0673 - val_loss: 1.4538 - val_mae: 0.7715\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0110 - mae: 0.0644 - val_loss: 1.4534 - val_mae: 0.7759\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0104 - mae: 0.0608 - val_loss: 1.4691 - val_mae: 0.7743\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0549 - val_loss: 1.4397 - val_mae: 0.7703\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0104 - mae: 0.0540 - val_loss: 1.4392 - val_mae: 0.7686\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0099 - mae: 0.0625 - val_loss: 1.4702 - val_mae: 0.7698\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0640 - val_loss: 1.4334 - val_mae: 0.7743\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4237 - mae: 0.7653\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 4.9269 - mae: 1.5976 - val_loss: 2.1442 - val_mae: 0.9978\n",
      "Epoch 2/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 1.1269 - mae: 0.7385 - val_loss: 1.9827 - val_mae: 0.9449\n",
      "Epoch 3/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.7301 - mae: 0.5659 - val_loss: 2.3415 - val_mae: 0.9589\n",
      "Epoch 4/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.5350 - mae: 0.4896 - val_loss: 1.7491 - val_mae: 0.8935\n",
      "Epoch 5/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.3768 - mae: 0.4065 - val_loss: 1.8048 - val_mae: 0.8842\n",
      "Epoch 6/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.3364 - mae: 0.3790 - val_loss: 1.7163 - val_mae: 0.8832\n",
      "Epoch 7/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2557 - mae: 0.3343 - val_loss: 1.6515 - val_mae: 0.8455\n",
      "Epoch 8/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2350 - mae: 0.3061 - val_loss: 1.6609 - val_mae: 0.8526\n",
      "Epoch 9/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.2061 - mae: 0.2984 - val_loss: 1.6034 - val_mae: 0.8408\n",
      "Epoch 10/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1964 - mae: 0.2827 - val_loss: 1.6199 - val_mae: 0.8414\n",
      "Epoch 11/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1880 - mae: 0.2730 - val_loss: 1.6856 - val_mae: 0.8388\n",
      "Epoch 12/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1822 - mae: 0.2762 - val_loss: 1.5349 - val_mae: 0.8397\n",
      "Epoch 13/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1748 - mae: 0.2691 - val_loss: 1.5765 - val_mae: 0.8168\n",
      "Epoch 14/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1649 - mae: 0.2542 - val_loss: 1.5806 - val_mae: 0.8257\n",
      "Epoch 15/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1364 - mae: 0.2524 - val_loss: 1.6722 - val_mae: 0.8321\n",
      "Epoch 16/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1434 - mae: 0.2497 - val_loss: 1.5256 - val_mae: 0.8113\n",
      "Epoch 17/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1251 - mae: 0.2383 - val_loss: 1.5014 - val_mae: 0.8132\n",
      "Epoch 18/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 0.1244 - mae: 0.2219 - val_loss: 1.4938 - val_mae: 0.7990\n",
      "Epoch 19/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1132 - mae: 0.2184 - val_loss: 1.5238 - val_mae: 0.7880\n",
      "Epoch 20/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1306 - mae: 0.2198 - val_loss: 1.4733 - val_mae: 0.7975\n",
      "Epoch 21/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1169 - mae: 0.2190 - val_loss: 1.4905 - val_mae: 0.8055\n",
      "Epoch 22/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1020 - mae: 0.2109 - val_loss: 1.4433 - val_mae: 0.7943\n",
      "Epoch 23/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1013 - mae: 0.1998 - val_loss: 1.4624 - val_mae: 0.7940\n",
      "Epoch 24/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0887 - mae: 0.1871 - val_loss: 1.4681 - val_mae: 0.7941\n",
      "Epoch 25/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0858 - mae: 0.1931 - val_loss: 1.4525 - val_mae: 0.7942\n",
      "Epoch 26/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0919 - mae: 0.1961 - val_loss: 1.4338 - val_mae: 0.7912\n",
      "Epoch 27/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0880 - mae: 0.1909 - val_loss: 1.4370 - val_mae: 0.7763\n",
      "Epoch 28/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0747 - mae: 0.1769 - val_loss: 1.4323 - val_mae: 0.7814\n",
      "Epoch 29/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0712 - mae: 0.1709 - val_loss: 1.4065 - val_mae: 0.7768\n",
      "Epoch 30/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0827 - mae: 0.1792 - val_loss: 1.4538 - val_mae: 0.7827\n",
      "Epoch 31/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0707 - mae: 0.1741 - val_loss: 1.4606 - val_mae: 0.7851\n",
      "Epoch 32/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0713 - mae: 0.1714 - val_loss: 1.4519 - val_mae: 0.7764\n",
      "Epoch 33/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0667 - mae: 0.1703 - val_loss: 1.4689 - val_mae: 0.7788\n",
      "Epoch 34/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0580 - mae: 0.1612 - val_loss: 1.4320 - val_mae: 0.7869\n",
      "Epoch 35/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0778 - mae: 0.1690 - val_loss: 1.4900 - val_mae: 0.7823\n",
      "Epoch 36/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0663 - mae: 0.1645 - val_loss: 1.4119 - val_mae: 0.7726\n",
      "Epoch 37/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0588 - mae: 0.1584 - val_loss: 1.4413 - val_mae: 0.7883\n",
      "Epoch 38/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0602 - mae: 0.1546 - val_loss: 1.4407 - val_mae: 0.7776\n",
      "Epoch 39/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0518 - mae: 0.1497 - val_loss: 1.3981 - val_mae: 0.7762\n",
      "Epoch 40/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0519 - mae: 0.1462 - val_loss: 1.4607 - val_mae: 0.7802\n",
      "Epoch 41/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0614 - mae: 0.1525 - val_loss: 1.4282 - val_mae: 0.7897\n",
      "Epoch 42/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0648 - mae: 0.1648 - val_loss: 1.4860 - val_mae: 0.7803\n",
      "Epoch 43/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0562 - mae: 0.1426 - val_loss: 1.3959 - val_mae: 0.7636\n",
      "Epoch 44/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0427 - mae: 0.1336 - val_loss: 1.4445 - val_mae: 0.7714\n",
      "Epoch 45/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0469 - mae: 0.1362 - val_loss: 1.3982 - val_mae: 0.7714\n",
      "Epoch 46/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0420 - mae: 0.1319 - val_loss: 1.3941 - val_mae: 0.7694\n",
      "Epoch 47/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0415 - mae: 0.1318 - val_loss: 1.4209 - val_mae: 0.7762\n",
      "Epoch 48/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0457 - mae: 0.1355 - val_loss: 1.4183 - val_mae: 0.7686\n",
      "Epoch 49/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0444 - mae: 0.1345 - val_loss: 1.4033 - val_mae: 0.7626\n",
      "Epoch 50/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0395 - mae: 0.1282 - val_loss: 1.4837 - val_mae: 0.7730\n",
      "Epoch 51/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0506 - mae: 0.1350 - val_loss: 1.4282 - val_mae: 0.7607\n",
      "Epoch 52/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0417 - mae: 0.1292 - val_loss: 1.4289 - val_mae: 0.7723\n",
      "Epoch 53/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0410 - mae: 0.1297 - val_loss: 1.4234 - val_mae: 0.7684\n",
      "Epoch 54/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0412 - mae: 0.1274 - val_loss: 1.4050 - val_mae: 0.7666\n",
      "Epoch 55/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0352 - mae: 0.1232 - val_loss: 1.4227 - val_mae: 0.7688\n",
      "Epoch 56/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0323 - mae: 0.1127 - val_loss: 1.3968 - val_mae: 0.7652\n",
      "Epoch 57/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0351 - mae: 0.1188 - val_loss: 1.4380 - val_mae: 0.7725\n",
      "Epoch 58/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0314 - mae: 0.1156 - val_loss: 1.4063 - val_mae: 0.7682\n",
      "Epoch 59/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0336 - mae: 0.1188 - val_loss: 1.4094 - val_mae: 0.7695\n",
      "Epoch 60/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0338 - mae: 0.1192 - val_loss: 1.4541 - val_mae: 0.7728\n",
      "Epoch 61/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0392 - mae: 0.1256 - val_loss: 1.3985 - val_mae: 0.7711\n",
      "Epoch 62/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0351 - mae: 0.1214 - val_loss: 1.3838 - val_mae: 0.7656\n",
      "Epoch 63/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0339 - mae: 0.1207 - val_loss: 1.4493 - val_mae: 0.7706\n",
      "Epoch 64/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0283 - mae: 0.1110 - val_loss: 1.4232 - val_mae: 0.7659\n",
      "Epoch 65/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0313 - mae: 0.1088 - val_loss: 1.4386 - val_mae: 0.7635\n",
      "Epoch 66/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0313 - mae: 0.1105 - val_loss: 1.4264 - val_mae: 0.7741\n",
      "Epoch 67/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0263 - mae: 0.1059 - val_loss: 1.4026 - val_mae: 0.7620\n",
      "Epoch 68/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0281 - mae: 0.1092 - val_loss: 1.4108 - val_mae: 0.7715\n",
      "Epoch 69/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0328 - mae: 0.1137 - val_loss: 1.4228 - val_mae: 0.7674\n",
      "Epoch 70/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0245 - mae: 0.1031 - val_loss: 1.4242 - val_mae: 0.7633\n",
      "Epoch 71/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0322 - mae: 0.1122 - val_loss: 1.4287 - val_mae: 0.7694\n",
      "Epoch 72/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0284 - mae: 0.1106 - val_loss: 1.4217 - val_mae: 0.7631\n",
      "Epoch 73/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0261 - mae: 0.1054 - val_loss: 1.4164 - val_mae: 0.7605\n",
      "Epoch 74/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0213 - mae: 0.0926 - val_loss: 1.4252 - val_mae: 0.7632\n",
      "Epoch 75/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0239 - mae: 0.0968 - val_loss: 1.4265 - val_mae: 0.7632\n",
      "Epoch 76/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0218 - mae: 0.0956 - val_loss: 1.4308 - val_mae: 0.7663\n",
      "Epoch 77/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0240 - mae: 0.0998 - val_loss: 1.4124 - val_mae: 0.7639\n",
      "Epoch 78/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0253 - mae: 0.1050 - val_loss: 1.4143 - val_mae: 0.7599\n",
      "Epoch 79/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0282 - mae: 0.1059 - val_loss: 1.3852 - val_mae: 0.7589\n",
      "Epoch 80/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0247 - mae: 0.0976 - val_loss: 1.4140 - val_mae: 0.7648\n",
      "Epoch 81/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0206 - mae: 0.0921 - val_loss: 1.4043 - val_mae: 0.7611\n",
      "Epoch 82/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0207 - mae: 0.0939 - val_loss: 1.4388 - val_mae: 0.7627\n",
      "Epoch 83/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0199 - mae: 0.0904 - val_loss: 1.3906 - val_mae: 0.7594\n",
      "Epoch 84/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0180 - mae: 0.0873 - val_loss: 1.4472 - val_mae: 0.7645\n",
      "Epoch 85/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0190 - mae: 0.0906 - val_loss: 1.4096 - val_mae: 0.7629\n",
      "Epoch 86/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0220 - mae: 0.0944 - val_loss: 1.4314 - val_mae: 0.7629\n",
      "Epoch 87/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0250 - mae: 0.0998 - val_loss: 1.4247 - val_mae: 0.7642\n",
      "Epoch 88/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0208 - mae: 0.0932 - val_loss: 1.4063 - val_mae: 0.7578\n",
      "Epoch 89/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0209 - mae: 0.0958 - val_loss: 1.4052 - val_mae: 0.7643\n",
      "Epoch 90/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0203 - mae: 0.0913 - val_loss: 1.4276 - val_mae: 0.7643\n",
      "Epoch 91/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0207 - mae: 0.0900 - val_loss: 1.4047 - val_mae: 0.7623\n",
      "Epoch 92/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0174 - mae: 0.0841 - val_loss: 1.3959 - val_mae: 0.7568\n",
      "Epoch 93/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0186 - mae: 0.0878 - val_loss: 1.4190 - val_mae: 0.7608\n",
      "Epoch 94/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0176 - mae: 0.0873 - val_loss: 1.4599 - val_mae: 0.7675\n",
      "Epoch 95/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0189 - mae: 0.0912 - val_loss: 1.4057 - val_mae: 0.7640\n",
      "Epoch 96/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0203 - mae: 0.0944 - val_loss: 1.4124 - val_mae: 0.7603\n",
      "Epoch 97/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0186 - mae: 0.0892 - val_loss: 1.4027 - val_mae: 0.7616\n",
      "Epoch 98/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0216 - mae: 0.0981 - val_loss: 1.4264 - val_mae: 0.7641\n",
      "Epoch 99/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0180 - mae: 0.0844 - val_loss: 1.4383 - val_mae: 0.7635\n",
      "Epoch 100/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0173 - mae: 0.0837 - val_loss: 1.4421 - val_mae: 0.7638\n",
      "Epoch 101/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0174 - mae: 0.0809 - val_loss: 1.3997 - val_mae: 0.7565\n",
      "Epoch 102/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0180 - mae: 0.0833 - val_loss: 1.4236 - val_mae: 0.7689\n",
      "Epoch 103/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0179 - mae: 0.0860 - val_loss: 1.4070 - val_mae: 0.7603\n",
      "Epoch 104/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0171 - mae: 0.0851 - val_loss: 1.4307 - val_mae: 0.7677\n",
      "Epoch 105/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0815 - val_loss: 1.3948 - val_mae: 0.7599\n",
      "Epoch 106/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0199 - mae: 0.0897 - val_loss: 1.4284 - val_mae: 0.7613\n",
      "Epoch 107/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0178 - mae: 0.0865 - val_loss: 1.3884 - val_mae: 0.7564\n",
      "Epoch 108/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0157 - mae: 0.0813 - val_loss: 1.4408 - val_mae: 0.7617\n",
      "Epoch 109/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0148 - mae: 0.0798 - val_loss: 1.3918 - val_mae: 0.7572\n",
      "Epoch 110/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0748 - val_loss: 1.4178 - val_mae: 0.7592\n",
      "Epoch 111/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0147 - mae: 0.0750 - val_loss: 1.4164 - val_mae: 0.7631\n",
      "Epoch 112/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0144 - mae: 0.0781 - val_loss: 1.4103 - val_mae: 0.7587\n",
      "Epoch 113/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0178 - mae: 0.0829 - val_loss: 1.3887 - val_mae: 0.7618\n",
      "Epoch 114/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0171 - mae: 0.0805 - val_loss: 1.4200 - val_mae: 0.7648\n",
      "Epoch 115/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0170 - mae: 0.0833 - val_loss: 1.3913 - val_mae: 0.7577\n",
      "Epoch 116/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0182 - mae: 0.0837 - val_loss: 1.4191 - val_mae: 0.7605\n",
      "Epoch 117/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0146 - mae: 0.0782 - val_loss: 1.4123 - val_mae: 0.7566\n",
      "Epoch 118/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0147 - mae: 0.0770 - val_loss: 1.4309 - val_mae: 0.7629\n",
      "Epoch 119/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0148 - mae: 0.0751 - val_loss: 1.4125 - val_mae: 0.7602\n",
      "Epoch 120/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0160 - mae: 0.0800 - val_loss: 1.3974 - val_mae: 0.7590\n",
      "Epoch 121/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0128 - mae: 0.0724 - val_loss: 1.4104 - val_mae: 0.7585\n",
      "Epoch 122/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0767 - val_loss: 1.4039 - val_mae: 0.7601\n",
      "Epoch 123/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0148 - mae: 0.0770 - val_loss: 1.4152 - val_mae: 0.7691\n",
      "Epoch 124/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0791 - val_loss: 1.4064 - val_mae: 0.7643\n",
      "Epoch 125/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0126 - mae: 0.0743 - val_loss: 1.4060 - val_mae: 0.7586\n",
      "Epoch 126/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0713 - val_loss: 1.4265 - val_mae: 0.7603\n",
      "Epoch 127/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0695 - val_loss: 1.3983 - val_mae: 0.7613\n",
      "Epoch 128/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0729 - val_loss: 1.4000 - val_mae: 0.7621\n",
      "Epoch 129/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0138 - mae: 0.0764 - val_loss: 1.4156 - val_mae: 0.7667\n",
      "Epoch 130/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0151 - mae: 0.0781 - val_loss: 1.3889 - val_mae: 0.7554\n",
      "Epoch 131/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0141 - mae: 0.0759 - val_loss: 1.4222 - val_mae: 0.7636\n",
      "Epoch 132/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0130 - mae: 0.0722 - val_loss: 1.3811 - val_mae: 0.7554\n",
      "Epoch 133/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0156 - mae: 0.0811 - val_loss: 1.4142 - val_mae: 0.7599\n",
      "Epoch 134/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0119 - mae: 0.0727 - val_loss: 1.4100 - val_mae: 0.7595\n",
      "Epoch 135/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0109 - mae: 0.0681 - val_loss: 1.4116 - val_mae: 0.7608\n",
      "Epoch 136/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0133 - mae: 0.0746 - val_loss: 1.4022 - val_mae: 0.7592\n",
      "Epoch 137/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0767 - val_loss: 1.3983 - val_mae: 0.7579\n",
      "Epoch 138/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0710 - val_loss: 1.3974 - val_mae: 0.7586\n",
      "Epoch 139/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0720 - val_loss: 1.4028 - val_mae: 0.7609\n",
      "Epoch 140/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0115 - mae: 0.0694 - val_loss: 1.3974 - val_mae: 0.7558\n",
      "Epoch 141/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0727 - val_loss: 1.3789 - val_mae: 0.7573\n",
      "Epoch 142/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0116 - mae: 0.0700 - val_loss: 1.4273 - val_mae: 0.7621\n",
      "Epoch 143/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0119 - mae: 0.0720 - val_loss: 1.4092 - val_mae: 0.7597\n",
      "Epoch 144/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0722 - val_loss: 1.4028 - val_mae: 0.7587\n",
      "Epoch 145/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0154 - mae: 0.0774 - val_loss: 1.3933 - val_mae: 0.7591\n",
      "Epoch 146/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0702 - val_loss: 1.3682 - val_mae: 0.7532\n",
      "Epoch 147/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0124 - mae: 0.0689 - val_loss: 1.4020 - val_mae: 0.7578\n",
      "Epoch 148/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0689 - val_loss: 1.3862 - val_mae: 0.7582\n",
      "Epoch 149/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0662 - val_loss: 1.3930 - val_mae: 0.7545\n",
      "Epoch 150/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0102 - mae: 0.0649 - val_loss: 1.3710 - val_mae: 0.7530\n",
      "Epoch 151/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0125 - mae: 0.0731 - val_loss: 1.3893 - val_mae: 0.7596\n",
      "Epoch 152/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0713 - val_loss: 1.3702 - val_mae: 0.7520\n",
      "Epoch 153/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0110 - mae: 0.0681 - val_loss: 1.4032 - val_mae: 0.7595\n",
      "Epoch 154/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0698 - val_loss: 1.3902 - val_mae: 0.7591\n",
      "Epoch 155/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0109 - mae: 0.0668 - val_loss: 1.3848 - val_mae: 0.7571\n",
      "Epoch 156/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0106 - mae: 0.0676 - val_loss: 1.3952 - val_mae: 0.7556\n",
      "Epoch 157/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0113 - mae: 0.0691 - val_loss: 1.3955 - val_mae: 0.7596\n",
      "Epoch 158/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0116 - mae: 0.0695 - val_loss: 1.3934 - val_mae: 0.7556\n",
      "Epoch 159/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0097 - mae: 0.0625 - val_loss: 1.3977 - val_mae: 0.7572\n",
      "Epoch 160/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0654 - val_loss: 1.4120 - val_mae: 0.7577\n",
      "Epoch 161/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0750 - val_loss: 1.3904 - val_mae: 0.7554\n",
      "Epoch 162/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0124 - mae: 0.0724 - val_loss: 1.3955 - val_mae: 0.7588\n",
      "Epoch 163/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0103 - mae: 0.0629 - val_loss: 1.3831 - val_mae: 0.7573\n",
      "Epoch 164/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0082 - mae: 0.0574 - val_loss: 1.3740 - val_mae: 0.7537\n",
      "Epoch 165/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0084 - mae: 0.0590 - val_loss: 1.3772 - val_mae: 0.7559\n",
      "Epoch 166/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0644 - val_loss: 1.3746 - val_mae: 0.7549\n",
      "Epoch 167/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0101 - mae: 0.0637 - val_loss: 1.3823 - val_mae: 0.7555\n",
      "Epoch 168/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0720 - val_loss: 1.3940 - val_mae: 0.7543\n",
      "Epoch 169/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0124 - mae: 0.0711 - val_loss: 1.3918 - val_mae: 0.7587\n",
      "Epoch 170/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0101 - mae: 0.0644 - val_loss: 1.3867 - val_mae: 0.7546\n",
      "Epoch 171/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0103 - mae: 0.0614 - val_loss: 1.3980 - val_mae: 0.7567\n",
      "Epoch 172/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0094 - mae: 0.0616 - val_loss: 1.3603 - val_mae: 0.7546\n",
      "Epoch 173/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0158 - mae: 0.0809 - val_loss: 1.3763 - val_mae: 0.7562\n",
      "Epoch 174/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0098 - mae: 0.0643 - val_loss: 1.4028 - val_mae: 0.7566\n",
      "Epoch 175/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0111 - mae: 0.0624 - val_loss: 1.3748 - val_mae: 0.7561\n",
      "Epoch 176/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0096 - mae: 0.0628 - val_loss: 1.3877 - val_mae: 0.7521\n",
      "Epoch 177/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0105 - mae: 0.0623 - val_loss: 1.3903 - val_mae: 0.7554\n",
      "Epoch 178/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0088 - mae: 0.0614 - val_loss: 1.3927 - val_mae: 0.7563\n",
      "Epoch 179/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0092 - mae: 0.0608 - val_loss: 1.3820 - val_mae: 0.7534\n",
      "Epoch 180/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0085 - mae: 0.0602 - val_loss: 1.3682 - val_mae: 0.7571\n",
      "Epoch 181/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0092 - mae: 0.0628 - val_loss: 1.3906 - val_mae: 0.7563\n",
      "Epoch 182/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0083 - mae: 0.0602 - val_loss: 1.3886 - val_mae: 0.7552\n",
      "Epoch 183/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0102 - mae: 0.0668 - val_loss: 1.3798 - val_mae: 0.7564\n",
      "Epoch 184/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0106 - mae: 0.0644 - val_loss: 1.3785 - val_mae: 0.7541\n",
      "Epoch 185/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0099 - mae: 0.0646 - val_loss: 1.3802 - val_mae: 0.7563\n",
      "Epoch 186/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0097 - mae: 0.0639 - val_loss: 1.4118 - val_mae: 0.7606\n",
      "Epoch 187/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0093 - mae: 0.0617 - val_loss: 1.3820 - val_mae: 0.7536\n",
      "Epoch 188/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0084 - mae: 0.0588 - val_loss: 1.3896 - val_mae: 0.7559\n",
      "Epoch 189/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0082 - mae: 0.0581 - val_loss: 1.3645 - val_mae: 0.7505\n",
      "Epoch 190/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0079 - mae: 0.0560 - val_loss: 1.3866 - val_mae: 0.7550\n",
      "Epoch 191/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0085 - mae: 0.0590 - val_loss: 1.4009 - val_mae: 0.7585\n",
      "Epoch 192/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0107 - mae: 0.0657 - val_loss: 1.3901 - val_mae: 0.7582\n",
      "Epoch 193/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0655 - val_loss: 1.3912 - val_mae: 0.7568\n",
      "Epoch 194/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0096 - mae: 0.0620 - val_loss: 1.3680 - val_mae: 0.7570\n",
      "Epoch 195/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0116 - mae: 0.0655 - val_loss: 1.3822 - val_mae: 0.7546\n",
      "Epoch 196/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0089 - mae: 0.0601 - val_loss: 1.3885 - val_mae: 0.7591\n",
      "Epoch 197/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0075 - mae: 0.0558 - val_loss: 1.3837 - val_mae: 0.7545\n",
      "Epoch 198/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0085 - mae: 0.0581 - val_loss: 1.3829 - val_mae: 0.7562\n",
      "Epoch 199/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0088 - mae: 0.0625 - val_loss: 1.3835 - val_mae: 0.7556\n",
      "Epoch 200/200\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0083 - mae: 0.0593 - val_loss: 1.3876 - val_mae: 0.7596\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3909 - mae: 0.7623\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\n",
    "    'use_count_option', 'fpSize_option', 'radius_option',\n",
    "    'train', 'test', 'loss', 'mae', 'r-squared', 'error'\n",
    "                          ])\n",
    "\n",
    "# Obtem os dados\n",
    "df_mouse_vi = pd.read_csv('dados/mouse_vi.csv', usecols=['mouse_vi', 'smiles'])\n",
    "\n",
    "# Converter valores da coluna 'valor' para float\n",
    "df_mouse_vi['mouse_vi'] = pd.to_numeric(df_mouse_vi['mouse_vi'], errors='coerce')\n",
    "\n",
    "# Remove NaN\n",
    "df_mouse_vi.dropna(subset=['mouse_vi', 'smiles'], inplace=True, ignore_index=True)\n",
    "\n",
    "# Normaliza LD50\n",
    "df_mouse_vi['log_ld50'] = -np.log(df_mouse_vi['mouse_vi'])\n",
    "\n",
    "# Realiza a limpeza dos dados\n",
    "limpeza = Limpeza(dataframe=df_mouse_vi)\n",
    "df_mouse_vi = limpeza.dados_limpos(col_smiles='smiles', col_valor='mouse_vi', sanitize=True, cutoff=.05, fragmento=False)\n",
    "\n",
    "for c in use_count_option:\n",
    "    for d in fpSize_option:\n",
    "        for e in radius_option:\n",
    "\n",
    "            try:\n",
    "\n",
    "                mouse_vi = df_mouse_vi.copy()\n",
    "            \n",
    "                # Define a representação fingerprint\n",
    "                representacao = Representacao(dataframe=mouse_vi)\n",
    "                mouse_vi = representacao.fingerprint(col_smiles='smiles', fingerprint='morgan', use_count=c, fpSize=d, radius=e)\n",
    "                \n",
    "                # Define os conjuntos de treinamento e teste\n",
    "                X = np.array(mouse_vi['Features'].to_list())\n",
    "                y = mouse_vi['log_ld50'].values\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Aplica ANN\n",
    "                model = ANN(fpSize=d)\n",
    "                model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "                history = model.fit(X_train, y_train, validation_split=0.1, epochs=200, batch_size=32)\n",
    "                \n",
    "                # Obtem as métricas do modelo\n",
    "                loss, mae = model.evaluate(X_test, y_test)\n",
    "                \n",
    "                # R-squared\n",
    "                predictions = model.predict(X_test)\n",
    "                y_true = np.array(y_test)\n",
    "                y_pred = np.array(predictions)\n",
    "                \n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                \n",
    "                df_ann = pd.DataFrame([{\n",
    "                    'use_count_option' : c, 'fpSize_option' : d, 'radius_option' : e,\n",
    "                    'train' : len(X_train), 'test' : len(X_test), 'loss' : loss, 'mae' : mae, 'r-squared' : r2, 'error' : np.nan\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n",
    "\n",
    "                df.to_excel('mouse_vi_modelos.xlsx', index=False)\n",
    "\n",
    "            except Exception as err:\n",
    "                \n",
    "                df_ann = pd.DataFrame([{\n",
    "                    'use_count_option' : c, 'fpSize_option' : d, 'radius_option' : e,\n",
    "                    'train' : np.nan, 'test' : np.nan, 'loss' : np.nan, 'mae' : np.nan, 'r-squared' : np.nan, 'error' : str(err)\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n",
    "\n",
    "                df.to_excel('mouse_vi_modelos.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d55f5-2271-4878-8d9b-350c27b88a5e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ee2fe-18be-4f1d-836c-e487233bbcb8",
   "metadata": {},
   "source": [
    "# MOUSE, ORAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1609a-f745-4800-88df-1ff29d181234",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 5.2406 - mae: 1.5817 - val_loss: 1.5829 - val_mae: 0.9034\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.0220 - mae: 0.7290 - val_loss: 1.4435 - val_mae: 0.8524\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.6212 - mae: 0.5686 - val_loss: 1.4017 - val_mae: 0.8136\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.5022 - mae: 0.5019 - val_loss: 1.4229 - val_mae: 0.8515\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.3896 - mae: 0.4509 - val_loss: 1.4693 - val_mae: 0.8610\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.3142 - mae: 0.3991 - val_loss: 1.3536 - val_mae: 0.7969\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2685 - mae: 0.3678 - val_loss: 1.3224 - val_mae: 0.7883\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2454 - mae: 0.3497 - val_loss: 1.3493 - val_mae: 0.7882\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2220 - mae: 0.3275 - val_loss: 1.4001 - val_mae: 0.8134\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2101 - mae: 0.3172 - val_loss: 1.3229 - val_mae: 0.7896\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1815 - mae: 0.2996 - val_loss: 1.3287 - val_mae: 0.7740\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1573 - mae: 0.2802 - val_loss: 1.3357 - val_mae: 0.7849\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1528 - mae: 0.2737 - val_loss: 1.3498 - val_mae: 0.7973\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1410 - mae: 0.2659 - val_loss: 1.3205 - val_mae: 0.7703\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1352 - mae: 0.2642 - val_loss: 1.3436 - val_mae: 0.7748\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1357 - mae: 0.2578 - val_loss: 1.3171 - val_mae: 0.7812\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1165 - mae: 0.2389 - val_loss: 1.3250 - val_mae: 0.7816\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1165 - mae: 0.2389 - val_loss: 1.3075 - val_mae: 0.7603\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1055 - mae: 0.2225 - val_loss: 1.3221 - val_mae: 0.7739\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0991 - mae: 0.2211 - val_loss: 1.3213 - val_mae: 0.7592\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0948 - mae: 0.2209 - val_loss: 1.2868 - val_mae: 0.7730\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0923 - mae: 0.2163 - val_loss: 1.2870 - val_mae: 0.7558\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0836 - mae: 0.2046 - val_loss: 1.2964 - val_mae: 0.7498\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0877 - mae: 0.2079 - val_loss: 1.3095 - val_mae: 0.7534\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0821 - mae: 0.1952 - val_loss: 1.2853 - val_mae: 0.7540\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0774 - mae: 0.1939 - val_loss: 1.3071 - val_mae: 0.7662\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0808 - mae: 0.1967 - val_loss: 1.3137 - val_mae: 0.7624\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0768 - mae: 0.1938 - val_loss: 1.2793 - val_mae: 0.7481\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0749 - mae: 0.1851 - val_loss: 1.2781 - val_mae: 0.7421\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0772 - mae: 0.1885 - val_loss: 1.2713 - val_mae: 0.7466\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0683 - mae: 0.1764 - val_loss: 1.3031 - val_mae: 0.7593\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0653 - mae: 0.1745 - val_loss: 1.2948 - val_mae: 0.7468\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0669 - mae: 0.1777 - val_loss: 1.2791 - val_mae: 0.7477\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0597 - mae: 0.1683 - val_loss: 1.2930 - val_mae: 0.7455\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0616 - mae: 0.1681 - val_loss: 1.2928 - val_mae: 0.7503\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0586 - mae: 0.1652 - val_loss: 1.2693 - val_mae: 0.7381\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0608 - mae: 0.1625 - val_loss: 1.2835 - val_mae: 0.7412\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0553 - mae: 0.1587 - val_loss: 1.2771 - val_mae: 0.7390\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0504 - mae: 0.1525 - val_loss: 1.2722 - val_mae: 0.7466\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0534 - mae: 0.1571 - val_loss: 1.2917 - val_mae: 0.7456\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0591 - mae: 0.1565 - val_loss: 1.2906 - val_mae: 0.7486\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0547 - mae: 0.1568 - val_loss: 1.2661 - val_mae: 0.7387\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0537 - mae: 0.1519 - val_loss: 1.2887 - val_mae: 0.7482\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0461 - mae: 0.1455 - val_loss: 1.2770 - val_mae: 0.7436\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0591 - mae: 0.1504 - val_loss: 1.2792 - val_mae: 0.7491\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0435 - mae: 0.1410 - val_loss: 1.2792 - val_mae: 0.7392\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0479 - mae: 0.1436 - val_loss: 1.2544 - val_mae: 0.7378\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0422 - mae: 0.1358 - val_loss: 1.3047 - val_mae: 0.7426\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0448 - mae: 0.1455 - val_loss: 1.2734 - val_mae: 0.7427\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0446 - mae: 0.1401 - val_loss: 1.2733 - val_mae: 0.7359\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0437 - mae: 0.1357 - val_loss: 1.2740 - val_mae: 0.7407\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0425 - mae: 0.1310 - val_loss: 1.2614 - val_mae: 0.7374\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0416 - mae: 0.1322 - val_loss: 1.2659 - val_mae: 0.7325\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0409 - mae: 0.1327 - val_loss: 1.2733 - val_mae: 0.7454\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0378 - mae: 0.1285 - val_loss: 1.2862 - val_mae: 0.7402\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0402 - mae: 0.1326 - val_loss: 1.2770 - val_mae: 0.7379\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0423 - mae: 0.1323 - val_loss: 1.2775 - val_mae: 0.7398\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0368 - mae: 0.1280 - val_loss: 1.2626 - val_mae: 0.7389\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0355 - mae: 0.1238 - val_loss: 1.2739 - val_mae: 0.7368\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0418 - mae: 0.1304 - val_loss: 1.2870 - val_mae: 0.7526\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0382 - mae: 0.1249 - val_loss: 1.2651 - val_mae: 0.7311\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0345 - mae: 0.1206 - val_loss: 1.2639 - val_mae: 0.7353\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0405 - mae: 0.1262 - val_loss: 1.2843 - val_mae: 0.7407\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0461 - mae: 0.1286 - val_loss: 1.2814 - val_mae: 0.7357\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0345 - mae: 0.1192 - val_loss: 1.2793 - val_mae: 0.7452\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0392 - mae: 0.1211 - val_loss: 1.2735 - val_mae: 0.7397\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0386 - mae: 0.1218 - val_loss: 1.2752 - val_mae: 0.7362\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0361 - mae: 0.1227 - val_loss: 1.2592 - val_mae: 0.7334\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1217 - val_loss: 1.2928 - val_mae: 0.7501\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0355 - mae: 0.1167 - val_loss: 1.2706 - val_mae: 0.7368\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0308 - mae: 0.1128 - val_loss: 1.2698 - val_mae: 0.7326\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0356 - mae: 0.1141 - val_loss: 1.2596 - val_mae: 0.7340\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0312 - mae: 0.1141 - val_loss: 1.2747 - val_mae: 0.7390\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0315 - mae: 0.1168 - val_loss: 1.2710 - val_mae: 0.7432\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0344 - mae: 0.1130 - val_loss: 1.2727 - val_mae: 0.7401\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0288 - mae: 0.1088 - val_loss: 1.2421 - val_mae: 0.7254\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.1094 - val_loss: 1.2690 - val_mae: 0.7390\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0325 - mae: 0.1122 - val_loss: 1.2681 - val_mae: 0.7350\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0284 - mae: 0.1086 - val_loss: 1.2576 - val_mae: 0.7316\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0291 - mae: 0.1076 - val_loss: 1.2630 - val_mae: 0.7410\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0393 - mae: 0.1111 - val_loss: 1.2655 - val_mae: 0.7332\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0272 - mae: 0.1020 - val_loss: 1.2625 - val_mae: 0.7318\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0327 - mae: 0.1038 - val_loss: 1.2668 - val_mae: 0.7360\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0282 - mae: 0.1079 - val_loss: 1.2689 - val_mae: 0.7327\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.1084 - val_loss: 1.2609 - val_mae: 0.7332\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0280 - mae: 0.1061 - val_loss: 1.2559 - val_mae: 0.7318\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0327 - mae: 0.1067 - val_loss: 1.2745 - val_mae: 0.7378\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0278 - mae: 0.1032 - val_loss: 1.2613 - val_mae: 0.7328\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0278 - mae: 0.1033 - val_loss: 1.2694 - val_mae: 0.7311\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0289 - mae: 0.1012 - val_loss: 1.2626 - val_mae: 0.7356\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0272 - mae: 0.1004 - val_loss: 1.2672 - val_mae: 0.7344\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0230 - mae: 0.1010 - val_loss: 1.2670 - val_mae: 0.7332\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0312 - mae: 0.1075 - val_loss: 1.2613 - val_mae: 0.7311\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0334 - mae: 0.0990 - val_loss: 1.2759 - val_mae: 0.7352\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0254 - mae: 0.0984 - val_loss: 1.2536 - val_mae: 0.7325\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0282 - mae: 0.0996 - val_loss: 1.2739 - val_mae: 0.7346\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0277 - mae: 0.0989 - val_loss: 1.2511 - val_mae: 0.7296\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0238 - mae: 0.0976 - val_loss: 1.2529 - val_mae: 0.7304\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0254 - mae: 0.0974 - val_loss: 1.2481 - val_mae: 0.7310\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0221 - mae: 0.0958 - val_loss: 1.2538 - val_mae: 0.7302\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0216 - mae: 0.0942 - val_loss: 1.2579 - val_mae: 0.7359\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0263 - mae: 0.0975 - val_loss: 1.2547 - val_mae: 0.7294\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.0939 - val_loss: 1.2647 - val_mae: 0.7425\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0217 - mae: 0.0957 - val_loss: 1.2404 - val_mae: 0.7207\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.0927 - val_loss: 1.2640 - val_mae: 0.7332\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0272 - mae: 0.0921 - val_loss: 1.2567 - val_mae: 0.7302\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.0915 - val_loss: 1.2537 - val_mae: 0.7314\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0213 - mae: 0.0916 - val_loss: 1.2545 - val_mae: 0.7372\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0312 - mae: 0.0950 - val_loss: 1.2499 - val_mae: 0.7294\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0223 - mae: 0.0921 - val_loss: 1.2548 - val_mae: 0.7269\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0229 - mae: 0.0932 - val_loss: 1.2539 - val_mae: 0.7261\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0864 - val_loss: 1.2673 - val_mae: 0.7405\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0211 - mae: 0.0867 - val_loss: 1.2611 - val_mae: 0.7284\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0232 - mae: 0.0894 - val_loss: 1.2484 - val_mae: 0.7291\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0844 - val_loss: 1.2470 - val_mae: 0.7274\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0191 - mae: 0.0869 - val_loss: 1.2637 - val_mae: 0.7305\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0878 - val_loss: 1.2483 - val_mae: 0.7311\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0901 - val_loss: 1.2562 - val_mae: 0.7291\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.0892 - val_loss: 1.2624 - val_mae: 0.7327\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0210 - mae: 0.0882 - val_loss: 1.2492 - val_mae: 0.7256\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0871 - val_loss: 1.2613 - val_mae: 0.7366\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0874 - val_loss: 1.2430 - val_mae: 0.7281\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0213 - mae: 0.0856 - val_loss: 1.2583 - val_mae: 0.7299\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0208 - mae: 0.0845 - val_loss: 1.2591 - val_mae: 0.7311\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0181 - mae: 0.0826 - val_loss: 1.2472 - val_mae: 0.7263\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0854 - val_loss: 1.2700 - val_mae: 0.7267\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0216 - mae: 0.0890 - val_loss: 1.2562 - val_mae: 0.7318\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0218 - mae: 0.0881 - val_loss: 1.2536 - val_mae: 0.7282\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0221 - mae: 0.0836 - val_loss: 1.2549 - val_mae: 0.7320\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0837 - val_loss: 1.2558 - val_mae: 0.7313\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0834 - val_loss: 1.2625 - val_mae: 0.7306\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0208 - mae: 0.0850 - val_loss: 1.2470 - val_mae: 0.7285\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184 - mae: 0.0823 - val_loss: 1.2503 - val_mae: 0.7293\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.0847 - val_loss: 1.2629 - val_mae: 0.7312\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.0816 - val_loss: 1.2594 - val_mae: 0.7305\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0815 - val_loss: 1.2518 - val_mae: 0.7261\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0206 - mae: 0.0822 - val_loss: 1.2441 - val_mae: 0.7261\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0797 - val_loss: 1.2530 - val_mae: 0.7288\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0167 - mae: 0.0804 - val_loss: 1.2466 - val_mae: 0.7315\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0184 - mae: 0.0805 - val_loss: 1.2430 - val_mae: 0.7244\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0790 - val_loss: 1.2531 - val_mae: 0.7309\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0795 - val_loss: 1.2492 - val_mae: 0.7284\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0802 - val_loss: 1.2511 - val_mae: 0.7274\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0195 - mae: 0.0799 - val_loss: 1.2518 - val_mae: 0.7282\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0767 - val_loss: 1.2527 - val_mae: 0.7286\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0780 - val_loss: 1.2491 - val_mae: 0.7230\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0809 - val_loss: 1.2570 - val_mae: 0.7337\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0241 - mae: 0.0837 - val_loss: 1.2501 - val_mae: 0.7303\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0186 - mae: 0.0819 - val_loss: 1.2445 - val_mae: 0.7254\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0762 - val_loss: 1.2479 - val_mae: 0.7261\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0156 - mae: 0.0750 - val_loss: 1.2355 - val_mae: 0.7247\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0734 - val_loss: 1.2501 - val_mae: 0.7246\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.0782 - val_loss: 1.2602 - val_mae: 0.7271\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0162 - mae: 0.0751 - val_loss: 1.2507 - val_mae: 0.7339\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.0818 - val_loss: 1.2512 - val_mae: 0.7267\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0765 - val_loss: 1.2527 - val_mae: 0.7274\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0748 - val_loss: 1.2460 - val_mae: 0.7220\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0783 - val_loss: 1.2454 - val_mae: 0.7285\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0763 - val_loss: 1.2508 - val_mae: 0.7300\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0747 - val_loss: 1.2517 - val_mae: 0.7329\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0163 - mae: 0.0742 - val_loss: 1.2440 - val_mae: 0.7272\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0760 - val_loss: 1.2441 - val_mae: 0.7255\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0779 - val_loss: 1.2542 - val_mae: 0.7291\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0748 - val_loss: 1.2442 - val_mae: 0.7260\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mae: 0.0736 - val_loss: 1.2445 - val_mae: 0.7261\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0154 - mae: 0.0717 - val_loss: 1.2398 - val_mae: 0.7240\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0168 - mae: 0.0734 - val_loss: 1.2526 - val_mae: 0.7259\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0723 - val_loss: 1.2520 - val_mae: 0.7280\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0745 - val_loss: 1.2399 - val_mae: 0.7267\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0157 - mae: 0.0717 - val_loss: 1.2477 - val_mae: 0.7249\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0158 - mae: 0.0720 - val_loss: 1.2546 - val_mae: 0.7337\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0695 - val_loss: 1.2365 - val_mae: 0.7240\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0152 - mae: 0.0718 - val_loss: 1.2432 - val_mae: 0.7236\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0167 - mae: 0.0728 - val_loss: 1.2408 - val_mae: 0.7247\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0157 - mae: 0.0716 - val_loss: 1.2367 - val_mae: 0.7277\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0731 - val_loss: 1.2417 - val_mae: 0.7260\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0725 - val_loss: 1.2398 - val_mae: 0.7214\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0212 - mae: 0.0747 - val_loss: 1.2541 - val_mae: 0.7297\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0678 - val_loss: 1.2383 - val_mae: 0.7237\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0713 - val_loss: 1.2525 - val_mae: 0.7271\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0148 - mae: 0.0694 - val_loss: 1.2396 - val_mae: 0.7258\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0184 - mae: 0.0707 - val_loss: 1.2478 - val_mae: 0.7250\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.0750 - val_loss: 1.2475 - val_mae: 0.7249\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0695 - val_loss: 1.2434 - val_mae: 0.7278\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0159 - mae: 0.0678 - val_loss: 1.2448 - val_mae: 0.7257\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0165 - mae: 0.0703 - val_loss: 1.2546 - val_mae: 0.7288\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0158 - mae: 0.0699 - val_loss: 1.2413 - val_mae: 0.7302\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0158 - mae: 0.0697 - val_loss: 1.2561 - val_mae: 0.7275\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0694 - val_loss: 1.2527 - val_mae: 0.7268\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0158 - mae: 0.0705 - val_loss: 1.2479 - val_mae: 0.7312\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182 - mae: 0.0708 - val_loss: 1.2533 - val_mae: 0.7306\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0143 - mae: 0.0673 - val_loss: 1.2394 - val_mae: 0.7258\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0145 - mae: 0.0652 - val_loss: 1.2549 - val_mae: 0.7271\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0164 - mae: 0.0710 - val_loss: 1.2398 - val_mae: 0.7232\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0244 - mae: 0.0723 - val_loss: 1.2429 - val_mae: 0.7282\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0167 - mae: 0.0662 - val_loss: 1.2528 - val_mae: 0.7278\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0698 - val_loss: 1.2509 - val_mae: 0.7277\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184 - mae: 0.0705 - val_loss: 1.2427 - val_mae: 0.7248\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0666 - val_loss: 1.2515 - val_mae: 0.7290\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0676 - val_loss: 1.2435 - val_mae: 0.7247\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2842 - mae: 0.7319\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\AppData\\Local\\Temp\\ipykernel_31464\\4008297102.py:60: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 5.2428 - mae: 1.5887 - val_loss: 1.6068 - val_mae: 0.9089\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9769 - mae: 0.7110 - val_loss: 1.4389 - val_mae: 0.8477\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.5764 - mae: 0.5456 - val_loss: 1.4233 - val_mae: 0.8419\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.4706 - mae: 0.4868 - val_loss: 1.4105 - val_mae: 0.8408\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.3629 - mae: 0.4222 - val_loss: 1.3834 - val_mae: 0.8287\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2913 - mae: 0.3852 - val_loss: 1.4147 - val_mae: 0.8178\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2697 - mae: 0.3699 - val_loss: 1.3663 - val_mae: 0.8120\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2234 - mae: 0.3400 - val_loss: 1.3659 - val_mae: 0.8046\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2113 - mae: 0.3188 - val_loss: 1.3625 - val_mae: 0.7989\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1779 - mae: 0.3036 - val_loss: 1.3822 - val_mae: 0.8197\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1687 - mae: 0.2954 - val_loss: 1.3542 - val_mae: 0.8001\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1531 - mae: 0.2840 - val_loss: 1.4247 - val_mae: 0.8130\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1403 - mae: 0.2671 - val_loss: 1.3589 - val_mae: 0.7980\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1432 - mae: 0.2674 - val_loss: 1.3550 - val_mae: 0.7974\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1269 - mae: 0.2522 - val_loss: 1.3281 - val_mae: 0.7771\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1223 - mae: 0.2470 - val_loss: 1.3516 - val_mae: 0.7983\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1108 - mae: 0.2396 - val_loss: 1.3399 - val_mae: 0.7823\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1051 - mae: 0.2311 - val_loss: 1.2878 - val_mae: 0.7688\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1036 - mae: 0.2263 - val_loss: 1.3483 - val_mae: 0.7938\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1048 - mae: 0.2259 - val_loss: 1.3287 - val_mae: 0.7830\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0866 - mae: 0.2072 - val_loss: 1.3646 - val_mae: 0.7861\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0922 - mae: 0.2132 - val_loss: 1.3158 - val_mae: 0.7754\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0748 - mae: 0.1944 - val_loss: 1.3214 - val_mae: 0.7764\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0791 - mae: 0.1963 - val_loss: 1.3190 - val_mae: 0.7822\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0824 - mae: 0.1998 - val_loss: 1.2993 - val_mae: 0.7676\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0736 - mae: 0.1897 - val_loss: 1.3229 - val_mae: 0.7763\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0722 - mae: 0.1836 - val_loss: 1.3161 - val_mae: 0.7761\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0677 - mae: 0.1837 - val_loss: 1.3077 - val_mae: 0.7632\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0627 - mae: 0.1790 - val_loss: 1.3394 - val_mae: 0.7717\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0666 - mae: 0.1765 - val_loss: 1.3154 - val_mae: 0.7721\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0658 - mae: 0.1765 - val_loss: 1.3330 - val_mae: 0.7748\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0520 - mae: 0.1629 - val_loss: 1.3203 - val_mae: 0.7643\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0538 - mae: 0.1648 - val_loss: 1.3004 - val_mae: 0.7595\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0588 - mae: 0.1667 - val_loss: 1.3255 - val_mae: 0.7663\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0562 - mae: 0.1654 - val_loss: 1.3041 - val_mae: 0.7628\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0512 - mae: 0.1597 - val_loss: 1.2956 - val_mae: 0.7599\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0571 - mae: 0.1616 - val_loss: 1.2965 - val_mae: 0.7612\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0554 - mae: 0.1598 - val_loss: 1.3261 - val_mae: 0.7727\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0517 - mae: 0.1555 - val_loss: 1.2975 - val_mae: 0.7594\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0506 - mae: 0.1459 - val_loss: 1.3011 - val_mae: 0.7669\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0428 - mae: 0.1441 - val_loss: 1.2960 - val_mae: 0.7603\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0477 - mae: 0.1464 - val_loss: 1.2919 - val_mae: 0.7610\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0447 - mae: 0.1452 - val_loss: 1.2980 - val_mae: 0.7703\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0438 - mae: 0.1455 - val_loss: 1.2906 - val_mae: 0.7621\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0446 - mae: 0.1427 - val_loss: 1.2942 - val_mae: 0.7585\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0437 - mae: 0.1412 - val_loss: 1.2850 - val_mae: 0.7553\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0413 - mae: 0.1397 - val_loss: 1.2938 - val_mae: 0.7562\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0387 - mae: 0.1351 - val_loss: 1.2795 - val_mae: 0.7513\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0366 - mae: 0.1320 - val_loss: 1.3154 - val_mae: 0.7710\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0331 - mae: 0.1259 - val_loss: 1.2934 - val_mae: 0.7563\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0364 - mae: 0.1324 - val_loss: 1.2975 - val_mae: 0.7604\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0415 - mae: 0.1375 - val_loss: 1.2795 - val_mae: 0.7543\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0382 - mae: 0.1288 - val_loss: 1.2955 - val_mae: 0.7598\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0343 - mae: 0.1213 - val_loss: 1.2848 - val_mae: 0.7562\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0321 - mae: 0.1193 - val_loss: 1.2858 - val_mae: 0.7578\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0348 - mae: 0.1219 - val_loss: 1.2848 - val_mae: 0.7540\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0352 - mae: 0.1245 - val_loss: 1.2742 - val_mae: 0.7568\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0344 - mae: 0.1244 - val_loss: 1.2855 - val_mae: 0.7592\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0318 - mae: 0.1184 - val_loss: 1.2708 - val_mae: 0.7527\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0320 - mae: 0.1150 - val_loss: 1.2805 - val_mae: 0.7525\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0310 - mae: 0.1184 - val_loss: 1.2722 - val_mae: 0.7464\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0298 - mae: 0.1161 - val_loss: 1.2820 - val_mae: 0.7553\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0331 - mae: 0.1212 - val_loss: 1.2683 - val_mae: 0.7508\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0269 - mae: 0.1117 - val_loss: 1.2828 - val_mae: 0.7562\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0316 - mae: 0.1146 - val_loss: 1.2629 - val_mae: 0.7471\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0341 - mae: 0.1124 - val_loss: 1.2701 - val_mae: 0.7562\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0268 - mae: 0.1116 - val_loss: 1.2662 - val_mae: 0.7509\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0292 - mae: 0.1095 - val_loss: 1.2833 - val_mae: 0.7590\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0265 - mae: 0.1120 - val_loss: 1.2680 - val_mae: 0.7558\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0265 - mae: 0.1083 - val_loss: 1.2583 - val_mae: 0.7490\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0262 - mae: 0.1059 - val_loss: 1.2631 - val_mae: 0.7507\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0270 - mae: 0.1039 - val_loss: 1.2615 - val_mae: 0.7482\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0290 - mae: 0.1053 - val_loss: 1.2738 - val_mae: 0.7498\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0264 - mae: 0.1040 - val_loss: 1.2858 - val_mae: 0.7602\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0262 - mae: 0.1073 - val_loss: 1.2735 - val_mae: 0.7498\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0256 - mae: 0.1059 - val_loss: 1.2726 - val_mae: 0.7531\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0268 - mae: 0.1060 - val_loss: 1.2694 - val_mae: 0.7469\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0259 - mae: 0.1023 - val_loss: 1.2826 - val_mae: 0.7578\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0240 - mae: 0.1026 - val_loss: 1.2627 - val_mae: 0.7485\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0285 - mae: 0.1040 - val_loss: 1.2682 - val_mae: 0.7496\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0266 - mae: 0.1019 - val_loss: 1.2702 - val_mae: 0.7491\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0240 - mae: 0.0994 - val_loss: 1.2741 - val_mae: 0.7499\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.0998 - val_loss: 1.2790 - val_mae: 0.7535\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0244 - mae: 0.0970 - val_loss: 1.2875 - val_mae: 0.7541\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0254 - mae: 0.1024 - val_loss: 1.2754 - val_mae: 0.7557\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0258 - mae: 0.1022 - val_loss: 1.2718 - val_mae: 0.7482\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0225 - mae: 0.0976 - val_loss: 1.2639 - val_mae: 0.7499\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0196 - mae: 0.0917 - val_loss: 1.2559 - val_mae: 0.7419\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0220 - mae: 0.0924 - val_loss: 1.2680 - val_mae: 0.7522\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0933 - val_loss: 1.2624 - val_mae: 0.7433\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0944 - val_loss: 1.2655 - val_mae: 0.7465\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0216 - mae: 0.0915 - val_loss: 1.2617 - val_mae: 0.7469\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0199 - mae: 0.0927 - val_loss: 1.2644 - val_mae: 0.7500\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0934 - val_loss: 1.2655 - val_mae: 0.7451\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0892 - val_loss: 1.2674 - val_mae: 0.7463\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0232 - mae: 0.0926 - val_loss: 1.2567 - val_mae: 0.7451\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0893 - val_loss: 1.2719 - val_mae: 0.7479\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0221 - mae: 0.0913 - val_loss: 1.2567 - val_mae: 0.7437\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0239 - mae: 0.0914 - val_loss: 1.2690 - val_mae: 0.7502\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0881 - val_loss: 1.2600 - val_mae: 0.7438\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0891 - val_loss: 1.2623 - val_mae: 0.7444\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0198 - mae: 0.0870 - val_loss: 1.2617 - val_mae: 0.7501\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0177 - mae: 0.0880 - val_loss: 1.2635 - val_mae: 0.7423\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0199 - mae: 0.0874 - val_loss: 1.2583 - val_mae: 0.7435\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0880 - val_loss: 1.2635 - val_mae: 0.7475\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0854 - val_loss: 1.2652 - val_mae: 0.7473\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0187 - mae: 0.0835 - val_loss: 1.2620 - val_mae: 0.7498\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0845 - val_loss: 1.2680 - val_mae: 0.7451\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0306 - mae: 0.0917 - val_loss: 1.2703 - val_mae: 0.7485\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0212 - mae: 0.0849 - val_loss: 1.2600 - val_mae: 0.7473\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0855 - val_loss: 1.2692 - val_mae: 0.7469\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0847 - val_loss: 1.2548 - val_mae: 0.7462\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0190 - mae: 0.0854 - val_loss: 1.2627 - val_mae: 0.7469\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0811 - val_loss: 1.2663 - val_mae: 0.7484\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0798 - val_loss: 1.2631 - val_mae: 0.7474\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0229 - mae: 0.0872 - val_loss: 1.2500 - val_mae: 0.7412\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0841 - val_loss: 1.2535 - val_mae: 0.7440\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0158 - mae: 0.0819 - val_loss: 1.2568 - val_mae: 0.7436\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0171 - mae: 0.0800 - val_loss: 1.2525 - val_mae: 0.7438\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0160 - mae: 0.0778 - val_loss: 1.2594 - val_mae: 0.7469\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0165 - mae: 0.0795 - val_loss: 1.2565 - val_mae: 0.7450\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0788 - val_loss: 1.2554 - val_mae: 0.7408\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0170 - mae: 0.0790 - val_loss: 1.2577 - val_mae: 0.7467\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0810 - val_loss: 1.2605 - val_mae: 0.7420\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0809 - val_loss: 1.2525 - val_mae: 0.7431\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0774 - val_loss: 1.2487 - val_mae: 0.7419\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0768 - val_loss: 1.2486 - val_mae: 0.7406\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0139 - mae: 0.0755 - val_loss: 1.2485 - val_mae: 0.7439\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0161 - mae: 0.0782 - val_loss: 1.2545 - val_mae: 0.7419\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0156 - mae: 0.0780 - val_loss: 1.2502 - val_mae: 0.7425\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0136 - mae: 0.0742 - val_loss: 1.2525 - val_mae: 0.7428\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0775 - val_loss: 1.2503 - val_mae: 0.7426\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0750 - val_loss: 1.2527 - val_mae: 0.7425\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0146 - mae: 0.0764 - val_loss: 1.2534 - val_mae: 0.7427\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0775 - val_loss: 1.2521 - val_mae: 0.7412\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0134 - mae: 0.0740 - val_loss: 1.2569 - val_mae: 0.7439\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0153 - mae: 0.0742 - val_loss: 1.2623 - val_mae: 0.7442\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0763 - val_loss: 1.2397 - val_mae: 0.7404\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0765 - val_loss: 1.2512 - val_mae: 0.7466\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0798 - val_loss: 1.2543 - val_mae: 0.7421\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0721 - val_loss: 1.2515 - val_mae: 0.7418\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0151 - mae: 0.0742 - val_loss: 1.2543 - val_mae: 0.7406\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0728 - val_loss: 1.2382 - val_mae: 0.7370\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0729 - val_loss: 1.2502 - val_mae: 0.7431\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0767 - val_loss: 1.2538 - val_mae: 0.7415\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0712 - val_loss: 1.2464 - val_mae: 0.7393\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0719 - val_loss: 1.2535 - val_mae: 0.7419\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0724 - val_loss: 1.2465 - val_mae: 0.7385\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0736 - val_loss: 1.2570 - val_mae: 0.7417\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0160 - mae: 0.0718 - val_loss: 1.2335 - val_mae: 0.7360\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0684 - val_loss: 1.2536 - val_mae: 0.7426\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0714 - val_loss: 1.2439 - val_mae: 0.7377\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0718 - val_loss: 1.2568 - val_mae: 0.7456\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0156 - mae: 0.0752 - val_loss: 1.2434 - val_mae: 0.7387\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0714 - val_loss: 1.2482 - val_mae: 0.7407\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0684 - val_loss: 1.2467 - val_mae: 0.7412\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0743 - val_loss: 1.2477 - val_mae: 0.7415\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0707 - val_loss: 1.2459 - val_mae: 0.7398\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0662 - val_loss: 1.2480 - val_mae: 0.7400\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0669 - val_loss: 1.2480 - val_mae: 0.7386\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0673 - val_loss: 1.2548 - val_mae: 0.7420\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0684 - val_loss: 1.2480 - val_mae: 0.7376\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0707 - val_loss: 1.2548 - val_mae: 0.7463\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0686 - val_loss: 1.2397 - val_mae: 0.7391\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0684 - val_loss: 1.2499 - val_mae: 0.7401\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0218 - mae: 0.0693 - val_loss: 1.2447 - val_mae: 0.7396\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0110 - mae: 0.0667 - val_loss: 1.2514 - val_mae: 0.7399\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0686 - val_loss: 1.2469 - val_mae: 0.7373\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0164 - mae: 0.0709 - val_loss: 1.2527 - val_mae: 0.7422\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0728 - val_loss: 1.2484 - val_mae: 0.7403\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0636 - val_loss: 1.2535 - val_mae: 0.7436\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0641 - val_loss: 1.2562 - val_mae: 0.7415\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0679 - val_loss: 1.2533 - val_mae: 0.7402\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0654 - val_loss: 1.2464 - val_mae: 0.7388\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0686 - val_loss: 1.2494 - val_mae: 0.7410\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0662 - val_loss: 1.2408 - val_mae: 0.7359\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0148 - mae: 0.0697 - val_loss: 1.2550 - val_mae: 0.7443\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0653 - val_loss: 1.2463 - val_mae: 0.7389\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0639 - val_loss: 1.2530 - val_mae: 0.7403\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0654 - val_loss: 1.2450 - val_mae: 0.7396\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0642 - val_loss: 1.2497 - val_mae: 0.7380\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0665 - val_loss: 1.2498 - val_mae: 0.7413\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0115 - mae: 0.0663 - val_loss: 1.2485 - val_mae: 0.7376\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0169 - mae: 0.0682 - val_loss: 1.2479 - val_mae: 0.7387\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0644 - val_loss: 1.2524 - val_mae: 0.7406\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0644 - val_loss: 1.2417 - val_mae: 0.7369\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0621 - val_loss: 1.2525 - val_mae: 0.7393\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0624 - val_loss: 1.2381 - val_mae: 0.7390\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0654 - val_loss: 1.2371 - val_mae: 0.7364\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0678 - val_loss: 1.2442 - val_mae: 0.7377\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0665 - val_loss: 1.2425 - val_mae: 0.7411\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0582 - val_loss: 1.2455 - val_mae: 0.7366\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0603 - val_loss: 1.2401 - val_mae: 0.7400\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0655 - val_loss: 1.2430 - val_mae: 0.7376\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0137 - mae: 0.0651 - val_loss: 1.2378 - val_mae: 0.7356\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0629 - val_loss: 1.2427 - val_mae: 0.7346\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0172 - mae: 0.0664 - val_loss: 1.2426 - val_mae: 0.7359\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0627 - val_loss: 1.2495 - val_mae: 0.7405\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0663 - val_loss: 1.2502 - val_mae: 0.7396\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0627 - val_loss: 1.2481 - val_mae: 0.7387\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3415 - mae: 0.7650\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.5207 - mae: 1.6333 - val_loss: 1.6215 - val_mae: 0.9229\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.9997 - mae: 0.7310 - val_loss: 1.4800 - val_mae: 0.8673\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.5903 - mae: 0.5534 - val_loss: 1.4376 - val_mae: 0.8640\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.4245 - mae: 0.4674 - val_loss: 1.4163 - val_mae: 0.8379\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3342 - mae: 0.4160 - val_loss: 1.4240 - val_mae: 0.8505\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.3109 - mae: 0.3986 - val_loss: 1.4464 - val_mae: 0.8618\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2632 - mae: 0.3696 - val_loss: 1.4472 - val_mae: 0.8448\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2270 - mae: 0.3462 - val_loss: 1.3969 - val_mae: 0.8227\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1948 - mae: 0.3163 - val_loss: 1.3719 - val_mae: 0.8246\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1759 - mae: 0.3024 - val_loss: 1.3614 - val_mae: 0.8121\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1793 - mae: 0.3035 - val_loss: 1.3674 - val_mae: 0.8079\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1656 - mae: 0.2950 - val_loss: 1.3793 - val_mae: 0.8193\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1414 - mae: 0.2724 - val_loss: 1.3671 - val_mae: 0.8170\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1526 - mae: 0.2740 - val_loss: 1.3604 - val_mae: 0.8125\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1370 - mae: 0.2594 - val_loss: 1.3707 - val_mae: 0.8124\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1228 - mae: 0.2455 - val_loss: 1.3391 - val_mae: 0.7973\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1047 - mae: 0.2320 - val_loss: 1.3295 - val_mae: 0.7946\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1131 - mae: 0.2396 - val_loss: 1.3216 - val_mae: 0.7953\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0944 - mae: 0.2215 - val_loss: 1.3519 - val_mae: 0.7977\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0966 - mae: 0.2230 - val_loss: 1.3854 - val_mae: 0.8224\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0992 - mae: 0.2249 - val_loss: 1.3518 - val_mae: 0.7998\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0985 - mae: 0.2194 - val_loss: 1.3440 - val_mae: 0.7899\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0881 - mae: 0.2008 - val_loss: 1.3261 - val_mae: 0.7906\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0780 - mae: 0.2019 - val_loss: 1.3584 - val_mae: 0.8033\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0892 - mae: 0.2067 - val_loss: 1.3079 - val_mae: 0.7875\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0771 - mae: 0.1966 - val_loss: 1.2939 - val_mae: 0.7783\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0723 - mae: 0.1905 - val_loss: 1.3282 - val_mae: 0.7886\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0727 - mae: 0.1906 - val_loss: 1.2954 - val_mae: 0.7811\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0688 - mae: 0.1807 - val_loss: 1.3581 - val_mae: 0.7997\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0587 - mae: 0.1732 - val_loss: 1.3244 - val_mae: 0.7860\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0583 - mae: 0.1707 - val_loss: 1.3264 - val_mae: 0.7923\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0577 - mae: 0.1698 - val_loss: 1.3232 - val_mae: 0.7954\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0556 - mae: 0.1650 - val_loss: 1.3219 - val_mae: 0.7826\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0587 - mae: 0.1650 - val_loss: 1.3230 - val_mae: 0.7852\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0516 - mae: 0.1643 - val_loss: 1.2994 - val_mae: 0.7779\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0538 - mae: 0.1609 - val_loss: 1.3407 - val_mae: 0.8008\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0539 - mae: 0.1627 - val_loss: 1.3031 - val_mae: 0.7820\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0545 - mae: 0.1603 - val_loss: 1.3275 - val_mae: 0.7938\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0464 - mae: 0.1495 - val_loss: 1.3077 - val_mae: 0.7784\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0450 - mae: 0.1458 - val_loss: 1.3065 - val_mae: 0.7751\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0477 - mae: 0.1492 - val_loss: 1.3137 - val_mae: 0.7847\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0513 - mae: 0.1532 - val_loss: 1.3241 - val_mae: 0.7897\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0472 - mae: 0.1485 - val_loss: 1.2975 - val_mae: 0.7794\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0428 - mae: 0.1429 - val_loss: 1.3021 - val_mae: 0.7730\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0420 - mae: 0.1405 - val_loss: 1.3003 - val_mae: 0.7748\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0490 - mae: 0.1436 - val_loss: 1.2931 - val_mae: 0.7725\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0400 - mae: 0.1396 - val_loss: 1.3005 - val_mae: 0.7746\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0396 - mae: 0.1351 - val_loss: 1.2921 - val_mae: 0.7752\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0395 - mae: 0.1340 - val_loss: 1.3011 - val_mae: 0.7740\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0376 - mae: 0.1309 - val_loss: 1.2868 - val_mae: 0.7680\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0354 - mae: 0.1296 - val_loss: 1.2941 - val_mae: 0.7685\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0373 - mae: 0.1302 - val_loss: 1.3126 - val_mae: 0.7842\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0341 - mae: 0.1267 - val_loss: 1.2917 - val_mae: 0.7751\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0367 - mae: 0.1275 - val_loss: 1.2960 - val_mae: 0.7721\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0349 - mae: 0.1253 - val_loss: 1.2932 - val_mae: 0.7783\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0346 - mae: 0.1246 - val_loss: 1.2761 - val_mae: 0.7676\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0364 - mae: 0.1263 - val_loss: 1.3039 - val_mae: 0.7746\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0340 - mae: 0.1262 - val_loss: 1.2849 - val_mae: 0.7749\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0314 - mae: 0.1209 - val_loss: 1.2823 - val_mae: 0.7693\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0293 - mae: 0.1148 - val_loss: 1.2744 - val_mae: 0.7645\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.1172 - val_loss: 1.2754 - val_mae: 0.7686\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0323 - mae: 0.1156 - val_loss: 1.2766 - val_mae: 0.7669\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0279 - mae: 0.1154 - val_loss: 1.2884 - val_mae: 0.7740\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0328 - mae: 0.1179 - val_loss: 1.2712 - val_mae: 0.7644\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0317 - mae: 0.1158 - val_loss: 1.2813 - val_mae: 0.7669\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0298 - mae: 0.1169 - val_loss: 1.2831 - val_mae: 0.7661\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0312 - mae: 0.1180 - val_loss: 1.2961 - val_mae: 0.7701\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0249 - mae: 0.1082 - val_loss: 1.2890 - val_mae: 0.7706\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0297 - mae: 0.1142 - val_loss: 1.2867 - val_mae: 0.7668\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0261 - mae: 0.1093 - val_loss: 1.2780 - val_mae: 0.7679\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0288 - mae: 0.1078 - val_loss: 1.2941 - val_mae: 0.7748\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0283 - mae: 0.1108 - val_loss: 1.2745 - val_mae: 0.7639\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0281 - mae: 0.1089 - val_loss: 1.2910 - val_mae: 0.7712\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0251 - mae: 0.1032 - val_loss: 1.2806 - val_mae: 0.7652\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0250 - mae: 0.1044 - val_loss: 1.2798 - val_mae: 0.7642\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0275 - mae: 0.1102 - val_loss: 1.2847 - val_mae: 0.7649\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0263 - mae: 0.1055 - val_loss: 1.2862 - val_mae: 0.7678\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0236 - mae: 0.1008 - val_loss: 1.2820 - val_mae: 0.7645\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0245 - mae: 0.1035 - val_loss: 1.2966 - val_mae: 0.7690\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0244 - mae: 0.1003 - val_loss: 1.2831 - val_mae: 0.7646\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0279 - mae: 0.1021 - val_loss: 1.2850 - val_mae: 0.7667\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0215 - mae: 0.0987 - val_loss: 1.2732 - val_mae: 0.7597\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0237 - mae: 0.1004 - val_loss: 1.2749 - val_mae: 0.7627\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0231 - mae: 0.0967 - val_loss: 1.2802 - val_mae: 0.7621\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0965 - val_loss: 1.2877 - val_mae: 0.7660\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0205 - mae: 0.0979 - val_loss: 1.2910 - val_mae: 0.7649\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0962 - val_loss: 1.2864 - val_mae: 0.7702\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0223 - mae: 0.0975 - val_loss: 1.2833 - val_mae: 0.7623\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.0947 - val_loss: 1.2889 - val_mae: 0.7652\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0908 - val_loss: 1.2861 - val_mae: 0.7652\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0230 - mae: 0.0950 - val_loss: 1.2905 - val_mae: 0.7698\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0252 - mae: 0.0971 - val_loss: 1.2787 - val_mae: 0.7608\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.0961 - val_loss: 1.2825 - val_mae: 0.7671\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0940 - val_loss: 1.2906 - val_mae: 0.7663\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0873 - val_loss: 1.2682 - val_mae: 0.7587\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0193 - mae: 0.0905 - val_loss: 1.2882 - val_mae: 0.7682\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0920 - val_loss: 1.2719 - val_mae: 0.7601\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0215 - mae: 0.0909 - val_loss: 1.2977 - val_mae: 0.7693\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0218 - mae: 0.0905 - val_loss: 1.2838 - val_mae: 0.7690\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0194 - mae: 0.0888 - val_loss: 1.2757 - val_mae: 0.7617\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0867 - val_loss: 1.2781 - val_mae: 0.7638\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0167 - mae: 0.0863 - val_loss: 1.2776 - val_mae: 0.7616\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0884 - val_loss: 1.2937 - val_mae: 0.7664\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0172 - mae: 0.0867 - val_loss: 1.2908 - val_mae: 0.7700\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0183 - mae: 0.0881 - val_loss: 1.2869 - val_mae: 0.7673\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0870 - val_loss: 1.2843 - val_mae: 0.7639\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0176 - mae: 0.0892 - val_loss: 1.2907 - val_mae: 0.7652\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0855 - val_loss: 1.2768 - val_mae: 0.7614\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0164 - mae: 0.0839 - val_loss: 1.2922 - val_mae: 0.7654\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0858 - val_loss: 1.2952 - val_mae: 0.7676\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0162 - mae: 0.0845 - val_loss: 1.2839 - val_mae: 0.7621\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0174 - mae: 0.0860 - val_loss: 1.2860 - val_mae: 0.7634\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184 - mae: 0.0860 - val_loss: 1.2980 - val_mae: 0.7730\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0857 - val_loss: 1.2774 - val_mae: 0.7611\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0158 - mae: 0.0803 - val_loss: 1.2782 - val_mae: 0.7579\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0172 - mae: 0.0817 - val_loss: 1.2942 - val_mae: 0.7694\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0883 - val_loss: 1.2836 - val_mae: 0.7613\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0188 - mae: 0.0842 - val_loss: 1.2959 - val_mae: 0.7690\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0151 - mae: 0.0809 - val_loss: 1.2795 - val_mae: 0.7617\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0159 - mae: 0.0794 - val_loss: 1.2851 - val_mae: 0.7612\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0774 - val_loss: 1.2786 - val_mae: 0.7637\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0153 - mae: 0.0792 - val_loss: 1.2865 - val_mae: 0.7647\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0178 - mae: 0.0800 - val_loss: 1.2822 - val_mae: 0.7628\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0783 - val_loss: 1.2914 - val_mae: 0.7626\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.0809 - val_loss: 1.2847 - val_mae: 0.7629\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0812 - val_loss: 1.2886 - val_mae: 0.7649\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0800 - val_loss: 1.2827 - val_mae: 0.7623\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0147 - mae: 0.0751 - val_loss: 1.2930 - val_mae: 0.7667\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0133 - mae: 0.0748 - val_loss: 1.2877 - val_mae: 0.7665\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0764 - val_loss: 1.2793 - val_mae: 0.7629\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0138 - mae: 0.0762 - val_loss: 1.2807 - val_mae: 0.7645\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0165 - mae: 0.0793 - val_loss: 1.2765 - val_mae: 0.7593\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0760 - val_loss: 1.2851 - val_mae: 0.7645\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0771 - val_loss: 1.2838 - val_mae: 0.7622\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0723 - val_loss: 1.2807 - val_mae: 0.7631\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0150 - mae: 0.0731 - val_loss: 1.2761 - val_mae: 0.7625\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0161 - mae: 0.0773 - val_loss: 1.2984 - val_mae: 0.7696\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0146 - mae: 0.0752 - val_loss: 1.2768 - val_mae: 0.7624\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0739 - val_loss: 1.2788 - val_mae: 0.7601\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0130 - mae: 0.0715 - val_loss: 1.2826 - val_mae: 0.7651\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0158 - mae: 0.0761 - val_loss: 1.2700 - val_mae: 0.7577\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0142 - mae: 0.0728 - val_loss: 1.2891 - val_mae: 0.7666\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0213 - mae: 0.0752 - val_loss: 1.2751 - val_mae: 0.7579\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0727 - val_loss: 1.2847 - val_mae: 0.7637\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0153 - mae: 0.0710 - val_loss: 1.2788 - val_mae: 0.7618\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0145 - mae: 0.0736 - val_loss: 1.2709 - val_mae: 0.7587\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0155 - mae: 0.0729 - val_loss: 1.2843 - val_mae: 0.7643\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0693 - val_loss: 1.2840 - val_mae: 0.7650\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0140 - mae: 0.0735 - val_loss: 1.2740 - val_mae: 0.7569\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0750 - val_loss: 1.2771 - val_mae: 0.7584\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0143 - mae: 0.0718 - val_loss: 1.2685 - val_mae: 0.7582\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0643 - val_loss: 1.2777 - val_mae: 0.7621\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0152 - mae: 0.0711 - val_loss: 1.2750 - val_mae: 0.7601\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0131 - mae: 0.0690 - val_loss: 1.2828 - val_mae: 0.7637\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0693 - val_loss: 1.2883 - val_mae: 0.7631\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0711 - val_loss: 1.2782 - val_mae: 0.7620\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0746 - val_loss: 1.2778 - val_mae: 0.7604\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0687 - val_loss: 1.2807 - val_mae: 0.7618\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0129 - mae: 0.0678 - val_loss: 1.2811 - val_mae: 0.7619\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0102 - mae: 0.0654 - val_loss: 1.2680 - val_mae: 0.7582\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0122 - mae: 0.0679 - val_loss: 1.2852 - val_mae: 0.7669\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0696 - val_loss: 1.2687 - val_mae: 0.7606\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0120 - mae: 0.0652 - val_loss: 1.2757 - val_mae: 0.7598\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0127 - mae: 0.0699 - val_loss: 1.2720 - val_mae: 0.7562\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0132 - mae: 0.0726 - val_loss: 1.2807 - val_mae: 0.7643\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0118 - mae: 0.0686 - val_loss: 1.2816 - val_mae: 0.7625\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0657 - val_loss: 1.2837 - val_mae: 0.7622\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0672 - val_loss: 1.2823 - val_mae: 0.7619\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0687 - val_loss: 1.2741 - val_mae: 0.7579\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0110 - mae: 0.0641 - val_loss: 1.2740 - val_mae: 0.7598\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0097 - mae: 0.0638 - val_loss: 1.2805 - val_mae: 0.7644\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0112 - mae: 0.0639 - val_loss: 1.2741 - val_mae: 0.7569\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0641 - val_loss: 1.2676 - val_mae: 0.7573\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0664 - val_loss: 1.2754 - val_mae: 0.7615\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0649 - val_loss: 1.2679 - val_mae: 0.7597\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0111 - mae: 0.0642 - val_loss: 1.2728 - val_mae: 0.7574\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0636 - val_loss: 1.2669 - val_mae: 0.7569\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0648 - val_loss: 1.2737 - val_mae: 0.7593\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0635 - val_loss: 1.2697 - val_mae: 0.7575\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0647 - val_loss: 1.2647 - val_mae: 0.7582\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0647 - val_loss: 1.2689 - val_mae: 0.7566\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0099 - mae: 0.0658 - val_loss: 1.2708 - val_mae: 0.7585\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0617 - val_loss: 1.2740 - val_mae: 0.7583\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0082 - mae: 0.0572 - val_loss: 1.2679 - val_mae: 0.7590\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0596 - val_loss: 1.2697 - val_mae: 0.7602\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0623 - val_loss: 1.2722 - val_mae: 0.7577\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0108 - mae: 0.0651 - val_loss: 1.2771 - val_mae: 0.7616\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0677 - val_loss: 1.2780 - val_mae: 0.7620\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0106 - mae: 0.0624 - val_loss: 1.2684 - val_mae: 0.7578\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0607 - val_loss: 1.2718 - val_mae: 0.7597\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0607 - val_loss: 1.2666 - val_mae: 0.7563\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0091 - mae: 0.0581 - val_loss: 1.2704 - val_mae: 0.7584\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0098 - mae: 0.0627 - val_loss: 1.2676 - val_mae: 0.7590\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0114 - mae: 0.0660 - val_loss: 1.2709 - val_mae: 0.7615\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0595 - val_loss: 1.2768 - val_mae: 0.7590\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0107 - mae: 0.0589 - val_loss: 1.2676 - val_mae: 0.7570\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0609 - val_loss: 1.2781 - val_mae: 0.7627\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0576 - val_loss: 1.2732 - val_mae: 0.7593\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0594 - val_loss: 1.2746 - val_mae: 0.7613\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0093 - mae: 0.0595 - val_loss: 1.2761 - val_mae: 0.7596\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4060 - mae: 0.7891\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 5.3317 - mae: 1.6104 - val_loss: 1.6200 - val_mae: 0.9018\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.9079 - mae: 0.6876 - val_loss: 1.4480 - val_mae: 0.8292\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.6390 - mae: 0.5633 - val_loss: 1.4511 - val_mae: 0.8268\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.4703 - mae: 0.4853 - val_loss: 1.3587 - val_mae: 0.8109\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.3913 - mae: 0.4429 - val_loss: 1.4329 - val_mae: 0.8048\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.3302 - mae: 0.4026 - val_loss: 1.4042 - val_mae: 0.8074\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.3013 - mae: 0.3816 - val_loss: 1.3865 - val_mae: 0.7931\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.2337 - mae: 0.3470 - val_loss: 1.3854 - val_mae: 0.7999\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2241 - mae: 0.3354 - val_loss: 1.4038 - val_mae: 0.7977\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1897 - mae: 0.3085 - val_loss: 1.3604 - val_mae: 0.7853\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1724 - mae: 0.2951 - val_loss: 1.3943 - val_mae: 0.7931\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1586 - mae: 0.2835 - val_loss: 1.3659 - val_mae: 0.7802\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1419 - mae: 0.2691 - val_loss: 1.3586 - val_mae: 0.7790\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1466 - mae: 0.2681 - val_loss: 1.3703 - val_mae: 0.7765\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1264 - mae: 0.2485 - val_loss: 1.3520 - val_mae: 0.7740\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1215 - mae: 0.2452 - val_loss: 1.3356 - val_mae: 0.7721\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1156 - mae: 0.2358 - val_loss: 1.3348 - val_mae: 0.7623\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1071 - mae: 0.2327 - val_loss: 1.3427 - val_mae: 0.7691\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1022 - mae: 0.2242 - val_loss: 1.3101 - val_mae: 0.7662\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0894 - mae: 0.2111 - val_loss: 1.3046 - val_mae: 0.7580\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0940 - mae: 0.2110 - val_loss: 1.3378 - val_mae: 0.7642\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0883 - mae: 0.2078 - val_loss: 1.3322 - val_mae: 0.7616\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0843 - mae: 0.2016 - val_loss: 1.3066 - val_mae: 0.7563\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0831 - mae: 0.1989 - val_loss: 1.3227 - val_mae: 0.7573\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0785 - mae: 0.1961 - val_loss: 1.3387 - val_mae: 0.7641\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0773 - mae: 0.1929 - val_loss: 1.3144 - val_mae: 0.7624\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0807 - mae: 0.1922 - val_loss: 1.3110 - val_mae: 0.7563\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0742 - mae: 0.1862 - val_loss: 1.2875 - val_mae: 0.7534\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0690 - mae: 0.1827 - val_loss: 1.3494 - val_mae: 0.7741\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0691 - mae: 0.1776 - val_loss: 1.2969 - val_mae: 0.7507\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0724 - mae: 0.1781 - val_loss: 1.2874 - val_mae: 0.7479\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0597 - mae: 0.1666 - val_loss: 1.3131 - val_mae: 0.7618\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0601 - mae: 0.1680 - val_loss: 1.3090 - val_mae: 0.7483\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0582 - mae: 0.1618 - val_loss: 1.3032 - val_mae: 0.7526\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0554 - mae: 0.1628 - val_loss: 1.3067 - val_mae: 0.7517\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0596 - mae: 0.1619 - val_loss: 1.3317 - val_mae: 0.7701\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0541 - mae: 0.1585 - val_loss: 1.2998 - val_mae: 0.7619\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0505 - mae: 0.1548 - val_loss: 1.3082 - val_mae: 0.7506\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0545 - mae: 0.1548 - val_loss: 1.3035 - val_mae: 0.7554\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0521 - mae: 0.1502 - val_loss: 1.3143 - val_mae: 0.7551\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0482 - mae: 0.1488 - val_loss: 1.3100 - val_mae: 0.7516\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0547 - mae: 0.1543 - val_loss: 1.2997 - val_mae: 0.7477\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0456 - mae: 0.1427 - val_loss: 1.2900 - val_mae: 0.7442\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0521 - mae: 0.1421 - val_loss: 1.2977 - val_mae: 0.7494\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0426 - mae: 0.1372 - val_loss: 1.2789 - val_mae: 0.7500\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0490 - mae: 0.1454 - val_loss: 1.2856 - val_mae: 0.7499\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0433 - mae: 0.1392 - val_loss: 1.3280 - val_mae: 0.7558\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0502 - mae: 0.1420 - val_loss: 1.2973 - val_mae: 0.7529\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0436 - mae: 0.1351 - val_loss: 1.2870 - val_mae: 0.7486\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0382 - mae: 0.1290 - val_loss: 1.2876 - val_mae: 0.7464\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0386 - mae: 0.1281 - val_loss: 1.2800 - val_mae: 0.7460\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0396 - mae: 0.1333 - val_loss: 1.2903 - val_mae: 0.7483\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0420 - mae: 0.1316 - val_loss: 1.2951 - val_mae: 0.7550\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0375 - mae: 0.1248 - val_loss: 1.3020 - val_mae: 0.7480\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0385 - mae: 0.1277 - val_loss: 1.2944 - val_mae: 0.7452\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0363 - mae: 0.1246 - val_loss: 1.2910 - val_mae: 0.7499\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0340 - mae: 0.1228 - val_loss: 1.2826 - val_mae: 0.7469\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0346 - mae: 0.1201 - val_loss: 1.2792 - val_mae: 0.7472\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0339 - mae: 0.1206 - val_loss: 1.3056 - val_mae: 0.7507\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0382 - mae: 0.1210 - val_loss: 1.2926 - val_mae: 0.7463\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0340 - mae: 0.1199 - val_loss: 1.2851 - val_mae: 0.7451\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0306 - mae: 0.1157 - val_loss: 1.3104 - val_mae: 0.7494\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0337 - mae: 0.1222 - val_loss: 1.2918 - val_mae: 0.7458\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0329 - mae: 0.1193 - val_loss: 1.2822 - val_mae: 0.7425\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0311 - mae: 0.1160 - val_loss: 1.3046 - val_mae: 0.7569\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0302 - mae: 0.1139 - val_loss: 1.2944 - val_mae: 0.7459\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0306 - mae: 0.1146 - val_loss: 1.3117 - val_mae: 0.7519\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0302 - mae: 0.1125 - val_loss: 1.2886 - val_mae: 0.7422\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0300 - mae: 0.1109 - val_loss: 1.2800 - val_mae: 0.7455\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0291 - mae: 0.1088 - val_loss: 1.2879 - val_mae: 0.7477\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0276 - mae: 0.1072 - val_loss: 1.2880 - val_mae: 0.7409\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0328 - mae: 0.1132 - val_loss: 1.2825 - val_mae: 0.7432\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0301 - mae: 0.1110 - val_loss: 1.2858 - val_mae: 0.7450\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0269 - mae: 0.1051 - val_loss: 1.2792 - val_mae: 0.7436\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0249 - mae: 0.1031 - val_loss: 1.2890 - val_mae: 0.7478\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0271 - mae: 0.1055 - val_loss: 1.3030 - val_mae: 0.7478\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0288 - mae: 0.1058 - val_loss: 1.2754 - val_mae: 0.7442\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0279 - mae: 0.1074 - val_loss: 1.2953 - val_mae: 0.7457\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0281 - mae: 0.1029 - val_loss: 1.2635 - val_mae: 0.7418\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0238 - mae: 0.0980 - val_loss: 1.2838 - val_mae: 0.7438\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0245 - mae: 0.0994 - val_loss: 1.2951 - val_mae: 0.7501\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0248 - mae: 0.1014 - val_loss: 1.2980 - val_mae: 0.7573\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0261 - mae: 0.1037 - val_loss: 1.2794 - val_mae: 0.7431\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0229 - mae: 0.0957 - val_loss: 1.2940 - val_mae: 0.7428\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0293 - mae: 0.1008 - val_loss: 1.2840 - val_mae: 0.7437\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0271 - mae: 0.0989 - val_loss: 1.2762 - val_mae: 0.7399\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0254 - mae: 0.0979 - val_loss: 1.2767 - val_mae: 0.7438\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0243 - mae: 0.0980 - val_loss: 1.2815 - val_mae: 0.7467\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0243 - mae: 0.0960 - val_loss: 1.2705 - val_mae: 0.7403\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0228 - mae: 0.0915 - val_loss: 1.3016 - val_mae: 0.7493\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0266 - mae: 0.1001 - val_loss: 1.2883 - val_mae: 0.7445\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0206 - mae: 0.0941 - val_loss: 1.2823 - val_mae: 0.7425\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0214 - mae: 0.0951 - val_loss: 1.2855 - val_mae: 0.7479\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0216 - mae: 0.0943 - val_loss: 1.2782 - val_mae: 0.7382\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0260 - mae: 0.0925 - val_loss: 1.2836 - val_mae: 0.7452\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0206 - mae: 0.0910 - val_loss: 1.2935 - val_mae: 0.7475\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0235 - mae: 0.0916 - val_loss: 1.2832 - val_mae: 0.7411\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0237 - mae: 0.0944 - val_loss: 1.2836 - val_mae: 0.7427\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0231 - mae: 0.0942 - val_loss: 1.2820 - val_mae: 0.7456\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0201 - mae: 0.0889 - val_loss: 1.2747 - val_mae: 0.7428\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0245 - mae: 0.0935 - val_loss: 1.2794 - val_mae: 0.7465\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0247 - mae: 0.0894 - val_loss: 1.2778 - val_mae: 0.7398\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0239 - mae: 0.0917 - val_loss: 1.2874 - val_mae: 0.7414\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.0888 - val_loss: 1.2740 - val_mae: 0.7394\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0227 - mae: 0.0912 - val_loss: 1.2707 - val_mae: 0.7393\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0194 - mae: 0.0852 - val_loss: 1.2863 - val_mae: 0.7468\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0206 - mae: 0.0855 - val_loss: 1.2639 - val_mae: 0.7407\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0213 - mae: 0.0888 - val_loss: 1.2872 - val_mae: 0.7441\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0224 - mae: 0.0868 - val_loss: 1.2820 - val_mae: 0.7447\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0205 - mae: 0.0867 - val_loss: 1.2692 - val_mae: 0.7388\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0236 - mae: 0.0886 - val_loss: 1.2726 - val_mae: 0.7361\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0223 - mae: 0.0900 - val_loss: 1.2841 - val_mae: 0.7451\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0187 - mae: 0.0833 - val_loss: 1.2780 - val_mae: 0.7374\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.0827 - val_loss: 1.2773 - val_mae: 0.7383\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0214 - mae: 0.0823 - val_loss: 1.2780 - val_mae: 0.7381\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0246 - mae: 0.0860 - val_loss: 1.2949 - val_mae: 0.7531\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0194 - mae: 0.0869 - val_loss: 1.2765 - val_mae: 0.7391\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0224 - mae: 0.0890 - val_loss: 1.2654 - val_mae: 0.7372\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0792 - val_loss: 1.2782 - val_mae: 0.7454\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0244 - mae: 0.0828 - val_loss: 1.2729 - val_mae: 0.7415\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0174 - mae: 0.0800 - val_loss: 1.2735 - val_mae: 0.7389\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0221 - mae: 0.0829 - val_loss: 1.2795 - val_mae: 0.7397\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0206 - mae: 0.0828 - val_loss: 1.2584 - val_mae: 0.7349\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0264 - mae: 0.0829 - val_loss: 1.2940 - val_mae: 0.7489\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0172 - mae: 0.0806 - val_loss: 1.2775 - val_mae: 0.7397\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0232 - mae: 0.0833 - val_loss: 1.2723 - val_mae: 0.7391\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0188 - mae: 0.0783 - val_loss: 1.2729 - val_mae: 0.7388\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0206 - mae: 0.0830 - val_loss: 1.2803 - val_mae: 0.7404\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0786 - val_loss: 1.2785 - val_mae: 0.7456\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0171 - mae: 0.0796 - val_loss: 1.2831 - val_mae: 0.7484\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0183 - mae: 0.0800 - val_loss: 1.2697 - val_mae: 0.7384\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0185 - mae: 0.0787 - val_loss: 1.2742 - val_mae: 0.7407\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0177 - mae: 0.0753 - val_loss: 1.2691 - val_mae: 0.7389\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0172 - mae: 0.0797 - val_loss: 1.2825 - val_mae: 0.7431\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0166 - mae: 0.0738 - val_loss: 1.2841 - val_mae: 0.7399\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0174 - mae: 0.0772 - val_loss: 1.2814 - val_mae: 0.7447\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0175 - mae: 0.0760 - val_loss: 1.2863 - val_mae: 0.7412\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0181 - mae: 0.0783 - val_loss: 1.2711 - val_mae: 0.7374\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0167 - mae: 0.0758 - val_loss: 1.2744 - val_mae: 0.7395\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0200 - mae: 0.0782 - val_loss: 1.2706 - val_mae: 0.7398\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0160 - mae: 0.0763 - val_loss: 1.2686 - val_mae: 0.7376\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0183 - mae: 0.0756 - val_loss: 1.2678 - val_mae: 0.7358\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0156 - mae: 0.0721 - val_loss: 1.2579 - val_mae: 0.7339\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0197 - mae: 0.0788 - val_loss: 1.2740 - val_mae: 0.7407\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0178 - mae: 0.0759 - val_loss: 1.2663 - val_mae: 0.7373\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0172 - mae: 0.0767 - val_loss: 1.2728 - val_mae: 0.7346\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0155 - mae: 0.0716 - val_loss: 1.2833 - val_mae: 0.7464\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0159 - mae: 0.0733 - val_loss: 1.2625 - val_mae: 0.7369\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0703 - val_loss: 1.2740 - val_mae: 0.7389\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0175 - mae: 0.0725 - val_loss: 1.2688 - val_mae: 0.7392\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0716 - val_loss: 1.2786 - val_mae: 0.7401\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0739 - val_loss: 1.2695 - val_mae: 0.7388\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0198 - mae: 0.0716 - val_loss: 1.2910 - val_mae: 0.7413\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0170 - mae: 0.0732 - val_loss: 1.2724 - val_mae: 0.7422\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0161 - mae: 0.0739 - val_loss: 1.2744 - val_mae: 0.7409\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0217 - mae: 0.0723 - val_loss: 1.2781 - val_mae: 0.7386\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0213 - mae: 0.0700 - val_loss: 1.2773 - val_mae: 0.7391\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0154 - mae: 0.0702 - val_loss: 1.2724 - val_mae: 0.7383\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0152 - mae: 0.0717 - val_loss: 1.2729 - val_mae: 0.7372\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0151 - mae: 0.0715 - val_loss: 1.2770 - val_mae: 0.7443\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0167 - mae: 0.0700 - val_loss: 1.2837 - val_mae: 0.7433\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.0702 - val_loss: 1.2746 - val_mae: 0.7426\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0184 - mae: 0.0742 - val_loss: 1.2729 - val_mae: 0.7382\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0176 - mae: 0.0680 - val_loss: 1.2657 - val_mae: 0.7354\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0166 - mae: 0.0701 - val_loss: 1.2739 - val_mae: 0.7400\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0690 - val_loss: 1.2763 - val_mae: 0.7417\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0233 - mae: 0.0736 - val_loss: 1.2644 - val_mae: 0.7351\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0158 - mae: 0.0675 - val_loss: 1.2788 - val_mae: 0.7402\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0161 - mae: 0.0705 - val_loss: 1.2688 - val_mae: 0.7410\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0702 - val_loss: 1.2730 - val_mae: 0.7409\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0172 - mae: 0.0693 - val_loss: 1.2588 - val_mae: 0.7364\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0217 - mae: 0.0702 - val_loss: 1.2804 - val_mae: 0.7399\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0192 - mae: 0.0696 - val_loss: 1.2623 - val_mae: 0.7357\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0186 - mae: 0.0678 - val_loss: 1.2785 - val_mae: 0.7398\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0192 - mae: 0.0699 - val_loss: 1.2767 - val_mae: 0.7404\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0664 - val_loss: 1.2838 - val_mae: 0.7406\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0667 - val_loss: 1.2779 - val_mae: 0.7428\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0190 - mae: 0.0717 - val_loss: 1.2726 - val_mae: 0.7384\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0638 - val_loss: 1.2664 - val_mae: 0.7409\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0142 - mae: 0.0692 - val_loss: 1.2742 - val_mae: 0.7398\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0650 - val_loss: 1.2705 - val_mae: 0.7396\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0125 - mae: 0.0647 - val_loss: 1.2800 - val_mae: 0.7406\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0683 - val_loss: 1.2711 - val_mae: 0.7404\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0673 - val_loss: 1.2760 - val_mae: 0.7390\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0158 - mae: 0.0635 - val_loss: 1.2743 - val_mae: 0.7378\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0677 - val_loss: 1.2629 - val_mae: 0.7347\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0142 - mae: 0.0648 - val_loss: 1.2684 - val_mae: 0.7372\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0137 - mae: 0.0650 - val_loss: 1.2682 - val_mae: 0.7367\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0135 - mae: 0.0646 - val_loss: 1.2627 - val_mae: 0.7375\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0185 - mae: 0.0678 - val_loss: 1.2717 - val_mae: 0.7372\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0150 - mae: 0.0667 - val_loss: 1.2649 - val_mae: 0.7347\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0152 - mae: 0.0667 - val_loss: 1.2673 - val_mae: 0.7360\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.0652 - val_loss: 1.2673 - val_mae: 0.7376\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0623 - val_loss: 1.2620 - val_mae: 0.7390\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0149 - mae: 0.0658 - val_loss: 1.2670 - val_mae: 0.7365\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0143 - mae: 0.0630 - val_loss: 1.2654 - val_mae: 0.7348\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0168 - mae: 0.0663 - val_loss: 1.2741 - val_mae: 0.7365\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0139 - mae: 0.0612 - val_loss: 1.2715 - val_mae: 0.7371\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0629 - val_loss: 1.2761 - val_mae: 0.7388\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.0638 - val_loss: 1.2661 - val_mae: 0.7354\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2988 - mae: 0.7376\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 5.6327 - mae: 1.6622 - val_loss: 1.6577 - val_mae: 0.9218\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.9031 - mae: 0.6849 - val_loss: 1.5405 - val_mae: 0.8783\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.6226 - mae: 0.5577 - val_loss: 1.4274 - val_mae: 0.8365\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.4333 - mae: 0.4645 - val_loss: 1.4026 - val_mae: 0.8312\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.3523 - mae: 0.4180 - val_loss: 1.4466 - val_mae: 0.8490\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.3176 - mae: 0.3872 - val_loss: 1.5674 - val_mae: 0.9071\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.2563 - mae: 0.3629 - val_loss: 1.4068 - val_mae: 0.8182\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.2278 - mae: 0.3413 - val_loss: 1.4621 - val_mae: 0.8495\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.2140 - mae: 0.3301 - val_loss: 1.4124 - val_mae: 0.8201\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1995 - mae: 0.3114 - val_loss: 1.3592 - val_mae: 0.8047\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1645 - mae: 0.2890 - val_loss: 1.3619 - val_mae: 0.8099\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1425 - mae: 0.2709 - val_loss: 1.3449 - val_mae: 0.8022\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1608 - mae: 0.2814 - val_loss: 1.3806 - val_mae: 0.8157\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1271 - mae: 0.2543 - val_loss: 1.3388 - val_mae: 0.7973\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1329 - mae: 0.2559 - val_loss: 1.3783 - val_mae: 0.8082\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1164 - mae: 0.2448 - val_loss: 1.3538 - val_mae: 0.7986\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1103 - mae: 0.2378 - val_loss: 1.3380 - val_mae: 0.8003\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1135 - mae: 0.2393 - val_loss: 1.3344 - val_mae: 0.7935\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0963 - mae: 0.2204 - val_loss: 1.3436 - val_mae: 0.7957\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0974 - mae: 0.2196 - val_loss: 1.4011 - val_mae: 0.8129\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0884 - mae: 0.2093 - val_loss: 1.3132 - val_mae: 0.7895\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0859 - mae: 0.2057 - val_loss: 1.3310 - val_mae: 0.7918\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0805 - mae: 0.2008 - val_loss: 1.3302 - val_mae: 0.7883\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0818 - mae: 0.1981 - val_loss: 1.3399 - val_mae: 0.7927\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0749 - mae: 0.1869 - val_loss: 1.3239 - val_mae: 0.7798\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0667 - mae: 0.1833 - val_loss: 1.3271 - val_mae: 0.7880\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0817 - mae: 0.1924 - val_loss: 1.3303 - val_mae: 0.7834\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0610 - mae: 0.1747 - val_loss: 1.2954 - val_mae: 0.7726\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0656 - mae: 0.1771 - val_loss: 1.3077 - val_mae: 0.7753\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0612 - mae: 0.1713 - val_loss: 1.3285 - val_mae: 0.7923\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0622 - mae: 0.1716 - val_loss: 1.3225 - val_mae: 0.7826\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0588 - mae: 0.1655 - val_loss: 1.3002 - val_mae: 0.7789\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0538 - mae: 0.1629 - val_loss: 1.3265 - val_mae: 0.7787\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0549 - mae: 0.1576 - val_loss: 1.3177 - val_mae: 0.7762\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0549 - mae: 0.1594 - val_loss: 1.3294 - val_mae: 0.7842\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0502 - mae: 0.1565 - val_loss: 1.3255 - val_mae: 0.7823\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0489 - mae: 0.1552 - val_loss: 1.3221 - val_mae: 0.7855\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0486 - mae: 0.1520 - val_loss: 1.3310 - val_mae: 0.7827\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0467 - mae: 0.1472 - val_loss: 1.3109 - val_mae: 0.7745\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0473 - mae: 0.1452 - val_loss: 1.3204 - val_mae: 0.7720\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0462 - mae: 0.1455 - val_loss: 1.2964 - val_mae: 0.7683\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0499 - mae: 0.1433 - val_loss: 1.3220 - val_mae: 0.7803\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0393 - mae: 0.1361 - val_loss: 1.3138 - val_mae: 0.7778\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0468 - mae: 0.1425 - val_loss: 1.3009 - val_mae: 0.7715\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0372 - mae: 0.1318 - val_loss: 1.3107 - val_mae: 0.7733\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0412 - mae: 0.1360 - val_loss: 1.3180 - val_mae: 0.7860\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0388 - mae: 0.1347 - val_loss: 1.3141 - val_mae: 0.7717\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0410 - mae: 0.1289 - val_loss: 1.3097 - val_mae: 0.7693\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0403 - mae: 0.1301 - val_loss: 1.3087 - val_mae: 0.7680\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0400 - mae: 0.1336 - val_loss: 1.3082 - val_mae: 0.7695\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0371 - mae: 0.1269 - val_loss: 1.3229 - val_mae: 0.7790\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0336 - mae: 0.1200 - val_loss: 1.3122 - val_mae: 0.7761\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0324 - mae: 0.1215 - val_loss: 1.3133 - val_mae: 0.7702\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0339 - mae: 0.1216 - val_loss: 1.3296 - val_mae: 0.7885\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0399 - mae: 0.1276 - val_loss: 1.3163 - val_mae: 0.7681\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0321 - mae: 0.1149 - val_loss: 1.3118 - val_mae: 0.7742\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0308 - mae: 0.1176 - val_loss: 1.3299 - val_mae: 0.7755\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0339 - mae: 0.1260 - val_loss: 1.3260 - val_mae: 0.7814\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0343 - mae: 0.1170 - val_loss: 1.3183 - val_mae: 0.7719\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0270 - mae: 0.1063 - val_loss: 1.3196 - val_mae: 0.7770\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0340 - mae: 0.1135 - val_loss: 1.3093 - val_mae: 0.7703\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0293 - mae: 0.1130 - val_loss: 1.3272 - val_mae: 0.7801\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0363 - mae: 0.1169 - val_loss: 1.3093 - val_mae: 0.7747\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0270 - mae: 0.1079 - val_loss: 1.3136 - val_mae: 0.7693\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0323 - mae: 0.1126 - val_loss: 1.3217 - val_mae: 0.7773\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0258 - mae: 0.1089 - val_loss: 1.3186 - val_mae: 0.7674\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0262 - mae: 0.1089 - val_loss: 1.3150 - val_mae: 0.7686\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0301 - mae: 0.1114 - val_loss: 1.3091 - val_mae: 0.7658\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0256 - mae: 0.1051 - val_loss: 1.3136 - val_mae: 0.7730\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0238 - mae: 0.1031 - val_loss: 1.3111 - val_mae: 0.7703\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0370 - mae: 0.1089 - val_loss: 1.3143 - val_mae: 0.7762\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0258 - mae: 0.1043 - val_loss: 1.3095 - val_mae: 0.7682\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0257 - mae: 0.1035 - val_loss: 1.3098 - val_mae: 0.7658\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0215 - mae: 0.0975 - val_loss: 1.3166 - val_mae: 0.7682\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0235 - mae: 0.1014 - val_loss: 1.3051 - val_mae: 0.7669\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0293 - mae: 0.1028 - val_loss: 1.3048 - val_mae: 0.7675\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0211 - mae: 0.0979 - val_loss: 1.3102 - val_mae: 0.7718\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0281 - mae: 0.1002 - val_loss: 1.2927 - val_mae: 0.7611\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0248 - mae: 0.0991 - val_loss: 1.2933 - val_mae: 0.7611\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0267 - mae: 0.0979 - val_loss: 1.3054 - val_mae: 0.7611\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0224 - mae: 0.0934 - val_loss: 1.3033 - val_mae: 0.7626\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0209 - mae: 0.0942 - val_loss: 1.3026 - val_mae: 0.7649\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0245 - mae: 0.0976 - val_loss: 1.3141 - val_mae: 0.7719\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0207 - mae: 0.0969 - val_loss: 1.3163 - val_mae: 0.7690\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0228 - mae: 0.0958 - val_loss: 1.2983 - val_mae: 0.7641\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0225 - mae: 0.0945 - val_loss: 1.3164 - val_mae: 0.7652\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0226 - mae: 0.0929 - val_loss: 1.3106 - val_mae: 0.7729\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0186 - mae: 0.0904 - val_loss: 1.3075 - val_mae: 0.7685\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0204 - mae: 0.0937 - val_loss: 1.3048 - val_mae: 0.7642\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.0930 - val_loss: 1.2954 - val_mae: 0.7646\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0226 - mae: 0.0913 - val_loss: 1.3049 - val_mae: 0.7666\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0256 - mae: 0.0893 - val_loss: 1.3035 - val_mae: 0.7680\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0247 - mae: 0.0906 - val_loss: 1.3037 - val_mae: 0.7668\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0211 - mae: 0.0908 - val_loss: 1.2998 - val_mae: 0.7628\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0217 - mae: 0.0892 - val_loss: 1.3134 - val_mae: 0.7691\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0261 - mae: 0.0903 - val_loss: 1.3101 - val_mae: 0.7619\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0205 - mae: 0.0885 - val_loss: 1.3034 - val_mae: 0.7674\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0240 - mae: 0.0919 - val_loss: 1.3116 - val_mae: 0.7641\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0181 - mae: 0.0835 - val_loss: 1.3190 - val_mae: 0.7700\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0220 - mae: 0.0874 - val_loss: 1.2883 - val_mae: 0.7592\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0182 - mae: 0.0834 - val_loss: 1.2969 - val_mae: 0.7620\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0204 - mae: 0.0879 - val_loss: 1.3180 - val_mae: 0.7687\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0260 - mae: 0.0904 - val_loss: 1.2901 - val_mae: 0.7570\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0198 - mae: 0.0881 - val_loss: 1.3083 - val_mae: 0.7683\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0186 - mae: 0.0832 - val_loss: 1.3099 - val_mae: 0.7675\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0192 - mae: 0.0849 - val_loss: 1.2980 - val_mae: 0.7600\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0192 - mae: 0.0846 - val_loss: 1.3070 - val_mae: 0.7687\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0172 - mae: 0.0842 - val_loss: 1.3145 - val_mae: 0.7692\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0184 - mae: 0.0832 - val_loss: 1.2931 - val_mae: 0.7560\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0175 - mae: 0.0802 - val_loss: 1.3162 - val_mae: 0.7610\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0188 - mae: 0.0833 - val_loss: 1.3077 - val_mae: 0.7632\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0172 - mae: 0.0799 - val_loss: 1.3059 - val_mae: 0.7621\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0174 - mae: 0.0824 - val_loss: 1.3052 - val_mae: 0.7643\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0186 - mae: 0.0830 - val_loss: 1.3002 - val_mae: 0.7601\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0201 - mae: 0.0818 - val_loss: 1.3064 - val_mae: 0.7656\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0233 - mae: 0.0778 - val_loss: 1.3155 - val_mae: 0.7641\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0149 - mae: 0.0755 - val_loss: 1.3090 - val_mae: 0.7630\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0766 - val_loss: 1.3022 - val_mae: 0.7625\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0157 - mae: 0.0776 - val_loss: 1.3036 - val_mae: 0.7598\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0788 - val_loss: 1.3075 - val_mae: 0.7613\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0185 - mae: 0.0790 - val_loss: 1.3047 - val_mae: 0.7618\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0744 - val_loss: 1.3142 - val_mae: 0.7659\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0154 - mae: 0.0773 - val_loss: 1.3066 - val_mae: 0.7655\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0155 - mae: 0.0750 - val_loss: 1.3093 - val_mae: 0.7617\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0758 - val_loss: 1.3072 - val_mae: 0.7603\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0201 - mae: 0.0812 - val_loss: 1.3104 - val_mae: 0.7636\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0140 - mae: 0.0766 - val_loss: 1.3003 - val_mae: 0.7582\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0173 - mae: 0.0787 - val_loss: 1.3173 - val_mae: 0.7663\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0728 - val_loss: 1.3050 - val_mae: 0.7610\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0143 - mae: 0.0743 - val_loss: 1.3108 - val_mae: 0.7629\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0185 - mae: 0.0763 - val_loss: 1.3105 - val_mae: 0.7620\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0170 - mae: 0.0765 - val_loss: 1.3114 - val_mae: 0.7643\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0720 - val_loss: 1.3122 - val_mae: 0.7620\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0131 - mae: 0.0728 - val_loss: 1.3140 - val_mae: 0.7635\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0145 - mae: 0.0719 - val_loss: 1.3063 - val_mae: 0.7615\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0707 - val_loss: 1.3082 - val_mae: 0.7613\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0175 - mae: 0.0757 - val_loss: 1.3101 - val_mae: 0.7644\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0140 - mae: 0.0723 - val_loss: 1.3128 - val_mae: 0.7649\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0177 - mae: 0.0753 - val_loss: 1.3183 - val_mae: 0.7622\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0688 - val_loss: 1.3138 - val_mae: 0.7634\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0145 - mae: 0.0729 - val_loss: 1.3184 - val_mae: 0.7658\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0154 - mae: 0.0733 - val_loss: 1.3253 - val_mae: 0.7715\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0137 - mae: 0.0722 - val_loss: 1.3219 - val_mae: 0.7646\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0159 - mae: 0.0739 - val_loss: 1.3140 - val_mae: 0.7650\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0673 - val_loss: 1.2994 - val_mae: 0.7587\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0138 - mae: 0.0691 - val_loss: 1.3120 - val_mae: 0.7626\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0680 - val_loss: 1.3067 - val_mae: 0.7618\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0125 - mae: 0.0714 - val_loss: 1.3064 - val_mae: 0.7599\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.0694 - val_loss: 1.2996 - val_mae: 0.7580\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0131 - mae: 0.0683 - val_loss: 1.3059 - val_mae: 0.7606\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0128 - mae: 0.0703 - val_loss: 1.3074 - val_mae: 0.7615\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0115 - mae: 0.0682 - val_loss: 1.3014 - val_mae: 0.7594\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0170 - mae: 0.0713 - val_loss: 1.2988 - val_mae: 0.7569\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0115 - mae: 0.0701 - val_loss: 1.3005 - val_mae: 0.7582\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0711 - val_loss: 1.2987 - val_mae: 0.7634\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0186 - mae: 0.0683 - val_loss: 1.2972 - val_mae: 0.7576\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0144 - mae: 0.0648 - val_loss: 1.3026 - val_mae: 0.7641\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0143 - mae: 0.0703 - val_loss: 1.3039 - val_mae: 0.7616\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0130 - mae: 0.0697 - val_loss: 1.2877 - val_mae: 0.7536\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0137 - mae: 0.0688 - val_loss: 1.3008 - val_mae: 0.7593\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0145 - mae: 0.0660 - val_loss: 1.3256 - val_mae: 0.7718\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0124 - mae: 0.0665 - val_loss: 1.3059 - val_mae: 0.7607\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0135 - mae: 0.0669 - val_loss: 1.3015 - val_mae: 0.7572\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0658 - val_loss: 1.2945 - val_mae: 0.7587\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0117 - mae: 0.0659 - val_loss: 1.2990 - val_mae: 0.7559\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0680 - val_loss: 1.3050 - val_mae: 0.7600\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0219 - mae: 0.0691 - val_loss: 1.2951 - val_mae: 0.7581\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0658 - val_loss: 1.2994 - val_mae: 0.7580\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0121 - mae: 0.0658 - val_loss: 1.3009 - val_mae: 0.7590\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0100 - mae: 0.0622 - val_loss: 1.2972 - val_mae: 0.7593\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0121 - mae: 0.0634 - val_loss: 1.3133 - val_mae: 0.7650\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0653 - val_loss: 1.2961 - val_mae: 0.7589\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0648 - val_loss: 1.2893 - val_mae: 0.7571\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0652 - val_loss: 1.3046 - val_mae: 0.7600\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0137 - mae: 0.0646 - val_loss: 1.2945 - val_mae: 0.7561\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0628 - val_loss: 1.3074 - val_mae: 0.7613\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0125 - mae: 0.0610 - val_loss: 1.2883 - val_mae: 0.7573\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0142 - mae: 0.0619 - val_loss: 1.2971 - val_mae: 0.7600\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0098 - mae: 0.0603 - val_loss: 1.2920 - val_mae: 0.7600\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0136 - mae: 0.0633 - val_loss: 1.3023 - val_mae: 0.7562\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0113 - mae: 0.0646 - val_loss: 1.2908 - val_mae: 0.7561\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0132 - mae: 0.0648 - val_loss: 1.3007 - val_mae: 0.7579\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0642 - val_loss: 1.2965 - val_mae: 0.7594\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0115 - mae: 0.0606 - val_loss: 1.3135 - val_mae: 0.7622\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0126 - mae: 0.0652 - val_loss: 1.3068 - val_mae: 0.7631\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0136 - mae: 0.0643 - val_loss: 1.3092 - val_mae: 0.7622\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0096 - mae: 0.0584 - val_loss: 1.2898 - val_mae: 0.7552\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0117 - mae: 0.0652 - val_loss: 1.3045 - val_mae: 0.7605\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0124 - mae: 0.0649 - val_loss: 1.2965 - val_mae: 0.7562\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0633 - val_loss: 1.3027 - val_mae: 0.7592\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0131 - mae: 0.0602 - val_loss: 1.3028 - val_mae: 0.7591\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0113 - mae: 0.0596 - val_loss: 1.3086 - val_mae: 0.7613\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0618 - val_loss: 1.2942 - val_mae: 0.7569\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0633 - val_loss: 1.2997 - val_mae: 0.7583\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0118 - mae: 0.0595 - val_loss: 1.3010 - val_mae: 0.7601\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0094 - mae: 0.0566 - val_loss: 1.2965 - val_mae: 0.7600\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0614 - val_loss: 1.2938 - val_mae: 0.7560\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0113 - mae: 0.0607 - val_loss: 1.2971 - val_mae: 0.7588\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0099 - mae: 0.0622 - val_loss: 1.3115 - val_mae: 0.7613\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0108 - mae: 0.0620 - val_loss: 1.3055 - val_mae: 0.7617\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3392 - mae: 0.7605\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 5.6009 - mae: 1.6685 - val_loss: 1.6490 - val_mae: 0.9190\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.9413 - mae: 0.7055 - val_loss: 1.5835 - val_mae: 0.8970\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.5838 - mae: 0.5512 - val_loss: 1.5260 - val_mae: 0.8771\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.4556 - mae: 0.4804 - val_loss: 1.4773 - val_mae: 0.8690\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.3743 - mae: 0.4264 - val_loss: 1.4810 - val_mae: 0.8621\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.3358 - mae: 0.4043 - val_loss: 1.4873 - val_mae: 0.8595\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2753 - mae: 0.3656 - val_loss: 1.4639 - val_mae: 0.8574\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2018 - mae: 0.3228 - val_loss: 1.4285 - val_mae: 0.8355\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.2263 - mae: 0.3318 - val_loss: 1.3845 - val_mae: 0.8235\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1926 - mae: 0.3159 - val_loss: 1.4735 - val_mae: 0.8557\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1633 - mae: 0.2931 - val_loss: 1.3678 - val_mae: 0.8130\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1576 - mae: 0.2837 - val_loss: 1.4160 - val_mae: 0.8248\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1567 - mae: 0.2798 - val_loss: 1.4030 - val_mae: 0.8327\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1495 - mae: 0.2692 - val_loss: 1.3751 - val_mae: 0.8101\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1374 - mae: 0.2676 - val_loss: 1.3694 - val_mae: 0.8018\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.1202 - mae: 0.2464 - val_loss: 1.3451 - val_mae: 0.7966\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1283 - mae: 0.2480 - val_loss: 1.4331 - val_mae: 0.8368\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1239 - mae: 0.2440 - val_loss: 1.3918 - val_mae: 0.8191\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1166 - mae: 0.2340 - val_loss: 1.3581 - val_mae: 0.7941\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0960 - mae: 0.2169 - val_loss: 1.4142 - val_mae: 0.8307\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0882 - mae: 0.2095 - val_loss: 1.3470 - val_mae: 0.8014\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0806 - mae: 0.2009 - val_loss: 1.3410 - val_mae: 0.7925\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0852 - mae: 0.2072 - val_loss: 1.3492 - val_mae: 0.7940\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0785 - mae: 0.1978 - val_loss: 1.3380 - val_mae: 0.7864\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0794 - mae: 0.1960 - val_loss: 1.3250 - val_mae: 0.7839\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0753 - mae: 0.1879 - val_loss: 1.3361 - val_mae: 0.7790\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0672 - mae: 0.1807 - val_loss: 1.3573 - val_mae: 0.7937\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0700 - mae: 0.1851 - val_loss: 1.3198 - val_mae: 0.7831\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0747 - mae: 0.1869 - val_loss: 1.3251 - val_mae: 0.7839\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0672 - mae: 0.1731 - val_loss: 1.3226 - val_mae: 0.7872\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0506 - mae: 0.1580 - val_loss: 1.3336 - val_mae: 0.7871\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0549 - mae: 0.1665 - val_loss: 1.3139 - val_mae: 0.7800\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0637 - mae: 0.1655 - val_loss: 1.3180 - val_mae: 0.7783\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0589 - mae: 0.1604 - val_loss: 1.3213 - val_mae: 0.7806\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0550 - mae: 0.1599 - val_loss: 1.3252 - val_mae: 0.7818\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0514 - mae: 0.1550 - val_loss: 1.3193 - val_mae: 0.7782\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0529 - mae: 0.1548 - val_loss: 1.3530 - val_mae: 0.7993\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0527 - mae: 0.1531 - val_loss: 1.3272 - val_mae: 0.7861\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0469 - mae: 0.1472 - val_loss: 1.2972 - val_mae: 0.7704\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0455 - mae: 0.1439 - val_loss: 1.3184 - val_mae: 0.7820\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0415 - mae: 0.1413 - val_loss: 1.3120 - val_mae: 0.7715\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0407 - mae: 0.1405 - val_loss: 1.3397 - val_mae: 0.7854\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0458 - mae: 0.1442 - val_loss: 1.3392 - val_mae: 0.7960\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0429 - mae: 0.1437 - val_loss: 1.3261 - val_mae: 0.7820\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0391 - mae: 0.1367 - val_loss: 1.3211 - val_mae: 0.7740\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0373 - mae: 0.1302 - val_loss: 1.3034 - val_mae: 0.7749\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0424 - mae: 0.1346 - val_loss: 1.3403 - val_mae: 0.7850\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0440 - mae: 0.1353 - val_loss: 1.3113 - val_mae: 0.7752\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0353 - mae: 0.1270 - val_loss: 1.3245 - val_mae: 0.7783\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0367 - mae: 0.1296 - val_loss: 1.3451 - val_mae: 0.7798\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0375 - mae: 0.1305 - val_loss: 1.3137 - val_mae: 0.7718\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0338 - mae: 0.1244 - val_loss: 1.3059 - val_mae: 0.7689\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0365 - mae: 0.1252 - val_loss: 1.2996 - val_mae: 0.7698\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0321 - mae: 0.1193 - val_loss: 1.2985 - val_mae: 0.7680\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0346 - mae: 0.1190 - val_loss: 1.3100 - val_mae: 0.7659\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0311 - mae: 0.1196 - val_loss: 1.3043 - val_mae: 0.7702\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0325 - mae: 0.1196 - val_loss: 1.3194 - val_mae: 0.7772\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0326 - mae: 0.1200 - val_loss: 1.3068 - val_mae: 0.7696\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0310 - mae: 0.1152 - val_loss: 1.3056 - val_mae: 0.7729\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0343 - mae: 0.1142 - val_loss: 1.3086 - val_mae: 0.7683\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0268 - mae: 0.1098 - val_loss: 1.3057 - val_mae: 0.7710\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0287 - mae: 0.1123 - val_loss: 1.3200 - val_mae: 0.7754\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0300 - mae: 0.1158 - val_loss: 1.3079 - val_mae: 0.7717\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0330 - mae: 0.1123 - val_loss: 1.3108 - val_mae: 0.7745\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0293 - mae: 0.1086 - val_loss: 1.3038 - val_mae: 0.7710\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0290 - mae: 0.1113 - val_loss: 1.3070 - val_mae: 0.7679\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0263 - mae: 0.1073 - val_loss: 1.3118 - val_mae: 0.7708\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0250 - mae: 0.1045 - val_loss: 1.3132 - val_mae: 0.7745\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0315 - mae: 0.1120 - val_loss: 1.2951 - val_mae: 0.7629\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0291 - mae: 0.1084 - val_loss: 1.3119 - val_mae: 0.7694\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0241 - mae: 0.1016 - val_loss: 1.2907 - val_mae: 0.7637\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0229 - mae: 0.1008 - val_loss: 1.3048 - val_mae: 0.7670\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0261 - mae: 0.1023 - val_loss: 1.3059 - val_mae: 0.7712\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0276 - mae: 0.1047 - val_loss: 1.3084 - val_mae: 0.7638\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0255 - mae: 0.1077 - val_loss: 1.3071 - val_mae: 0.7743\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0223 - mae: 0.1017 - val_loss: 1.3140 - val_mae: 0.7705\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0258 - mae: 0.0990 - val_loss: 1.3229 - val_mae: 0.7753\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0206 - mae: 0.0965 - val_loss: 1.3030 - val_mae: 0.7682\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0250 - mae: 0.1004 - val_loss: 1.2999 - val_mae: 0.7681\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0228 - mae: 0.1020 - val_loss: 1.3142 - val_mae: 0.7691\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0237 - mae: 0.0967 - val_loss: 1.3149 - val_mae: 0.7681\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0199 - mae: 0.0943 - val_loss: 1.3263 - val_mae: 0.7733\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0204 - mae: 0.0948 - val_loss: 1.3075 - val_mae: 0.7665\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0226 - mae: 0.0975 - val_loss: 1.3113 - val_mae: 0.7673\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0243 - mae: 0.0970 - val_loss: 1.3032 - val_mae: 0.7658\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0265 - mae: 0.0981 - val_loss: 1.2939 - val_mae: 0.7623\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0202 - mae: 0.0932 - val_loss: 1.2996 - val_mae: 0.7640\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0207 - mae: 0.0948 - val_loss: 1.3083 - val_mae: 0.7656\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0200 - mae: 0.0925 - val_loss: 1.3061 - val_mae: 0.7678\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0197 - mae: 0.0896 - val_loss: 1.3023 - val_mae: 0.7632\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0195 - mae: 0.0872 - val_loss: 1.2966 - val_mae: 0.7644\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0190 - mae: 0.0874 - val_loss: 1.3000 - val_mae: 0.7645\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0198 - mae: 0.0878 - val_loss: 1.2985 - val_mae: 0.7671\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0180 - mae: 0.0873 - val_loss: 1.3105 - val_mae: 0.7693\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0194 - mae: 0.0891 - val_loss: 1.3004 - val_mae: 0.7627\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0205 - mae: 0.0909 - val_loss: 1.3019 - val_mae: 0.7633\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0183 - mae: 0.0881 - val_loss: 1.2963 - val_mae: 0.7628\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0202 - mae: 0.0870 - val_loss: 1.3000 - val_mae: 0.7690\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0184 - mae: 0.0862 - val_loss: 1.3026 - val_mae: 0.7673\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0196 - mae: 0.0852 - val_loss: 1.2965 - val_mae: 0.7628\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0175 - mae: 0.0841 - val_loss: 1.3037 - val_mae: 0.7644\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0172 - mae: 0.0852 - val_loss: 1.2988 - val_mae: 0.7630\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0190 - mae: 0.0859 - val_loss: 1.3089 - val_mae: 0.7738\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0180 - mae: 0.0852 - val_loss: 1.2976 - val_mae: 0.7626\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0172 - mae: 0.0846 - val_loss: 1.2984 - val_mae: 0.7615\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0826 - val_loss: 1.3001 - val_mae: 0.7635\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0177 - mae: 0.0850 - val_loss: 1.2940 - val_mae: 0.7625\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0149 - mae: 0.0800 - val_loss: 1.3025 - val_mae: 0.7655\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0179 - mae: 0.0844 - val_loss: 1.2876 - val_mae: 0.7587\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0168 - mae: 0.0844 - val_loss: 1.3162 - val_mae: 0.7719\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0771 - val_loss: 1.2962 - val_mae: 0.7642\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0156 - mae: 0.0765 - val_loss: 1.2990 - val_mae: 0.7627\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0761 - val_loss: 1.3050 - val_mae: 0.7647\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0804 - val_loss: 1.3051 - val_mae: 0.7656\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0166 - mae: 0.0813 - val_loss: 1.3118 - val_mae: 0.7695\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.0783 - val_loss: 1.2974 - val_mae: 0.7631\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0159 - mae: 0.0772 - val_loss: 1.2928 - val_mae: 0.7625\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0156 - mae: 0.0792 - val_loss: 1.3060 - val_mae: 0.7667\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0758 - val_loss: 1.2940 - val_mae: 0.7626\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0162 - mae: 0.0785 - val_loss: 1.2963 - val_mae: 0.7652\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0789 - val_loss: 1.3031 - val_mae: 0.7649\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0754 - val_loss: 1.2889 - val_mae: 0.7576\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.0748 - val_loss: 1.2958 - val_mae: 0.7610\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0133 - mae: 0.0745 - val_loss: 1.2943 - val_mae: 0.7602\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0138 - mae: 0.0761 - val_loss: 1.2869 - val_mae: 0.7608\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0139 - mae: 0.0759 - val_loss: 1.2911 - val_mae: 0.7596\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0150 - mae: 0.0741 - val_loss: 1.2830 - val_mae: 0.7574\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0124 - mae: 0.0734 - val_loss: 1.2978 - val_mae: 0.7642\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0158 - mae: 0.0775 - val_loss: 1.2906 - val_mae: 0.7614\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0700 - val_loss: 1.2940 - val_mae: 0.7631\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0731 - val_loss: 1.2916 - val_mae: 0.7612\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0126 - mae: 0.0702 - val_loss: 1.3063 - val_mae: 0.7708\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0125 - mae: 0.0720 - val_loss: 1.2923 - val_mae: 0.7601\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0718 - val_loss: 1.2972 - val_mae: 0.7622\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0119 - mae: 0.0701 - val_loss: 1.2888 - val_mae: 0.7605\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0714 - val_loss: 1.2838 - val_mae: 0.7553\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0125 - mae: 0.0700 - val_loss: 1.2925 - val_mae: 0.7592\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0159 - mae: 0.0724 - val_loss: 1.2792 - val_mae: 0.7566\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0159 - mae: 0.0720 - val_loss: 1.2922 - val_mae: 0.7599\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0117 - mae: 0.0675 - val_loss: 1.2840 - val_mae: 0.7592\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0161 - mae: 0.0709 - val_loss: 1.2923 - val_mae: 0.7607\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0116 - mae: 0.0695 - val_loss: 1.2890 - val_mae: 0.7596\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0126 - mae: 0.0706 - val_loss: 1.2807 - val_mae: 0.7596\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0162 - mae: 0.0738 - val_loss: 1.2936 - val_mae: 0.7626\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0681 - val_loss: 1.2883 - val_mae: 0.7574\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0112 - mae: 0.0667 - val_loss: 1.2814 - val_mae: 0.7592\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0114 - mae: 0.0689 - val_loss: 1.2988 - val_mae: 0.7678\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0717 - val_loss: 1.2896 - val_mae: 0.7586\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0686 - val_loss: 1.2918 - val_mae: 0.7608\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0113 - mae: 0.0677 - val_loss: 1.2879 - val_mae: 0.7597\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0116 - mae: 0.0677 - val_loss: 1.2870 - val_mae: 0.7602\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0120 - mae: 0.0656 - val_loss: 1.2813 - val_mae: 0.7566\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0099 - mae: 0.0667 - val_loss: 1.2812 - val_mae: 0.7595\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0113 - mae: 0.0675 - val_loss: 1.2848 - val_mae: 0.7580\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0120 - mae: 0.0692 - val_loss: 1.2918 - val_mae: 0.7650\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0141 - mae: 0.0678 - val_loss: 1.2783 - val_mae: 0.7587\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0125 - mae: 0.0686 - val_loss: 1.2941 - val_mae: 0.7642\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0642 - val_loss: 1.2878 - val_mae: 0.7575\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0103 - mae: 0.0654 - val_loss: 1.2947 - val_mae: 0.7637\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0646 - val_loss: 1.2884 - val_mae: 0.7581\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0123 - mae: 0.0623 - val_loss: 1.2837 - val_mae: 0.7556\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0132 - mae: 0.0642 - val_loss: 1.2841 - val_mae: 0.7620\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0109 - mae: 0.0672 - val_loss: 1.2823 - val_mae: 0.7556\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0129 - mae: 0.0667 - val_loss: 1.2889 - val_mae: 0.7591\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0657 - val_loss: 1.2796 - val_mae: 0.7563\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0122 - mae: 0.0626 - val_loss: 1.2818 - val_mae: 0.7556\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0082 - mae: 0.0602 - val_loss: 1.2868 - val_mae: 0.7590\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0660 - val_loss: 1.2820 - val_mae: 0.7593\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0117 - mae: 0.0676 - val_loss: 1.2911 - val_mae: 0.7615\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0110 - mae: 0.0649 - val_loss: 1.2870 - val_mae: 0.7630\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0107 - mae: 0.0628 - val_loss: 1.2836 - val_mae: 0.7580\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0099 - mae: 0.0635 - val_loss: 1.2841 - val_mae: 0.7581\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0116 - mae: 0.0625 - val_loss: 1.2867 - val_mae: 0.7573\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0106 - mae: 0.0638 - val_loss: 1.2775 - val_mae: 0.7552\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0109 - mae: 0.0628 - val_loss: 1.2921 - val_mae: 0.7605\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0093 - mae: 0.0607 - val_loss: 1.2848 - val_mae: 0.7594\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0102 - mae: 0.0641 - val_loss: 1.2889 - val_mae: 0.7610\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0106 - mae: 0.0625 - val_loss: 1.2873 - val_mae: 0.7573\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0105 - mae: 0.0636 - val_loss: 1.2855 - val_mae: 0.7576\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0604 - val_loss: 1.2888 - val_mae: 0.7580\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0088 - mae: 0.0592 - val_loss: 1.2826 - val_mae: 0.7574\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0087 - mae: 0.0595 - val_loss: 1.2776 - val_mae: 0.7527\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0106 - mae: 0.0632 - val_loss: 1.2873 - val_mae: 0.7576\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0628 - val_loss: 1.2778 - val_mae: 0.7545\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0104 - mae: 0.0614 - val_loss: 1.2899 - val_mae: 0.7588\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0094 - mae: 0.0619 - val_loss: 1.2874 - val_mae: 0.7575\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0106 - mae: 0.0628 - val_loss: 1.2892 - val_mae: 0.7590\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0090 - mae: 0.0597 - val_loss: 1.2836 - val_mae: 0.7552\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0089 - mae: 0.0561 - val_loss: 1.2896 - val_mae: 0.7593\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0095 - mae: 0.0571 - val_loss: 1.2859 - val_mae: 0.7570\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0085 - mae: 0.0578 - val_loss: 1.2894 - val_mae: 0.7603\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0581 - val_loss: 1.2873 - val_mae: 0.7571\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0113 - mae: 0.0607 - val_loss: 1.2951 - val_mae: 0.7577\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0088 - mae: 0.0593 - val_loss: 1.2880 - val_mae: 0.7585\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0088 - mae: 0.0586 - val_loss: 1.2863 - val_mae: 0.7583\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0111 - mae: 0.0631 - val_loss: 1.2862 - val_mae: 0.7560\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0114 - mae: 0.0613 - val_loss: 1.2938 - val_mae: 0.7613\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0102 - mae: 0.0608 - val_loss: 1.2852 - val_mae: 0.7565\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0098 - mae: 0.0555 - val_loss: 1.2836 - val_mae: 0.7564\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0086 - mae: 0.0569 - val_loss: 1.2802 - val_mae: 0.7543\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3679 - mae: 0.7784\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - loss: 5.6903 - mae: 1.6431 - val_loss: 1.5886 - val_mae: 0.8930\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.9046 - mae: 0.6840 - val_loss: 1.4361 - val_mae: 0.8342\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.5860 - mae: 0.5470 - val_loss: 1.4146 - val_mae: 0.8201\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.4529 - mae: 0.4788 - val_loss: 1.5239 - val_mae: 0.8570\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.3907 - mae: 0.4467 - val_loss: 1.4581 - val_mae: 0.8570\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.3272 - mae: 0.4097 - val_loss: 1.4384 - val_mae: 0.8353\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.2923 - mae: 0.3829 - val_loss: 1.4235 - val_mae: 0.8118\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2512 - mae: 0.3508 - val_loss: 1.4374 - val_mae: 0.8149\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.2178 - mae: 0.3311 - val_loss: 1.3932 - val_mae: 0.8076\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1966 - mae: 0.3137 - val_loss: 1.3933 - val_mae: 0.7937\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1903 - mae: 0.3069 - val_loss: 1.3510 - val_mae: 0.7771\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1517 - mae: 0.2782 - val_loss: 1.3922 - val_mae: 0.7877\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1642 - mae: 0.2836 - val_loss: 1.3567 - val_mae: 0.7903\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1452 - mae: 0.2664 - val_loss: 1.3734 - val_mae: 0.7838\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1259 - mae: 0.2497 - val_loss: 1.3243 - val_mae: 0.7630\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1129 - mae: 0.2402 - val_loss: 1.3965 - val_mae: 0.7906\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1191 - mae: 0.2425 - val_loss: 1.3513 - val_mae: 0.7868\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1107 - mae: 0.2330 - val_loss: 1.3359 - val_mae: 0.7644\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1041 - mae: 0.2233 - val_loss: 1.3211 - val_mae: 0.7584\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1007 - mae: 0.2177 - val_loss: 1.3319 - val_mae: 0.7731\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0923 - mae: 0.2094 - val_loss: 1.3439 - val_mae: 0.7674\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0879 - mae: 0.2040 - val_loss: 1.3199 - val_mae: 0.7576\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0829 - mae: 0.2020 - val_loss: 1.3435 - val_mae: 0.7719\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0831 - mae: 0.1995 - val_loss: 1.3225 - val_mae: 0.7713\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0763 - mae: 0.1909 - val_loss: 1.3579 - val_mae: 0.7677\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0775 - mae: 0.1909 - val_loss: 1.3255 - val_mae: 0.7704\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0694 - mae: 0.1833 - val_loss: 1.3283 - val_mae: 0.7560\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0747 - mae: 0.1814 - val_loss: 1.3400 - val_mae: 0.7654\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0762 - mae: 0.1854 - val_loss: 1.3358 - val_mae: 0.7628\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0742 - mae: 0.1808 - val_loss: 1.3204 - val_mae: 0.7564\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0659 - mae: 0.1716 - val_loss: 1.3270 - val_mae: 0.7600\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0556 - mae: 0.1582 - val_loss: 1.3199 - val_mae: 0.7545\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0601 - mae: 0.1608 - val_loss: 1.3128 - val_mae: 0.7521\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0598 - mae: 0.1647 - val_loss: 1.3257 - val_mae: 0.7581\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0595 - mae: 0.1635 - val_loss: 1.3205 - val_mae: 0.7586\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0596 - mae: 0.1610 - val_loss: 1.2909 - val_mae: 0.7512\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0548 - mae: 0.1569 - val_loss: 1.3144 - val_mae: 0.7570\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0537 - mae: 0.1523 - val_loss: 1.3025 - val_mae: 0.7502\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0510 - mae: 0.1481 - val_loss: 1.2814 - val_mae: 0.7408\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0468 - mae: 0.1449 - val_loss: 1.2985 - val_mae: 0.7461\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0481 - mae: 0.1447 - val_loss: 1.3094 - val_mae: 0.7540\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0475 - mae: 0.1467 - val_loss: 1.3100 - val_mae: 0.7483\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0455 - mae: 0.1450 - val_loss: 1.2798 - val_mae: 0.7431\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0541 - mae: 0.1465 - val_loss: 1.3160 - val_mae: 0.7509\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0446 - mae: 0.1372 - val_loss: 1.3191 - val_mae: 0.7628\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0427 - mae: 0.1366 - val_loss: 1.3072 - val_mae: 0.7519\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0396 - mae: 0.1312 - val_loss: 1.3098 - val_mae: 0.7493\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0442 - mae: 0.1328 - val_loss: 1.3027 - val_mae: 0.7453\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0436 - mae: 0.1301 - val_loss: 1.2936 - val_mae: 0.7482\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0409 - mae: 0.1335 - val_loss: 1.3174 - val_mae: 0.7515\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0424 - mae: 0.1303 - val_loss: 1.3097 - val_mae: 0.7558\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0392 - mae: 0.1284 - val_loss: 1.3119 - val_mae: 0.7459\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0402 - mae: 0.1268 - val_loss: 1.2911 - val_mae: 0.7480\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0373 - mae: 0.1247 - val_loss: 1.3124 - val_mae: 0.7524\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0385 - mae: 0.1282 - val_loss: 1.2970 - val_mae: 0.7463\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0382 - mae: 0.1223 - val_loss: 1.2882 - val_mae: 0.7431\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0327 - mae: 0.1182 - val_loss: 1.3131 - val_mae: 0.7516\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0390 - mae: 0.1246 - val_loss: 1.3018 - val_mae: 0.7514\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0377 - mae: 0.1205 - val_loss: 1.3189 - val_mae: 0.7536\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0325 - mae: 0.1170 - val_loss: 1.3074 - val_mae: 0.7460\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0336 - mae: 0.1150 - val_loss: 1.3148 - val_mae: 0.7511\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0332 - mae: 0.1185 - val_loss: 1.3057 - val_mae: 0.7420\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0358 - mae: 0.1201 - val_loss: 1.3017 - val_mae: 0.7446\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0385 - mae: 0.1128 - val_loss: 1.3006 - val_mae: 0.7448\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0347 - mae: 0.1146 - val_loss: 1.2984 - val_mae: 0.7431\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0321 - mae: 0.1132 - val_loss: 1.2947 - val_mae: 0.7518\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0302 - mae: 0.1113 - val_loss: 1.3061 - val_mae: 0.7501\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0300 - mae: 0.1106 - val_loss: 1.2930 - val_mae: 0.7459\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0329 - mae: 0.1099 - val_loss: 1.2887 - val_mae: 0.7430\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0353 - mae: 0.1137 - val_loss: 1.2843 - val_mae: 0.7491\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0289 - mae: 0.1068 - val_loss: 1.3117 - val_mae: 0.7437\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0284 - mae: 0.1063 - val_loss: 1.3018 - val_mae: 0.7540\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0295 - mae: 0.1101 - val_loss: 1.3203 - val_mae: 0.7514\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0328 - mae: 0.1121 - val_loss: 1.3012 - val_mae: 0.7472\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0296 - mae: 0.1071 - val_loss: 1.3048 - val_mae: 0.7444\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0268 - mae: 0.1011 - val_loss: 1.3053 - val_mae: 0.7433\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0263 - mae: 0.1025 - val_loss: 1.2973 - val_mae: 0.7443\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0262 - mae: 0.1033 - val_loss: 1.2958 - val_mae: 0.7389\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0268 - mae: 0.1041 - val_loss: 1.2991 - val_mae: 0.7485\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0270 - mae: 0.1019 - val_loss: 1.2904 - val_mae: 0.7413\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0257 - mae: 0.0997 - val_loss: 1.2911 - val_mae: 0.7447\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0297 - mae: 0.1036 - val_loss: 1.2892 - val_mae: 0.7432\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0251 - mae: 0.1006 - val_loss: 1.3094 - val_mae: 0.7507\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0269 - mae: 0.1005 - val_loss: 1.2966 - val_mae: 0.7452\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0307 - mae: 0.1020 - val_loss: 1.3026 - val_mae: 0.7445\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0229 - mae: 0.0974 - val_loss: 1.3027 - val_mae: 0.7445\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0242 - mae: 0.0955 - val_loss: 1.3136 - val_mae: 0.7514\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0254 - mae: 0.0975 - val_loss: 1.3024 - val_mae: 0.7510\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0249 - mae: 0.0995 - val_loss: 1.2996 - val_mae: 0.7443\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0248 - mae: 0.0974 - val_loss: 1.3083 - val_mae: 0.7472\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0239 - mae: 0.0942 - val_loss: 1.3091 - val_mae: 0.7457\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0208 - mae: 0.0924 - val_loss: 1.2956 - val_mae: 0.7419\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0243 - mae: 0.0939 - val_loss: 1.2996 - val_mae: 0.7461\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0258 - mae: 0.0927 - val_loss: 1.3062 - val_mae: 0.7455\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0254 - mae: 0.0972 - val_loss: 1.3076 - val_mae: 0.7470\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0233 - mae: 0.0967 - val_loss: 1.2940 - val_mae: 0.7434\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0232 - mae: 0.0932 - val_loss: 1.2894 - val_mae: 0.7403\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0238 - mae: 0.0915 - val_loss: 1.2916 - val_mae: 0.7437\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0266 - mae: 0.0928 - val_loss: 1.2869 - val_mae: 0.7398\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0226 - mae: 0.0928 - val_loss: 1.3054 - val_mae: 0.7462\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0237 - mae: 0.0927 - val_loss: 1.2997 - val_mae: 0.7422\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0245 - mae: 0.0895 - val_loss: 1.2902 - val_mae: 0.7410\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0246 - mae: 0.0897 - val_loss: 1.2866 - val_mae: 0.7383\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0227 - mae: 0.0896 - val_loss: 1.2967 - val_mae: 0.7440\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0225 - mae: 0.0877 - val_loss: 1.2865 - val_mae: 0.7436\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0238 - mae: 0.0878 - val_loss: 1.2909 - val_mae: 0.7399\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0187 - mae: 0.0840 - val_loss: 1.2867 - val_mae: 0.7420\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0227 - mae: 0.0888 - val_loss: 1.2918 - val_mae: 0.7396\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0210 - mae: 0.0861 - val_loss: 1.3024 - val_mae: 0.7431\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.0828 - val_loss: 1.2921 - val_mae: 0.7403\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0254 - mae: 0.0892 - val_loss: 1.2858 - val_mae: 0.7395\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0202 - mae: 0.0834 - val_loss: 1.2876 - val_mae: 0.7426\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0215 - mae: 0.0824 - val_loss: 1.2973 - val_mae: 0.7434\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0223 - mae: 0.0866 - val_loss: 1.2806 - val_mae: 0.7377\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0209 - mae: 0.0848 - val_loss: 1.2931 - val_mae: 0.7371\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0230 - mae: 0.0866 - val_loss: 1.2857 - val_mae: 0.7380\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0188 - mae: 0.0836 - val_loss: 1.2956 - val_mae: 0.7442\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0228 - mae: 0.0820 - val_loss: 1.2854 - val_mae: 0.7402\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0176 - mae: 0.0784 - val_loss: 1.2911 - val_mae: 0.7398\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0263 - mae: 0.0875 - val_loss: 1.3043 - val_mae: 0.7416\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0202 - mae: 0.0839 - val_loss: 1.2888 - val_mae: 0.7429\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0176 - mae: 0.0787 - val_loss: 1.3020 - val_mae: 0.7438\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0196 - mae: 0.0817 - val_loss: 1.2840 - val_mae: 0.7367\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0223 - mae: 0.0844 - val_loss: 1.2970 - val_mae: 0.7409\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0194 - mae: 0.0824 - val_loss: 1.3023 - val_mae: 0.7449\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0198 - mae: 0.0812 - val_loss: 1.2900 - val_mae: 0.7404\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0181 - mae: 0.0792 - val_loss: 1.2805 - val_mae: 0.7399\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0177 - mae: 0.0796 - val_loss: 1.3048 - val_mae: 0.7455\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0204 - mae: 0.0798 - val_loss: 1.2785 - val_mae: 0.7389\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.0804 - val_loss: 1.2963 - val_mae: 0.7397\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0198 - mae: 0.0845 - val_loss: 1.3043 - val_mae: 0.7423\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0158 - mae: 0.0744 - val_loss: 1.2967 - val_mae: 0.7408\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0174 - mae: 0.0770 - val_loss: 1.2801 - val_mae: 0.7371\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0188 - mae: 0.0744 - val_loss: 1.3002 - val_mae: 0.7426\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0732 - val_loss: 1.2934 - val_mae: 0.7408\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0168 - mae: 0.0805 - val_loss: 1.2971 - val_mae: 0.7430\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.0777 - val_loss: 1.2747 - val_mae: 0.7354\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0184 - mae: 0.0763 - val_loss: 1.2999 - val_mae: 0.7429\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0211 - mae: 0.0763 - val_loss: 1.3005 - val_mae: 0.7440\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0217 - mae: 0.0802 - val_loss: 1.2886 - val_mae: 0.7378\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0174 - mae: 0.0751 - val_loss: 1.2860 - val_mae: 0.7382\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0198 - mae: 0.0741 - val_loss: 1.2949 - val_mae: 0.7404\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0244 - mae: 0.0778 - val_loss: 1.2922 - val_mae: 0.7428\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0192 - mae: 0.0757 - val_loss: 1.2927 - val_mae: 0.7416\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0162 - mae: 0.0758 - val_loss: 1.2986 - val_mae: 0.7396\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0188 - mae: 0.0780 - val_loss: 1.2982 - val_mae: 0.7395\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0169 - mae: 0.0797 - val_loss: 1.2915 - val_mae: 0.7369\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0179 - mae: 0.0750 - val_loss: 1.2901 - val_mae: 0.7397\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0152 - mae: 0.0706 - val_loss: 1.2814 - val_mae: 0.7392\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0226 - mae: 0.0766 - val_loss: 1.2966 - val_mae: 0.7405\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0162 - mae: 0.0705 - val_loss: 1.2771 - val_mae: 0.7363\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0226 - mae: 0.0763 - val_loss: 1.2968 - val_mae: 0.7392\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0170 - mae: 0.0705 - val_loss: 1.2762 - val_mae: 0.7351\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0211 - mae: 0.0717 - val_loss: 1.2926 - val_mae: 0.7409\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0159 - mae: 0.0714 - val_loss: 1.2888 - val_mae: 0.7411\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0176 - mae: 0.0726 - val_loss: 1.2923 - val_mae: 0.7409\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0723 - val_loss: 1.2772 - val_mae: 0.7335\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0161 - mae: 0.0707 - val_loss: 1.2777 - val_mae: 0.7336\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0172 - mae: 0.0739 - val_loss: 1.2924 - val_mae: 0.7433\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0172 - mae: 0.0718 - val_loss: 1.2838 - val_mae: 0.7402\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0149 - mae: 0.0703 - val_loss: 1.2773 - val_mae: 0.7368\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0162 - mae: 0.0709 - val_loss: 1.2822 - val_mae: 0.7372\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0187 - mae: 0.0691 - val_loss: 1.2952 - val_mae: 0.7396\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0147 - mae: 0.0706 - val_loss: 1.2810 - val_mae: 0.7362\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0194 - mae: 0.0706 - val_loss: 1.2819 - val_mae: 0.7368\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0704 - val_loss: 1.2813 - val_mae: 0.7368\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0142 - mae: 0.0663 - val_loss: 1.2840 - val_mae: 0.7347\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0207 - mae: 0.0699 - val_loss: 1.2799 - val_mae: 0.7349\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0163 - mae: 0.0701 - val_loss: 1.2803 - val_mae: 0.7357\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0175 - mae: 0.0683 - val_loss: 1.2788 - val_mae: 0.7351\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0167 - mae: 0.0679 - val_loss: 1.2903 - val_mae: 0.7375\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0146 - mae: 0.0676 - val_loss: 1.2842 - val_mae: 0.7399\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0141 - mae: 0.0668 - val_loss: 1.2951 - val_mae: 0.7364\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0178 - mae: 0.0733 - val_loss: 1.2878 - val_mae: 0.7407\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0186 - mae: 0.0696 - val_loss: 1.2912 - val_mae: 0.7413\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0176 - mae: 0.0682 - val_loss: 1.2813 - val_mae: 0.7392\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0143 - mae: 0.0644 - val_loss: 1.3015 - val_mae: 0.7421\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0192 - mae: 0.0671 - val_loss: 1.2803 - val_mae: 0.7357\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0198 - mae: 0.0682 - val_loss: 1.2873 - val_mae: 0.7379\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0148 - mae: 0.0649 - val_loss: 1.2858 - val_mae: 0.7387\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0176 - mae: 0.0669 - val_loss: 1.2793 - val_mae: 0.7367\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0688 - val_loss: 1.2842 - val_mae: 0.7362\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0157 - mae: 0.0660 - val_loss: 1.2898 - val_mae: 0.7419\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0167 - mae: 0.0670 - val_loss: 1.2955 - val_mae: 0.7377\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0139 - mae: 0.0649 - val_loss: 1.2869 - val_mae: 0.7362\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0135 - mae: 0.0639 - val_loss: 1.2820 - val_mae: 0.7375\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0136 - mae: 0.0645 - val_loss: 1.2808 - val_mae: 0.7341\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0144 - mae: 0.0649 - val_loss: 1.2828 - val_mae: 0.7402\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0141 - mae: 0.0644 - val_loss: 1.2797 - val_mae: 0.7346\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0155 - mae: 0.0656 - val_loss: 1.2866 - val_mae: 0.7449\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0129 - mae: 0.0643 - val_loss: 1.2813 - val_mae: 0.7353\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0159 - mae: 0.0638 - val_loss: 1.2823 - val_mae: 0.7382\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0156 - mae: 0.0653 - val_loss: 1.2865 - val_mae: 0.7396\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0116 - mae: 0.0611 - val_loss: 1.2860 - val_mae: 0.7359\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0154 - mae: 0.0647 - val_loss: 1.3000 - val_mae: 0.7387\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0146 - mae: 0.0646 - val_loss: 1.2860 - val_mae: 0.7358\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0133 - mae: 0.0637 - val_loss: 1.2864 - val_mae: 0.7384\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0162 - mae: 0.0635 - val_loss: 1.2851 - val_mae: 0.7372\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0168 - mae: 0.0687 - val_loss: 1.2908 - val_mae: 0.7390\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0131 - mae: 0.0614 - val_loss: 1.2913 - val_mae: 0.7366\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2546 - mae: 0.7208\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - loss: 6.0005 - mae: 1.7199 - val_loss: 1.7252 - val_mae: 0.9507\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.8838 - mae: 0.6785 - val_loss: 1.5233 - val_mae: 0.8721\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.5926 - mae: 0.5436 - val_loss: 1.5325 - val_mae: 0.8654\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.4266 - mae: 0.4638 - val_loss: 1.4990 - val_mae: 0.8523\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.3466 - mae: 0.4177 - val_loss: 1.5330 - val_mae: 0.8877\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.3336 - mae: 0.3998 - val_loss: 1.5003 - val_mae: 0.8552\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.2845 - mae: 0.3697 - val_loss: 1.5318 - val_mae: 0.8660\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2419 - mae: 0.3479 - val_loss: 1.4983 - val_mae: 0.8644\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.2365 - mae: 0.3410 - val_loss: 1.4652 - val_mae: 0.8413\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1952 - mae: 0.3158 - val_loss: 1.4908 - val_mae: 0.8372\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1905 - mae: 0.3061 - val_loss: 1.4593 - val_mae: 0.8371\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1515 - mae: 0.2726 - val_loss: 1.4544 - val_mae: 0.8200\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1388 - mae: 0.2621 - val_loss: 1.4871 - val_mae: 0.8513\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1475 - mae: 0.2746 - val_loss: 1.4316 - val_mae: 0.8127\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1321 - mae: 0.2604 - val_loss: 1.3814 - val_mae: 0.8043\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1214 - mae: 0.2438 - val_loss: 1.4451 - val_mae: 0.8208\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1141 - mae: 0.2383 - val_loss: 1.4266 - val_mae: 0.8228\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1048 - mae: 0.2335 - val_loss: 1.3952 - val_mae: 0.8041\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1085 - mae: 0.2328 - val_loss: 1.3913 - val_mae: 0.8002\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1014 - mae: 0.2218 - val_loss: 1.3439 - val_mae: 0.7918\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0996 - mae: 0.2161 - val_loss: 1.3871 - val_mae: 0.8017\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0850 - mae: 0.2035 - val_loss: 1.4106 - val_mae: 0.8113\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0792 - mae: 0.1973 - val_loss: 1.3835 - val_mae: 0.7974\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0820 - mae: 0.1993 - val_loss: 1.3903 - val_mae: 0.7992\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0812 - mae: 0.1939 - val_loss: 1.3541 - val_mae: 0.7891\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0807 - mae: 0.1932 - val_loss: 1.3599 - val_mae: 0.7885\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0700 - mae: 0.1829 - val_loss: 1.3547 - val_mae: 0.7833\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0690 - mae: 0.1838 - val_loss: 1.3498 - val_mae: 0.7876\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0634 - mae: 0.1783 - val_loss: 1.3543 - val_mae: 0.7927\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0640 - mae: 0.1706 - val_loss: 1.3588 - val_mae: 0.7852\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0654 - mae: 0.1697 - val_loss: 1.3668 - val_mae: 0.7905\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0571 - mae: 0.1647 - val_loss: 1.3402 - val_mae: 0.7874\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0534 - mae: 0.1596 - val_loss: 1.3428 - val_mae: 0.7843\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0595 - mae: 0.1637 - val_loss: 1.3438 - val_mae: 0.7802\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0540 - mae: 0.1580 - val_loss: 1.3437 - val_mae: 0.7757\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0559 - mae: 0.1599 - val_loss: 1.3707 - val_mae: 0.7853\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0492 - mae: 0.1505 - val_loss: 1.3441 - val_mae: 0.7794\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0525 - mae: 0.1532 - val_loss: 1.3466 - val_mae: 0.7742\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0515 - mae: 0.1505 - val_loss: 1.3417 - val_mae: 0.7771\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0460 - mae: 0.1481 - val_loss: 1.3436 - val_mae: 0.7773\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0462 - mae: 0.1470 - val_loss: 1.3732 - val_mae: 0.7940\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0452 - mae: 0.1430 - val_loss: 1.3742 - val_mae: 0.7848\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0467 - mae: 0.1438 - val_loss: 1.3397 - val_mae: 0.7764\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0433 - mae: 0.1389 - val_loss: 1.3689 - val_mae: 0.7843\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0386 - mae: 0.1344 - val_loss: 1.3585 - val_mae: 0.7853\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0449 - mae: 0.1376 - val_loss: 1.3485 - val_mae: 0.7769\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0389 - mae: 0.1340 - val_loss: 1.3484 - val_mae: 0.7745\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0421 - mae: 0.1304 - val_loss: 1.3423 - val_mae: 0.7750\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0333 - mae: 0.1247 - val_loss: 1.3519 - val_mae: 0.7775\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0389 - mae: 0.1307 - val_loss: 1.3471 - val_mae: 0.7747\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0362 - mae: 0.1263 - val_loss: 1.3594 - val_mae: 0.7828\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0430 - mae: 0.1264 - val_loss: 1.3485 - val_mae: 0.7803\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0337 - mae: 0.1210 - val_loss: 1.3514 - val_mae: 0.7771\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0340 - mae: 0.1212 - val_loss: 1.3404 - val_mae: 0.7783\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0318 - mae: 0.1194 - val_loss: 1.3460 - val_mae: 0.7770\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0310 - mae: 0.1189 - val_loss: 1.3460 - val_mae: 0.7716\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0336 - mae: 0.1185 - val_loss: 1.3392 - val_mae: 0.7772\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0320 - mae: 0.1180 - val_loss: 1.3407 - val_mae: 0.7688\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0403 - mae: 0.1187 - val_loss: 1.3426 - val_mae: 0.7743\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0298 - mae: 0.1135 - val_loss: 1.3346 - val_mae: 0.7659\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0289 - mae: 0.1093 - val_loss: 1.3577 - val_mae: 0.7746\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0322 - mae: 0.1152 - val_loss: 1.3429 - val_mae: 0.7736\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0293 - mae: 0.1145 - val_loss: 1.3685 - val_mae: 0.7756\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0324 - mae: 0.1134 - val_loss: 1.3289 - val_mae: 0.7681\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0275 - mae: 0.1090 - val_loss: 1.3438 - val_mae: 0.7707\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0328 - mae: 0.1113 - val_loss: 1.3376 - val_mae: 0.7733\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0283 - mae: 0.1074 - val_loss: 1.3354 - val_mae: 0.7752\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0303 - mae: 0.1095 - val_loss: 1.3445 - val_mae: 0.7709\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0280 - mae: 0.1058 - val_loss: 1.3346 - val_mae: 0.7650\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0276 - mae: 0.1033 - val_loss: 1.3288 - val_mae: 0.7634\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0271 - mae: 0.1073 - val_loss: 1.3296 - val_mae: 0.7659\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0264 - mae: 0.1041 - val_loss: 1.3302 - val_mae: 0.7688\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0286 - mae: 0.1021 - val_loss: 1.3413 - val_mae: 0.7653\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0242 - mae: 0.0973 - val_loss: 1.3316 - val_mae: 0.7692\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0244 - mae: 0.1014 - val_loss: 1.3227 - val_mae: 0.7611\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0207 - mae: 0.0962 - val_loss: 1.3253 - val_mae: 0.7671\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0231 - mae: 0.0966 - val_loss: 1.3332 - val_mae: 0.7698\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - loss: 0.0231 - mae: 0.0965 - val_loss: 1.3300 - val_mae: 0.7638\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0252 - mae: 0.0990 - val_loss: 1.3324 - val_mae: 0.7643\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0284 - mae: 0.1020 - val_loss: 1.3420 - val_mae: 0.7682\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0231 - mae: 0.0962 - val_loss: 1.3324 - val_mae: 0.7690\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0269 - mae: 0.0985 - val_loss: 1.3499 - val_mae: 0.7760\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0198 - mae: 0.0932 - val_loss: 1.3432 - val_mae: 0.7653\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0231 - mae: 0.0981 - val_loss: 1.3424 - val_mae: 0.7685\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0249 - mae: 0.0972 - val_loss: 1.3301 - val_mae: 0.7624\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0242 - mae: 0.0959 - val_loss: 1.3360 - val_mae: 0.7689\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0188 - mae: 0.0902 - val_loss: 1.3244 - val_mae: 0.7600\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0206 - mae: 0.0902 - val_loss: 1.3329 - val_mae: 0.7654\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0225 - mae: 0.0940 - val_loss: 1.3364 - val_mae: 0.7662\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0187 - mae: 0.0891 - val_loss: 1.3302 - val_mae: 0.7665\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0201 - mae: 0.0906 - val_loss: 1.3323 - val_mae: 0.7652\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0217 - mae: 0.0897 - val_loss: 1.3445 - val_mae: 0.7663\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0205 - mae: 0.0886 - val_loss: 1.3265 - val_mae: 0.7648\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0222 - mae: 0.0896 - val_loss: 1.3364 - val_mae: 0.7645\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0207 - mae: 0.0911 - val_loss: 1.3284 - val_mae: 0.7636\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0214 - mae: 0.0883 - val_loss: 1.3343 - val_mae: 0.7672\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0192 - mae: 0.0882 - val_loss: 1.3295 - val_mae: 0.7696\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0188 - mae: 0.0888 - val_loss: 1.3214 - val_mae: 0.7627\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0258 - mae: 0.0871 - val_loss: 1.3280 - val_mae: 0.7642\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - loss: 0.0208 - mae: 0.0860 - val_loss: 1.3320 - val_mae: 0.7656\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0197 - mae: 0.0873 - val_loss: 1.3238 - val_mae: 0.7631\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0163 - mae: 0.0820 - val_loss: 1.3130 - val_mae: 0.7576\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0258 - mae: 0.0872 - val_loss: 1.3184 - val_mae: 0.7614\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0219 - mae: 0.0869 - val_loss: 1.3322 - val_mae: 0.7636\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0208 - mae: 0.0859 - val_loss: 1.3329 - val_mae: 0.7656\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0209 - mae: 0.0854 - val_loss: 1.3251 - val_mae: 0.7621\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0189 - mae: 0.0853 - val_loss: 1.3314 - val_mae: 0.7646\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0185 - mae: 0.0828 - val_loss: 1.3301 - val_mae: 0.7635\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0185 - mae: 0.0786 - val_loss: 1.3185 - val_mae: 0.7610\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0212 - mae: 0.0839 - val_loss: 1.3151 - val_mae: 0.7615\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0150 - mae: 0.0808 - val_loss: 1.3275 - val_mae: 0.7629\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0165 - mae: 0.0826 - val_loss: 1.3237 - val_mae: 0.7644\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0153 - mae: 0.0773 - val_loss: 1.3301 - val_mae: 0.7645\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0186 - mae: 0.0805 - val_loss: 1.3317 - val_mae: 0.7640\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0150 - mae: 0.0775 - val_loss: 1.3261 - val_mae: 0.7682\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0211 - mae: 0.0813 - val_loss: 1.3198 - val_mae: 0.7599\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0153 - mae: 0.0787 - val_loss: 1.3366 - val_mae: 0.7644\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0154 - mae: 0.0792 - val_loss: 1.3284 - val_mae: 0.7654\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0172 - mae: 0.0793 - val_loss: 1.3386 - val_mae: 0.7657\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0171 - mae: 0.0776 - val_loss: 1.3303 - val_mae: 0.7621\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0183 - mae: 0.0744 - val_loss: 1.3205 - val_mae: 0.7605\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0165 - mae: 0.0778 - val_loss: 1.3218 - val_mae: 0.7595\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0175 - mae: 0.0793 - val_loss: 1.3248 - val_mae: 0.7626\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0212 - mae: 0.0816 - val_loss: 1.3237 - val_mae: 0.7618\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0210 - mae: 0.0811 - val_loss: 1.3291 - val_mae: 0.7624\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0177 - mae: 0.0771 - val_loss: 1.3322 - val_mae: 0.7633\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0140 - mae: 0.0720 - val_loss: 1.3278 - val_mae: 0.7636\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0142 - mae: 0.0743 - val_loss: 1.3409 - val_mae: 0.7661\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0176 - mae: 0.0773 - val_loss: 1.3131 - val_mae: 0.7568\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0173 - mae: 0.0754 - val_loss: 1.3229 - val_mae: 0.7615\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0159 - mae: 0.0742 - val_loss: 1.3133 - val_mae: 0.7602\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0144 - mae: 0.0724 - val_loss: 1.3140 - val_mae: 0.7604\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0706 - val_loss: 1.3287 - val_mae: 0.7653\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0150 - mae: 0.0725 - val_loss: 1.3078 - val_mae: 0.7568\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0169 - mae: 0.0732 - val_loss: 1.3213 - val_mae: 0.7616\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0135 - mae: 0.0702 - val_loss: 1.3191 - val_mae: 0.7590\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0162 - mae: 0.0746 - val_loss: 1.3278 - val_mae: 0.7622\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0186 - mae: 0.0723 - val_loss: 1.3216 - val_mae: 0.7617\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0196 - mae: 0.0738 - val_loss: 1.3171 - val_mae: 0.7590\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0124 - mae: 0.0681 - val_loss: 1.3188 - val_mae: 0.7577\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0696 - val_loss: 1.3220 - val_mae: 0.7639\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0748 - val_loss: 1.3227 - val_mae: 0.7582\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0746 - val_loss: 1.3143 - val_mae: 0.7565\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0164 - mae: 0.0711 - val_loss: 1.3109 - val_mae: 0.7571\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0675 - val_loss: 1.3233 - val_mae: 0.7584\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0660 - val_loss: 1.3273 - val_mae: 0.7592\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0705 - val_loss: 1.3190 - val_mae: 0.7644\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0139 - mae: 0.0717 - val_loss: 1.3234 - val_mae: 0.7597\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0156 - mae: 0.0726 - val_loss: 1.3253 - val_mae: 0.7624\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0149 - mae: 0.0675 - val_loss: 1.3064 - val_mae: 0.7556\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0132 - mae: 0.0679 - val_loss: 1.3211 - val_mae: 0.7601\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0142 - mae: 0.0680 - val_loss: 1.3148 - val_mae: 0.7588\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0126 - mae: 0.0684 - val_loss: 1.3276 - val_mae: 0.7630\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0158 - mae: 0.0743 - val_loss: 1.3132 - val_mae: 0.7590\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0146 - mae: 0.0676 - val_loss: 1.3120 - val_mae: 0.7568\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0169 - mae: 0.0673 - val_loss: 1.3152 - val_mae: 0.7581\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0124 - mae: 0.0651 - val_loss: 1.3249 - val_mae: 0.7616\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0669 - val_loss: 1.3143 - val_mae: 0.7576\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0155 - mae: 0.0690 - val_loss: 1.3215 - val_mae: 0.7602\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0130 - mae: 0.0682 - val_loss: 1.3223 - val_mae: 0.7617\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0140 - mae: 0.0669 - val_loss: 1.3167 - val_mae: 0.7594\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0655 - val_loss: 1.3061 - val_mae: 0.7544\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0149 - mae: 0.0657 - val_loss: 1.3243 - val_mae: 0.7586\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0158 - mae: 0.0664 - val_loss: 1.3101 - val_mae: 0.7568\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0649 - val_loss: 1.3274 - val_mae: 0.7601\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0656 - val_loss: 1.3118 - val_mae: 0.7582\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0114 - mae: 0.0656 - val_loss: 1.3116 - val_mae: 0.7587\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0658 - val_loss: 1.3308 - val_mae: 0.7620\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0660 - val_loss: 1.3077 - val_mae: 0.7566\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0112 - mae: 0.0647 - val_loss: 1.3098 - val_mae: 0.7548\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0129 - mae: 0.0668 - val_loss: 1.3028 - val_mae: 0.7529\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0670 - val_loss: 1.3052 - val_mae: 0.7565\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0139 - mae: 0.0656 - val_loss: 1.3038 - val_mae: 0.7561\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0636 - val_loss: 1.3111 - val_mae: 0.7586\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0132 - mae: 0.0638 - val_loss: 1.3058 - val_mae: 0.7542\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0107 - mae: 0.0609 - val_loss: 1.3163 - val_mae: 0.7570\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0127 - mae: 0.0642 - val_loss: 1.3089 - val_mae: 0.7561\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0633 - val_loss: 1.3081 - val_mae: 0.7575\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0115 - mae: 0.0625 - val_loss: 1.3045 - val_mae: 0.7563\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0147 - mae: 0.0636 - val_loss: 1.3083 - val_mae: 0.7553\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0120 - mae: 0.0617 - val_loss: 1.3075 - val_mae: 0.7566\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0130 - mae: 0.0634 - val_loss: 1.3042 - val_mae: 0.7555\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0103 - mae: 0.0623 - val_loss: 1.3013 - val_mae: 0.7564\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0126 - mae: 0.0668 - val_loss: 1.3075 - val_mae: 0.7545\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0156 - mae: 0.0659 - val_loss: 1.3012 - val_mae: 0.7548\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0172 - mae: 0.0649 - val_loss: 1.3083 - val_mae: 0.7589\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0616 - val_loss: 1.3018 - val_mae: 0.7526\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0602 - val_loss: 1.3133 - val_mae: 0.7569\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0119 - mae: 0.0636 - val_loss: 1.2954 - val_mae: 0.7506\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0627 - val_loss: 1.3142 - val_mae: 0.7598\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0624 - val_loss: 1.3001 - val_mae: 0.7540\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0091 - mae: 0.0568 - val_loss: 1.3155 - val_mae: 0.7584\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0098 - mae: 0.0598 - val_loss: 1.2987 - val_mae: 0.7527\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0110 - mae: 0.0621 - val_loss: 1.3002 - val_mae: 0.7552\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0222 - mae: 0.0648 - val_loss: 1.3084 - val_mae: 0.7540\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0112 - mae: 0.0605 - val_loss: 1.2911 - val_mae: 0.7527\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0204 - mae: 0.0612 - val_loss: 1.3085 - val_mae: 0.7555\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0590 - val_loss: 1.2974 - val_mae: 0.7520\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0093 - mae: 0.0592 - val_loss: 1.2973 - val_mae: 0.7544\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0144 - mae: 0.0581 - val_loss: 1.3010 - val_mae: 0.7520\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3163 - mae: 0.7502\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - loss: 5.6656 - mae: 1.6863 - val_loss: 1.7200 - val_mae: 0.9371\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.9023 - mae: 0.6847 - val_loss: 1.5533 - val_mae: 0.8844\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.5284 - mae: 0.5138 - val_loss: 1.6078 - val_mae: 0.8950\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.4393 - mae: 0.4608 - val_loss: 1.5479 - val_mae: 0.8896\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.3468 - mae: 0.4176 - val_loss: 1.5438 - val_mae: 0.8775\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.2985 - mae: 0.3864 - val_loss: 1.4911 - val_mae: 0.8588\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2609 - mae: 0.3611 - val_loss: 1.5041 - val_mae: 0.8651\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2512 - mae: 0.3475 - val_loss: 1.5455 - val_mae: 0.8785\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2246 - mae: 0.3306 - val_loss: 1.4750 - val_mae: 0.8496\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1896 - mae: 0.3028 - val_loss: 1.5743 - val_mae: 0.8943\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1741 - mae: 0.2968 - val_loss: 1.4765 - val_mae: 0.8453\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1822 - mae: 0.2962 - val_loss: 1.4660 - val_mae: 0.8398\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1578 - mae: 0.2817 - val_loss: 1.4237 - val_mae: 0.8279\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1393 - mae: 0.2645 - val_loss: 1.4186 - val_mae: 0.8184\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1331 - mae: 0.2555 - val_loss: 1.4263 - val_mae: 0.8255\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1239 - mae: 0.2469 - val_loss: 1.4141 - val_mae: 0.8190\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.1079 - mae: 0.2322 - val_loss: 1.3854 - val_mae: 0.8062\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1128 - mae: 0.2271 - val_loss: 1.4043 - val_mae: 0.8092\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1132 - mae: 0.2261 - val_loss: 1.4036 - val_mae: 0.8105\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0919 - mae: 0.2101 - val_loss: 1.4325 - val_mae: 0.8223\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0889 - mae: 0.2064 - val_loss: 1.3855 - val_mae: 0.8083\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0853 - mae: 0.2018 - val_loss: 1.4065 - val_mae: 0.8098\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0843 - mae: 0.2012 - val_loss: 1.3966 - val_mae: 0.8053\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0818 - mae: 0.1986 - val_loss: 1.3695 - val_mae: 0.7942\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0801 - mae: 0.1916 - val_loss: 1.3787 - val_mae: 0.7966\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0697 - mae: 0.1801 - val_loss: 1.3564 - val_mae: 0.7894\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0630 - mae: 0.1677 - val_loss: 1.3793 - val_mae: 0.7989\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0652 - mae: 0.1752 - val_loss: 1.3549 - val_mae: 0.7913\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0678 - mae: 0.1752 - val_loss: 1.3654 - val_mae: 0.7903\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0632 - mae: 0.1754 - val_loss: 1.3530 - val_mae: 0.7902\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0577 - mae: 0.1662 - val_loss: 1.3425 - val_mae: 0.7862\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0594 - mae: 0.1685 - val_loss: 1.3596 - val_mae: 0.7955\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0543 - mae: 0.1590 - val_loss: 1.3570 - val_mae: 0.7926\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0508 - mae: 0.1546 - val_loss: 1.3448 - val_mae: 0.7842\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0454 - mae: 0.1468 - val_loss: 1.3460 - val_mae: 0.7848\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0520 - mae: 0.1536 - val_loss: 1.3467 - val_mae: 0.7870\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0526 - mae: 0.1513 - val_loss: 1.3533 - val_mae: 0.7852\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0471 - mae: 0.1444 - val_loss: 1.3460 - val_mae: 0.7891\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0475 - mae: 0.1433 - val_loss: 1.3261 - val_mae: 0.7826\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0461 - mae: 0.1437 - val_loss: 1.3438 - val_mae: 0.7926\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0485 - mae: 0.1436 - val_loss: 1.3296 - val_mae: 0.7785\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0487 - mae: 0.1386 - val_loss: 1.3326 - val_mae: 0.7826\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0416 - mae: 0.1357 - val_loss: 1.3290 - val_mae: 0.7803\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0372 - mae: 0.1316 - val_loss: 1.3305 - val_mae: 0.7777\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0365 - mae: 0.1295 - val_loss: 1.3403 - val_mae: 0.7844\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0379 - mae: 0.1305 - val_loss: 1.3261 - val_mae: 0.7775\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0421 - mae: 0.1301 - val_loss: 1.3282 - val_mae: 0.7762\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0356 - mae: 0.1257 - val_loss: 1.3111 - val_mae: 0.7706\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0380 - mae: 0.1241 - val_loss: 1.3235 - val_mae: 0.7786\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0379 - mae: 0.1254 - val_loss: 1.3285 - val_mae: 0.7817\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0387 - mae: 0.1234 - val_loss: 1.3564 - val_mae: 0.7887\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0371 - mae: 0.1229 - val_loss: 1.3193 - val_mae: 0.7733\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0343 - mae: 0.1229 - val_loss: 1.3344 - val_mae: 0.7822\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0327 - mae: 0.1183 - val_loss: 1.3168 - val_mae: 0.7690\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0336 - mae: 0.1183 - val_loss: 1.3206 - val_mae: 0.7743\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0325 - mae: 0.1169 - val_loss: 1.3211 - val_mae: 0.7755\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0281 - mae: 0.1112 - val_loss: 1.3162 - val_mae: 0.7747\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0319 - mae: 0.1139 - val_loss: 1.3025 - val_mae: 0.7701\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0297 - mae: 0.1116 - val_loss: 1.3305 - val_mae: 0.7749\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0310 - mae: 0.1129 - val_loss: 1.3091 - val_mae: 0.7717\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0312 - mae: 0.1131 - val_loss: 1.3270 - val_mae: 0.7725\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0285 - mae: 0.1087 - val_loss: 1.3179 - val_mae: 0.7721\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0280 - mae: 0.1082 - val_loss: 1.3030 - val_mae: 0.7664\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0253 - mae: 0.1056 - val_loss: 1.3142 - val_mae: 0.7729\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0253 - mae: 0.1028 - val_loss: 1.3062 - val_mae: 0.7631\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0291 - mae: 0.1055 - val_loss: 1.3332 - val_mae: 0.7804\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0278 - mae: 0.1078 - val_loss: 1.2982 - val_mae: 0.7658\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0234 - mae: 0.1021 - val_loss: 1.3174 - val_mae: 0.7772\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0285 - mae: 0.1057 - val_loss: 1.3113 - val_mae: 0.7692\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0272 - mae: 0.0993 - val_loss: 1.3137 - val_mae: 0.7699\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0278 - mae: 0.1023 - val_loss: 1.3084 - val_mae: 0.7683\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0233 - mae: 0.1009 - val_loss: 1.3086 - val_mae: 0.7695\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0242 - mae: 0.0992 - val_loss: 1.3094 - val_mae: 0.7670\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0263 - mae: 0.1005 - val_loss: 1.3096 - val_mae: 0.7719\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0233 - mae: 0.0952 - val_loss: 1.2999 - val_mae: 0.7664\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0230 - mae: 0.0974 - val_loss: 1.2983 - val_mae: 0.7679\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0210 - mae: 0.0928 - val_loss: 1.3024 - val_mae: 0.7654\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0236 - mae: 0.0982 - val_loss: 1.3166 - val_mae: 0.7731\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0234 - mae: 0.0985 - val_loss: 1.3116 - val_mae: 0.7728\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0242 - mae: 0.0972 - val_loss: 1.2970 - val_mae: 0.7646\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0209 - mae: 0.0906 - val_loss: 1.3015 - val_mae: 0.7641\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0236 - mae: 0.0938 - val_loss: 1.3165 - val_mae: 0.7714\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0228 - mae: 0.0947 - val_loss: 1.3084 - val_mae: 0.7661\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0243 - mae: 0.0973 - val_loss: 1.2910 - val_mae: 0.7648\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0224 - mae: 0.0914 - val_loss: 1.2987 - val_mae: 0.7638\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0192 - mae: 0.0863 - val_loss: 1.2856 - val_mae: 0.7603\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0196 - mae: 0.0874 - val_loss: 1.3025 - val_mae: 0.7669\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0189 - mae: 0.0895 - val_loss: 1.2899 - val_mae: 0.7608\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0206 - mae: 0.0891 - val_loss: 1.3085 - val_mae: 0.7668\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0203 - mae: 0.0865 - val_loss: 1.3132 - val_mae: 0.7674\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0197 - mae: 0.0895 - val_loss: 1.3046 - val_mae: 0.7671\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0182 - mae: 0.0859 - val_loss: 1.3042 - val_mae: 0.7639\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0217 - mae: 0.0879 - val_loss: 1.3089 - val_mae: 0.7681\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0193 - mae: 0.0860 - val_loss: 1.3160 - val_mae: 0.7696\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0181 - mae: 0.0855 - val_loss: 1.2820 - val_mae: 0.7592\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0177 - mae: 0.0846 - val_loss: 1.3157 - val_mae: 0.7690\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.0873 - val_loss: 1.3112 - val_mae: 0.7726\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0203 - mae: 0.0880 - val_loss: 1.3093 - val_mae: 0.7719\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0194 - mae: 0.0888 - val_loss: 1.3016 - val_mae: 0.7630\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0164 - mae: 0.0788 - val_loss: 1.2847 - val_mae: 0.7590\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0167 - mae: 0.0803 - val_loss: 1.2913 - val_mae: 0.7622\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0217 - mae: 0.0835 - val_loss: 1.3046 - val_mae: 0.7659\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0233 - mae: 0.0839 - val_loss: 1.3008 - val_mae: 0.7628\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0819 - val_loss: 1.2979 - val_mae: 0.7636\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0203 - mae: 0.0891 - val_loss: 1.2954 - val_mae: 0.7639\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0181 - mae: 0.0802 - val_loss: 1.3071 - val_mae: 0.7646\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0214 - mae: 0.0809 - val_loss: 1.2993 - val_mae: 0.7669\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0168 - mae: 0.0802 - val_loss: 1.2992 - val_mae: 0.7618\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0158 - mae: 0.0825 - val_loss: 1.2911 - val_mae: 0.7620\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0159 - mae: 0.0779 - val_loss: 1.2945 - val_mae: 0.7607\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0151 - mae: 0.0767 - val_loss: 1.3010 - val_mae: 0.7651\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0158 - mae: 0.0774 - val_loss: 1.2965 - val_mae: 0.7598\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0187 - mae: 0.0800 - val_loss: 1.2909 - val_mae: 0.7609\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0156 - mae: 0.0804 - val_loss: 1.2936 - val_mae: 0.7605\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0166 - mae: 0.0783 - val_loss: 1.3091 - val_mae: 0.7673\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0170 - mae: 0.0746 - val_loss: 1.3019 - val_mae: 0.7646\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0198 - mae: 0.0740 - val_loss: 1.3008 - val_mae: 0.7650\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0177 - mae: 0.0790 - val_loss: 1.2984 - val_mae: 0.7617\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0154 - mae: 0.0775 - val_loss: 1.2983 - val_mae: 0.7620\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0138 - mae: 0.0743 - val_loss: 1.2945 - val_mae: 0.7605\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0145 - mae: 0.0727 - val_loss: 1.2998 - val_mae: 0.7609\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0154 - mae: 0.0718 - val_loss: 1.2918 - val_mae: 0.7605\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0162 - mae: 0.0723 - val_loss: 1.2999 - val_mae: 0.7624\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0161 - mae: 0.0783 - val_loss: 1.2851 - val_mae: 0.7595\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0155 - mae: 0.0745 - val_loss: 1.3035 - val_mae: 0.7615\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0139 - mae: 0.0709 - val_loss: 1.3029 - val_mae: 0.7630\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0131 - mae: 0.0716 - val_loss: 1.2971 - val_mae: 0.7613\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0173 - mae: 0.0725 - val_loss: 1.2884 - val_mae: 0.7582\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0145 - mae: 0.0730 - val_loss: 1.3018 - val_mae: 0.7628\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0144 - mae: 0.0735 - val_loss: 1.2960 - val_mae: 0.7643\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0121 - mae: 0.0709 - val_loss: 1.2986 - val_mae: 0.7612\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0143 - mae: 0.0697 - val_loss: 1.2974 - val_mae: 0.7600\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0140 - mae: 0.0689 - val_loss: 1.2969 - val_mae: 0.7594\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0143 - mae: 0.0709 - val_loss: 1.2939 - val_mae: 0.7594\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0187 - mae: 0.0757 - val_loss: 1.2990 - val_mae: 0.7638\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0119 - mae: 0.0692 - val_loss: 1.3025 - val_mae: 0.7617\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0122 - mae: 0.0691 - val_loss: 1.2925 - val_mae: 0.7601\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0129 - mae: 0.0695 - val_loss: 1.2969 - val_mae: 0.7620\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0120 - mae: 0.0682 - val_loss: 1.2987 - val_mae: 0.7609\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0140 - mae: 0.0718 - val_loss: 1.2981 - val_mae: 0.7607\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0136 - mae: 0.0695 - val_loss: 1.2905 - val_mae: 0.7568\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0125 - mae: 0.0694 - val_loss: 1.3015 - val_mae: 0.7626\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0119 - mae: 0.0665 - val_loss: 1.2974 - val_mae: 0.7604\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0130 - mae: 0.0676 - val_loss: 1.2957 - val_mae: 0.7624\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0112 - mae: 0.0669 - val_loss: 1.3020 - val_mae: 0.7587\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0128 - mae: 0.0672 - val_loss: 1.2913 - val_mae: 0.7595\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0139 - mae: 0.0687 - val_loss: 1.2999 - val_mae: 0.7608\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0130 - mae: 0.0667 - val_loss: 1.3028 - val_mae: 0.7637\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0115 - mae: 0.0644 - val_loss: 1.2989 - val_mae: 0.7598\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0144 - mae: 0.0663 - val_loss: 1.2958 - val_mae: 0.7592\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0125 - mae: 0.0688 - val_loss: 1.2965 - val_mae: 0.7593\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0125 - mae: 0.0665 - val_loss: 1.3055 - val_mae: 0.7655\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0143 - mae: 0.0665 - val_loss: 1.3037 - val_mae: 0.7632\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0121 - mae: 0.0630 - val_loss: 1.2983 - val_mae: 0.7594\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0109 - mae: 0.0616 - val_loss: 1.2929 - val_mae: 0.7585\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0125 - mae: 0.0675 - val_loss: 1.2993 - val_mae: 0.7602\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0121 - mae: 0.0672 - val_loss: 1.2948 - val_mae: 0.7597\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0127 - mae: 0.0646 - val_loss: 1.2913 - val_mae: 0.7587\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0103 - mae: 0.0633 - val_loss: 1.2936 - val_mae: 0.7584\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0139 - mae: 0.0652 - val_loss: 1.2945 - val_mae: 0.7577\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0123 - mae: 0.0619 - val_loss: 1.2941 - val_mae: 0.7594\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0137 - mae: 0.0641 - val_loss: 1.2972 - val_mae: 0.7623\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0122 - mae: 0.0671 - val_loss: 1.2829 - val_mae: 0.7553\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0124 - mae: 0.0662 - val_loss: 1.2965 - val_mae: 0.7620\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0137 - mae: 0.0661 - val_loss: 1.2970 - val_mae: 0.7602\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0120 - mae: 0.0639 - val_loss: 1.2883 - val_mae: 0.7589\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0128 - mae: 0.0652 - val_loss: 1.2952 - val_mae: 0.7596\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0106 - mae: 0.0596 - val_loss: 1.2985 - val_mae: 0.7587\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0111 - mae: 0.0584 - val_loss: 1.2967 - val_mae: 0.7610\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0112 - mae: 0.0623 - val_loss: 1.3012 - val_mae: 0.7603\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0101 - mae: 0.0612 - val_loss: 1.2970 - val_mae: 0.7602\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0127 - mae: 0.0654 - val_loss: 1.3031 - val_mae: 0.7648\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0094 - mae: 0.0610 - val_loss: 1.3012 - val_mae: 0.7599\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0104 - mae: 0.0596 - val_loss: 1.3040 - val_mae: 0.7625\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0099 - mae: 0.0576 - val_loss: 1.2946 - val_mae: 0.7608\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0123 - mae: 0.0627 - val_loss: 1.3066 - val_mae: 0.7652\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0141 - mae: 0.0633 - val_loss: 1.2908 - val_mae: 0.7587\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0107 - mae: 0.0596 - val_loss: 1.2975 - val_mae: 0.7594\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0106 - mae: 0.0602 - val_loss: 1.2888 - val_mae: 0.7580\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0111 - mae: 0.0589 - val_loss: 1.3046 - val_mae: 0.7606\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0092 - mae: 0.0587 - val_loss: 1.2877 - val_mae: 0.7574\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0112 - mae: 0.0603 - val_loss: 1.2951 - val_mae: 0.7580\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0094 - mae: 0.0587 - val_loss: 1.2928 - val_mae: 0.7601\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0098 - mae: 0.0574 - val_loss: 1.2945 - val_mae: 0.7571\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0113 - mae: 0.0596 - val_loss: 1.2855 - val_mae: 0.7574\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0093 - mae: 0.0584 - val_loss: 1.3012 - val_mae: 0.7606\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0091 - mae: 0.0583 - val_loss: 1.2950 - val_mae: 0.7598\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0112 - mae: 0.0598 - val_loss: 1.2933 - val_mae: 0.7582\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0141 - mae: 0.0607 - val_loss: 1.2902 - val_mae: 0.7578\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0092 - mae: 0.0594 - val_loss: 1.2979 - val_mae: 0.7592\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0116 - mae: 0.0589 - val_loss: 1.2846 - val_mae: 0.7550\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0097 - mae: 0.0577 - val_loss: 1.2970 - val_mae: 0.7607\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0105 - mae: 0.0628 - val_loss: 1.2828 - val_mae: 0.7561\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0094 - mae: 0.0586 - val_loss: 1.3018 - val_mae: 0.7589\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0096 - mae: 0.0560 - val_loss: 1.2799 - val_mae: 0.7542\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0083 - mae: 0.0555 - val_loss: 1.2950 - val_mae: 0.7603\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0091 - mae: 0.0586 - val_loss: 1.2849 - val_mae: 0.7566\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0095 - mae: 0.0584 - val_loss: 1.2943 - val_mae: 0.7575\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0080 - mae: 0.0548 - val_loss: 1.2868 - val_mae: 0.7561\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0091 - mae: 0.0567 - val_loss: 1.2899 - val_mae: 0.7561\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3426 - mae: 0.7682\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 5.8638 - mae: 1.7174 - val_loss: 2.1433 - val_mae: 1.0351\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.3335 - mae: 0.8400 - val_loss: 1.6833 - val_mae: 0.9276\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1.0579 - mae: 0.7167 - val_loss: 1.5409 - val_mae: 0.8446\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.7098 - mae: 0.5984 - val_loss: 1.5373 - val_mae: 0.8405\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.5852 - mae: 0.5355 - val_loss: 1.4744 - val_mae: 0.8151\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.4687 - mae: 0.4760 - val_loss: 1.4822 - val_mae: 0.8060\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.4132 - mae: 0.4411 - val_loss: 1.4253 - val_mae: 0.7950\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3259 - mae: 0.3910 - val_loss: 1.6230 - val_mae: 0.8532\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3082 - mae: 0.3785 - val_loss: 1.4505 - val_mae: 0.8007\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2456 - mae: 0.3410 - val_loss: 1.4064 - val_mae: 0.7812\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2326 - mae: 0.3272 - val_loss: 1.4197 - val_mae: 0.7862\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2092 - mae: 0.3163 - val_loss: 1.3393 - val_mae: 0.7746\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1899 - mae: 0.2955 - val_loss: 1.3659 - val_mae: 0.7825\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1788 - mae: 0.2847 - val_loss: 1.4283 - val_mae: 0.8111\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1763 - mae: 0.2865 - val_loss: 1.4007 - val_mae: 0.7722\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1954 - mae: 0.2854 - val_loss: 1.3578 - val_mae: 0.7652\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1562 - mae: 0.2640 - val_loss: 1.3258 - val_mae: 0.7551\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1452 - mae: 0.2520 - val_loss: 1.3627 - val_mae: 0.7624\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1416 - mae: 0.2467 - val_loss: 1.3069 - val_mae: 0.7530\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1189 - mae: 0.2323 - val_loss: 1.3371 - val_mae: 0.7614\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1147 - mae: 0.2314 - val_loss: 1.3002 - val_mae: 0.7508\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1208 - mae: 0.2317 - val_loss: 1.3366 - val_mae: 0.7525\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1104 - mae: 0.2187 - val_loss: 1.3329 - val_mae: 0.7588\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1063 - mae: 0.2223 - val_loss: 1.3578 - val_mae: 0.7588\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0916 - mae: 0.2056 - val_loss: 1.3284 - val_mae: 0.7603\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0877 - mae: 0.2007 - val_loss: 1.3519 - val_mae: 0.7586\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0975 - mae: 0.2089 - val_loss: 1.3127 - val_mae: 0.7556\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0912 - mae: 0.1990 - val_loss: 1.3470 - val_mae: 0.7561\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0895 - mae: 0.2016 - val_loss: 1.3248 - val_mae: 0.7547\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0848 - mae: 0.1929 - val_loss: 1.3100 - val_mae: 0.7565\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0831 - mae: 0.1952 - val_loss: 1.3031 - val_mae: 0.7437\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0724 - mae: 0.1831 - val_loss: 1.2916 - val_mae: 0.7413\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0741 - mae: 0.1835 - val_loss: 1.3232 - val_mae: 0.7467\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0691 - mae: 0.1791 - val_loss: 1.3063 - val_mae: 0.7475\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0705 - mae: 0.1801 - val_loss: 1.3237 - val_mae: 0.7486\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0707 - mae: 0.1783 - val_loss: 1.3590 - val_mae: 0.7602\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0725 - mae: 0.1789 - val_loss: 1.3312 - val_mae: 0.7507\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0587 - mae: 0.1636 - val_loss: 1.2982 - val_mae: 0.7431\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0572 - mae: 0.1635 - val_loss: 1.3623 - val_mae: 0.7496\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0624 - mae: 0.1696 - val_loss: 1.3130 - val_mae: 0.7409\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0581 - mae: 0.1604 - val_loss: 1.3446 - val_mae: 0.7549\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0670 - mae: 0.1716 - val_loss: 1.2787 - val_mae: 0.7318\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0552 - mae: 0.1575 - val_loss: 1.3005 - val_mae: 0.7403\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0573 - mae: 0.1537 - val_loss: 1.3080 - val_mae: 0.7380\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0487 - mae: 0.1495 - val_loss: 1.3114 - val_mae: 0.7391\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0586 - mae: 0.1527 - val_loss: 1.2917 - val_mae: 0.7389\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0484 - mae: 0.1488 - val_loss: 1.3147 - val_mae: 0.7414\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0590 - mae: 0.1548 - val_loss: 1.2862 - val_mae: 0.7356\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0484 - mae: 0.1439 - val_loss: 1.3243 - val_mae: 0.7458\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0427 - mae: 0.1366 - val_loss: 1.3080 - val_mae: 0.7428\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0410 - mae: 0.1374 - val_loss: 1.2871 - val_mae: 0.7358\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0503 - mae: 0.1472 - val_loss: 1.2964 - val_mae: 0.7350\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0470 - mae: 0.1438 - val_loss: 1.2913 - val_mae: 0.7383\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0396 - mae: 0.1351 - val_loss: 1.2900 - val_mae: 0.7389\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0468 - mae: 0.1421 - val_loss: 1.2997 - val_mae: 0.7413\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0404 - mae: 0.1336 - val_loss: 1.2899 - val_mae: 0.7369\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0381 - mae: 0.1321 - val_loss: 1.2817 - val_mae: 0.7348\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0378 - mae: 0.1325 - val_loss: 1.2811 - val_mae: 0.7339\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0327 - mae: 0.1245 - val_loss: 1.2930 - val_mae: 0.7322\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0342 - mae: 0.1245 - val_loss: 1.2977 - val_mae: 0.7366\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0393 - mae: 0.1334 - val_loss: 1.2918 - val_mae: 0.7337\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0412 - mae: 0.1353 - val_loss: 1.2741 - val_mae: 0.7314\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0392 - mae: 0.1290 - val_loss: 1.2870 - val_mae: 0.7377\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0335 - mae: 0.1231 - val_loss: 1.2872 - val_mae: 0.7337\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0559 - mae: 0.1409 - val_loss: 1.3146 - val_mae: 0.7356\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0377 - mae: 0.1267 - val_loss: 1.2841 - val_mae: 0.7336\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0362 - mae: 0.1198 - val_loss: 1.2919 - val_mae: 0.7325\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0348 - mae: 0.1195 - val_loss: 1.2916 - val_mae: 0.7318\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0332 - mae: 0.1156 - val_loss: 1.2936 - val_mae: 0.7367\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0337 - mae: 0.1194 - val_loss: 1.2842 - val_mae: 0.7311\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0289 - mae: 0.1146 - val_loss: 1.2906 - val_mae: 0.7329\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0361 - mae: 0.1230 - val_loss: 1.2720 - val_mae: 0.7268\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0303 - mae: 0.1217 - val_loss: 1.2707 - val_mae: 0.7250\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0359 - mae: 0.1206 - val_loss: 1.2557 - val_mae: 0.7271\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0308 - mae: 0.1149 - val_loss: 1.2830 - val_mae: 0.7280\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0268 - mae: 0.1066 - val_loss: 1.2892 - val_mae: 0.7292\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0304 - mae: 0.1142 - val_loss: 1.2853 - val_mae: 0.7267\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.1195 - val_loss: 1.2662 - val_mae: 0.7285\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0336 - mae: 0.1168 - val_loss: 1.2812 - val_mae: 0.7270\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0289 - mae: 0.1120 - val_loss: 1.2570 - val_mae: 0.7261\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.1064 - val_loss: 1.2714 - val_mae: 0.7274\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0307 - mae: 0.1099 - val_loss: 1.2519 - val_mae: 0.7214\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0285 - mae: 0.1103 - val_loss: 1.2741 - val_mae: 0.7270\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0262 - mae: 0.1067 - val_loss: 1.2725 - val_mae: 0.7244\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0273 - mae: 0.1115 - val_loss: 1.2641 - val_mae: 0.7228\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0334 - mae: 0.1096 - val_loss: 1.2727 - val_mae: 0.7262\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0324 - mae: 0.1160 - val_loss: 1.2785 - val_mae: 0.7249\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0281 - mae: 0.1047 - val_loss: 1.2587 - val_mae: 0.7211\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0249 - mae: 0.1035 - val_loss: 1.2611 - val_mae: 0.7217\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0233 - mae: 0.1042 - val_loss: 1.2727 - val_mae: 0.7229\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0255 - mae: 0.1028 - val_loss: 1.2757 - val_mae: 0.7225\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1094 - val_loss: 1.2690 - val_mae: 0.7231\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0309 - mae: 0.1109 - val_loss: 1.2744 - val_mae: 0.7231\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0240 - mae: 0.0994 - val_loss: 1.2776 - val_mae: 0.7323\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0206 - mae: 0.0987 - val_loss: 1.2507 - val_mae: 0.7196\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0218 - mae: 0.0979 - val_loss: 1.2807 - val_mae: 0.7227\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0247 - mae: 0.0994 - val_loss: 1.2709 - val_mae: 0.7228\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0235 - mae: 0.1032 - val_loss: 1.2768 - val_mae: 0.7263\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0229 - mae: 0.0992 - val_loss: 1.2642 - val_mae: 0.7217\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0209 - mae: 0.0981 - val_loss: 1.2730 - val_mae: 0.7227\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0235 - mae: 0.1007 - val_loss: 1.2784 - val_mae: 0.7245\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0230 - mae: 0.0967 - val_loss: 1.2705 - val_mae: 0.7203\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.0990 - val_loss: 1.2850 - val_mae: 0.7244\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0937 - val_loss: 1.2533 - val_mae: 0.7197\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0228 - mae: 0.0987 - val_loss: 1.2890 - val_mae: 0.7277\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0253 - mae: 0.1018 - val_loss: 1.2797 - val_mae: 0.7217\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0220 - mae: 0.0957 - val_loss: 1.2562 - val_mae: 0.7165\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0202 - mae: 0.0931 - val_loss: 1.2773 - val_mae: 0.7253\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0950 - val_loss: 1.2665 - val_mae: 0.7193\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0231 - mae: 0.0994 - val_loss: 1.2732 - val_mae: 0.7254\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0237 - mae: 0.0952 - val_loss: 1.2683 - val_mae: 0.7211\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0907 - val_loss: 1.2643 - val_mae: 0.7195\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0938 - val_loss: 1.2910 - val_mae: 0.7272\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0243 - mae: 0.1048 - val_loss: 1.2731 - val_mae: 0.7185\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0259 - mae: 0.0990 - val_loss: 1.2612 - val_mae: 0.7247\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0932 - val_loss: 1.2523 - val_mae: 0.7161\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0180 - mae: 0.0845 - val_loss: 1.2589 - val_mae: 0.7232\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0200 - mae: 0.0878 - val_loss: 1.2612 - val_mae: 0.7230\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0887 - val_loss: 1.2644 - val_mae: 0.7210\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.0909 - val_loss: 1.2570 - val_mae: 0.7199\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0201 - mae: 0.0943 - val_loss: 1.2781 - val_mae: 0.7197\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0158 - mae: 0.0842 - val_loss: 1.2679 - val_mae: 0.7224\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0858 - val_loss: 1.3014 - val_mae: 0.7296\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0189 - mae: 0.0879 - val_loss: 1.3010 - val_mae: 0.7307\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0920 - val_loss: 1.2677 - val_mae: 0.7265\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0905 - val_loss: 1.2781 - val_mae: 0.7220\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0220 - mae: 0.0890 - val_loss: 1.2644 - val_mae: 0.7192\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0178 - mae: 0.0864 - val_loss: 1.2699 - val_mae: 0.7246\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0173 - mae: 0.0850 - val_loss: 1.2773 - val_mae: 0.7236\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0829 - val_loss: 1.2746 - val_mae: 0.7260\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0179 - mae: 0.0883 - val_loss: 1.2904 - val_mae: 0.7251\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0874 - val_loss: 1.2726 - val_mae: 0.7252\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0865 - val_loss: 1.2663 - val_mae: 0.7187\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0153 - mae: 0.0832 - val_loss: 1.2569 - val_mae: 0.7215\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0810 - val_loss: 1.2973 - val_mae: 0.7260\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0891 - val_loss: 1.2701 - val_mae: 0.7227\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0161 - mae: 0.0845 - val_loss: 1.2652 - val_mae: 0.7216\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0840 - val_loss: 1.2725 - val_mae: 0.7253\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0818 - val_loss: 1.2932 - val_mae: 0.7245\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0884 - val_loss: 1.2655 - val_mae: 0.7203\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0185 - mae: 0.0849 - val_loss: 1.2699 - val_mae: 0.7204\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0232 - mae: 0.0873 - val_loss: 1.2725 - val_mae: 0.7260\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0247 - mae: 0.0857 - val_loss: 1.2734 - val_mae: 0.7220\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0791 - val_loss: 1.2711 - val_mae: 0.7211\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0772 - val_loss: 1.2760 - val_mae: 0.7213\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0788 - val_loss: 1.2714 - val_mae: 0.7218\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182 - mae: 0.0835 - val_loss: 1.2688 - val_mae: 0.7216\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0844 - val_loss: 1.2822 - val_mae: 0.7214\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0799 - val_loss: 1.2855 - val_mae: 0.7235\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0756 - val_loss: 1.2804 - val_mae: 0.7243\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0791 - val_loss: 1.2783 - val_mae: 0.7256\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0817 - val_loss: 1.2817 - val_mae: 0.7286\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0160 - mae: 0.0792 - val_loss: 1.2749 - val_mae: 0.7227\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0786 - val_loss: 1.2802 - val_mae: 0.7308\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0833 - val_loss: 1.2756 - val_mae: 0.7216\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0758 - val_loss: 1.2689 - val_mae: 0.7248\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0141 - mae: 0.0748 - val_loss: 1.2857 - val_mae: 0.7256\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0748 - val_loss: 1.2710 - val_mae: 0.7240\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0156 - mae: 0.0774 - val_loss: 1.2851 - val_mae: 0.7257\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0754 - val_loss: 1.2757 - val_mae: 0.7236\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0785 - val_loss: 1.2906 - val_mae: 0.7261\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0144 - mae: 0.0791 - val_loss: 1.2781 - val_mae: 0.7221\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0778 - val_loss: 1.2758 - val_mae: 0.7239\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0196 - mae: 0.0764 - val_loss: 1.2728 - val_mae: 0.7239\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0738 - val_loss: 1.2801 - val_mae: 0.7260\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0739 - val_loss: 1.2622 - val_mae: 0.7236\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0751 - val_loss: 1.2852 - val_mae: 0.7227\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0149 - mae: 0.0798 - val_loss: 1.2842 - val_mae: 0.7262\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0151 - mae: 0.0758 - val_loss: 1.2721 - val_mae: 0.7213\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0743 - val_loss: 1.2811 - val_mae: 0.7235\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0716 - val_loss: 1.2746 - val_mae: 0.7233\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0716 - val_loss: 1.2741 - val_mae: 0.7240\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0766 - val_loss: 1.2683 - val_mae: 0.7204\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0124 - mae: 0.0718 - val_loss: 1.2745 - val_mae: 0.7228\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0109 - mae: 0.0709 - val_loss: 1.2679 - val_mae: 0.7226\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0729 - val_loss: 1.2812 - val_mae: 0.7245\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0748 - val_loss: 1.2702 - val_mae: 0.7246\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0747 - val_loss: 1.2674 - val_mae: 0.7235\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0720 - val_loss: 1.2661 - val_mae: 0.7223\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0706 - val_loss: 1.2699 - val_mae: 0.7250\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0740 - val_loss: 1.2795 - val_mae: 0.7282\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0696 - val_loss: 1.2579 - val_mae: 0.7183\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0729 - val_loss: 1.2861 - val_mae: 0.7266\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0687 - val_loss: 1.2747 - val_mae: 0.7270\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0737 - val_loss: 1.2806 - val_mae: 0.7229\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0109 - mae: 0.0678 - val_loss: 1.2763 - val_mae: 0.7277\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0682 - val_loss: 1.2707 - val_mae: 0.7219\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0705 - val_loss: 1.2764 - val_mae: 0.7224\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0752 - val_loss: 1.2835 - val_mae: 0.7264\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0666 - val_loss: 1.2626 - val_mae: 0.7205\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0681 - val_loss: 1.2768 - val_mae: 0.7201\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0681 - val_loss: 1.2756 - val_mae: 0.7211\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0674 - val_loss: 1.2627 - val_mae: 0.7208\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0705 - val_loss: 1.2727 - val_mae: 0.7231\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0757 - val_loss: 1.2675 - val_mae: 0.7227\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0136 - mae: 0.0720 - val_loss: 1.2727 - val_mae: 0.7203\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0680 - val_loss: 1.2741 - val_mae: 0.7219\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0688 - val_loss: 1.2681 - val_mae: 0.7243\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0145 - mae: 0.0734 - val_loss: 1.2814 - val_mae: 0.7261\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0746 - val_loss: 1.2780 - val_mae: 0.7230\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2337 - mae: 0.7210\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 6.1629 - mae: 1.7514 - val_loss: 2.2294 - val_mae: 1.0519\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.3597 - mae: 0.8437 - val_loss: 1.7291 - val_mae: 0.9143\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.8869 - mae: 0.6741 - val_loss: 1.5649 - val_mae: 0.8757\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6525 - mae: 0.5668 - val_loss: 1.4989 - val_mae: 0.8416\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.4875 - mae: 0.4892 - val_loss: 1.4651 - val_mae: 0.8114\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3984 - mae: 0.4300 - val_loss: 1.4991 - val_mae: 0.8325\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3541 - mae: 0.4042 - val_loss: 1.4670 - val_mae: 0.8237\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3158 - mae: 0.3841 - val_loss: 1.4510 - val_mae: 0.8084\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.3060 - mae: 0.3632 - val_loss: 1.4706 - val_mae: 0.8058\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2434 - mae: 0.3322 - val_loss: 1.4674 - val_mae: 0.8108\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2339 - mae: 0.3215 - val_loss: 1.3985 - val_mae: 0.8048\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2135 - mae: 0.3150 - val_loss: 1.3924 - val_mae: 0.7905\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1879 - mae: 0.2884 - val_loss: 1.3597 - val_mae: 0.7761\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1696 - mae: 0.2754 - val_loss: 1.4077 - val_mae: 0.7868\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1665 - mae: 0.2699 - val_loss: 1.3202 - val_mae: 0.7587\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1494 - mae: 0.2571 - val_loss: 1.3272 - val_mae: 0.7740\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1411 - mae: 0.2566 - val_loss: 1.3298 - val_mae: 0.7627\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1498 - mae: 0.2433 - val_loss: 1.2934 - val_mae: 0.7592\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1315 - mae: 0.2350 - val_loss: 1.3364 - val_mae: 0.7645\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1244 - mae: 0.2299 - val_loss: 1.3128 - val_mae: 0.7628\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1257 - mae: 0.2252 - val_loss: 1.3052 - val_mae: 0.7599\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0968 - mae: 0.2065 - val_loss: 1.3172 - val_mae: 0.7588\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0998 - mae: 0.2061 - val_loss: 1.2681 - val_mae: 0.7443\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.1022 - mae: 0.2092 - val_loss: 1.3077 - val_mae: 0.7571\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0969 - mae: 0.2013 - val_loss: 1.2875 - val_mae: 0.7551\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0839 - mae: 0.1952 - val_loss: 1.2797 - val_mae: 0.7495\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0836 - mae: 0.1934 - val_loss: 1.2969 - val_mae: 0.7512\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0815 - mae: 0.1890 - val_loss: 1.3209 - val_mae: 0.7555\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0812 - mae: 0.1913 - val_loss: 1.2652 - val_mae: 0.7416\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0775 - mae: 0.1824 - val_loss: 1.3326 - val_mae: 0.7586\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0910 - mae: 0.1954 - val_loss: 1.2675 - val_mae: 0.7410\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0638 - mae: 0.1711 - val_loss: 1.2987 - val_mae: 0.7490\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0687 - mae: 0.1716 - val_loss: 1.2700 - val_mae: 0.7385\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0657 - mae: 0.1713 - val_loss: 1.3054 - val_mae: 0.7476\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0614 - mae: 0.1689 - val_loss: 1.2908 - val_mae: 0.7455\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0635 - mae: 0.1674 - val_loss: 1.2719 - val_mae: 0.7368\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0617 - mae: 0.1620 - val_loss: 1.2872 - val_mae: 0.7405\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0670 - mae: 0.1647 - val_loss: 1.2755 - val_mae: 0.7435\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0538 - mae: 0.1550 - val_loss: 1.2693 - val_mae: 0.7369\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0500 - mae: 0.1511 - val_loss: 1.2764 - val_mae: 0.7389\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0595 - mae: 0.1572 - val_loss: 1.2636 - val_mae: 0.7402\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0564 - mae: 0.1563 - val_loss: 1.2775 - val_mae: 0.7418\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0559 - mae: 0.1568 - val_loss: 1.2679 - val_mae: 0.7448\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0473 - mae: 0.1443 - val_loss: 1.2769 - val_mae: 0.7360\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0666 - mae: 0.1632 - val_loss: 1.2591 - val_mae: 0.7325\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0447 - mae: 0.1434 - val_loss: 1.2445 - val_mae: 0.7302\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0444 - mae: 0.1414 - val_loss: 1.2655 - val_mae: 0.7341\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0559 - mae: 0.1520 - val_loss: 1.2618 - val_mae: 0.7356\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0455 - mae: 0.1423 - val_loss: 1.2855 - val_mae: 0.7382\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0402 - mae: 0.1346 - val_loss: 1.2791 - val_mae: 0.7370\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0382 - mae: 0.1338 - val_loss: 1.2613 - val_mae: 0.7304\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0443 - mae: 0.1343 - val_loss: 1.2898 - val_mae: 0.7402\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0479 - mae: 0.1404 - val_loss: 1.2801 - val_mae: 0.7404\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0432 - mae: 0.1323 - val_loss: 1.2539 - val_mae: 0.7355\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0348 - mae: 0.1248 - val_loss: 1.2574 - val_mae: 0.7343\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0360 - mae: 0.1281 - val_loss: 1.2777 - val_mae: 0.7394\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0322 - mae: 0.1193 - val_loss: 1.2652 - val_mae: 0.7413\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0397 - mae: 0.1263 - val_loss: 1.2603 - val_mae: 0.7321\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0342 - mae: 0.1217 - val_loss: 1.2762 - val_mae: 0.7357\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0324 - mae: 0.1215 - val_loss: 1.2856 - val_mae: 0.7405\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.1237 - val_loss: 1.2637 - val_mae: 0.7353\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0379 - mae: 0.1259 - val_loss: 1.2780 - val_mae: 0.7378\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0316 - mae: 0.1151 - val_loss: 1.2652 - val_mae: 0.7336\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0278 - mae: 0.1119 - val_loss: 1.2541 - val_mae: 0.7325\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0279 - mae: 0.1147 - val_loss: 1.2480 - val_mae: 0.7299\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0288 - mae: 0.1151 - val_loss: 1.2639 - val_mae: 0.7319\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0387 - mae: 0.1270 - val_loss: 1.2544 - val_mae: 0.7312\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0315 - mae: 0.1205 - val_loss: 1.2709 - val_mae: 0.7366\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0316 - mae: 0.1194 - val_loss: 1.2585 - val_mae: 0.7344\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0293 - mae: 0.1119 - val_loss: 1.2737 - val_mae: 0.7374\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0273 - mae: 0.1100 - val_loss: 1.2393 - val_mae: 0.7298\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0361 - mae: 0.1162 - val_loss: 1.2568 - val_mae: 0.7343\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0348 - mae: 0.1183 - val_loss: 1.2624 - val_mae: 0.7310\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0267 - mae: 0.1096 - val_loss: 1.2642 - val_mae: 0.7349\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0270 - mae: 0.1088 - val_loss: 1.2605 - val_mae: 0.7285\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0258 - mae: 0.1070 - val_loss: 1.2779 - val_mae: 0.7371\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0321 - mae: 0.1103 - val_loss: 1.2763 - val_mae: 0.7336\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0325 - mae: 0.1104 - val_loss: 1.2785 - val_mae: 0.7393\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0258 - mae: 0.1063 - val_loss: 1.2479 - val_mae: 0.7317\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0262 - mae: 0.1072 - val_loss: 1.2656 - val_mae: 0.7317\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0267 - mae: 0.1046 - val_loss: 1.2591 - val_mae: 0.7327\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0236 - mae: 0.1012 - val_loss: 1.2460 - val_mae: 0.7257\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0329 - mae: 0.1162 - val_loss: 1.2565 - val_mae: 0.7309\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0226 - mae: 0.1006 - val_loss: 1.2682 - val_mae: 0.7316\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0235 - mae: 0.1002 - val_loss: 1.2471 - val_mae: 0.7272\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0898 - val_loss: 1.2588 - val_mae: 0.7330\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0222 - mae: 0.0979 - val_loss: 1.2533 - val_mae: 0.7300\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0306 - mae: 0.1102 - val_loss: 1.2491 - val_mae: 0.7288\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0243 - mae: 0.1018 - val_loss: 1.2760 - val_mae: 0.7308\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.0964 - val_loss: 1.2793 - val_mae: 0.7347\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0250 - mae: 0.1018 - val_loss: 1.2720 - val_mae: 0.7334\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.0963 - val_loss: 1.2778 - val_mae: 0.7350\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0941 - val_loss: 1.2699 - val_mae: 0.7333\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0234 - mae: 0.0998 - val_loss: 1.2651 - val_mae: 0.7268\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.0942 - val_loss: 1.2598 - val_mae: 0.7301\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0206 - mae: 0.0928 - val_loss: 1.2578 - val_mae: 0.7271\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0918 - val_loss: 1.2461 - val_mae: 0.7261\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0212 - mae: 0.0979 - val_loss: 1.2696 - val_mae: 0.7306\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0946 - val_loss: 1.2588 - val_mae: 0.7300\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0911 - val_loss: 1.2729 - val_mae: 0.7332\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0240 - mae: 0.0946 - val_loss: 1.2482 - val_mae: 0.7295\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0885 - val_loss: 1.2569 - val_mae: 0.7262\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.0940 - val_loss: 1.2783 - val_mae: 0.7358\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0195 - mae: 0.0900 - val_loss: 1.2545 - val_mae: 0.7294\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0219 - mae: 0.0905 - val_loss: 1.2728 - val_mae: 0.7329\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0205 - mae: 0.0927 - val_loss: 1.2635 - val_mae: 0.7295\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0221 - mae: 0.0940 - val_loss: 1.2645 - val_mae: 0.7321\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0215 - mae: 0.0929 - val_loss: 1.2794 - val_mae: 0.7314\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0910 - val_loss: 1.2746 - val_mae: 0.7292\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0896 - val_loss: 1.2486 - val_mae: 0.7259\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.0916 - val_loss: 1.2670 - val_mae: 0.7315\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0178 - mae: 0.0875 - val_loss: 1.2587 - val_mae: 0.7291\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0143 - mae: 0.0797 - val_loss: 1.2745 - val_mae: 0.7324\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0860 - val_loss: 1.2667 - val_mae: 0.7310\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0213 - mae: 0.0903 - val_loss: 1.2716 - val_mae: 0.7295\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0871 - val_loss: 1.2563 - val_mae: 0.7286\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0891 - val_loss: 1.2705 - val_mae: 0.7336\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0825 - val_loss: 1.2629 - val_mae: 0.7292\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0165 - mae: 0.0824 - val_loss: 1.2521 - val_mae: 0.7274\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0824 - val_loss: 1.2654 - val_mae: 0.7303\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0860 - val_loss: 1.2867 - val_mae: 0.7353\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0869 - val_loss: 1.2762 - val_mae: 0.7326\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0174 - mae: 0.0821 - val_loss: 1.2700 - val_mae: 0.7273\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0812 - val_loss: 1.2751 - val_mae: 0.7312\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166 - mae: 0.0815 - val_loss: 1.2747 - val_mae: 0.7322\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0827 - val_loss: 1.2717 - val_mae: 0.7313\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0834 - val_loss: 1.2746 - val_mae: 0.7323\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0794 - val_loss: 1.2617 - val_mae: 0.7309\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0165 - mae: 0.0802 - val_loss: 1.2697 - val_mae: 0.7269\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0163 - mae: 0.0799 - val_loss: 1.2544 - val_mae: 0.7302\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0793 - val_loss: 1.2934 - val_mae: 0.7372\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0205 - mae: 0.0859 - val_loss: 1.2577 - val_mae: 0.7273\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0164 - mae: 0.0795 - val_loss: 1.2810 - val_mae: 0.7384\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0850 - val_loss: 1.2660 - val_mae: 0.7262\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0152 - mae: 0.0776 - val_loss: 1.2653 - val_mae: 0.7309\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0793 - val_loss: 1.2650 - val_mae: 0.7313\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0149 - mae: 0.0775 - val_loss: 1.2804 - val_mae: 0.7328\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0785 - val_loss: 1.2622 - val_mae: 0.7281\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0142 - mae: 0.0746 - val_loss: 1.2808 - val_mae: 0.7310\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0799 - val_loss: 1.2810 - val_mae: 0.7347\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0793 - val_loss: 1.2772 - val_mae: 0.7326\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0730 - val_loss: 1.2669 - val_mae: 0.7285\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0707 - val_loss: 1.2703 - val_mae: 0.7309\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0138 - mae: 0.0787 - val_loss: 1.2663 - val_mae: 0.7320\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0757 - val_loss: 1.2657 - val_mae: 0.7289\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0146 - mae: 0.0774 - val_loss: 1.2664 - val_mae: 0.7279\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0783 - val_loss: 1.2725 - val_mae: 0.7280\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0766 - val_loss: 1.2742 - val_mae: 0.7313\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0772 - val_loss: 1.2728 - val_mae: 0.7299\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0747 - val_loss: 1.2744 - val_mae: 0.7289\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0690 - val_loss: 1.2746 - val_mae: 0.7277\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0723 - val_loss: 1.2710 - val_mae: 0.7308\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0139 - mae: 0.0749 - val_loss: 1.2795 - val_mae: 0.7327\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0801 - val_loss: 1.2684 - val_mae: 0.7291\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0737 - val_loss: 1.2656 - val_mae: 0.7304\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0759 - val_loss: 1.2768 - val_mae: 0.7351\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0759 - val_loss: 1.2740 - val_mae: 0.7348\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0145 - mae: 0.0758 - val_loss: 1.2641 - val_mae: 0.7295\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0731 - val_loss: 1.2751 - val_mae: 0.7321\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0107 - mae: 0.0668 - val_loss: 1.2688 - val_mae: 0.7308\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0690 - val_loss: 1.2764 - val_mae: 0.7323\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0682 - val_loss: 1.2750 - val_mae: 0.7349\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0139 - mae: 0.0729 - val_loss: 1.2805 - val_mae: 0.7348\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0698 - val_loss: 1.2725 - val_mae: 0.7307\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0710 - val_loss: 1.2809 - val_mae: 0.7341\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0781 - val_loss: 1.2646 - val_mae: 0.7335\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0143 - mae: 0.0724 - val_loss: 1.2782 - val_mae: 0.7328\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0716 - val_loss: 1.2653 - val_mae: 0.7286\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0684 - val_loss: 1.2741 - val_mae: 0.7331\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0156 - mae: 0.0708 - val_loss: 1.2682 - val_mae: 0.7307\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0645 - val_loss: 1.2783 - val_mae: 0.7331\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0678 - val_loss: 1.2755 - val_mae: 0.7312\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0140 - mae: 0.0722 - val_loss: 1.2780 - val_mae: 0.7345\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0139 - mae: 0.0710 - val_loss: 1.2783 - val_mae: 0.7301\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0690 - val_loss: 1.2888 - val_mae: 0.7372\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0100 - mae: 0.0670 - val_loss: 1.2733 - val_mae: 0.7300\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0128 - mae: 0.0713 - val_loss: 1.2772 - val_mae: 0.7306\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0682 - val_loss: 1.2735 - val_mae: 0.7305\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0695 - val_loss: 1.2781 - val_mae: 0.7335\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0126 - mae: 0.0683 - val_loss: 1.2717 - val_mae: 0.7290\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0705 - val_loss: 1.2913 - val_mae: 0.7329\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0112 - mae: 0.0670 - val_loss: 1.2921 - val_mae: 0.7336\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0654 - val_loss: 1.2752 - val_mae: 0.7292\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0675 - val_loss: 1.2635 - val_mae: 0.7277\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0668 - val_loss: 1.2818 - val_mae: 0.7335\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0700 - val_loss: 1.2754 - val_mae: 0.7294\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0115 - mae: 0.0683 - val_loss: 1.2746 - val_mae: 0.7321\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0165 - mae: 0.0725 - val_loss: 1.2772 - val_mae: 0.7307\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0668 - val_loss: 1.2590 - val_mae: 0.7266\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0647 - val_loss: 1.2765 - val_mae: 0.7304\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0631 - val_loss: 1.2822 - val_mae: 0.7319\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0103 - mae: 0.0679 - val_loss: 1.2680 - val_mae: 0.7285\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0109 - mae: 0.0655 - val_loss: 1.2770 - val_mae: 0.7320\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0638 - val_loss: 1.2652 - val_mae: 0.7290\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0692 - val_loss: 1.2650 - val_mae: 0.7298\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0750 - val_loss: 1.2555 - val_mae: 0.7257\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0674 - val_loss: 1.2824 - val_mae: 0.7332\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0105 - mae: 0.0637 - val_loss: 1.2628 - val_mae: 0.7264\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0614 - val_loss: 1.2804 - val_mae: 0.7344\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0616 - val_loss: 1.2804 - val_mae: 0.7351\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2464 - mae: 0.7297\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 6.6334 - mae: 1.8486 - val_loss: 2.2620 - val_mae: 1.0852\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1.3807 - mae: 0.8593 - val_loss: 1.7132 - val_mae: 0.9453\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.9795 - mae: 0.7047 - val_loss: 1.7017 - val_mae: 0.9049\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6590 - mae: 0.5755 - val_loss: 1.4585 - val_mae: 0.8388\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.5039 - mae: 0.4906 - val_loss: 1.5290 - val_mae: 0.8576\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.4495 - mae: 0.4568 - val_loss: 1.5341 - val_mae: 0.8494\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.5596 - mae: 0.4677 - val_loss: 1.5109 - val_mae: 0.8350\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2938 - mae: 0.3675 - val_loss: 1.4386 - val_mae: 0.8259\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2573 - mae: 0.3442 - val_loss: 1.4061 - val_mae: 0.8153\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2343 - mae: 0.3249 - val_loss: 1.4751 - val_mae: 0.8224\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2334 - mae: 0.3156 - val_loss: 1.3944 - val_mae: 0.8041\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.2091 - mae: 0.2993 - val_loss: 1.3810 - val_mae: 0.7973\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1922 - mae: 0.2926 - val_loss: 1.4001 - val_mae: 0.8029\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1773 - mae: 0.2747 - val_loss: 1.3755 - val_mae: 0.7985\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1646 - mae: 0.2633 - val_loss: 1.3474 - val_mae: 0.7822\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1359 - mae: 0.2472 - val_loss: 1.3509 - val_mae: 0.7918\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1494 - mae: 0.2540 - val_loss: 1.2965 - val_mae: 0.7684\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1198 - mae: 0.2283 - val_loss: 1.3269 - val_mae: 0.7744\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1263 - mae: 0.2334 - val_loss: 1.2889 - val_mae: 0.7624\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1262 - mae: 0.2355 - val_loss: 1.2958 - val_mae: 0.7722\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1211 - mae: 0.2278 - val_loss: 1.2737 - val_mae: 0.7629\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1045 - mae: 0.2150 - val_loss: 1.2784 - val_mae: 0.7624\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0954 - mae: 0.2074 - val_loss: 1.2755 - val_mae: 0.7565\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0968 - mae: 0.2030 - val_loss: 1.2793 - val_mae: 0.7608\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0980 - mae: 0.2049 - val_loss: 1.3107 - val_mae: 0.7708\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1066 - mae: 0.2107 - val_loss: 1.2754 - val_mae: 0.7616\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0870 - mae: 0.1929 - val_loss: 1.2984 - val_mae: 0.7567\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0727 - mae: 0.1775 - val_loss: 1.2694 - val_mae: 0.7496\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0828 - mae: 0.1842 - val_loss: 1.2822 - val_mae: 0.7584\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0802 - mae: 0.1857 - val_loss: 1.2775 - val_mae: 0.7543\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0807 - mae: 0.1855 - val_loss: 1.2662 - val_mae: 0.7475\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0663 - mae: 0.1725 - val_loss: 1.3195 - val_mae: 0.7599\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0834 - mae: 0.1860 - val_loss: 1.2867 - val_mae: 0.7520\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0731 - mae: 0.1725 - val_loss: 1.2729 - val_mae: 0.7535\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0622 - mae: 0.1639 - val_loss: 1.2603 - val_mae: 0.7533\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0570 - mae: 0.1546 - val_loss: 1.2619 - val_mae: 0.7457\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0615 - mae: 0.1585 - val_loss: 1.2775 - val_mae: 0.7460\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0639 - mae: 0.1649 - val_loss: 1.2845 - val_mae: 0.7488\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0550 - mae: 0.1585 - val_loss: 1.2548 - val_mae: 0.7485\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0587 - mae: 0.1585 - val_loss: 1.2659 - val_mae: 0.7459\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0601 - mae: 0.1602 - val_loss: 1.2605 - val_mae: 0.7490\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0494 - mae: 0.1473 - val_loss: 1.2407 - val_mae: 0.7439\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0439 - mae: 0.1428 - val_loss: 1.2432 - val_mae: 0.7395\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0521 - mae: 0.1493 - val_loss: 1.2515 - val_mae: 0.7463\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0576 - mae: 0.1488 - val_loss: 1.2354 - val_mae: 0.7407\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0623 - mae: 0.1556 - val_loss: 1.2356 - val_mae: 0.7388\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0502 - mae: 0.1383 - val_loss: 1.2511 - val_mae: 0.7404\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0476 - mae: 0.1372 - val_loss: 1.2503 - val_mae: 0.7427\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0479 - mae: 0.1409 - val_loss: 1.2239 - val_mae: 0.7369\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0411 - mae: 0.1337 - val_loss: 1.2465 - val_mae: 0.7425\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0433 - mae: 0.1355 - val_loss: 1.2677 - val_mae: 0.7447\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0427 - mae: 0.1372 - val_loss: 1.2516 - val_mae: 0.7423\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0381 - mae: 0.1283 - val_loss: 1.2222 - val_mae: 0.7367\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0407 - mae: 0.1311 - val_loss: 1.2364 - val_mae: 0.7366\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0382 - mae: 0.1278 - val_loss: 1.2433 - val_mae: 0.7438\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0394 - mae: 0.1276 - val_loss: 1.2375 - val_mae: 0.7386\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0418 - mae: 0.1291 - val_loss: 1.2267 - val_mae: 0.7424\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0378 - mae: 0.1245 - val_loss: 1.2477 - val_mae: 0.7407\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0353 - mae: 0.1233 - val_loss: 1.2659 - val_mae: 0.7480\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0435 - mae: 0.1327 - val_loss: 1.2575 - val_mae: 0.7408\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0398 - mae: 0.1300 - val_loss: 1.2315 - val_mae: 0.7331\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0391 - mae: 0.1269 - val_loss: 1.2311 - val_mae: 0.7359\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0299 - mae: 0.1146 - val_loss: 1.2283 - val_mae: 0.7341\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0315 - mae: 0.1150 - val_loss: 1.2380 - val_mae: 0.7356\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0441 - mae: 0.1273 - val_loss: 1.2467 - val_mae: 0.7408\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0332 - mae: 0.1198 - val_loss: 1.2492 - val_mae: 0.7366\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0328 - mae: 0.1171 - val_loss: 1.2179 - val_mae: 0.7288\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0373 - mae: 0.1207 - val_loss: 1.2349 - val_mae: 0.7324\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0323 - mae: 0.1148 - val_loss: 1.2179 - val_mae: 0.7379\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.1118 - val_loss: 1.2348 - val_mae: 0.7359\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0325 - mae: 0.1138 - val_loss: 1.2186 - val_mae: 0.7308\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0291 - mae: 0.1098 - val_loss: 1.2396 - val_mae: 0.7373\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1105 - val_loss: 1.2508 - val_mae: 0.7410\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0288 - mae: 0.1108 - val_loss: 1.2536 - val_mae: 0.7390\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0272 - mae: 0.1096 - val_loss: 1.2109 - val_mae: 0.7243\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0247 - mae: 0.1051 - val_loss: 1.2566 - val_mae: 0.7395\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0256 - mae: 0.1064 - val_loss: 1.2278 - val_mae: 0.7328\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.1086 - val_loss: 1.2239 - val_mae: 0.7327\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0269 - mae: 0.1081 - val_loss: 1.2118 - val_mae: 0.7294\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0292 - mae: 0.1059 - val_loss: 1.2593 - val_mae: 0.7425\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0264 - mae: 0.1083 - val_loss: 1.2387 - val_mae: 0.7354\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0227 - mae: 0.0991 - val_loss: 1.2204 - val_mae: 0.7345\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0240 - mae: 0.1018 - val_loss: 1.2390 - val_mae: 0.7338\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0226 - mae: 0.1000 - val_loss: 1.2199 - val_mae: 0.7324\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0287 - mae: 0.1078 - val_loss: 1.2267 - val_mae: 0.7308\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0288 - mae: 0.1075 - val_loss: 1.2109 - val_mae: 0.7317\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0210 - mae: 0.0978 - val_loss: 1.2302 - val_mae: 0.7351\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0248 - mae: 0.0999 - val_loss: 1.2222 - val_mae: 0.7336\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0224 - mae: 0.0967 - val_loss: 1.2130 - val_mae: 0.7296\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0244 - mae: 0.0978 - val_loss: 1.2159 - val_mae: 0.7301\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0242 - mae: 0.0981 - val_loss: 1.2343 - val_mae: 0.7348\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0279 - mae: 0.0973 - val_loss: 1.2182 - val_mae: 0.7291\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0261 - mae: 0.1020 - val_loss: 1.2242 - val_mae: 0.7331\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0228 - mae: 0.0992 - val_loss: 1.2145 - val_mae: 0.7310\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0216 - mae: 0.0943 - val_loss: 1.2320 - val_mae: 0.7315\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0930 - val_loss: 1.2208 - val_mae: 0.7325\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0211 - mae: 0.0921 - val_loss: 1.2271 - val_mae: 0.7307\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0898 - val_loss: 1.2106 - val_mae: 0.7310\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0268 - mae: 0.1054 - val_loss: 1.2305 - val_mae: 0.7328\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0202 - mae: 0.0935 - val_loss: 1.2265 - val_mae: 0.7340\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0222 - mae: 0.0965 - val_loss: 1.2482 - val_mae: 0.7375\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0933 - val_loss: 1.2212 - val_mae: 0.7318\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0907 - val_loss: 1.2500 - val_mae: 0.7344\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0868 - val_loss: 1.2251 - val_mae: 0.7307\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0203 - mae: 0.0911 - val_loss: 1.2450 - val_mae: 0.7345\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0187 - mae: 0.0888 - val_loss: 1.2350 - val_mae: 0.7350\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0923 - val_loss: 1.2330 - val_mae: 0.7345\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0900 - val_loss: 1.2348 - val_mae: 0.7350\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0913 - val_loss: 1.2375 - val_mae: 0.7353\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0894 - val_loss: 1.2216 - val_mae: 0.7277\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0870 - val_loss: 1.2505 - val_mae: 0.7403\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0163 - mae: 0.0859 - val_loss: 1.2434 - val_mae: 0.7332\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0906 - val_loss: 1.2227 - val_mae: 0.7309\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0254 - mae: 0.0921 - val_loss: 1.2321 - val_mae: 0.7377\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0867 - val_loss: 1.2432 - val_mae: 0.7381\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0897 - val_loss: 1.2232 - val_mae: 0.7276\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0170 - mae: 0.0833 - val_loss: 1.2325 - val_mae: 0.7323\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0145 - mae: 0.0802 - val_loss: 1.2485 - val_mae: 0.7337\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0825 - val_loss: 1.2182 - val_mae: 0.7284\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0171 - mae: 0.0867 - val_loss: 1.2328 - val_mae: 0.7312\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0876 - val_loss: 1.2293 - val_mae: 0.7320\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0844 - val_loss: 1.2354 - val_mae: 0.7340\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0170 - mae: 0.0824 - val_loss: 1.2193 - val_mae: 0.7307\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0173 - mae: 0.0828 - val_loss: 1.2368 - val_mae: 0.7329\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0871 - val_loss: 1.2167 - val_mae: 0.7282\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0781 - val_loss: 1.2312 - val_mae: 0.7349\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0842 - val_loss: 1.2170 - val_mae: 0.7268\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0144 - mae: 0.0799 - val_loss: 1.2323 - val_mae: 0.7339\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0789 - val_loss: 1.2235 - val_mae: 0.7303\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0776 - val_loss: 1.2486 - val_mae: 0.7382\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0871 - val_loss: 1.2161 - val_mae: 0.7269\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0810 - val_loss: 1.2274 - val_mae: 0.7305\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0160 - mae: 0.0811 - val_loss: 1.2244 - val_mae: 0.7305\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0767 - val_loss: 1.2283 - val_mae: 0.7290\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0145 - mae: 0.0759 - val_loss: 1.2155 - val_mae: 0.7269\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0149 - mae: 0.0817 - val_loss: 1.2143 - val_mae: 0.7269\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0137 - mae: 0.0799 - val_loss: 1.2202 - val_mae: 0.7291\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0145 - mae: 0.0754 - val_loss: 1.2157 - val_mae: 0.7260\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0736 - val_loss: 1.2255 - val_mae: 0.7285\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0765 - val_loss: 1.2300 - val_mae: 0.7308\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0143 - mae: 0.0774 - val_loss: 1.2163 - val_mae: 0.7248\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0755 - val_loss: 1.2554 - val_mae: 0.7333\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0149 - mae: 0.0774 - val_loss: 1.2341 - val_mae: 0.7323\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0148 - mae: 0.0774 - val_loss: 1.2323 - val_mae: 0.7302\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0765 - val_loss: 1.2286 - val_mae: 0.7322\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.0799 - val_loss: 1.2164 - val_mae: 0.7272\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0763 - val_loss: 1.2149 - val_mae: 0.7265\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0741 - val_loss: 1.2281 - val_mae: 0.7326\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0711 - val_loss: 1.2199 - val_mae: 0.7295\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0136 - mae: 0.0723 - val_loss: 1.2267 - val_mae: 0.7305\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0770 - val_loss: 1.2150 - val_mae: 0.7266\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0136 - mae: 0.0757 - val_loss: 1.2246 - val_mae: 0.7325\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0150 - mae: 0.0750 - val_loss: 1.2302 - val_mae: 0.7316\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0723 - val_loss: 1.2210 - val_mae: 0.7280\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0742 - val_loss: 1.2510 - val_mae: 0.7382\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0704 - val_loss: 1.2228 - val_mae: 0.7301\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0745 - val_loss: 1.2260 - val_mae: 0.7322\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0725 - val_loss: 1.2340 - val_mae: 0.7353\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0125 - mae: 0.0732 - val_loss: 1.2259 - val_mae: 0.7313\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0704 - val_loss: 1.2368 - val_mae: 0.7328\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0721 - val_loss: 1.2369 - val_mae: 0.7333\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0736 - val_loss: 1.2394 - val_mae: 0.7349\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0718 - val_loss: 1.2168 - val_mae: 0.7287\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0121 - mae: 0.0707 - val_loss: 1.2415 - val_mae: 0.7346\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0707 - val_loss: 1.2264 - val_mae: 0.7313\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0722 - val_loss: 1.2459 - val_mae: 0.7388\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0727 - val_loss: 1.2268 - val_mae: 0.7296\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0693 - val_loss: 1.2241 - val_mae: 0.7323\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0697 - val_loss: 1.2438 - val_mae: 0.7395\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0692 - val_loss: 1.2314 - val_mae: 0.7344\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0723 - val_loss: 1.2240 - val_mae: 0.7320\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0705 - val_loss: 1.2152 - val_mae: 0.7297\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0662 - val_loss: 1.2312 - val_mae: 0.7325\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0696 - val_loss: 1.2282 - val_mae: 0.7297\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0105 - mae: 0.0680 - val_loss: 1.2366 - val_mae: 0.7367\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0714 - val_loss: 1.2221 - val_mae: 0.7330\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0716 - val_loss: 1.2499 - val_mae: 0.7387\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0737 - val_loss: 1.2347 - val_mae: 0.7363\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0109 - mae: 0.0665 - val_loss: 1.2281 - val_mae: 0.7345\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0641 - val_loss: 1.2227 - val_mae: 0.7327\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0676 - val_loss: 1.2212 - val_mae: 0.7299\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0656 - val_loss: 1.2315 - val_mae: 0.7314\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0096 - mae: 0.0665 - val_loss: 1.2266 - val_mae: 0.7304\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0701 - val_loss: 1.2296 - val_mae: 0.7327\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0113 - mae: 0.0669 - val_loss: 1.2341 - val_mae: 0.7357\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0658 - val_loss: 1.2361 - val_mae: 0.7335\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0103 - mae: 0.0663 - val_loss: 1.2211 - val_mae: 0.7338\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0677 - val_loss: 1.2499 - val_mae: 0.7373\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0101 - mae: 0.0655 - val_loss: 1.2242 - val_mae: 0.7308\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0684 - val_loss: 1.2422 - val_mae: 0.7350\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0646 - val_loss: 1.2302 - val_mae: 0.7315\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0708 - val_loss: 1.2268 - val_mae: 0.7326\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0107 - mae: 0.0643 - val_loss: 1.2330 - val_mae: 0.7324\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0097 - mae: 0.0634 - val_loss: 1.2300 - val_mae: 0.7317\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0668 - val_loss: 1.2411 - val_mae: 0.7350\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0114 - mae: 0.0685 - val_loss: 1.2259 - val_mae: 0.7340\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0109 - mae: 0.0643 - val_loss: 1.2220 - val_mae: 0.7295\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0612 - val_loss: 1.2337 - val_mae: 0.7372\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0673 - val_loss: 1.2300 - val_mae: 0.7326\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0108 - mae: 0.0643 - val_loss: 1.2220 - val_mae: 0.7340\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2975 - mae: 0.7569\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 6.2548 - mae: 1.7674 - val_loss: 1.9790 - val_mae: 0.9837\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 1.2247 - mae: 0.8073 - val_loss: 1.6368 - val_mae: 0.8773\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.8699 - mae: 0.6556 - val_loss: 1.5511 - val_mae: 0.8446\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.7473 - mae: 0.5815 - val_loss: 1.5370 - val_mae: 0.8428\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.4830 - mae: 0.4896 - val_loss: 1.5026 - val_mae: 0.8283\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.4425 - mae: 0.4545 - val_loss: 1.5350 - val_mae: 0.8377\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.3734 - mae: 0.4127 - val_loss: 1.5336 - val_mae: 0.8571\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.3130 - mae: 0.3879 - val_loss: 1.5180 - val_mae: 0.8088\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2991 - mae: 0.3595 - val_loss: 1.3860 - val_mae: 0.7897\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2478 - mae: 0.3300 - val_loss: 1.4187 - val_mae: 0.7783\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2351 - mae: 0.3194 - val_loss: 1.3450 - val_mae: 0.7832\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2114 - mae: 0.3085 - val_loss: 1.4048 - val_mae: 0.7844\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1751 - mae: 0.2857 - val_loss: 1.3668 - val_mae: 0.7750\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1895 - mae: 0.2783 - val_loss: 1.3210 - val_mae: 0.7585\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1816 - mae: 0.2804 - val_loss: 1.3662 - val_mae: 0.7615\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1518 - mae: 0.2618 - val_loss: 1.3182 - val_mae: 0.7605\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1550 - mae: 0.2572 - val_loss: 1.4110 - val_mae: 0.7721\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1570 - mae: 0.2533 - val_loss: 1.3554 - val_mae: 0.7603\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1298 - mae: 0.2409 - val_loss: 1.4384 - val_mae: 0.7877\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1294 - mae: 0.2305 - val_loss: 1.3497 - val_mae: 0.7552\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1012 - mae: 0.2143 - val_loss: 1.3200 - val_mae: 0.7508\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1244 - mae: 0.2279 - val_loss: 1.3572 - val_mae: 0.7587\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1180 - mae: 0.2239 - val_loss: 1.3375 - val_mae: 0.7524\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1127 - mae: 0.2151 - val_loss: 1.3396 - val_mae: 0.7515\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0846 - mae: 0.1957 - val_loss: 1.3026 - val_mae: 0.7392\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0869 - mae: 0.1975 - val_loss: 1.3065 - val_mae: 0.7533\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0934 - mae: 0.2001 - val_loss: 1.2991 - val_mae: 0.7362\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0982 - mae: 0.1923 - val_loss: 1.2857 - val_mae: 0.7498\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0724 - mae: 0.1830 - val_loss: 1.2965 - val_mae: 0.7424\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0917 - mae: 0.1974 - val_loss: 1.2742 - val_mae: 0.7298\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0697 - mae: 0.1785 - val_loss: 1.2895 - val_mae: 0.7357\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0698 - mae: 0.1753 - val_loss: 1.2888 - val_mae: 0.7369\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0725 - mae: 0.1723 - val_loss: 1.3095 - val_mae: 0.7410\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0778 - mae: 0.1768 - val_loss: 1.3003 - val_mae: 0.7379\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0615 - mae: 0.1692 - val_loss: 1.2705 - val_mae: 0.7349\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0652 - mae: 0.1726 - val_loss: 1.2638 - val_mae: 0.7313\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0690 - mae: 0.1718 - val_loss: 1.2776 - val_mae: 0.7317\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0562 - mae: 0.1583 - val_loss: 1.2778 - val_mae: 0.7306\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0597 - mae: 0.1600 - val_loss: 1.2613 - val_mae: 0.7246\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0763 - mae: 0.1605 - val_loss: 1.2838 - val_mae: 0.7267\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0541 - mae: 0.1543 - val_loss: 1.2707 - val_mae: 0.7308\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0622 - mae: 0.1647 - val_loss: 1.2620 - val_mae: 0.7249\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0544 - mae: 0.1554 - val_loss: 1.2563 - val_mae: 0.7195\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0489 - mae: 0.1442 - val_loss: 1.2571 - val_mae: 0.7252\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0470 - mae: 0.1440 - val_loss: 1.2435 - val_mae: 0.7286\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0459 - mae: 0.1431 - val_loss: 1.2664 - val_mae: 0.7232\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0540 - mae: 0.1500 - val_loss: 1.2829 - val_mae: 0.7305\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0490 - mae: 0.1450 - val_loss: 1.2683 - val_mae: 0.7274\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0507 - mae: 0.1453 - val_loss: 1.2469 - val_mae: 0.7136\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0477 - mae: 0.1380 - val_loss: 1.2575 - val_mae: 0.7269\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0388 - mae: 0.1284 - val_loss: 1.2346 - val_mae: 0.7182\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0415 - mae: 0.1363 - val_loss: 1.2499 - val_mae: 0.7194\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0437 - mae: 0.1363 - val_loss: 1.2320 - val_mae: 0.7136\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0390 - mae: 0.1309 - val_loss: 1.2520 - val_mae: 0.7188\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0460 - mae: 0.1367 - val_loss: 1.2547 - val_mae: 0.7118\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0418 - mae: 0.1284 - val_loss: 1.2522 - val_mae: 0.7187\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0374 - mae: 0.1271 - val_loss: 1.2685 - val_mae: 0.7199\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0364 - mae: 0.1270 - val_loss: 1.2477 - val_mae: 0.7159\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0360 - mae: 0.1255 - val_loss: 1.2496 - val_mae: 0.7131\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0369 - mae: 0.1247 - val_loss: 1.2637 - val_mae: 0.7161\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0350 - mae: 0.1245 - val_loss: 1.2524 - val_mae: 0.7199\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0378 - mae: 0.1298 - val_loss: 1.2440 - val_mae: 0.7135\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0352 - mae: 0.1208 - val_loss: 1.2448 - val_mae: 0.7138\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0334 - mae: 0.1173 - val_loss: 1.2456 - val_mae: 0.7159\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0314 - mae: 0.1195 - val_loss: 1.2184 - val_mae: 0.7093\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0347 - mae: 0.1225 - val_loss: 1.2517 - val_mae: 0.7161\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0354 - mae: 0.1198 - val_loss: 1.2443 - val_mae: 0.7138\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0358 - mae: 0.1179 - val_loss: 1.2694 - val_mae: 0.7207\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0363 - mae: 0.1228 - val_loss: 1.2545 - val_mae: 0.7123\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0332 - mae: 0.1184 - val_loss: 1.2318 - val_mae: 0.7067\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0295 - mae: 0.1123 - val_loss: 1.2680 - val_mae: 0.7131\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0362 - mae: 0.1155 - val_loss: 1.2268 - val_mae: 0.7051\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0311 - mae: 0.1142 - val_loss: 1.2428 - val_mae: 0.7072\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0273 - mae: 0.1107 - val_loss: 1.2395 - val_mae: 0.7154\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0329 - mae: 0.1135 - val_loss: 1.2203 - val_mae: 0.7071\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0300 - mae: 0.1123 - val_loss: 1.2425 - val_mae: 0.7120\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0280 - mae: 0.1095 - val_loss: 1.2284 - val_mae: 0.7053\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0273 - mae: 0.1073 - val_loss: 1.2315 - val_mae: 0.7081\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0276 - mae: 0.1050 - val_loss: 1.2335 - val_mae: 0.7080\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0302 - mae: 0.1116 - val_loss: 1.2385 - val_mae: 0.7101\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0304 - mae: 0.1090 - val_loss: 1.2305 - val_mae: 0.7167\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0347 - mae: 0.1175 - val_loss: 1.2300 - val_mae: 0.7043\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0253 - mae: 0.1010 - val_loss: 1.2259 - val_mae: 0.7077\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0329 - mae: 0.1136 - val_loss: 1.2448 - val_mae: 0.7097\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0305 - mae: 0.1075 - val_loss: 1.2335 - val_mae: 0.7071\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0274 - mae: 0.1076 - val_loss: 1.2498 - val_mae: 0.7137\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0291 - mae: 0.1033 - val_loss: 1.2543 - val_mae: 0.7159\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0270 - mae: 0.1039 - val_loss: 1.2436 - val_mae: 0.7097\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0252 - mae: 0.0994 - val_loss: 1.2306 - val_mae: 0.7065\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0260 - mae: 0.1007 - val_loss: 1.2384 - val_mae: 0.7079\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0240 - mae: 0.0982 - val_loss: 1.2464 - val_mae: 0.7099\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0225 - mae: 0.0969 - val_loss: 1.2499 - val_mae: 0.7093\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0242 - mae: 0.0963 - val_loss: 1.2292 - val_mae: 0.7129\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0274 - mae: 0.1099 - val_loss: 1.2503 - val_mae: 0.7097\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0304 - mae: 0.1071 - val_loss: 1.2529 - val_mae: 0.7100\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0268 - mae: 0.0990 - val_loss: 1.2418 - val_mae: 0.7150\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0211 - mae: 0.0963 - val_loss: 1.2497 - val_mae: 0.7095\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0230 - mae: 0.1005 - val_loss: 1.2783 - val_mae: 0.7140\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0240 - mae: 0.0969 - val_loss: 1.2424 - val_mae: 0.7085\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0281 - mae: 0.1018 - val_loss: 1.2341 - val_mae: 0.7088\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0253 - mae: 0.0952 - val_loss: 1.2318 - val_mae: 0.7061\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0200 - mae: 0.0903 - val_loss: 1.2398 - val_mae: 0.7075\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0210 - mae: 0.0936 - val_loss: 1.2487 - val_mae: 0.7056\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0203 - mae: 0.0922 - val_loss: 1.2419 - val_mae: 0.7098\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0219 - mae: 0.0952 - val_loss: 1.2413 - val_mae: 0.7180\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0228 - mae: 0.0984 - val_loss: 1.2408 - val_mae: 0.7085\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0330 - mae: 0.0949 - val_loss: 1.2372 - val_mae: 0.7049\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0175 - mae: 0.0863 - val_loss: 1.2295 - val_mae: 0.7050\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0885 - val_loss: 1.2457 - val_mae: 0.7074\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0237 - mae: 0.0940 - val_loss: 1.2306 - val_mae: 0.7061\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0182 - mae: 0.0865 - val_loss: 1.2534 - val_mae: 0.7120\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0220 - mae: 0.0902 - val_loss: 1.2459 - val_mae: 0.7101\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0197 - mae: 0.0904 - val_loss: 1.2415 - val_mae: 0.7088\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0185 - mae: 0.0884 - val_loss: 1.2383 - val_mae: 0.7093\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0191 - mae: 0.0861 - val_loss: 1.2370 - val_mae: 0.7080\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0174 - mae: 0.0835 - val_loss: 1.2389 - val_mae: 0.7057\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0211 - mae: 0.0918 - val_loss: 1.2554 - val_mae: 0.7100\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0182 - mae: 0.0870 - val_loss: 1.2507 - val_mae: 0.7129\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0225 - mae: 0.0857 - val_loss: 1.2493 - val_mae: 0.7068\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0216 - mae: 0.0891 - val_loss: 1.2356 - val_mae: 0.7096\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0233 - mae: 0.0942 - val_loss: 1.2513 - val_mae: 0.7074\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0183 - mae: 0.0883 - val_loss: 1.2411 - val_mae: 0.7113\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0209 - mae: 0.0903 - val_loss: 1.2432 - val_mae: 0.7080\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0193 - mae: 0.0865 - val_loss: 1.2644 - val_mae: 0.7142\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0183 - mae: 0.0845 - val_loss: 1.2359 - val_mae: 0.7036\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0218 - mae: 0.0834 - val_loss: 1.2361 - val_mae: 0.7058\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0173 - mae: 0.0845 - val_loss: 1.2392 - val_mae: 0.7029\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0164 - mae: 0.0796 - val_loss: 1.2525 - val_mae: 0.7074\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0173 - mae: 0.0854 - val_loss: 1.2401 - val_mae: 0.7046\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0806 - val_loss: 1.2655 - val_mae: 0.7163\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0204 - mae: 0.0886 - val_loss: 1.2320 - val_mae: 0.7020\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0236 - mae: 0.0867 - val_loss: 1.2514 - val_mae: 0.7038\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0176 - mae: 0.0828 - val_loss: 1.2305 - val_mae: 0.7009\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0856 - val_loss: 1.2549 - val_mae: 0.7087\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0211 - mae: 0.0880 - val_loss: 1.2518 - val_mae: 0.7054\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0158 - mae: 0.0799 - val_loss: 1.2445 - val_mae: 0.7094\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0186 - mae: 0.0858 - val_loss: 1.2452 - val_mae: 0.7068\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0190 - mae: 0.0800 - val_loss: 1.2577 - val_mae: 0.7125\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0159 - mae: 0.0814 - val_loss: 1.2509 - val_mae: 0.7086\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0169 - mae: 0.0836 - val_loss: 1.2358 - val_mae: 0.7065\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0181 - mae: 0.0846 - val_loss: 1.2384 - val_mae: 0.7076\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0157 - mae: 0.0803 - val_loss: 1.2501 - val_mae: 0.7069\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0162 - mae: 0.0829 - val_loss: 1.2469 - val_mae: 0.7069\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0135 - mae: 0.0752 - val_loss: 1.2505 - val_mae: 0.7091\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0151 - mae: 0.0787 - val_loss: 1.2512 - val_mae: 0.7104\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0798 - val_loss: 1.2420 - val_mae: 0.7121\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0171 - mae: 0.0846 - val_loss: 1.2586 - val_mae: 0.7107\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0802 - val_loss: 1.2473 - val_mae: 0.7073\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0177 - mae: 0.0798 - val_loss: 1.2450 - val_mae: 0.7078\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0216 - mae: 0.0775 - val_loss: 1.2559 - val_mae: 0.7086\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0195 - mae: 0.0779 - val_loss: 1.2437 - val_mae: 0.7065\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0758 - val_loss: 1.2383 - val_mae: 0.7066\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.0739 - val_loss: 1.2454 - val_mae: 0.7078\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0161 - mae: 0.0787 - val_loss: 1.2535 - val_mae: 0.7059\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0166 - mae: 0.0770 - val_loss: 1.2477 - val_mae: 0.7040\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0135 - mae: 0.0757 - val_loss: 1.2763 - val_mae: 0.7163\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0143 - mae: 0.0771 - val_loss: 1.2573 - val_mae: 0.7075\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0156 - mae: 0.0735 - val_loss: 1.2550 - val_mae: 0.7057\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0127 - mae: 0.0695 - val_loss: 1.2539 - val_mae: 0.7107\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0122 - mae: 0.0720 - val_loss: 1.2505 - val_mae: 0.7061\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0764 - val_loss: 1.2719 - val_mae: 0.7134\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0194 - mae: 0.0881 - val_loss: 1.2471 - val_mae: 0.7069\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0747 - val_loss: 1.2470 - val_mae: 0.7057\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0698 - val_loss: 1.2584 - val_mae: 0.7092\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0671 - val_loss: 1.2519 - val_mae: 0.7095\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0753 - val_loss: 1.2468 - val_mae: 0.7044\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0142 - mae: 0.0741 - val_loss: 1.2614 - val_mae: 0.7101\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0121 - mae: 0.0716 - val_loss: 1.2516 - val_mae: 0.7088\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0172 - mae: 0.0795 - val_loss: 1.2507 - val_mae: 0.7087\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0179 - mae: 0.0759 - val_loss: 1.2466 - val_mae: 0.7059\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0706 - val_loss: 1.2619 - val_mae: 0.7090\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0704 - val_loss: 1.2543 - val_mae: 0.7079\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0689 - val_loss: 1.2439 - val_mae: 0.7064\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0713 - val_loss: 1.2500 - val_mae: 0.7081\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0126 - mae: 0.0716 - val_loss: 1.2544 - val_mae: 0.7079\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0692 - val_loss: 1.2488 - val_mae: 0.7054\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0115 - mae: 0.0690 - val_loss: 1.2535 - val_mae: 0.7121\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0140 - mae: 0.0715 - val_loss: 1.2451 - val_mae: 0.7084\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0204 - mae: 0.0738 - val_loss: 1.2521 - val_mae: 0.7075\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0142 - mae: 0.0710 - val_loss: 1.2433 - val_mae: 0.7073\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.0697 - val_loss: 1.2595 - val_mae: 0.7143\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0103 - mae: 0.0650 - val_loss: 1.2502 - val_mae: 0.7048\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0134 - mae: 0.0697 - val_loss: 1.2503 - val_mae: 0.7094\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0128 - mae: 0.0713 - val_loss: 1.2429 - val_mae: 0.7078\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0141 - mae: 0.0689 - val_loss: 1.2602 - val_mae: 0.7095\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0107 - mae: 0.0689 - val_loss: 1.2485 - val_mae: 0.7088\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0723 - val_loss: 1.2334 - val_mae: 0.7036\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0657 - val_loss: 1.2447 - val_mae: 0.7087\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0141 - mae: 0.0721 - val_loss: 1.2422 - val_mae: 0.7061\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0118 - mae: 0.0659 - val_loss: 1.2336 - val_mae: 0.7061\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0123 - mae: 0.0667 - val_loss: 1.2386 - val_mae: 0.7040\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0115 - mae: 0.0673 - val_loss: 1.2512 - val_mae: 0.7086\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0119 - mae: 0.0649 - val_loss: 1.2353 - val_mae: 0.7033\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0117 - mae: 0.0682 - val_loss: 1.2484 - val_mae: 0.7085\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0664 - val_loss: 1.2445 - val_mae: 0.7071\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0652 - val_loss: 1.2500 - val_mae: 0.7057\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.0704 - val_loss: 1.2521 - val_mae: 0.7084\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0113 - mae: 0.0672 - val_loss: 1.2415 - val_mae: 0.7056\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0116 - mae: 0.0644 - val_loss: 1.2538 - val_mae: 0.7078\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0709 - val_loss: 1.2389 - val_mae: 0.7068\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2010 - mae: 0.7163\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 5.9675 - mae: 1.7350 - val_loss: 2.1370 - val_mae: 1.0313\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 1.2945 - mae: 0.8291 - val_loss: 1.8075 - val_mae: 0.9395\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.8627 - mae: 0.6729 - val_loss: 2.1770 - val_mae: 1.0354\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.7099 - mae: 0.5921 - val_loss: 1.5752 - val_mae: 0.8837\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.4686 - mae: 0.4828 - val_loss: 1.5877 - val_mae: 0.8600\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.3948 - mae: 0.4230 - val_loss: 1.5303 - val_mae: 0.8369\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.3441 - mae: 0.4026 - val_loss: 1.5884 - val_mae: 0.8446\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2808 - mae: 0.3498 - val_loss: 1.5524 - val_mae: 0.8359\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2309 - mae: 0.3310 - val_loss: 1.4691 - val_mae: 0.8287\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2233 - mae: 0.3250 - val_loss: 1.5865 - val_mae: 0.8436\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2713 - mae: 0.3334 - val_loss: 1.4241 - val_mae: 0.8033\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.2004 - mae: 0.2939 - val_loss: 1.4251 - val_mae: 0.8007\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1876 - mae: 0.2795 - val_loss: 1.3665 - val_mae: 0.7880\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1673 - mae: 0.2662 - val_loss: 1.3978 - val_mae: 0.7920\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1473 - mae: 0.2525 - val_loss: 1.4108 - val_mae: 0.7900\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1493 - mae: 0.2585 - val_loss: 1.3795 - val_mae: 0.7937\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1545 - mae: 0.2573 - val_loss: 1.3962 - val_mae: 0.7835\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1342 - mae: 0.2437 - val_loss: 1.3744 - val_mae: 0.7816\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1203 - mae: 0.2305 - val_loss: 1.3290 - val_mae: 0.7619\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1105 - mae: 0.2192 - val_loss: 1.3185 - val_mae: 0.7582\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1050 - mae: 0.2181 - val_loss: 1.3605 - val_mae: 0.7671\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1048 - mae: 0.2141 - val_loss: 1.3273 - val_mae: 0.7642\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1017 - mae: 0.2064 - val_loss: 1.3393 - val_mae: 0.7697\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1018 - mae: 0.2051 - val_loss: 1.3389 - val_mae: 0.7628\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0852 - mae: 0.1918 - val_loss: 1.3226 - val_mae: 0.7605\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0828 - mae: 0.1910 - val_loss: 1.3184 - val_mae: 0.7512\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0851 - mae: 0.1910 - val_loss: 1.2935 - val_mae: 0.7502\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0858 - mae: 0.1860 - val_loss: 1.3063 - val_mae: 0.7527\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0767 - mae: 0.1802 - val_loss: 1.3288 - val_mae: 0.7518\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0680 - mae: 0.1718 - val_loss: 1.3019 - val_mae: 0.7445\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0734 - mae: 0.1813 - val_loss: 1.3159 - val_mae: 0.7643\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0693 - mae: 0.1765 - val_loss: 1.2806 - val_mae: 0.7415\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0639 - mae: 0.1651 - val_loss: 1.2909 - val_mae: 0.7422\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0703 - mae: 0.1710 - val_loss: 1.2727 - val_mae: 0.7405\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0621 - mae: 0.1584 - val_loss: 1.3217 - val_mae: 0.7508\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0679 - mae: 0.1604 - val_loss: 1.2735 - val_mae: 0.7382\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0620 - mae: 0.1650 - val_loss: 1.2975 - val_mae: 0.7445\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0516 - mae: 0.1537 - val_loss: 1.2709 - val_mae: 0.7363\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0522 - mae: 0.1521 - val_loss: 1.3100 - val_mae: 0.7480\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0505 - mae: 0.1489 - val_loss: 1.2947 - val_mae: 0.7424\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0561 - mae: 0.1467 - val_loss: 1.2910 - val_mae: 0.7443\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0467 - mae: 0.1440 - val_loss: 1.2724 - val_mae: 0.7352\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0508 - mae: 0.1431 - val_loss: 1.2677 - val_mae: 0.7324\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0525 - mae: 0.1495 - val_loss: 1.3126 - val_mae: 0.7453\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0467 - mae: 0.1418 - val_loss: 1.2864 - val_mae: 0.7394\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0402 - mae: 0.1314 - val_loss: 1.2944 - val_mae: 0.7422\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0512 - mae: 0.1384 - val_loss: 1.2835 - val_mae: 0.7397\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0407 - mae: 0.1337 - val_loss: 1.2809 - val_mae: 0.7423\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0392 - mae: 0.1309 - val_loss: 1.2782 - val_mae: 0.7372\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0345 - mae: 0.1240 - val_loss: 1.2881 - val_mae: 0.7342\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0351 - mae: 0.1252 - val_loss: 1.2904 - val_mae: 0.7416\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0391 - mae: 0.1327 - val_loss: 1.2725 - val_mae: 0.7378\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0406 - mae: 0.1300 - val_loss: 1.2743 - val_mae: 0.7337\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0429 - mae: 0.1316 - val_loss: 1.2926 - val_mae: 0.7377\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0332 - mae: 0.1223 - val_loss: 1.3053 - val_mae: 0.7376\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0405 - mae: 0.1291 - val_loss: 1.2818 - val_mae: 0.7345\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0332 - mae: 0.1208 - val_loss: 1.2900 - val_mae: 0.7405\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0312 - mae: 0.1150 - val_loss: 1.2763 - val_mae: 0.7301\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0304 - mae: 0.1170 - val_loss: 1.2959 - val_mae: 0.7415\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0353 - mae: 0.1191 - val_loss: 1.2865 - val_mae: 0.7400\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0324 - mae: 0.1177 - val_loss: 1.3003 - val_mae: 0.7354\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0354 - mae: 0.1234 - val_loss: 1.2863 - val_mae: 0.7375\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0337 - mae: 0.1167 - val_loss: 1.2891 - val_mae: 0.7358\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0304 - mae: 0.1132 - val_loss: 1.2865 - val_mae: 0.7372\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0299 - mae: 0.1138 - val_loss: 1.2874 - val_mae: 0.7343\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0334 - mae: 0.1164 - val_loss: 1.2651 - val_mae: 0.7303\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0324 - mae: 0.1149 - val_loss: 1.2877 - val_mae: 0.7352\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0295 - mae: 0.1125 - val_loss: 1.2942 - val_mae: 0.7378\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0276 - mae: 0.1092 - val_loss: 1.2823 - val_mae: 0.7364\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0253 - mae: 0.1077 - val_loss: 1.2737 - val_mae: 0.7340\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0263 - mae: 0.1075 - val_loss: 1.2841 - val_mae: 0.7316\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0278 - mae: 0.1078 - val_loss: 1.2959 - val_mae: 0.7318\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0276 - mae: 0.1087 - val_loss: 1.2669 - val_mae: 0.7296\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0243 - mae: 0.1034 - val_loss: 1.2714 - val_mae: 0.7312\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0239 - mae: 0.1031 - val_loss: 1.3061 - val_mae: 0.7397\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0252 - mae: 0.1071 - val_loss: 1.2760 - val_mae: 0.7323\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0269 - mae: 0.1081 - val_loss: 1.2630 - val_mae: 0.7301\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0324 - mae: 0.1116 - val_loss: 1.2705 - val_mae: 0.7315\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0254 - mae: 0.1058 - val_loss: 1.2966 - val_mae: 0.7367\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0217 - mae: 0.1001 - val_loss: 1.2559 - val_mae: 0.7263\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0278 - mae: 0.1002 - val_loss: 1.2611 - val_mae: 0.7306\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0240 - mae: 0.1009 - val_loss: 1.2685 - val_mae: 0.7296\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0243 - mae: 0.1002 - val_loss: 1.2734 - val_mae: 0.7258\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0259 - mae: 0.1046 - val_loss: 1.2983 - val_mae: 0.7327\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0222 - mae: 0.1016 - val_loss: 1.2628 - val_mae: 0.7270\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0200 - mae: 0.0950 - val_loss: 1.2796 - val_mae: 0.7289\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0227 - mae: 0.0992 - val_loss: 1.2832 - val_mae: 0.7308\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0230 - mae: 0.1006 - val_loss: 1.2867 - val_mae: 0.7339\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0213 - mae: 0.0996 - val_loss: 1.2608 - val_mae: 0.7228\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0224 - mae: 0.0961 - val_loss: 1.2785 - val_mae: 0.7309\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0217 - mae: 0.0935 - val_loss: 1.2744 - val_mae: 0.7305\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0223 - mae: 0.0967 - val_loss: 1.2714 - val_mae: 0.7255\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0196 - mae: 0.0903 - val_loss: 1.2705 - val_mae: 0.7327\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0224 - mae: 0.0946 - val_loss: 1.2876 - val_mae: 0.7303\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0210 - mae: 0.0968 - val_loss: 1.2805 - val_mae: 0.7302\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0175 - mae: 0.0879 - val_loss: 1.2553 - val_mae: 0.7245\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0184 - mae: 0.0876 - val_loss: 1.2728 - val_mae: 0.7273\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0180 - mae: 0.0894 - val_loss: 1.2786 - val_mae: 0.7325\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0223 - mae: 0.0985 - val_loss: 1.2649 - val_mae: 0.7290\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0217 - mae: 0.0980 - val_loss: 1.2617 - val_mae: 0.7284\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0191 - mae: 0.0904 - val_loss: 1.2601 - val_mae: 0.7258\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0211 - mae: 0.0938 - val_loss: 1.2673 - val_mae: 0.7267\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0169 - mae: 0.0865 - val_loss: 1.2600 - val_mae: 0.7268\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0189 - mae: 0.0835 - val_loss: 1.2708 - val_mae: 0.7264\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0191 - mae: 0.0876 - val_loss: 1.2559 - val_mae: 0.7264\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0917 - val_loss: 1.2676 - val_mae: 0.7253\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0211 - mae: 0.0907 - val_loss: 1.2524 - val_mae: 0.7254\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0884 - val_loss: 1.2891 - val_mae: 0.7305\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0166 - mae: 0.0852 - val_loss: 1.2758 - val_mae: 0.7302\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0189 - mae: 0.0906 - val_loss: 1.2804 - val_mae: 0.7333\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0193 - mae: 0.0891 - val_loss: 1.2594 - val_mae: 0.7236\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0175 - mae: 0.0866 - val_loss: 1.2790 - val_mae: 0.7305\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0135 - mae: 0.0778 - val_loss: 1.2749 - val_mae: 0.7256\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0151 - mae: 0.0809 - val_loss: 1.2678 - val_mae: 0.7271\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0208 - mae: 0.0865 - val_loss: 1.2756 - val_mae: 0.7327\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0172 - mae: 0.0857 - val_loss: 1.2707 - val_mae: 0.7261\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0152 - mae: 0.0823 - val_loss: 1.2706 - val_mae: 0.7293\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0190 - mae: 0.0858 - val_loss: 1.2793 - val_mae: 0.7287\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0164 - mae: 0.0835 - val_loss: 1.2562 - val_mae: 0.7242\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0181 - mae: 0.0852 - val_loss: 1.2889 - val_mae: 0.7334\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0159 - mae: 0.0828 - val_loss: 1.2636 - val_mae: 0.7252\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0773 - val_loss: 1.2547 - val_mae: 0.7236\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0777 - val_loss: 1.2662 - val_mae: 0.7255\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0772 - val_loss: 1.2644 - val_mae: 0.7239\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0162 - mae: 0.0815 - val_loss: 1.2714 - val_mae: 0.7302\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0804 - val_loss: 1.2594 - val_mae: 0.7242\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0180 - mae: 0.0818 - val_loss: 1.2702 - val_mae: 0.7266\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0156 - mae: 0.0803 - val_loss: 1.2648 - val_mae: 0.7267\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0161 - mae: 0.0807 - val_loss: 1.2728 - val_mae: 0.7266\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0161 - mae: 0.0783 - val_loss: 1.2709 - val_mae: 0.7273\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0769 - val_loss: 1.2632 - val_mae: 0.7240\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0774 - val_loss: 1.2791 - val_mae: 0.7281\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0137 - mae: 0.0765 - val_loss: 1.2776 - val_mae: 0.7247\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0783 - val_loss: 1.2733 - val_mae: 0.7280\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0130 - mae: 0.0756 - val_loss: 1.2770 - val_mae: 0.7258\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0150 - mae: 0.0784 - val_loss: 1.2863 - val_mae: 0.7316\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0136 - mae: 0.0760 - val_loss: 1.2662 - val_mae: 0.7227\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0773 - val_loss: 1.2759 - val_mae: 0.7278\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.0770 - val_loss: 1.2656 - val_mae: 0.7215\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0156 - mae: 0.0739 - val_loss: 1.2842 - val_mae: 0.7285\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0123 - mae: 0.0729 - val_loss: 1.2740 - val_mae: 0.7273\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0762 - val_loss: 1.2674 - val_mae: 0.7220\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0752 - val_loss: 1.2699 - val_mae: 0.7252\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0782 - val_loss: 1.2897 - val_mae: 0.7302\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0134 - mae: 0.0761 - val_loss: 1.2661 - val_mae: 0.7254\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0716 - val_loss: 1.2759 - val_mae: 0.7278\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0134 - mae: 0.0732 - val_loss: 1.2759 - val_mae: 0.7278\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0130 - mae: 0.0708 - val_loss: 1.2643 - val_mae: 0.7233\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0138 - mae: 0.0731 - val_loss: 1.2709 - val_mae: 0.7267\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0732 - val_loss: 1.2700 - val_mae: 0.7274\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0116 - mae: 0.0707 - val_loss: 1.2667 - val_mae: 0.7249\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0157 - mae: 0.0717 - val_loss: 1.2730 - val_mae: 0.7264\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0137 - mae: 0.0728 - val_loss: 1.2700 - val_mae: 0.7274\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0717 - val_loss: 1.2880 - val_mae: 0.7298\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0723 - val_loss: 1.2927 - val_mae: 0.7314\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0142 - mae: 0.0746 - val_loss: 1.2681 - val_mae: 0.7267\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0177 - mae: 0.0735 - val_loss: 1.2712 - val_mae: 0.7231\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0686 - val_loss: 1.2743 - val_mae: 0.7248\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0111 - mae: 0.0705 - val_loss: 1.2944 - val_mae: 0.7279\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0137 - mae: 0.0717 - val_loss: 1.2725 - val_mae: 0.7232\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0122 - mae: 0.0705 - val_loss: 1.2958 - val_mae: 0.7306\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0114 - mae: 0.0678 - val_loss: 1.2789 - val_mae: 0.7292\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0142 - mae: 0.0771 - val_loss: 1.2712 - val_mae: 0.7261\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0133 - mae: 0.0720 - val_loss: 1.2782 - val_mae: 0.7253\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0117 - mae: 0.0710 - val_loss: 1.2822 - val_mae: 0.7263\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0125 - mae: 0.0695 - val_loss: 1.2818 - val_mae: 0.7288\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0107 - mae: 0.0678 - val_loss: 1.2762 - val_mae: 0.7272\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0104 - mae: 0.0651 - val_loss: 1.2820 - val_mae: 0.7301\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0111 - mae: 0.0690 - val_loss: 1.2791 - val_mae: 0.7248\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0723 - val_loss: 1.2807 - val_mae: 0.7291\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0687 - val_loss: 1.2712 - val_mae: 0.7251\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0097 - mae: 0.0657 - val_loss: 1.2660 - val_mae: 0.7242\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0668 - val_loss: 1.2866 - val_mae: 0.7303\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0098 - mae: 0.0646 - val_loss: 1.2730 - val_mae: 0.7283\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0109 - mae: 0.0674 - val_loss: 1.2848 - val_mae: 0.7304\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0096 - mae: 0.0627 - val_loss: 1.2784 - val_mae: 0.7291\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0694 - val_loss: 1.2841 - val_mae: 0.7287\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0117 - mae: 0.0695 - val_loss: 1.2755 - val_mae: 0.7315\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0690 - val_loss: 1.2781 - val_mae: 0.7262\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0098 - mae: 0.0632 - val_loss: 1.2720 - val_mae: 0.7288\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0654 - val_loss: 1.2694 - val_mae: 0.7267\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0103 - mae: 0.0653 - val_loss: 1.2673 - val_mae: 0.7238\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0670 - val_loss: 1.2796 - val_mae: 0.7282\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0120 - mae: 0.0684 - val_loss: 1.2748 - val_mae: 0.7261\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0098 - mae: 0.0619 - val_loss: 1.2882 - val_mae: 0.7304\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0100 - mae: 0.0644 - val_loss: 1.2714 - val_mae: 0.7269\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0659 - val_loss: 1.2751 - val_mae: 0.7248\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0102 - mae: 0.0638 - val_loss: 1.2686 - val_mae: 0.7276\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0103 - mae: 0.0638 - val_loss: 1.2702 - val_mae: 0.7286\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0100 - mae: 0.0632 - val_loss: 1.2685 - val_mae: 0.7263\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0636 - val_loss: 1.2752 - val_mae: 0.7260\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0128 - mae: 0.0691 - val_loss: 1.2781 - val_mae: 0.7278\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0100 - mae: 0.0628 - val_loss: 1.2750 - val_mae: 0.7254\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0620 - val_loss: 1.2713 - val_mae: 0.7270\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0135 - mae: 0.0643 - val_loss: 1.2739 - val_mae: 0.7273\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0142 - mae: 0.0661 - val_loss: 1.2840 - val_mae: 0.7301\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0093 - mae: 0.0629 - val_loss: 1.2774 - val_mae: 0.7286\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0094 - mae: 0.0657 - val_loss: 1.2946 - val_mae: 0.7328\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0088 - mae: 0.0634 - val_loss: 1.2872 - val_mae: 0.7298\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0130 - mae: 0.0663 - val_loss: 1.2774 - val_mae: 0.7294\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2055 - mae: 0.7218\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 6.9086 - mae: 1.8885 - val_loss: 2.2512 - val_mae: 1.0783\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 1.3589 - mae: 0.8475 - val_loss: 1.8138 - val_mae: 0.9704\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.8333 - mae: 0.6555 - val_loss: 1.7012 - val_mae: 0.9290\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.5862 - mae: 0.5411 - val_loss: 1.6233 - val_mae: 0.8956\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.4905 - mae: 0.4763 - val_loss: 1.5873 - val_mae: 0.8867\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.3789 - mae: 0.4181 - val_loss: 1.5739 - val_mae: 0.9017\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.3525 - mae: 0.3893 - val_loss: 1.6604 - val_mae: 0.8947\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2971 - mae: 0.3687 - val_loss: 1.5541 - val_mae: 0.8615\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2712 - mae: 0.3413 - val_loss: 1.4707 - val_mae: 0.8367\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2671 - mae: 0.3288 - val_loss: 1.5082 - val_mae: 0.8473\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2208 - mae: 0.3219 - val_loss: 1.4920 - val_mae: 0.8273\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2276 - mae: 0.3032 - val_loss: 1.4203 - val_mae: 0.8283\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2170 - mae: 0.2917 - val_loss: 1.4182 - val_mae: 0.8069\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1659 - mae: 0.2650 - val_loss: 1.3580 - val_mae: 0.7941\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1646 - mae: 0.2544 - val_loss: 1.3828 - val_mae: 0.7977\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1346 - mae: 0.2391 - val_loss: 1.4092 - val_mae: 0.8042\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1343 - mae: 0.2381 - val_loss: 1.4624 - val_mae: 0.8153\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1259 - mae: 0.2349 - val_loss: 1.3948 - val_mae: 0.7938\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1338 - mae: 0.2294 - val_loss: 1.3865 - val_mae: 0.7960\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1025 - mae: 0.2123 - val_loss: 1.3523 - val_mae: 0.7861\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1018 - mae: 0.2112 - val_loss: 1.3859 - val_mae: 0.7890\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0982 - mae: 0.2048 - val_loss: 1.3351 - val_mae: 0.7864\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1009 - mae: 0.2064 - val_loss: 1.3175 - val_mae: 0.7711\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1063 - mae: 0.2084 - val_loss: 1.3017 - val_mae: 0.7736\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0934 - mae: 0.1990 - val_loss: 1.3304 - val_mae: 0.7717\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0963 - mae: 0.1993 - val_loss: 1.3183 - val_mae: 0.7691\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0804 - mae: 0.1828 - val_loss: 1.3254 - val_mae: 0.7752\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0734 - mae: 0.1858 - val_loss: 1.3007 - val_mae: 0.7586\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0777 - mae: 0.1736 - val_loss: 1.3140 - val_mae: 0.7622\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0689 - mae: 0.1691 - val_loss: 1.2743 - val_mae: 0.7545\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0640 - mae: 0.1638 - val_loss: 1.2879 - val_mae: 0.7557\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0727 - mae: 0.1704 - val_loss: 1.2844 - val_mae: 0.7534\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0570 - mae: 0.1548 - val_loss: 1.2894 - val_mae: 0.7558\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0655 - mae: 0.1649 - val_loss: 1.2781 - val_mae: 0.7571\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0598 - mae: 0.1601 - val_loss: 1.3496 - val_mae: 0.7735\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0719 - mae: 0.1719 - val_loss: 1.2865 - val_mae: 0.7549\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0533 - mae: 0.1497 - val_loss: 1.2938 - val_mae: 0.7583\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0519 - mae: 0.1474 - val_loss: 1.2874 - val_mae: 0.7578\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0555 - mae: 0.1492 - val_loss: 1.2861 - val_mae: 0.7501\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0488 - mae: 0.1428 - val_loss: 1.2764 - val_mae: 0.7502\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0507 - mae: 0.1417 - val_loss: 1.2716 - val_mae: 0.7516\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0542 - mae: 0.1430 - val_loss: 1.2584 - val_mae: 0.7504\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0508 - mae: 0.1438 - val_loss: 1.2727 - val_mae: 0.7478\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0436 - mae: 0.1315 - val_loss: 1.2945 - val_mae: 0.7582\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0436 - mae: 0.1346 - val_loss: 1.2652 - val_mae: 0.7468\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0486 - mae: 0.1365 - val_loss: 1.2646 - val_mae: 0.7449\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0385 - mae: 0.1285 - val_loss: 1.2829 - val_mae: 0.7538\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0491 - mae: 0.1417 - val_loss: 1.2413 - val_mae: 0.7403\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0367 - mae: 0.1273 - val_loss: 1.2890 - val_mae: 0.7502\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0409 - mae: 0.1286 - val_loss: 1.2662 - val_mae: 0.7490\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0424 - mae: 0.1274 - val_loss: 1.2598 - val_mae: 0.7497\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0399 - mae: 0.1270 - val_loss: 1.2640 - val_mae: 0.7483\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0426 - mae: 0.1331 - val_loss: 1.2403 - val_mae: 0.7411\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0430 - mae: 0.1308 - val_loss: 1.2544 - val_mae: 0.7429\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0341 - mae: 0.1187 - val_loss: 1.2869 - val_mae: 0.7519\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0444 - mae: 0.1310 - val_loss: 1.2717 - val_mae: 0.7480\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0320 - mae: 0.1201 - val_loss: 1.2725 - val_mae: 0.7528\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0373 - mae: 0.1245 - val_loss: 1.2712 - val_mae: 0.7460\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0319 - mae: 0.1155 - val_loss: 1.2493 - val_mae: 0.7370\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0347 - mae: 0.1178 - val_loss: 1.2764 - val_mae: 0.7474\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0303 - mae: 0.1140 - val_loss: 1.2517 - val_mae: 0.7401\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0291 - mae: 0.1108 - val_loss: 1.2535 - val_mae: 0.7411\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0286 - mae: 0.1118 - val_loss: 1.2618 - val_mae: 0.7416\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0346 - mae: 0.1154 - val_loss: 1.2473 - val_mae: 0.7377\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0373 - mae: 0.1112 - val_loss: 1.2471 - val_mae: 0.7383\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0292 - mae: 0.1112 - val_loss: 1.2355 - val_mae: 0.7340\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0295 - mae: 0.1113 - val_loss: 1.2337 - val_mae: 0.7364\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0279 - mae: 0.1089 - val_loss: 1.2437 - val_mae: 0.7387\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0277 - mae: 0.1069 - val_loss: 1.2442 - val_mae: 0.7357\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0271 - mae: 0.1050 - val_loss: 1.2467 - val_mae: 0.7433\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0281 - mae: 0.1053 - val_loss: 1.2457 - val_mae: 0.7390\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0257 - mae: 0.1021 - val_loss: 1.2403 - val_mae: 0.7386\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0253 - mae: 0.1048 - val_loss: 1.2399 - val_mae: 0.7367\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0256 - mae: 0.1025 - val_loss: 1.2346 - val_mae: 0.7377\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0232 - mae: 0.1008 - val_loss: 1.2367 - val_mae: 0.7348\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0232 - mae: 0.0988 - val_loss: 1.2321 - val_mae: 0.7357\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0248 - mae: 0.1010 - val_loss: 1.2293 - val_mae: 0.7293\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0238 - mae: 0.0996 - val_loss: 1.2544 - val_mae: 0.7394\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0244 - mae: 0.1009 - val_loss: 1.2431 - val_mae: 0.7367\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0246 - mae: 0.1020 - val_loss: 1.2335 - val_mae: 0.7332\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0234 - mae: 0.0949 - val_loss: 1.2382 - val_mae: 0.7382\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0262 - mae: 0.1008 - val_loss: 1.2344 - val_mae: 0.7326\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0199 - mae: 0.0932 - val_loss: 1.2768 - val_mae: 0.7429\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0241 - mae: 0.1001 - val_loss: 1.2488 - val_mae: 0.7372\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0263 - mae: 0.0990 - val_loss: 1.2544 - val_mae: 0.7348\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0214 - mae: 0.0945 - val_loss: 1.2391 - val_mae: 0.7325\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0180 - mae: 0.0868 - val_loss: 1.2475 - val_mae: 0.7369\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0253 - mae: 0.0972 - val_loss: 1.2388 - val_mae: 0.7390\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0233 - mae: 0.0947 - val_loss: 1.2369 - val_mae: 0.7334\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0229 - mae: 0.0934 - val_loss: 1.2437 - val_mae: 0.7338\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0206 - mae: 0.0890 - val_loss: 1.2323 - val_mae: 0.7323\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0195 - mae: 0.0894 - val_loss: 1.2488 - val_mae: 0.7370\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0218 - mae: 0.0909 - val_loss: 1.2305 - val_mae: 0.7318\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0218 - mae: 0.0955 - val_loss: 1.2561 - val_mae: 0.7424\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0889 - val_loss: 1.2394 - val_mae: 0.7325\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0895 - val_loss: 1.2453 - val_mae: 0.7334\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0211 - mae: 0.0929 - val_loss: 1.2448 - val_mae: 0.7342\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0189 - mae: 0.0866 - val_loss: 1.2336 - val_mae: 0.7338\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0168 - mae: 0.0824 - val_loss: 1.2407 - val_mae: 0.7364\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0186 - mae: 0.0890 - val_loss: 1.2315 - val_mae: 0.7295\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0203 - mae: 0.0893 - val_loss: 1.2530 - val_mae: 0.7398\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0210 - mae: 0.0888 - val_loss: 1.2309 - val_mae: 0.7325\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0789 - val_loss: 1.2395 - val_mae: 0.7333\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0166 - mae: 0.0812 - val_loss: 1.2368 - val_mae: 0.7345\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0170 - mae: 0.0801 - val_loss: 1.2387 - val_mae: 0.7345\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0186 - mae: 0.0855 - val_loss: 1.2510 - val_mae: 0.7352\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0170 - mae: 0.0827 - val_loss: 1.2536 - val_mae: 0.7347\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0177 - mae: 0.0816 - val_loss: 1.2436 - val_mae: 0.7359\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0799 - val_loss: 1.2421 - val_mae: 0.7342\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0161 - mae: 0.0810 - val_loss: 1.2510 - val_mae: 0.7343\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0205 - mae: 0.0857 - val_loss: 1.2382 - val_mae: 0.7375\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0185 - mae: 0.0867 - val_loss: 1.2523 - val_mae: 0.7396\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0141 - mae: 0.0770 - val_loss: 1.2540 - val_mae: 0.7375\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0152 - mae: 0.0757 - val_loss: 1.2607 - val_mae: 0.7368\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0139 - mae: 0.0747 - val_loss: 1.2433 - val_mae: 0.7396\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0157 - mae: 0.0771 - val_loss: 1.2433 - val_mae: 0.7388\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0145 - mae: 0.0799 - val_loss: 1.2578 - val_mae: 0.7429\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0166 - mae: 0.0840 - val_loss: 1.2441 - val_mae: 0.7368\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0163 - mae: 0.0817 - val_loss: 1.2418 - val_mae: 0.7326\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0140 - mae: 0.0760 - val_loss: 1.2363 - val_mae: 0.7359\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0168 - mae: 0.0794 - val_loss: 1.2419 - val_mae: 0.7371\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0156 - mae: 0.0760 - val_loss: 1.2472 - val_mae: 0.7360\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0168 - mae: 0.0777 - val_loss: 1.2453 - val_mae: 0.7348\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0771 - val_loss: 1.2340 - val_mae: 0.7381\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0785 - val_loss: 1.2470 - val_mae: 0.7380\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0166 - mae: 0.0788 - val_loss: 1.2459 - val_mae: 0.7356\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0140 - mae: 0.0758 - val_loss: 1.2475 - val_mae: 0.7345\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0750 - val_loss: 1.2350 - val_mae: 0.7320\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0143 - mae: 0.0779 - val_loss: 1.2307 - val_mae: 0.7348\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0123 - mae: 0.0717 - val_loss: 1.2434 - val_mae: 0.7338\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0133 - mae: 0.0730 - val_loss: 1.2261 - val_mae: 0.7306\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0141 - mae: 0.0748 - val_loss: 1.2317 - val_mae: 0.7346\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0171 - mae: 0.0785 - val_loss: 1.2332 - val_mae: 0.7320\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0726 - val_loss: 1.2301 - val_mae: 0.7319\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0157 - mae: 0.0776 - val_loss: 1.2387 - val_mae: 0.7323\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0717 - val_loss: 1.2330 - val_mae: 0.7343\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0115 - mae: 0.0690 - val_loss: 1.2442 - val_mae: 0.7343\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0133 - mae: 0.0710 - val_loss: 1.2331 - val_mae: 0.7328\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0126 - mae: 0.0706 - val_loss: 1.2428 - val_mae: 0.7356\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0706 - val_loss: 1.2353 - val_mae: 0.7322\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0694 - val_loss: 1.2421 - val_mae: 0.7363\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0724 - val_loss: 1.2458 - val_mae: 0.7355\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0158 - mae: 0.0746 - val_loss: 1.2220 - val_mae: 0.7336\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0736 - val_loss: 1.2378 - val_mae: 0.7339\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0127 - mae: 0.0686 - val_loss: 1.2372 - val_mae: 0.7326\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0114 - mae: 0.0686 - val_loss: 1.2371 - val_mae: 0.7342\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0111 - mae: 0.0682 - val_loss: 1.2258 - val_mae: 0.7370\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.0704 - val_loss: 1.2432 - val_mae: 0.7365\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0152 - mae: 0.0745 - val_loss: 1.2367 - val_mae: 0.7338\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0662 - val_loss: 1.2475 - val_mae: 0.7348\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0116 - mae: 0.0700 - val_loss: 1.2273 - val_mae: 0.7317\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0112 - mae: 0.0669 - val_loss: 1.2359 - val_mae: 0.7372\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0144 - mae: 0.0717 - val_loss: 1.2436 - val_mae: 0.7361\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0700 - val_loss: 1.2523 - val_mae: 0.7369\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0105 - mae: 0.0672 - val_loss: 1.2439 - val_mae: 0.7366\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0710 - val_loss: 1.2434 - val_mae: 0.7359\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0111 - mae: 0.0667 - val_loss: 1.2532 - val_mae: 0.7386\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0145 - mae: 0.0706 - val_loss: 1.2254 - val_mae: 0.7304\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0676 - val_loss: 1.2408 - val_mae: 0.7339\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0115 - mae: 0.0632 - val_loss: 1.2260 - val_mae: 0.7296\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0110 - mae: 0.0639 - val_loss: 1.2449 - val_mae: 0.7359\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0122 - mae: 0.0672 - val_loss: 1.2397 - val_mae: 0.7324\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0123 - mae: 0.0668 - val_loss: 1.2345 - val_mae: 0.7313\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0102 - mae: 0.0643 - val_loss: 1.2301 - val_mae: 0.7332\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0127 - mae: 0.0661 - val_loss: 1.2360 - val_mae: 0.7337\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0647 - val_loss: 1.2319 - val_mae: 0.7332\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0116 - mae: 0.0655 - val_loss: 1.2291 - val_mae: 0.7334\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0132 - mae: 0.0688 - val_loss: 1.2443 - val_mae: 0.7350\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0102 - mae: 0.0647 - val_loss: 1.2283 - val_mae: 0.7340\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0103 - mae: 0.0649 - val_loss: 1.2520 - val_mae: 0.7368\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0648 - val_loss: 1.2508 - val_mae: 0.7361\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0643 - val_loss: 1.2346 - val_mae: 0.7328\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0103 - mae: 0.0635 - val_loss: 1.2362 - val_mae: 0.7350\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0093 - mae: 0.0617 - val_loss: 1.2414 - val_mae: 0.7357\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0090 - mae: 0.0609 - val_loss: 1.2466 - val_mae: 0.7341\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0095 - mae: 0.0629 - val_loss: 1.2291 - val_mae: 0.7351\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0115 - mae: 0.0653 - val_loss: 1.2378 - val_mae: 0.7335\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0107 - mae: 0.0635 - val_loss: 1.2333 - val_mae: 0.7337\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0097 - mae: 0.0629 - val_loss: 1.2370 - val_mae: 0.7329\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0104 - mae: 0.0644 - val_loss: 1.2341 - val_mae: 0.7353\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0095 - mae: 0.0615 - val_loss: 1.2288 - val_mae: 0.7326\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0091 - mae: 0.0604 - val_loss: 1.2364 - val_mae: 0.7346\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0581 - val_loss: 1.2391 - val_mae: 0.7342\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0094 - mae: 0.0601 - val_loss: 1.2412 - val_mae: 0.7357\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0095 - mae: 0.0598 - val_loss: 1.2356 - val_mae: 0.7348\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0096 - mae: 0.0614 - val_loss: 1.2370 - val_mae: 0.7326\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0087 - mae: 0.0603 - val_loss: 1.2489 - val_mae: 0.7372\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0089 - mae: 0.0607 - val_loss: 1.2430 - val_mae: 0.7354\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0086 - mae: 0.0603 - val_loss: 1.2431 - val_mae: 0.7374\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0672 - val_loss: 1.2425 - val_mae: 0.7354\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0093 - mae: 0.0614 - val_loss: 1.2407 - val_mae: 0.7354\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0108 - mae: 0.0614 - val_loss: 1.2432 - val_mae: 0.7341\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0094 - mae: 0.0563 - val_loss: 1.2442 - val_mae: 0.7367\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0104 - mae: 0.0589 - val_loss: 1.2546 - val_mae: 0.7399\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0092 - mae: 0.0612 - val_loss: 1.2452 - val_mae: 0.7384\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0100 - mae: 0.0639 - val_loss: 1.2595 - val_mae: 0.7362\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0100 - mae: 0.0663 - val_loss: 1.2412 - val_mae: 0.7370\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0089 - mae: 0.0587 - val_loss: 1.2493 - val_mae: 0.7367\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0089 - mae: 0.0567 - val_loss: 1.2407 - val_mae: 0.7331\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0110 - mae: 0.0594 - val_loss: 1.2516 - val_mae: 0.7379\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2770 - mae: 0.7592\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 6.8051 - mae: 1.7931 - val_loss: 1.9942 - val_mae: 1.0204\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 1.1639 - mae: 0.7724 - val_loss: 1.6671 - val_mae: 0.9077\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.7669 - mae: 0.6176 - val_loss: 1.6639 - val_mae: 0.8818\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.6067 - mae: 0.5466 - val_loss: 1.6688 - val_mae: 0.8834\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.4889 - mae: 0.4877 - val_loss: 1.5950 - val_mae: 0.8569\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.4039 - mae: 0.4385 - val_loss: 1.6060 - val_mae: 0.8524\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.3650 - mae: 0.4125 - val_loss: 1.5001 - val_mae: 0.8418\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.3157 - mae: 0.3831 - val_loss: 1.5399 - val_mae: 0.8279\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2819 - mae: 0.3594 - val_loss: 1.4681 - val_mae: 0.8223\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.2390 - mae: 0.3406 - val_loss: 1.5240 - val_mae: 0.8236\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2112 - mae: 0.3144 - val_loss: 1.4950 - val_mae: 0.8179\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.2255 - mae: 0.3203 - val_loss: 1.5056 - val_mae: 0.8201\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1844 - mae: 0.2903 - val_loss: 1.4929 - val_mae: 0.8065\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1825 - mae: 0.2874 - val_loss: 1.4764 - val_mae: 0.7992\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1840 - mae: 0.2851 - val_loss: 1.4602 - val_mae: 0.8003\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1489 - mae: 0.2651 - val_loss: 1.4009 - val_mae: 0.7884\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1360 - mae: 0.2480 - val_loss: 1.4664 - val_mae: 0.7888\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1354 - mae: 0.2474 - val_loss: 1.4205 - val_mae: 0.7885\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1274 - mae: 0.2420 - val_loss: 1.4814 - val_mae: 0.7997\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1377 - mae: 0.2488 - val_loss: 1.4231 - val_mae: 0.7819\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1119 - mae: 0.2245 - val_loss: 1.4001 - val_mae: 0.7797\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1121 - mae: 0.2227 - val_loss: 1.4340 - val_mae: 0.7975\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1011 - mae: 0.2162 - val_loss: 1.4005 - val_mae: 0.7757\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0958 - mae: 0.2148 - val_loss: 1.3935 - val_mae: 0.7768\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.1078 - mae: 0.2136 - val_loss: 1.4133 - val_mae: 0.7703\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.1034 - mae: 0.2113 - val_loss: 1.4060 - val_mae: 0.7735\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.1063 - mae: 0.2021 - val_loss: 1.4053 - val_mae: 0.7727\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0741 - mae: 0.1801 - val_loss: 1.3652 - val_mae: 0.7584\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0907 - mae: 0.1891 - val_loss: 1.3964 - val_mae: 0.7691\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0951 - mae: 0.2017 - val_loss: 1.3873 - val_mae: 0.7684\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0791 - mae: 0.1878 - val_loss: 1.3994 - val_mae: 0.7644\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0736 - mae: 0.1759 - val_loss: 1.3513 - val_mae: 0.7625\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0662 - mae: 0.1684 - val_loss: 1.3946 - val_mae: 0.7685\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0617 - mae: 0.1682 - val_loss: 1.3914 - val_mae: 0.7670\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0615 - mae: 0.1670 - val_loss: 1.3916 - val_mae: 0.7590\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0655 - mae: 0.1676 - val_loss: 1.3707 - val_mae: 0.7685\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0660 - mae: 0.1690 - val_loss: 1.3641 - val_mae: 0.7585\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0659 - mae: 0.1669 - val_loss: 1.3568 - val_mae: 0.7492\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0544 - mae: 0.1570 - val_loss: 1.3709 - val_mae: 0.7587\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0600 - mae: 0.1575 - val_loss: 1.3682 - val_mae: 0.7504\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0579 - mae: 0.1537 - val_loss: 1.3399 - val_mae: 0.7461\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0482 - mae: 0.1488 - val_loss: 1.3571 - val_mae: 0.7487\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0603 - mae: 0.1564 - val_loss: 1.3404 - val_mae: 0.7492\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0600 - mae: 0.1508 - val_loss: 1.4173 - val_mae: 0.7679\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0468 - mae: 0.1433 - val_loss: 1.3739 - val_mae: 0.7520\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0518 - mae: 0.1480 - val_loss: 1.3442 - val_mae: 0.7517\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0471 - mae: 0.1426 - val_loss: 1.3558 - val_mae: 0.7519\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0473 - mae: 0.1408 - val_loss: 1.3560 - val_mae: 0.7479\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0418 - mae: 0.1376 - val_loss: 1.3416 - val_mae: 0.7436\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0413 - mae: 0.1328 - val_loss: 1.3521 - val_mae: 0.7437\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0416 - mae: 0.1341 - val_loss: 1.3298 - val_mae: 0.7451\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0446 - mae: 0.1357 - val_loss: 1.3481 - val_mae: 0.7434\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0405 - mae: 0.1332 - val_loss: 1.3442 - val_mae: 0.7454\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0406 - mae: 0.1337 - val_loss: 1.3451 - val_mae: 0.7425\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0379 - mae: 0.1301 - val_loss: 1.3345 - val_mae: 0.7471\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0411 - mae: 0.1271 - val_loss: 1.3387 - val_mae: 0.7408\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0341 - mae: 0.1215 - val_loss: 1.3739 - val_mae: 0.7501\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0434 - mae: 0.1328 - val_loss: 1.3374 - val_mae: 0.7405\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0336 - mae: 0.1208 - val_loss: 1.3375 - val_mae: 0.7434\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0386 - mae: 0.1233 - val_loss: 1.3575 - val_mae: 0.7433\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0307 - mae: 0.1158 - val_loss: 1.3260 - val_mae: 0.7376\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0328 - mae: 0.1175 - val_loss: 1.3364 - val_mae: 0.7392\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0332 - mae: 0.1188 - val_loss: 1.3090 - val_mae: 0.7364\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0348 - mae: 0.1200 - val_loss: 1.3345 - val_mae: 0.7378\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0353 - mae: 0.1193 - val_loss: 1.3291 - val_mae: 0.7358\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0306 - mae: 0.1116 - val_loss: 1.3427 - val_mae: 0.7395\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0302 - mae: 0.1146 - val_loss: 1.3197 - val_mae: 0.7333\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0383 - mae: 0.1138 - val_loss: 1.3231 - val_mae: 0.7346\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0283 - mae: 0.1109 - val_loss: 1.3549 - val_mae: 0.7442\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0308 - mae: 0.1165 - val_loss: 1.3161 - val_mae: 0.7330\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0347 - mae: 0.1175 - val_loss: 1.3357 - val_mae: 0.7405\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0308 - mae: 0.1149 - val_loss: 1.3179 - val_mae: 0.7395\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0278 - mae: 0.1090 - val_loss: 1.3613 - val_mae: 0.7420\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0296 - mae: 0.1108 - val_loss: 1.3337 - val_mae: 0.7374\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0270 - mae: 0.1073 - val_loss: 1.3195 - val_mae: 0.7338\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0308 - mae: 0.1097 - val_loss: 1.3197 - val_mae: 0.7351\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0265 - mae: 0.1062 - val_loss: 1.3159 - val_mae: 0.7394\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0277 - mae: 0.1077 - val_loss: 1.3233 - val_mae: 0.7402\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0250 - mae: 0.1050 - val_loss: 1.3251 - val_mae: 0.7351\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0276 - mae: 0.1057 - val_loss: 1.3671 - val_mae: 0.7390\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0273 - mae: 0.1071 - val_loss: 1.3355 - val_mae: 0.7377\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0231 - mae: 0.0995 - val_loss: 1.3200 - val_mae: 0.7361\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0272 - mae: 0.1062 - val_loss: 1.3309 - val_mae: 0.7403\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0230 - mae: 0.0987 - val_loss: 1.3218 - val_mae: 0.7368\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0229 - mae: 0.1003 - val_loss: 1.3321 - val_mae: 0.7380\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0248 - mae: 0.1020 - val_loss: 1.3225 - val_mae: 0.7361\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0269 - mae: 0.1053 - val_loss: 1.3302 - val_mae: 0.7370\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0230 - mae: 0.0980 - val_loss: 1.3335 - val_mae: 0.7405\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0256 - mae: 0.0987 - val_loss: 1.3176 - val_mae: 0.7386\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0254 - mae: 0.0992 - val_loss: 1.3204 - val_mae: 0.7360\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0218 - mae: 0.0973 - val_loss: 1.3373 - val_mae: 0.7359\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0247 - mae: 0.0971 - val_loss: 1.3188 - val_mae: 0.7371\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0232 - mae: 0.0988 - val_loss: 1.3349 - val_mae: 0.7363\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0210 - mae: 0.0940 - val_loss: 1.3253 - val_mae: 0.7356\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0194 - mae: 0.0906 - val_loss: 1.3252 - val_mae: 0.7379\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0244 - mae: 0.0998 - val_loss: 1.3082 - val_mae: 0.7346\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0212 - mae: 0.0951 - val_loss: 1.3163 - val_mae: 0.7337\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.0916 - val_loss: 1.3128 - val_mae: 0.7333\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0208 - mae: 0.0946 - val_loss: 1.3108 - val_mae: 0.7284\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0216 - mae: 0.0932 - val_loss: 1.3338 - val_mae: 0.7368\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0256 - mae: 0.0971 - val_loss: 1.3239 - val_mae: 0.7321\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0188 - mae: 0.0879 - val_loss: 1.3058 - val_mae: 0.7291\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0233 - mae: 0.0908 - val_loss: 1.3158 - val_mae: 0.7336\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0186 - mae: 0.0874 - val_loss: 1.3282 - val_mae: 0.7333\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0228 - mae: 0.0898 - val_loss: 1.3244 - val_mae: 0.7344\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0193 - mae: 0.0890 - val_loss: 1.3236 - val_mae: 0.7328\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0228 - mae: 0.0926 - val_loss: 1.3375 - val_mae: 0.7337\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0202 - mae: 0.0878 - val_loss: 1.3011 - val_mae: 0.7256\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0195 - mae: 0.0841 - val_loss: 1.3284 - val_mae: 0.7321\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0196 - mae: 0.0929 - val_loss: 1.3286 - val_mae: 0.7295\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0176 - mae: 0.0856 - val_loss: 1.2984 - val_mae: 0.7307\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0174 - mae: 0.0860 - val_loss: 1.3244 - val_mae: 0.7414\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0164 - mae: 0.0832 - val_loss: 1.3127 - val_mae: 0.7292\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0190 - mae: 0.0855 - val_loss: 1.3049 - val_mae: 0.7242\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0191 - mae: 0.0865 - val_loss: 1.3302 - val_mae: 0.7342\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0183 - mae: 0.0868 - val_loss: 1.3060 - val_mae: 0.7272\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0187 - mae: 0.0862 - val_loss: 1.3182 - val_mae: 0.7295\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0170 - mae: 0.0843 - val_loss: 1.3277 - val_mae: 0.7353\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0184 - mae: 0.0844 - val_loss: 1.3202 - val_mae: 0.7307\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0189 - mae: 0.0866 - val_loss: 1.3069 - val_mae: 0.7319\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0220 - mae: 0.0835 - val_loss: 1.3156 - val_mae: 0.7301\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0181 - mae: 0.0815 - val_loss: 1.3186 - val_mae: 0.7302\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0165 - mae: 0.0821 - val_loss: 1.3264 - val_mae: 0.7325\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0175 - mae: 0.0819 - val_loss: 1.3063 - val_mae: 0.7301\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0161 - mae: 0.0823 - val_loss: 1.3083 - val_mae: 0.7305\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0182 - mae: 0.0847 - val_loss: 1.3133 - val_mae: 0.7280\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0195 - mae: 0.0816 - val_loss: 1.3065 - val_mae: 0.7282\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0162 - mae: 0.0810 - val_loss: 1.3252 - val_mae: 0.7300\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0792 - val_loss: 1.3240 - val_mae: 0.7384\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0147 - mae: 0.0784 - val_loss: 1.3156 - val_mae: 0.7300\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0142 - mae: 0.0765 - val_loss: 1.3346 - val_mae: 0.7327\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0143 - mae: 0.0758 - val_loss: 1.3352 - val_mae: 0.7354\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0162 - mae: 0.0812 - val_loss: 1.3272 - val_mae: 0.7312\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0166 - mae: 0.0805 - val_loss: 1.3094 - val_mae: 0.7263\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - loss: 0.0142 - mae: 0.0765 - val_loss: 1.3176 - val_mae: 0.7316\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 22ms/step - loss: 0.0150 - mae: 0.0793 - val_loss: 1.3000 - val_mae: 0.7319\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0134 - mae: 0.0751 - val_loss: 1.3227 - val_mae: 0.7331\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0127 - mae: 0.0741 - val_loss: 1.3105 - val_mae: 0.7301\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0139 - mae: 0.0766 - val_loss: 1.3198 - val_mae: 0.7296\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0142 - mae: 0.0786 - val_loss: 1.3153 - val_mae: 0.7314\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0212 - mae: 0.0840 - val_loss: 1.3189 - val_mae: 0.7346\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0146 - mae: 0.0766 - val_loss: 1.3143 - val_mae: 0.7297\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0124 - mae: 0.0701 - val_loss: 1.3258 - val_mae: 0.7338\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0155 - mae: 0.0758 - val_loss: 1.3360 - val_mae: 0.7310\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0146 - mae: 0.0754 - val_loss: 1.3115 - val_mae: 0.7293\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0128 - mae: 0.0737 - val_loss: 1.3295 - val_mae: 0.7339\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0143 - mae: 0.0761 - val_loss: 1.3077 - val_mae: 0.7275\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0138 - mae: 0.0717 - val_loss: 1.3276 - val_mae: 0.7324\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0124 - mae: 0.0708 - val_loss: 1.3124 - val_mae: 0.7267\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0130 - mae: 0.0715 - val_loss: 1.3110 - val_mae: 0.7309\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0131 - mae: 0.0744 - val_loss: 1.3230 - val_mae: 0.7309\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0152 - mae: 0.0760 - val_loss: 1.3262 - val_mae: 0.7315\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0140 - mae: 0.0727 - val_loss: 1.3259 - val_mae: 0.7295\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0140 - mae: 0.0728 - val_loss: 1.3241 - val_mae: 0.7296\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0142 - mae: 0.0738 - val_loss: 1.3138 - val_mae: 0.7302\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0139 - mae: 0.0734 - val_loss: 1.3243 - val_mae: 0.7304\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0151 - mae: 0.0715 - val_loss: 1.3202 - val_mae: 0.7316\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0104 - mae: 0.0676 - val_loss: 1.3058 - val_mae: 0.7293\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0136 - mae: 0.0709 - val_loss: 1.3195 - val_mae: 0.7317\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0115 - mae: 0.0668 - val_loss: 1.3031 - val_mae: 0.7290\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0118 - mae: 0.0700 - val_loss: 1.3214 - val_mae: 0.7296\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0120 - mae: 0.0705 - val_loss: 1.3051 - val_mae: 0.7281\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0129 - mae: 0.0698 - val_loss: 1.3105 - val_mae: 0.7259\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0150 - mae: 0.0729 - val_loss: 1.3058 - val_mae: 0.7305\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0121 - mae: 0.0679 - val_loss: 1.3158 - val_mae: 0.7300\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0184 - mae: 0.0700 - val_loss: 1.3116 - val_mae: 0.7279\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0145 - mae: 0.0735 - val_loss: 1.3211 - val_mae: 0.7331\n",
      "Epoch 168/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0143 - mae: 0.0731 - val_loss: 1.3118 - val_mae: 0.7270\n",
      "Epoch 169/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0120 - mae: 0.0712 - val_loss: 1.3065 - val_mae: 0.7271\n",
      "Epoch 170/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0127 - mae: 0.0680 - val_loss: 1.3121 - val_mae: 0.7313\n",
      "Epoch 171/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0105 - mae: 0.0649 - val_loss: 1.3024 - val_mae: 0.7260\n",
      "Epoch 172/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0127 - mae: 0.0708 - val_loss: 1.3130 - val_mae: 0.7288\n",
      "Epoch 173/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0117 - mae: 0.0666 - val_loss: 1.3076 - val_mae: 0.7270\n",
      "Epoch 174/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0110 - mae: 0.0667 - val_loss: 1.3008 - val_mae: 0.7279\n",
      "Epoch 175/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0104 - mae: 0.0685 - val_loss: 1.3134 - val_mae: 0.7285\n",
      "Epoch 176/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0096 - mae: 0.0643 - val_loss: 1.3225 - val_mae: 0.7310\n",
      "Epoch 177/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0156 - mae: 0.0678 - val_loss: 1.3027 - val_mae: 0.7235\n",
      "Epoch 178/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0097 - mae: 0.0642 - val_loss: 1.3134 - val_mae: 0.7276\n",
      "Epoch 179/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0110 - mae: 0.0684 - val_loss: 1.3377 - val_mae: 0.7360\n",
      "Epoch 180/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0131 - mae: 0.0700 - val_loss: 1.3067 - val_mae: 0.7282\n",
      "Epoch 181/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0136 - mae: 0.0696 - val_loss: 1.3088 - val_mae: 0.7304\n",
      "Epoch 182/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0112 - mae: 0.0664 - val_loss: 1.3135 - val_mae: 0.7274\n",
      "Epoch 183/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0097 - mae: 0.0638 - val_loss: 1.3083 - val_mae: 0.7273\n",
      "Epoch 184/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0123 - mae: 0.0656 - val_loss: 1.3066 - val_mae: 0.7307\n",
      "Epoch 185/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0097 - mae: 0.0642 - val_loss: 1.3327 - val_mae: 0.7358\n",
      "Epoch 186/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0109 - mae: 0.0674 - val_loss: 1.3124 - val_mae: 0.7268\n",
      "Epoch 187/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0174 - mae: 0.0738 - val_loss: 1.3388 - val_mae: 0.7348\n",
      "Epoch 188/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0111 - mae: 0.0659 - val_loss: 1.3105 - val_mae: 0.7284\n",
      "Epoch 189/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0130 - mae: 0.0660 - val_loss: 1.3038 - val_mae: 0.7268\n",
      "Epoch 190/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0117 - mae: 0.0663 - val_loss: 1.3186 - val_mae: 0.7342\n",
      "Epoch 191/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0125 - mae: 0.0679 - val_loss: 1.3141 - val_mae: 0.7306\n",
      "Epoch 192/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0101 - mae: 0.0635 - val_loss: 1.3277 - val_mae: 0.7313\n",
      "Epoch 193/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0096 - mae: 0.0618 - val_loss: 1.3227 - val_mae: 0.7324\n",
      "Epoch 194/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0107 - mae: 0.0650 - val_loss: 1.3081 - val_mae: 0.7252\n",
      "Epoch 195/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0144 - mae: 0.0668 - val_loss: 1.3090 - val_mae: 0.7258\n",
      "Epoch 196/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0092 - mae: 0.0612 - val_loss: 1.3034 - val_mae: 0.7249\n",
      "Epoch 197/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0106 - mae: 0.0629 - val_loss: 1.3181 - val_mae: 0.7285\n",
      "Epoch 198/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0121 - mae: 0.0645 - val_loss: 1.3221 - val_mae: 0.7308\n",
      "Epoch 199/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0106 - mae: 0.0639 - val_loss: 1.3021 - val_mae: 0.7263\n",
      "Epoch 200/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0175 - mae: 0.0649 - val_loss: 1.2991 - val_mae: 0.7239\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2400 - mae: 0.7148\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - loss: 6.7623 - mae: 1.8285 - val_loss: 2.1054 - val_mae: 1.0115\n",
      "Epoch 2/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 1.1394 - mae: 0.7633 - val_loss: 1.9869 - val_mae: 0.9949\n",
      "Epoch 3/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.7567 - mae: 0.6224 - val_loss: 1.6250 - val_mae: 0.8893\n",
      "Epoch 4/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.5697 - mae: 0.5332 - val_loss: 1.6084 - val_mae: 0.8834\n",
      "Epoch 5/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.4624 - mae: 0.4643 - val_loss: 1.6370 - val_mae: 0.8926\n",
      "Epoch 6/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.3900 - mae: 0.4246 - val_loss: 1.5510 - val_mae: 0.8466\n",
      "Epoch 7/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.3274 - mae: 0.3870 - val_loss: 1.5963 - val_mae: 0.8527\n",
      "Epoch 8/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2442 - mae: 0.3362 - val_loss: 1.5627 - val_mae: 0.8565\n",
      "Epoch 9/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2756 - mae: 0.3536 - val_loss: 1.4705 - val_mae: 0.8358\n",
      "Epoch 10/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2331 - mae: 0.3231 - val_loss: 1.4836 - val_mae: 0.8143\n",
      "Epoch 11/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.2217 - mae: 0.3127 - val_loss: 1.4504 - val_mae: 0.8287\n",
      "Epoch 12/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1846 - mae: 0.2909 - val_loss: 1.3935 - val_mae: 0.8055\n",
      "Epoch 13/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1616 - mae: 0.2694 - val_loss: 1.3768 - val_mae: 0.7885\n",
      "Epoch 14/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1444 - mae: 0.2571 - val_loss: 1.4291 - val_mae: 0.8090\n",
      "Epoch 15/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1530 - mae: 0.2608 - val_loss: 1.4424 - val_mae: 0.8069\n",
      "Epoch 16/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1680 - mae: 0.2711 - val_loss: 1.3783 - val_mae: 0.7780\n",
      "Epoch 17/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1344 - mae: 0.2416 - val_loss: 1.3793 - val_mae: 0.7778\n",
      "Epoch 18/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1101 - mae: 0.2212 - val_loss: 1.3550 - val_mae: 0.7715\n",
      "Epoch 19/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1171 - mae: 0.2290 - val_loss: 1.3483 - val_mae: 0.7681\n",
      "Epoch 20/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1050 - mae: 0.2135 - val_loss: 1.3839 - val_mae: 0.7759\n",
      "Epoch 21/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0922 - mae: 0.2061 - val_loss: 1.3495 - val_mae: 0.7833\n",
      "Epoch 22/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.1055 - mae: 0.2119 - val_loss: 1.3364 - val_mae: 0.7668\n",
      "Epoch 23/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0912 - mae: 0.2028 - val_loss: 1.3194 - val_mae: 0.7539\n",
      "Epoch 24/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0921 - mae: 0.1996 - val_loss: 1.3653 - val_mae: 0.7701\n",
      "Epoch 25/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0919 - mae: 0.2001 - val_loss: 1.3323 - val_mae: 0.7678\n",
      "Epoch 26/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0967 - mae: 0.2001 - val_loss: 1.3243 - val_mae: 0.7520\n",
      "Epoch 27/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0693 - mae: 0.1781 - val_loss: 1.3547 - val_mae: 0.7615\n",
      "Epoch 28/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0768 - mae: 0.1822 - val_loss: 1.3012 - val_mae: 0.7488\n",
      "Epoch 29/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0681 - mae: 0.1741 - val_loss: 1.2949 - val_mae: 0.7614\n",
      "Epoch 30/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0671 - mae: 0.1733 - val_loss: 1.2801 - val_mae: 0.7448\n",
      "Epoch 31/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0602 - mae: 0.1627 - val_loss: 1.3295 - val_mae: 0.7621\n",
      "Epoch 32/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0655 - mae: 0.1678 - val_loss: 1.2962 - val_mae: 0.7418\n",
      "Epoch 33/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0624 - mae: 0.1600 - val_loss: 1.2952 - val_mae: 0.7526\n",
      "Epoch 34/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0643 - mae: 0.1655 - val_loss: 1.3004 - val_mae: 0.7516\n",
      "Epoch 35/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0672 - mae: 0.1674 - val_loss: 1.2913 - val_mae: 0.7425\n",
      "Epoch 36/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0585 - mae: 0.1575 - val_loss: 1.2690 - val_mae: 0.7357\n",
      "Epoch 37/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0493 - mae: 0.1439 - val_loss: 1.2740 - val_mae: 0.7411\n",
      "Epoch 38/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0472 - mae: 0.1410 - val_loss: 1.2698 - val_mae: 0.7380\n",
      "Epoch 39/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0476 - mae: 0.1410 - val_loss: 1.2922 - val_mae: 0.7431\n",
      "Epoch 40/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0489 - mae: 0.1451 - val_loss: 1.2856 - val_mae: 0.7437\n",
      "Epoch 41/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0485 - mae: 0.1445 - val_loss: 1.2847 - val_mae: 0.7380\n",
      "Epoch 42/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0509 - mae: 0.1463 - val_loss: 1.2783 - val_mae: 0.7378\n",
      "Epoch 43/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0554 - mae: 0.1455 - val_loss: 1.2768 - val_mae: 0.7366\n",
      "Epoch 44/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0475 - mae: 0.1378 - val_loss: 1.2763 - val_mae: 0.7399\n",
      "Epoch 45/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0412 - mae: 0.1345 - val_loss: 1.2786 - val_mae: 0.7398\n",
      "Epoch 46/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0437 - mae: 0.1330 - val_loss: 1.2657 - val_mae: 0.7347\n",
      "Epoch 47/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0432 - mae: 0.1341 - val_loss: 1.2825 - val_mae: 0.7386\n",
      "Epoch 48/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0405 - mae: 0.1329 - val_loss: 1.2781 - val_mae: 0.7395\n",
      "Epoch 49/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0452 - mae: 0.1377 - val_loss: 1.2800 - val_mae: 0.7375\n",
      "Epoch 50/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0381 - mae: 0.1286 - val_loss: 1.2614 - val_mae: 0.7334\n",
      "Epoch 51/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0382 - mae: 0.1246 - val_loss: 1.2408 - val_mae: 0.7242\n",
      "Epoch 52/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0357 - mae: 0.1226 - val_loss: 1.2800 - val_mae: 0.7351\n",
      "Epoch 53/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0395 - mae: 0.1284 - val_loss: 1.2791 - val_mae: 0.7369\n",
      "Epoch 54/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0369 - mae: 0.1239 - val_loss: 1.2737 - val_mae: 0.7368\n",
      "Epoch 55/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0400 - mae: 0.1304 - val_loss: 1.2972 - val_mae: 0.7360\n",
      "Epoch 56/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0358 - mae: 0.1170 - val_loss: 1.2777 - val_mae: 0.7384\n",
      "Epoch 57/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0321 - mae: 0.1182 - val_loss: 1.2726 - val_mae: 0.7338\n",
      "Epoch 58/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0309 - mae: 0.1146 - val_loss: 1.2597 - val_mae: 0.7341\n",
      "Epoch 59/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0327 - mae: 0.1168 - val_loss: 1.2898 - val_mae: 0.7370\n",
      "Epoch 60/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0322 - mae: 0.1132 - val_loss: 1.2752 - val_mae: 0.7323\n",
      "Epoch 61/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0264 - mae: 0.1095 - val_loss: 1.2821 - val_mae: 0.7365\n",
      "Epoch 62/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0344 - mae: 0.1184 - val_loss: 1.2669 - val_mae: 0.7320\n",
      "Epoch 63/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0313 - mae: 0.1108 - val_loss: 1.2651 - val_mae: 0.7330\n",
      "Epoch 64/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0272 - mae: 0.1097 - val_loss: 1.2729 - val_mae: 0.7433\n",
      "Epoch 65/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0338 - mae: 0.1197 - val_loss: 1.2598 - val_mae: 0.7295\n",
      "Epoch 66/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0321 - mae: 0.1100 - val_loss: 1.2660 - val_mae: 0.7319\n",
      "Epoch 67/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0301 - mae: 0.1109 - val_loss: 1.2772 - val_mae: 0.7369\n",
      "Epoch 68/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0312 - mae: 0.1107 - val_loss: 1.2631 - val_mae: 0.7293\n",
      "Epoch 69/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0286 - mae: 0.1061 - val_loss: 1.2906 - val_mae: 0.7344\n",
      "Epoch 70/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0242 - mae: 0.1035 - val_loss: 1.2707 - val_mae: 0.7293\n",
      "Epoch 71/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0303 - mae: 0.1090 - val_loss: 1.2856 - val_mae: 0.7362\n",
      "Epoch 72/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0266 - mae: 0.1008 - val_loss: 1.2793 - val_mae: 0.7333\n",
      "Epoch 73/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0246 - mae: 0.1024 - val_loss: 1.2730 - val_mae: 0.7319\n",
      "Epoch 74/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0258 - mae: 0.1038 - val_loss: 1.2819 - val_mae: 0.7293\n",
      "Epoch 75/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0272 - mae: 0.1024 - val_loss: 1.2746 - val_mae: 0.7355\n",
      "Epoch 76/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0249 - mae: 0.1009 - val_loss: 1.2647 - val_mae: 0.7268\n",
      "Epoch 77/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0216 - mae: 0.0966 - val_loss: 1.2734 - val_mae: 0.7307\n",
      "Epoch 78/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0251 - mae: 0.1022 - val_loss: 1.2683 - val_mae: 0.7306\n",
      "Epoch 79/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0219 - mae: 0.0964 - val_loss: 1.2816 - val_mae: 0.7320\n",
      "Epoch 80/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0243 - mae: 0.0979 - val_loss: 1.2821 - val_mae: 0.7339\n",
      "Epoch 81/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0230 - mae: 0.0952 - val_loss: 1.2746 - val_mae: 0.7329\n",
      "Epoch 82/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0261 - mae: 0.1000 - val_loss: 1.2857 - val_mae: 0.7365\n",
      "Epoch 83/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0215 - mae: 0.0938 - val_loss: 1.2594 - val_mae: 0.7322\n",
      "Epoch 84/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0256 - mae: 0.0997 - val_loss: 1.2785 - val_mae: 0.7300\n",
      "Epoch 85/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0226 - mae: 0.0938 - val_loss: 1.2764 - val_mae: 0.7332\n",
      "Epoch 86/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0204 - mae: 0.0924 - val_loss: 1.2702 - val_mae: 0.7288\n",
      "Epoch 87/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0264 - mae: 0.0965 - val_loss: 1.2906 - val_mae: 0.7351\n",
      "Epoch 88/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0210 - mae: 0.0947 - val_loss: 1.2777 - val_mae: 0.7340\n",
      "Epoch 89/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0215 - mae: 0.0924 - val_loss: 1.2638 - val_mae: 0.7317\n",
      "Epoch 90/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0195 - mae: 0.0904 - val_loss: 1.2673 - val_mae: 0.7306\n",
      "Epoch 91/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0195 - mae: 0.0894 - val_loss: 1.2737 - val_mae: 0.7299\n",
      "Epoch 92/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0188 - mae: 0.0896 - val_loss: 1.2706 - val_mae: 0.7304\n",
      "Epoch 93/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0208 - mae: 0.0907 - val_loss: 1.2750 - val_mae: 0.7315\n",
      "Epoch 94/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0200 - mae: 0.0871 - val_loss: 1.2800 - val_mae: 0.7337\n",
      "Epoch 95/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0172 - mae: 0.0868 - val_loss: 1.2777 - val_mae: 0.7317\n",
      "Epoch 96/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0247 - mae: 0.0942 - val_loss: 1.2737 - val_mae: 0.7307\n",
      "Epoch 97/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0205 - mae: 0.0933 - val_loss: 1.2733 - val_mae: 0.7272\n",
      "Epoch 98/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0219 - mae: 0.0894 - val_loss: 1.2709 - val_mae: 0.7287\n",
      "Epoch 99/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0174 - mae: 0.0864 - val_loss: 1.2679 - val_mae: 0.7267\n",
      "Epoch 100/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0175 - mae: 0.0857 - val_loss: 1.2829 - val_mae: 0.7332\n",
      "Epoch 101/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0201 - mae: 0.0884 - val_loss: 1.2711 - val_mae: 0.7331\n",
      "Epoch 102/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0178 - mae: 0.0846 - val_loss: 1.2752 - val_mae: 0.7310\n",
      "Epoch 103/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0170 - mae: 0.0846 - val_loss: 1.2866 - val_mae: 0.7323\n",
      "Epoch 104/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0162 - mae: 0.0822 - val_loss: 1.2701 - val_mae: 0.7280\n",
      "Epoch 105/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0169 - mae: 0.0870 - val_loss: 1.2750 - val_mae: 0.7320\n",
      "Epoch 106/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0208 - mae: 0.0857 - val_loss: 1.2570 - val_mae: 0.7258\n",
      "Epoch 107/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0180 - mae: 0.0829 - val_loss: 1.2860 - val_mae: 0.7321\n",
      "Epoch 108/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.0837 - val_loss: 1.2719 - val_mae: 0.7333\n",
      "Epoch 109/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0178 - mae: 0.0852 - val_loss: 1.2783 - val_mae: 0.7268\n",
      "Epoch 110/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.0835 - val_loss: 1.2777 - val_mae: 0.7326\n",
      "Epoch 111/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0807 - val_loss: 1.2798 - val_mae: 0.7296\n",
      "Epoch 112/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0172 - mae: 0.0821 - val_loss: 1.2638 - val_mae: 0.7301\n",
      "Epoch 113/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0154 - mae: 0.0789 - val_loss: 1.2739 - val_mae: 0.7332\n",
      "Epoch 114/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0167 - mae: 0.0796 - val_loss: 1.2746 - val_mae: 0.7347\n",
      "Epoch 115/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0143 - mae: 0.0779 - val_loss: 1.2758 - val_mae: 0.7294\n",
      "Epoch 116/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0802 - val_loss: 1.2770 - val_mae: 0.7301\n",
      "Epoch 117/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0165 - mae: 0.0813 - val_loss: 1.2729 - val_mae: 0.7297\n",
      "Epoch 118/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0186 - mae: 0.0839 - val_loss: 1.2667 - val_mae: 0.7293\n",
      "Epoch 119/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0163 - mae: 0.0816 - val_loss: 1.2889 - val_mae: 0.7319\n",
      "Epoch 120/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0151 - mae: 0.0782 - val_loss: 1.2683 - val_mae: 0.7283\n",
      "Epoch 121/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0159 - mae: 0.0791 - val_loss: 1.2743 - val_mae: 0.7309\n",
      "Epoch 122/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0167 - mae: 0.0806 - val_loss: 1.2646 - val_mae: 0.7286\n",
      "Epoch 123/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0163 - mae: 0.0759 - val_loss: 1.2802 - val_mae: 0.7324\n",
      "Epoch 124/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0124 - mae: 0.0739 - val_loss: 1.2844 - val_mae: 0.7365\n",
      "Epoch 125/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0157 - mae: 0.0765 - val_loss: 1.2783 - val_mae: 0.7318\n",
      "Epoch 126/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0138 - mae: 0.0751 - val_loss: 1.2723 - val_mae: 0.7317\n",
      "Epoch 127/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0157 - mae: 0.0780 - val_loss: 1.2646 - val_mae: 0.7287\n",
      "Epoch 128/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0145 - mae: 0.0748 - val_loss: 1.2742 - val_mae: 0.7310\n",
      "Epoch 129/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0130 - mae: 0.0718 - val_loss: 1.2792 - val_mae: 0.7309\n",
      "Epoch 130/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0127 - mae: 0.0747 - val_loss: 1.2988 - val_mae: 0.7425\n",
      "Epoch 131/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0166 - mae: 0.0812 - val_loss: 1.2641 - val_mae: 0.7296\n",
      "Epoch 132/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0144 - mae: 0.0754 - val_loss: 1.3018 - val_mae: 0.7355\n",
      "Epoch 133/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0145 - mae: 0.0778 - val_loss: 1.2840 - val_mae: 0.7317\n",
      "Epoch 134/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0151 - mae: 0.0795 - val_loss: 1.2936 - val_mae: 0.7357\n",
      "Epoch 135/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0167 - mae: 0.0799 - val_loss: 1.2712 - val_mae: 0.7297\n",
      "Epoch 136/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0141 - mae: 0.0721 - val_loss: 1.2904 - val_mae: 0.7323\n",
      "Epoch 137/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0133 - mae: 0.0726 - val_loss: 1.2706 - val_mae: 0.7326\n",
      "Epoch 138/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0146 - mae: 0.0756 - val_loss: 1.2836 - val_mae: 0.7332\n",
      "Epoch 139/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0162 - mae: 0.0731 - val_loss: 1.2908 - val_mae: 0.7331\n",
      "Epoch 140/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0185 - mae: 0.0796 - val_loss: 1.2905 - val_mae: 0.7332\n",
      "Epoch 141/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0132 - mae: 0.0737 - val_loss: 1.2817 - val_mae: 0.7331\n",
      "Epoch 142/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0126 - mae: 0.0721 - val_loss: 1.2789 - val_mae: 0.7314\n",
      "Epoch 143/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0121 - mae: 0.0699 - val_loss: 1.2773 - val_mae: 0.7305\n",
      "Epoch 144/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0112 - mae: 0.0660 - val_loss: 1.2932 - val_mae: 0.7347\n",
      "Epoch 145/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0149 - mae: 0.0744 - val_loss: 1.2884 - val_mae: 0.7327\n",
      "Epoch 146/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0118 - mae: 0.0704 - val_loss: 1.2771 - val_mae: 0.7299\n",
      "Epoch 147/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0120 - mae: 0.0719 - val_loss: 1.2897 - val_mae: 0.7319\n",
      "Epoch 148/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0128 - mae: 0.0686 - val_loss: 1.2688 - val_mae: 0.7334\n",
      "Epoch 149/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0108 - mae: 0.0681 - val_loss: 1.2910 - val_mae: 0.7329\n",
      "Epoch 150/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0137 - mae: 0.0708 - val_loss: 1.2747 - val_mae: 0.7326\n",
      "Epoch 151/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0148 - mae: 0.0726 - val_loss: 1.2737 - val_mae: 0.7344\n",
      "Epoch 152/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0137 - mae: 0.0724 - val_loss: 1.2735 - val_mae: 0.7303\n",
      "Epoch 153/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0109 - mae: 0.0662 - val_loss: 1.2756 - val_mae: 0.7297\n",
      "Epoch 154/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0120 - mae: 0.0697 - val_loss: 1.2646 - val_mae: 0.7278\n",
      "Epoch 155/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0117 - mae: 0.0676 - val_loss: 1.2731 - val_mae: 0.7299\n",
      "Epoch 156/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0116 - mae: 0.0675 - val_loss: 1.2812 - val_mae: 0.7314\n",
      "Epoch 157/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0128 - mae: 0.0697 - val_loss: 1.2814 - val_mae: 0.7327\n",
      "Epoch 158/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0127 - mae: 0.0697 - val_loss: 1.2828 - val_mae: 0.7310\n",
      "Epoch 159/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 0.0117 - mae: 0.0702 - val_loss: 1.2955 - val_mae: 0.7350\n",
      "Epoch 160/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0121 - mae: 0.0692 - val_loss: 1.2748 - val_mae: 0.7313\n",
      "Epoch 161/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0124 - mae: 0.0682 - val_loss: 1.2668 - val_mae: 0.7276\n",
      "Epoch 162/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0111 - mae: 0.0646 - val_loss: 1.2730 - val_mae: 0.7298\n",
      "Epoch 163/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0102 - mae: 0.0655 - val_loss: 1.2757 - val_mae: 0.7291\n",
      "Epoch 164/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 0.0111 - mae: 0.0680 - val_loss: 1.2868 - val_mae: 0.7355\n",
      "Epoch 165/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0133 - mae: 0.0705 - val_loss: 1.2957 - val_mae: 0.7339\n",
      "Epoch 166/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0100 - mae: 0.0660 - val_loss: 1.2664 - val_mae: 0.7279\n",
      "Epoch 167/200\n",
      "\u001b[1m604/604\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0106 - mae: 0.0645 - val_loss: 1.2839 - val_mae: 0.7312\n",
      "Epoch 168/200\n",
      "\u001b[1m201/604\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - loss: 0.0108 - mae: 0.0667"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\n",
    "    'use_count_option', 'fpSize_option', 'radius_option',\n",
    "    'train', 'test', 'loss', 'mae', 'r-squared', 'error'\n",
    "                          ])\n",
    "\n",
    "# Obtem os dados\n",
    "df_mouse_vo = pd.read_csv('dados/mouse_vo.csv', usecols=['mouse_vo', 'smiles'])\n",
    "\n",
    "# Converter valores da coluna 'valor' para float\n",
    "df_mouse_vo['mouse_vo'] = pd.to_numeric(df_mouse_vo['mouse_vo'], errors='coerce')\n",
    "\n",
    "# Remove NaN\n",
    "df_mouse_vo.dropna(subset=['mouse_vo', 'smiles'], inplace=True, ignore_index=True)\n",
    "\n",
    "# Normaliza LD50\n",
    "df_mouse_vo['log_ld50'] = -np.log(df_mouse_vo['mouse_vo'])\n",
    "\n",
    "# Realiza a limpeza dos dados\n",
    "limpeza = Limpeza(dataframe=df_mouse_vo)\n",
    "df_mouse_vo = limpeza.dados_limpos(col_smiles='smiles', col_valor='mouse_vo', sanitize=True, cutoff=.05, fragmento=False)\n",
    "\n",
    "for c in use_count_option:\n",
    "    for d in fpSize_option:\n",
    "        for e in radius_option:\n",
    "\n",
    "            try:\n",
    "\n",
    "                mouse_vo = df_mouse_vo.copy()\n",
    "                \n",
    "                # Define a representação fingerprint\n",
    "                representacao = Representacao(dataframe=mouse_vo)\n",
    "                mouse_vo = representacao.fingerprint(col_smiles='smiles', fingerprint='morgan', use_count=c, fpSize=d, radius=e)\n",
    "                \n",
    "                # Define os conjuntos de treinamento e teste\n",
    "                X = np.array(mouse_vo['Features'].to_list())\n",
    "                y = mouse_vo['log_ld50'].values\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Aplica ANN\n",
    "                model = ANN(fpSize=d)\n",
    "                model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "                history = model.fit(X_train, y_train, validation_split=0.1, epochs=200, batch_size=32)\n",
    "                \n",
    "                # Obtem as métricas do modelo\n",
    "                loss, mae = model.evaluate(X_test, y_test)\n",
    "                \n",
    "                # R-squared\n",
    "                predictions = model.predict(X_test)\n",
    "                y_true = np.array(y_test)\n",
    "                y_pred = np.array(predictions)\n",
    "                \n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                \n",
    "                df_ann = pd.DataFrame([{\n",
    "                    'use_count_option' : c, 'fpSize_option' : d, 'radius_option' : e,\n",
    "                    'train' : len(X_train), 'test' : len(X_test), 'loss' : loss, 'mae' : mae, 'r-squared' : r2, 'error' : np.nan\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n",
    "\n",
    "                df.to_excel('mouse_vo_modelos.xlsx', index=False)\n",
    "\n",
    "            except Exception as err:\n",
    "\n",
    "                print(err)\n",
    "                \n",
    "                df_ann = pd.DataFrame([{\n",
    "                    'use_count_option' : c, 'fpSize_option' : d, 'radius_option' : e,\n",
    "                    'train' : np.nan, 'test' : np.nan, 'loss' : np.nan, 'mae' : np.nan, 'r-squared' : np.nan, 'error' : str(err)\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n",
    "\n",
    "                df.to_excel('mouse_vo_modelos.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924037f-aedc-4c9b-85cf-eac97407db4a",
   "metadata": {},
   "source": [
    "# RAT, INTRAVENOSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ebb11b-cad6-4d24-8aa1-b77afe0f25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\n",
    "    'use_count_option', 'fpSize_option', 'radius_option',\n",
    "    'train', 'test', 'loss', 'mae', 'r-squared', 'error'\n",
    "                          ])\n",
    "\n",
    "# Obtem os dados\n",
    "df_rat_vi = pd.read_csv('dados/rat_vi.csv', usecols=['rat_vi', 'smiles'])\n",
    "\n",
    "# Converter valores da coluna 'valor' para float\n",
    "df_rat_vi['rat_vi'] = pd.to_numeric(df_rat_vi['rat_vi'], errors='coerce')\n",
    "\n",
    "# Remove NaN\n",
    "df_rat_vi.dropna(subset=['rat_vi', 'smiles'], inplace=True, ignore_index=True)\n",
    "\n",
    "# Normaliza LD50\n",
    "df_rat_vi['log_ld50'] = -np.log(df_rat_vi['rat_vi'])\n",
    "\n",
    "# Realiza a limpeza dos dados\n",
    "limpeza = Limpeza(dataframe=df_rat_vi)\n",
    "df_rat_vi = limpeza.dados_limpos(col_smiles='smiles', col_valor='rat_vi', sanitize=True, cutoff=.05, fragmento=False)\n",
    "\n",
    "for c in use_count_option:\n",
    "    for d in fpSize_option:\n",
    "        for e in radius_option:\n",
    "\n",
    "            try:\n",
    "\n",
    "                rat_vi = df_rat_vi.copy()\n",
    "\n",
    "                # Define a representação fingerprint\n",
    "                representacao = Representacao(dataframe=rat_vi)\n",
    "                rat_vi = representacao.fingerprint(col_smiles='smiles', fingerprint='morgan', use_count=c, fpSize=d, radius=e)\n",
    "                \n",
    "                # Define os conjuntos de treinamento e teste\n",
    "                X = np.array(rat_vi['Features'].to_list())\n",
    "                y = rat_vi['log_ld50'].values\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Aplica ANN\n",
    "                model = ANN(fpSize=d)\n",
    "                model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "                history = model.fit(X_train, y_train, validation_split=0.1, epochs=200, batch_size=32)\n",
    "                \n",
    "                # Obtem as métricas do modelo\n",
    "                loss, mae = model.evaluate(X_test, y_test)\n",
    "                \n",
    "                # R-squared\n",
    "                predictions = model.predict(X_test)\n",
    "                y_true = np.array(y_test)\n",
    "                y_pred = np.array(predictions)\n",
    "                \n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                \n",
    "                df_ann = pd.DataFrame([{\n",
    "                    'use_count_option' : c, 'fpSize_option' : d, 'radius_option' : e,\n",
    "                    'train' : len(X_train), 'test' : len(X_test), 'loss' : loss, 'mae' : mae, 'r-squared' : r2, 'error' : np.nan\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n",
    "\n",
    "                df.to_excel('rat_vi_modelos.xlsx', index=False)\n",
    "\n",
    "            except Exception as err:\n",
    "                \n",
    "                df_ann = pd.DataFrame([{\n",
    "                    'use_count_option' : c, 'fpSize_option' : d, 'radius_option' : e,\n",
    "                    'train' : np.nan, 'test' : np.nan, 'loss' : np.nan, 'mae' : np.nan, 'r-squared' : np.nan, 'error' : str(err)\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n",
    "\n",
    "                df.to_excel('rat_vi_modelos.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623463f-532a-4ffa-a1b8-12a4d11e4e24",
   "metadata": {},
   "source": [
    "# RAT, ORAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "285cc592-5bff-4ebe-abbf-6c7ca1c21ebf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1732 - mae: 0.3033 - val_loss: 2.7146 - val_mae: 1.1265\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1468 - mae: 0.2637 - val_loss: 2.6656 - val_mae: 1.1116\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1270 - mae: 0.2451 - val_loss: 2.6888 - val_mae: 1.1095\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1401 - mae: 0.2523 - val_loss: 2.7003 - val_mae: 1.1146\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1328 - mae: 0.2442 - val_loss: 2.7317 - val_mae: 1.1282\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1197 - mae: 0.2402 - val_loss: 2.7057 - val_mae: 1.1173\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1186 - mae: 0.2387 - val_loss: 2.6467 - val_mae: 1.1075\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1332 - mae: 0.2413 - val_loss: 2.7067 - val_mae: 1.1112\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1109 - mae: 0.2283 - val_loss: 2.6931 - val_mae: 1.1166\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1274 - mae: 0.2415 - val_loss: 2.6924 - val_mae: 1.1117\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1337 - mae: 0.2575 - val_loss: 2.7028 - val_mae: 1.1167\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1243 - mae: 0.2433 - val_loss: 2.6908 - val_mae: 1.1240\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1197 - mae: 0.2361 - val_loss: 2.6545 - val_mae: 1.0949\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1124 - mae: 0.2242 - val_loss: 2.7055 - val_mae: 1.1225\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0883 - mae: 0.2030 - val_loss: 2.6654 - val_mae: 1.1085\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1006 - mae: 0.2135 - val_loss: 2.6607 - val_mae: 1.1086\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1035 - mae: 0.2193 - val_loss: 2.6482 - val_mae: 1.1019\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1020 - mae: 0.2112 - val_loss: 2.6235 - val_mae: 1.1012\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0835 - mae: 0.1903 - val_loss: 2.6293 - val_mae: 1.0981\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0899 - mae: 0.2004 - val_loss: 2.6499 - val_mae: 1.0922\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0870 - mae: 0.1996 - val_loss: 2.6927 - val_mae: 1.1081\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0963 - mae: 0.2035 - val_loss: 2.6271 - val_mae: 1.0941\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0934 - mae: 0.1953 - val_loss: 2.6685 - val_mae: 1.0970\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0869 - mae: 0.1968 - val_loss: 2.6138 - val_mae: 1.0890\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0884 - mae: 0.1955 - val_loss: 2.5982 - val_mae: 1.0889\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1003 - mae: 0.1978 - val_loss: 2.6432 - val_mae: 1.0976\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0858 - mae: 0.1875 - val_loss: 2.6202 - val_mae: 1.0923\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0811 - mae: 0.1818 - val_loss: 2.5918 - val_mae: 1.0897\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0915 - mae: 0.1913 - val_loss: 2.6313 - val_mae: 1.0938\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0823 - mae: 0.1910 - val_loss: 2.6194 - val_mae: 1.1042\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0856 - mae: 0.1868 - val_loss: 2.6353 - val_mae: 1.0956\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0784 - mae: 0.1780 - val_loss: 2.6217 - val_mae: 1.1017\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0933 - mae: 0.1925 - val_loss: 2.6295 - val_mae: 1.0852\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0760 - mae: 0.1786 - val_loss: 2.6364 - val_mae: 1.1209\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0809 - mae: 0.1772 - val_loss: 2.6019 - val_mae: 1.0849\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0669 - mae: 0.1702 - val_loss: 2.6060 - val_mae: 1.0978\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0806 - mae: 0.1764 - val_loss: 2.6397 - val_mae: 1.0920\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0736 - mae: 0.1645 - val_loss: 2.5931 - val_mae: 1.0963\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0674 - mae: 0.1672 - val_loss: 2.6463 - val_mae: 1.0959\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0861 - mae: 0.1841 - val_loss: 2.6088 - val_mae: 1.0934\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0682 - mae: 0.1653 - val_loss: 2.6075 - val_mae: 1.0848\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0704 - mae: 0.1635 - val_loss: 2.6044 - val_mae: 1.0804\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0722 - mae: 0.1668 - val_loss: 2.5946 - val_mae: 1.0865\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0698 - mae: 0.1599 - val_loss: 2.5733 - val_mae: 1.0837\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0698 - mae: 0.1646 - val_loss: 2.6000 - val_mae: 1.0815\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0659 - mae: 0.1622 - val_loss: 2.6035 - val_mae: 1.0772\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0575 - mae: 0.1551 - val_loss: 2.6230 - val_mae: 1.0883\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0585 - mae: 0.1462 - val_loss: 2.6123 - val_mae: 1.0835\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0779 - mae: 0.1644 - val_loss: 2.6064 - val_mae: 1.0884\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0665 - mae: 0.1532 - val_loss: 2.5832 - val_mae: 1.0764\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0676 - mae: 0.1517 - val_loss: 2.6120 - val_mae: 1.0919\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0565 - mae: 0.1471 - val_loss: 2.5937 - val_mae: 1.0803\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0527 - mae: 0.1448 - val_loss: 2.5823 - val_mae: 1.0876\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0698 - mae: 0.1538 - val_loss: 2.6023 - val_mae: 1.0851\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0706 - mae: 0.1610 - val_loss: 2.5832 - val_mae: 1.0712\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0776 - mae: 0.1596 - val_loss: 2.5907 - val_mae: 1.0821\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0590 - mae: 0.1456 - val_loss: 2.5844 - val_mae: 1.0795\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0665 - mae: 0.1503 - val_loss: 2.5891 - val_mae: 1.0850\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0535 - mae: 0.1421 - val_loss: 2.6052 - val_mae: 1.0996\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0689 - mae: 0.1609 - val_loss: 2.5999 - val_mae: 1.0901\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0654 - mae: 0.1531 - val_loss: 2.5816 - val_mae: 1.0834\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0529 - mae: 0.1409 - val_loss: 2.6009 - val_mae: 1.0965\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0620 - mae: 0.1451 - val_loss: 2.5668 - val_mae: 1.0770\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0754 - mae: 0.1501 - val_loss: 2.5771 - val_mae: 1.0825\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0581 - mae: 0.1429 - val_loss: 2.5805 - val_mae: 1.0748\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0557 - mae: 0.1451 - val_loss: 2.5773 - val_mae: 1.0828\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0609 - mae: 0.1487 - val_loss: 2.5770 - val_mae: 1.0830\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0548 - mae: 0.1346 - val_loss: 2.6198 - val_mae: 1.0963\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0545 - mae: 0.1387 - val_loss: 2.5839 - val_mae: 1.0835\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0562 - mae: 0.1368 - val_loss: 2.6226 - val_mae: 1.0903\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0525 - mae: 0.1372 - val_loss: 2.5843 - val_mae: 1.0827\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0692 - mae: 0.1513 - val_loss: 2.5703 - val_mae: 1.0726\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0506 - mae: 0.1398 - val_loss: 2.5944 - val_mae: 1.0905\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0560 - mae: 0.1424 - val_loss: 2.5955 - val_mae: 1.0798\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0472 - mae: 0.1267 - val_loss: 2.5827 - val_mae: 1.0845\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0498 - mae: 0.1290 - val_loss: 2.5695 - val_mae: 1.0844\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0560 - mae: 0.1287 - val_loss: 2.6136 - val_mae: 1.0865\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0590 - mae: 0.1312 - val_loss: 2.5785 - val_mae: 1.0791\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0526 - mae: 0.1309 - val_loss: 2.5950 - val_mae: 1.0901\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0552 - mae: 0.1379 - val_loss: 2.5885 - val_mae: 1.0762\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0531 - mae: 0.1407 - val_loss: 2.5729 - val_mae: 1.0766\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0542 - mae: 0.1271 - val_loss: 2.5691 - val_mae: 1.0747\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0513 - mae: 0.1318 - val_loss: 2.5883 - val_mae: 1.0780\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0435 - mae: 0.1257 - val_loss: 2.6004 - val_mae: 1.0770\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0611 - mae: 0.1369 - val_loss: 2.5715 - val_mae: 1.0761\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0404 - mae: 0.1191 - val_loss: 2.5960 - val_mae: 1.0805\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0552 - mae: 0.1281 - val_loss: 2.5841 - val_mae: 1.0797\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0603 - mae: 0.1334 - val_loss: 2.5592 - val_mae: 1.0854\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0448 - mae: 0.1221 - val_loss: 2.5627 - val_mae: 1.0821\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0508 - mae: 0.1243 - val_loss: 2.5772 - val_mae: 1.0813\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0577 - mae: 0.1263 - val_loss: 2.5705 - val_mae: 1.0803\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0652 - mae: 0.1364 - val_loss: 2.6088 - val_mae: 1.0834\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0501 - mae: 0.1242 - val_loss: 2.5785 - val_mae: 1.0874\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0572 - mae: 0.1329 - val_loss: 2.5570 - val_mae: 1.0747\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0546 - mae: 0.1209 - val_loss: 2.5721 - val_mae: 1.0756\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0510 - mae: 0.1257 - val_loss: 2.5618 - val_mae: 1.0707\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0576 - mae: 0.1199 - val_loss: 2.5479 - val_mae: 1.0728\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0598 - mae: 0.1311 - val_loss: 2.5860 - val_mae: 1.0767\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0553 - mae: 0.1270 - val_loss: 2.5453 - val_mae: 1.0751\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0610 - mae: 0.1275 - val_loss: 2.6054 - val_mae: 1.0831\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0380 - mae: 0.1149 - val_loss: 2.5874 - val_mae: 1.0735\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0452 - mae: 0.1180 - val_loss: 2.5724 - val_mae: 1.0796\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0422 - mae: 0.1155 - val_loss: 2.5675 - val_mae: 1.0777\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0406 - mae: 0.1151 - val_loss: 2.5937 - val_mae: 1.0823\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0444 - mae: 0.1154 - val_loss: 2.5888 - val_mae: 1.0793\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0589 - mae: 0.1237 - val_loss: 2.5909 - val_mae: 1.0795\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0411 - mae: 0.1132 - val_loss: 2.5848 - val_mae: 1.0856\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0437 - mae: 0.1168 - val_loss: 2.5811 - val_mae: 1.0897\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0589 - mae: 0.1369 - val_loss: 2.6074 - val_mae: 1.0861\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0473 - mae: 0.1147 - val_loss: 2.5791 - val_mae: 1.0776\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0534 - mae: 0.1152 - val_loss: 2.5998 - val_mae: 1.0843\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0488 - mae: 0.1184 - val_loss: 2.5893 - val_mae: 1.0797\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0516 - mae: 0.1239 - val_loss: 2.5789 - val_mae: 1.0813\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0537 - mae: 0.1181 - val_loss: 2.5931 - val_mae: 1.0760\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0471 - mae: 0.1135 - val_loss: 2.6039 - val_mae: 1.0850\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0580 - mae: 0.1115 - val_loss: 2.5832 - val_mae: 1.0802\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0558 - mae: 0.1169 - val_loss: 2.6036 - val_mae: 1.0811\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0478 - mae: 0.1104 - val_loss: 2.5844 - val_mae: 1.0803\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0395 - mae: 0.1138 - val_loss: 2.6090 - val_mae: 1.0820\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0481 - mae: 0.1183 - val_loss: 2.5823 - val_mae: 1.0827\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0554 - mae: 0.1203 - val_loss: 2.5936 - val_mae: 1.0786\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0497 - mae: 0.1160 - val_loss: 2.5869 - val_mae: 1.0844\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0417 - mae: 0.1111 - val_loss: 2.5928 - val_mae: 1.0809\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0438 - mae: 0.1070 - val_loss: 2.5797 - val_mae: 1.0732\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0437 - mae: 0.1056 - val_loss: 2.5964 - val_mae: 1.0845\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0448 - mae: 0.1080 - val_loss: 2.5874 - val_mae: 1.0788\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0515 - mae: 0.1122 - val_loss: 2.5729 - val_mae: 1.0811\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0360 - mae: 0.1025 - val_loss: 2.5901 - val_mae: 1.0893\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0562 - mae: 0.1149 - val_loss: 2.5900 - val_mae: 1.0862\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0513 - mae: 0.1143 - val_loss: 2.6017 - val_mae: 1.0794\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0532 - mae: 0.1172 - val_loss: 2.5818 - val_mae: 1.0859\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0494 - mae: 0.1109 - val_loss: 2.5959 - val_mae: 1.0791\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0437 - mae: 0.1042 - val_loss: 2.5963 - val_mae: 1.0816\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0469 - mae: 0.1065 - val_loss: 2.5929 - val_mae: 1.0842\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0487 - mae: 0.1098 - val_loss: 2.5867 - val_mae: 1.0806\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0495 - mae: 0.1098 - val_loss: 2.5998 - val_mae: 1.0834\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0490 - mae: 0.1075 - val_loss: 2.5936 - val_mae: 1.0807\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0440 - mae: 0.1044 - val_loss: 2.5701 - val_mae: 1.0738\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0471 - mae: 0.1106 - val_loss: 2.5847 - val_mae: 1.0820\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0468 - mae: 0.1027 - val_loss: 2.5855 - val_mae: 1.0775\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0499 - mae: 0.1070 - val_loss: 2.5821 - val_mae: 1.0798\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0481 - mae: 0.1134 - val_loss: 2.5806 - val_mae: 1.0804\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0536 - mae: 0.1164 - val_loss: 2.5771 - val_mae: 1.0751\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0402 - mae: 0.1075 - val_loss: 2.5685 - val_mae: 1.0770\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0430 - mae: 0.1043 - val_loss: 2.5823 - val_mae: 1.0792\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0421 - mae: 0.1005 - val_loss: 2.5596 - val_mae: 1.0738\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0448 - mae: 0.0967 - val_loss: 2.5865 - val_mae: 1.0792\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0392 - mae: 0.1000 - val_loss: 2.5739 - val_mae: 1.0749\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0468 - mae: 0.1036 - val_loss: 2.5794 - val_mae: 1.0826\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0431 - mae: 0.1040 - val_loss: 2.5625 - val_mae: 1.0735\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0419 - mae: 0.1016 - val_loss: 2.5831 - val_mae: 1.0701\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0417 - mae: 0.1049 - val_loss: 2.5807 - val_mae: 1.0732\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0354 - mae: 0.1010 - val_loss: 2.5493 - val_mae: 1.0730\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0406 - mae: 0.1054 - val_loss: 2.5530 - val_mae: 1.0726\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0419 - mae: 0.1035 - val_loss: 2.5729 - val_mae: 1.0747\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0465 - mae: 0.1071 - val_loss: 2.5667 - val_mae: 1.0766\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0507 - mae: 0.1013 - val_loss: 2.5538 - val_mae: 1.0654\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0376 - mae: 0.0932 - val_loss: 2.5643 - val_mae: 1.0730\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0339 - mae: 0.0932 - val_loss: 2.5808 - val_mae: 1.0821\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0376 - mae: 0.0951 - val_loss: 2.5840 - val_mae: 1.0822\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0533 - mae: 0.1091 - val_loss: 2.5767 - val_mae: 1.0808\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0402 - mae: 0.1011 - val_loss: 2.5730 - val_mae: 1.0742\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0424 - mae: 0.1032 - val_loss: 2.5767 - val_mae: 1.0769\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0532 - mae: 0.1041 - val_loss: 2.5838 - val_mae: 1.0834\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0444 - mae: 0.1005 - val_loss: 2.5716 - val_mae: 1.0772\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0355 - mae: 0.0938 - val_loss: 2.5700 - val_mae: 1.0697\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0490 - mae: 0.1014 - val_loss: 2.5636 - val_mae: 1.0783\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0445 - mae: 0.1013 - val_loss: 2.5761 - val_mae: 1.0716\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0388 - mae: 0.0988 - val_loss: 2.5652 - val_mae: 1.0753\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0401 - mae: 0.1005 - val_loss: 2.5669 - val_mae: 1.0801\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0345 - mae: 0.0948 - val_loss: 2.5664 - val_mae: 1.0748\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0430 - mae: 0.0955 - val_loss: 2.5881 - val_mae: 1.0777\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0457 - mae: 0.1005 - val_loss: 2.5620 - val_mae: 1.0741\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0465 - mae: 0.0977 - val_loss: 2.5740 - val_mae: 1.0765\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0329 - mae: 0.0939 - val_loss: 2.5653 - val_mae: 1.0736\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4119 - mae: 1.1123\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 11.8950 - mae: 2.6208 - val_loss: 3.2877 - val_mae: 1.3286\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 1.5974 - mae: 0.9493 - val_loss: 2.9964 - val_mae: 1.2441\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.9255 - mae: 0.7081 - val_loss: 2.8690 - val_mae: 1.2160\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.6151 - mae: 0.5680 - val_loss: 2.8711 - val_mae: 1.2115\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.5409 - mae: 0.5230 - val_loss: 3.0723 - val_mae: 1.2734\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.4794 - mae: 0.4999 - val_loss: 2.9571 - val_mae: 1.2238\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.4086 - mae: 0.4552 - val_loss: 2.9064 - val_mae: 1.2086\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.3769 - mae: 0.4336 - val_loss: 2.8350 - val_mae: 1.1897\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.3221 - mae: 0.4096 - val_loss: 2.8133 - val_mae: 1.1720\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3054 - mae: 0.3931 - val_loss: 2.8258 - val_mae: 1.1898\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2687 - mae: 0.3725 - val_loss: 2.8430 - val_mae: 1.1873\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2567 - mae: 0.3583 - val_loss: 2.8590 - val_mae: 1.1966\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2438 - mae: 0.3482 - val_loss: 2.7600 - val_mae: 1.1680\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2240 - mae: 0.3425 - val_loss: 2.7733 - val_mae: 1.1698\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2253 - mae: 0.3412 - val_loss: 2.8652 - val_mae: 1.1976\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2000 - mae: 0.3228 - val_loss: 2.8076 - val_mae: 1.1729\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2007 - mae: 0.3209 - val_loss: 2.7926 - val_mae: 1.1664\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2037 - mae: 0.3276 - val_loss: 2.8335 - val_mae: 1.1640\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1953 - mae: 0.3223 - val_loss: 2.7935 - val_mae: 1.1676\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1921 - mae: 0.3151 - val_loss: 2.7970 - val_mae: 1.1913\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1584 - mae: 0.2902 - val_loss: 2.7580 - val_mae: 1.1730\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1676 - mae: 0.2827 - val_loss: 2.7417 - val_mae: 1.1477\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1734 - mae: 0.3006 - val_loss: 2.7825 - val_mae: 1.1832\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1793 - mae: 0.3095 - val_loss: 2.7272 - val_mae: 1.1515\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1667 - mae: 0.2911 - val_loss: 2.7848 - val_mae: 1.1875\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1497 - mae: 0.2767 - val_loss: 2.7208 - val_mae: 1.1422\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1294 - mae: 0.2508 - val_loss: 2.6977 - val_mae: 1.1472\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1234 - mae: 0.2489 - val_loss: 2.7941 - val_mae: 1.1842\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1219 - mae: 0.2440 - val_loss: 2.7233 - val_mae: 1.1367\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1265 - mae: 0.2514 - val_loss: 2.7296 - val_mae: 1.1520\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1309 - mae: 0.2583 - val_loss: 2.7015 - val_mae: 1.1463\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1196 - mae: 0.2423 - val_loss: 2.6503 - val_mae: 1.1278\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1179 - mae: 0.2433 - val_loss: 2.7144 - val_mae: 1.1501\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1129 - mae: 0.2325 - val_loss: 2.7302 - val_mae: 1.1670\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1137 - mae: 0.2424 - val_loss: 2.6946 - val_mae: 1.1454\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1107 - mae: 0.2345 - val_loss: 2.6990 - val_mae: 1.1520\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1104 - mae: 0.2244 - val_loss: 2.6501 - val_mae: 1.1300\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0912 - mae: 0.2114 - val_loss: 2.6384 - val_mae: 1.1390\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1176 - mae: 0.2376 - val_loss: 2.6677 - val_mae: 1.1356\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0939 - mae: 0.2206 - val_loss: 2.6426 - val_mae: 1.1386\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0921 - mae: 0.2103 - val_loss: 2.6580 - val_mae: 1.1430\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1057 - mae: 0.2172 - val_loss: 2.6460 - val_mae: 1.1217\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0889 - mae: 0.2031 - val_loss: 2.6911 - val_mae: 1.1367\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0892 - mae: 0.2015 - val_loss: 2.6043 - val_mae: 1.1171\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0755 - mae: 0.1892 - val_loss: 2.6841 - val_mae: 1.1319\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0739 - mae: 0.1922 - val_loss: 2.6346 - val_mae: 1.1217\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0757 - mae: 0.1866 - val_loss: 2.7105 - val_mae: 1.1358\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0937 - mae: 0.2071 - val_loss: 2.6113 - val_mae: 1.1278\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1026 - mae: 0.2101 - val_loss: 2.6100 - val_mae: 1.1159\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0902 - mae: 0.2037 - val_loss: 2.6061 - val_mae: 1.1127\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0741 - mae: 0.1903 - val_loss: 2.6244 - val_mae: 1.1200\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0666 - mae: 0.1786 - val_loss: 2.6363 - val_mae: 1.1301\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0728 - mae: 0.1839 - val_loss: 2.6177 - val_mae: 1.1197\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0710 - mae: 0.1731 - val_loss: 2.5747 - val_mae: 1.1094\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0629 - mae: 0.1633 - val_loss: 2.6211 - val_mae: 1.1192\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0662 - mae: 0.1720 - val_loss: 2.6256 - val_mae: 1.1299\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0639 - mae: 0.1775 - val_loss: 2.6099 - val_mae: 1.1201\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0582 - mae: 0.1681 - val_loss: 2.6513 - val_mae: 1.1209\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0726 - mae: 0.1766 - val_loss: 2.6093 - val_mae: 1.1267\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0733 - mae: 0.1862 - val_loss: 2.5872 - val_mae: 1.1128\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0769 - mae: 0.1814 - val_loss: 2.6247 - val_mae: 1.1212\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0590 - mae: 0.1638 - val_loss: 2.6149 - val_mae: 1.1203\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0596 - mae: 0.1566 - val_loss: 2.5980 - val_mae: 1.1179\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0574 - mae: 0.1548 - val_loss: 2.5738 - val_mae: 1.1090\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0577 - mae: 0.1553 - val_loss: 2.5868 - val_mae: 1.1115\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0505 - mae: 0.1466 - val_loss: 2.5802 - val_mae: 1.1120\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0727 - mae: 0.1662 - val_loss: 2.6138 - val_mae: 1.1224\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0607 - mae: 0.1624 - val_loss: 2.5960 - val_mae: 1.1161\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0647 - mae: 0.1687 - val_loss: 2.5904 - val_mae: 1.1132\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0561 - mae: 0.1560 - val_loss: 2.5836 - val_mae: 1.1128\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0495 - mae: 0.1464 - val_loss: 2.6065 - val_mae: 1.1193\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0483 - mae: 0.1466 - val_loss: 2.5863 - val_mae: 1.1075\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0545 - mae: 0.1497 - val_loss: 2.6035 - val_mae: 1.1134\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0567 - mae: 0.1526 - val_loss: 2.5636 - val_mae: 1.0960\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0590 - mae: 0.1566 - val_loss: 2.6019 - val_mae: 1.1178\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0479 - mae: 0.1475 - val_loss: 2.5988 - val_mae: 1.1110\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0511 - mae: 0.1477 - val_loss: 2.5824 - val_mae: 1.1123\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0419 - mae: 0.1339 - val_loss: 2.5851 - val_mae: 1.1132\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0523 - mae: 0.1413 - val_loss: 2.5797 - val_mae: 1.1141\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0508 - mae: 0.1460 - val_loss: 2.5840 - val_mae: 1.1070\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0532 - mae: 0.1406 - val_loss: 2.5780 - val_mae: 1.1101\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0565 - mae: 0.1481 - val_loss: 2.5560 - val_mae: 1.1028\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0492 - mae: 0.1412 - val_loss: 2.5694 - val_mae: 1.1130\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0516 - mae: 0.1435 - val_loss: 2.5827 - val_mae: 1.1123\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0594 - mae: 0.1477 - val_loss: 2.5706 - val_mae: 1.1098\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0437 - mae: 0.1397 - val_loss: 2.5771 - val_mae: 1.1125\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0454 - mae: 0.1382 - val_loss: 2.5732 - val_mae: 1.1049\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0498 - mae: 0.1388 - val_loss: 2.5354 - val_mae: 1.1039\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0536 - mae: 0.1488 - val_loss: 2.5848 - val_mae: 1.1093\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0475 - mae: 0.1323 - val_loss: 2.6078 - val_mae: 1.1204\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0472 - mae: 0.1342 - val_loss: 2.5613 - val_mae: 1.1083\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0366 - mae: 0.1241 - val_loss: 2.6028 - val_mae: 1.1200\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0491 - mae: 0.1348 - val_loss: 2.5766 - val_mae: 1.1057\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0502 - mae: 0.1465 - val_loss: 2.5925 - val_mae: 1.1129\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0492 - mae: 0.1399 - val_loss: 2.5771 - val_mae: 1.1014\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0440 - mae: 0.1276 - val_loss: 2.5871 - val_mae: 1.1023\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0392 - mae: 0.1247 - val_loss: 2.5868 - val_mae: 1.1134\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0504 - mae: 0.1316 - val_loss: 2.5802 - val_mae: 1.1069\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0389 - mae: 0.1212 - val_loss: 2.6004 - val_mae: 1.1109\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0443 - mae: 0.1377 - val_loss: 2.5596 - val_mae: 1.1032\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0461 - mae: 0.1374 - val_loss: 2.6043 - val_mae: 1.1101\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0398 - mae: 0.1222 - val_loss: 2.5634 - val_mae: 1.1081\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0427 - mae: 0.1265 - val_loss: 2.5751 - val_mae: 1.1106\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0441 - mae: 0.1295 - val_loss: 2.5437 - val_mae: 1.1022\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0450 - mae: 0.1251 - val_loss: 2.5910 - val_mae: 1.1166\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0372 - mae: 0.1191 - val_loss: 2.5714 - val_mae: 1.1027\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0449 - mae: 0.1234 - val_loss: 2.5733 - val_mae: 1.1087\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0355 - mae: 0.1210 - val_loss: 2.5714 - val_mae: 1.1082\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0431 - mae: 0.1165 - val_loss: 2.5855 - val_mae: 1.1032\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0334 - mae: 0.1157 - val_loss: 2.5703 - val_mae: 1.1045\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0370 - mae: 0.1203 - val_loss: 2.5755 - val_mae: 1.0996\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0519 - mae: 0.1329 - val_loss: 2.5885 - val_mae: 1.1123\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0452 - mae: 0.1208 - val_loss: 2.5492 - val_mae: 1.0966\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0326 - mae: 0.1126 - val_loss: 2.5917 - val_mae: 1.1034\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0422 - mae: 0.1173 - val_loss: 2.5618 - val_mae: 1.1025\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0408 - mae: 0.1216 - val_loss: 2.5874 - val_mae: 1.1098\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0407 - mae: 0.1201 - val_loss: 2.5779 - val_mae: 1.1030\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0397 - mae: 0.1190 - val_loss: 2.5901 - val_mae: 1.1094\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0387 - mae: 0.1152 - val_loss: 2.5917 - val_mae: 1.1102\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0303 - mae: 0.1080 - val_loss: 2.5713 - val_mae: 1.0987\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0402 - mae: 0.1197 - val_loss: 2.5765 - val_mae: 1.0991\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0317 - mae: 0.1125 - val_loss: 2.5715 - val_mae: 1.1053\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0401 - mae: 0.1171 - val_loss: 2.5846 - val_mae: 1.1081\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0335 - mae: 0.1097 - val_loss: 2.5842 - val_mae: 1.1090\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0344 - mae: 0.1139 - val_loss: 2.5975 - val_mae: 1.1062\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0375 - mae: 0.1129 - val_loss: 2.5596 - val_mae: 1.1047\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0381 - mae: 0.1136 - val_loss: 2.5955 - val_mae: 1.1044\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0369 - mae: 0.1176 - val_loss: 2.5631 - val_mae: 1.1004\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0338 - mae: 0.1103 - val_loss: 2.5937 - val_mae: 1.1126\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0358 - mae: 0.1129 - val_loss: 2.5719 - val_mae: 1.1084\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0339 - mae: 0.1040 - val_loss: 2.5781 - val_mae: 1.1070\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0296 - mae: 0.1061 - val_loss: 2.5868 - val_mae: 1.1101\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0272 - mae: 0.0996 - val_loss: 2.5881 - val_mae: 1.1120\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0358 - mae: 0.1129 - val_loss: 2.5730 - val_mae: 1.1031\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0380 - mae: 0.1116 - val_loss: 2.5939 - val_mae: 1.1111\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0375 - mae: 0.1125 - val_loss: 2.5603 - val_mae: 1.1012\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0305 - mae: 0.1012 - val_loss: 2.5705 - val_mae: 1.1043\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0336 - mae: 0.1065 - val_loss: 2.5670 - val_mae: 1.1036\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0364 - mae: 0.1090 - val_loss: 2.5726 - val_mae: 1.1131\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0339 - mae: 0.1093 - val_loss: 2.5579 - val_mae: 1.1018\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0352 - mae: 0.1076 - val_loss: 2.5685 - val_mae: 1.1025\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0362 - mae: 0.1043 - val_loss: 2.5807 - val_mae: 1.1048\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0256 - mae: 0.0950 - val_loss: 2.5639 - val_mae: 1.1031\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0379 - mae: 0.1107 - val_loss: 2.5948 - val_mae: 1.1120\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0294 - mae: 0.1055 - val_loss: 2.5777 - val_mae: 1.1051\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0332 - mae: 0.1020 - val_loss: 2.5701 - val_mae: 1.1057\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0308 - mae: 0.0978 - val_loss: 2.6061 - val_mae: 1.1112\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0316 - mae: 0.0981 - val_loss: 2.5992 - val_mae: 1.1169\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0300 - mae: 0.0996 - val_loss: 2.5630 - val_mae: 1.1002\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0262 - mae: 0.0968 - val_loss: 2.5843 - val_mae: 1.1044\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0292 - mae: 0.1044 - val_loss: 2.5784 - val_mae: 1.1049\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0294 - mae: 0.0974 - val_loss: 2.5603 - val_mae: 1.1023\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0282 - mae: 0.1000 - val_loss: 2.5758 - val_mae: 1.1054\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0264 - mae: 0.0984 - val_loss: 2.5735 - val_mae: 1.1037\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0341 - mae: 0.1036 - val_loss: 2.5898 - val_mae: 1.1097\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0242 - mae: 0.0937 - val_loss: 2.5668 - val_mae: 1.1061\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0446 - mae: 0.1043 - val_loss: 2.5810 - val_mae: 1.1077\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0312 - mae: 0.0957 - val_loss: 2.5601 - val_mae: 1.0984\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0275 - mae: 0.0961 - val_loss: 2.5506 - val_mae: 1.0998\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0309 - mae: 0.1008 - val_loss: 2.5804 - val_mae: 1.1012\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0249 - mae: 0.0982 - val_loss: 2.5753 - val_mae: 1.1072\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0311 - mae: 0.0973 - val_loss: 2.5831 - val_mae: 1.1041\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0260 - mae: 0.0993 - val_loss: 2.5837 - val_mae: 1.1115\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0419 - mae: 0.1163 - val_loss: 2.5884 - val_mae: 1.1080\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0350 - mae: 0.1047 - val_loss: 2.5727 - val_mae: 1.1036\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0259 - mae: 0.0940 - val_loss: 2.5801 - val_mae: 1.1054\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0355 - mae: 0.0989 - val_loss: 2.5653 - val_mae: 1.1020\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0307 - mae: 0.0877 - val_loss: 2.5633 - val_mae: 1.1042\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0251 - mae: 0.0841 - val_loss: 2.5680 - val_mae: 1.1042\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0326 - mae: 0.0930 - val_loss: 2.5451 - val_mae: 1.0956\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0258 - mae: 0.0962 - val_loss: 2.5909 - val_mae: 1.1019\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0313 - mae: 0.1013 - val_loss: 2.5710 - val_mae: 1.1065\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0288 - mae: 0.1024 - val_loss: 2.5791 - val_mae: 1.1084\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0368 - mae: 0.1029 - val_loss: 2.5520 - val_mae: 1.1029\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0275 - mae: 0.0963 - val_loss: 2.5540 - val_mae: 1.1014\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0320 - mae: 0.0910 - val_loss: 2.5599 - val_mae: 1.0999\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0261 - mae: 0.0909 - val_loss: 2.5615 - val_mae: 1.1013\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0254 - mae: 0.0917 - val_loss: 2.5674 - val_mae: 1.1059\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0312 - mae: 0.0983 - val_loss: 2.5544 - val_mae: 1.0977\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0363 - mae: 0.0907 - val_loss: 2.5653 - val_mae: 1.1009\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0253 - mae: 0.0833 - val_loss: 2.5577 - val_mae: 1.1013\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0284 - mae: 0.0877 - val_loss: 2.5502 - val_mae: 1.1036\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0380 - mae: 0.1019 - val_loss: 2.5576 - val_mae: 1.1022\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0298 - mae: 0.0962 - val_loss: 2.5531 - val_mae: 1.0982\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0287 - mae: 0.0912 - val_loss: 2.5599 - val_mae: 1.1019\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0333 - mae: 0.0923 - val_loss: 2.5651 - val_mae: 1.1061\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0304 - mae: 0.0910 - val_loss: 2.5861 - val_mae: 1.1025\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0341 - mae: 0.0938 - val_loss: 2.5512 - val_mae: 1.0993\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0249 - mae: 0.0870 - val_loss: 2.5442 - val_mae: 1.0983\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0266 - mae: 0.0912 - val_loss: 2.5587 - val_mae: 1.1033\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0271 - mae: 0.0880 - val_loss: 2.5505 - val_mae: 1.1019\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0268 - mae: 0.0856 - val_loss: 2.5591 - val_mae: 1.1008\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 0.0245 - mae: 0.0847 - val_loss: 2.5626 - val_mae: 1.1082\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0278 - mae: 0.0863 - val_loss: 2.5602 - val_mae: 1.1001\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0256 - mae: 0.0834 - val_loss: 2.5454 - val_mae: 1.0989\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0295 - mae: 0.0894 - val_loss: 2.5455 - val_mae: 1.1017\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0356 - mae: 0.0932 - val_loss: 2.5713 - val_mae: 1.1028\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0297 - mae: 0.0967 - val_loss: 2.5654 - val_mae: 1.1054\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0319 - mae: 0.0931 - val_loss: 2.5681 - val_mae: 1.1062\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0297 - mae: 0.0947 - val_loss: 2.5443 - val_mae: 1.1004\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4366 - mae: 1.1184\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 11.9613 - mae: 2.6553 - val_loss: 3.5794 - val_mae: 1.4251\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 1.6882 - mae: 0.9820 - val_loss: 3.0794 - val_mae: 1.2640\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.8687 - mae: 0.6723 - val_loss: 3.2468 - val_mae: 1.3165\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.6544 - mae: 0.5815 - val_loss: 3.0938 - val_mae: 1.2867\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.5490 - mae: 0.5197 - val_loss: 3.1024 - val_mae: 1.2685\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.5002 - mae: 0.4874 - val_loss: 3.0480 - val_mae: 1.2575\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.4300 - mae: 0.4690 - val_loss: 3.0937 - val_mae: 1.2613\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.3742 - mae: 0.4317 - val_loss: 3.1010 - val_mae: 1.2724\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.3539 - mae: 0.4199 - val_loss: 3.0893 - val_mae: 1.2671\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2979 - mae: 0.3861 - val_loss: 3.0608 - val_mae: 1.2500\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2732 - mae: 0.3698 - val_loss: 3.1112 - val_mae: 1.2576\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2730 - mae: 0.3640 - val_loss: 3.0835 - val_mae: 1.2599\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.3059 - mae: 0.3724 - val_loss: 3.0285 - val_mae: 1.2456\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2538 - mae: 0.3505 - val_loss: 3.0726 - val_mae: 1.2487\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2260 - mae: 0.3353 - val_loss: 2.9789 - val_mae: 1.2256\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2007 - mae: 0.3195 - val_loss: 3.0356 - val_mae: 1.2430\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2153 - mae: 0.3225 - val_loss: 3.1067 - val_mae: 1.2637\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1929 - mae: 0.3138 - val_loss: 2.9698 - val_mae: 1.2282\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1890 - mae: 0.3134 - val_loss: 3.0364 - val_mae: 1.2525\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1965 - mae: 0.3107 - val_loss: 2.9649 - val_mae: 1.2313\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1935 - mae: 0.3118 - val_loss: 2.9535 - val_mae: 1.2202\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1670 - mae: 0.2879 - val_loss: 2.8768 - val_mae: 1.1984\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1774 - mae: 0.2930 - val_loss: 2.9081 - val_mae: 1.2102\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1476 - mae: 0.2711 - val_loss: 2.9290 - val_mae: 1.2072\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1495 - mae: 0.2768 - val_loss: 2.9350 - val_mae: 1.2076\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1694 - mae: 0.2856 - val_loss: 2.9021 - val_mae: 1.2070\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1495 - mae: 0.2753 - val_loss: 2.9314 - val_mae: 1.2144\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1407 - mae: 0.2695 - val_loss: 2.8788 - val_mae: 1.1942\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1243 - mae: 0.2511 - val_loss: 2.9332 - val_mae: 1.2130\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1215 - mae: 0.2459 - val_loss: 3.0045 - val_mae: 1.2512\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1196 - mae: 0.2479 - val_loss: 2.9383 - val_mae: 1.2132\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1208 - mae: 0.2442 - val_loss: 2.9565 - val_mae: 1.2195\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1142 - mae: 0.2449 - val_loss: 2.9182 - val_mae: 1.2089\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1196 - mae: 0.2430 - val_loss: 2.8549 - val_mae: 1.1932\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1101 - mae: 0.2314 - val_loss: 2.8870 - val_mae: 1.1909\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0946 - mae: 0.2193 - val_loss: 3.0386 - val_mae: 1.2725\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1150 - mae: 0.2426 - val_loss: 2.8532 - val_mae: 1.1912\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1053 - mae: 0.2234 - val_loss: 2.8307 - val_mae: 1.1952\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0968 - mae: 0.2203 - val_loss: 2.8721 - val_mae: 1.1881\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1026 - mae: 0.2278 - val_loss: 2.8522 - val_mae: 1.1924\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0938 - mae: 0.2169 - val_loss: 2.8279 - val_mae: 1.1747\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0911 - mae: 0.2202 - val_loss: 2.8243 - val_mae: 1.1853\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0843 - mae: 0.2046 - val_loss: 2.8830 - val_mae: 1.2050\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0744 - mae: 0.1931 - val_loss: 2.8140 - val_mae: 1.1828\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0906 - mae: 0.2070 - val_loss: 2.8412 - val_mae: 1.1921\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0801 - mae: 0.1952 - val_loss: 2.8575 - val_mae: 1.1936\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0732 - mae: 0.1928 - val_loss: 2.8175 - val_mae: 1.1789\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0739 - mae: 0.1917 - val_loss: 2.8064 - val_mae: 1.1731\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0943 - mae: 0.2209 - val_loss: 2.8400 - val_mae: 1.1775\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1171 - mae: 0.2247 - val_loss: 2.8572 - val_mae: 1.1874\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0824 - mae: 0.1994 - val_loss: 2.8554 - val_mae: 1.1745\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0660 - mae: 0.1844 - val_loss: 2.8204 - val_mae: 1.1726\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0645 - mae: 0.1775 - val_loss: 2.8229 - val_mae: 1.1746\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0665 - mae: 0.1730 - val_loss: 2.8132 - val_mae: 1.1817\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0531 - mae: 0.1564 - val_loss: 2.8180 - val_mae: 1.1795\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0551 - mae: 0.1583 - val_loss: 2.7944 - val_mae: 1.1693\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0563 - mae: 0.1616 - val_loss: 2.8146 - val_mae: 1.1681\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0616 - mae: 0.1723 - val_loss: 2.8087 - val_mae: 1.1761\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0640 - mae: 0.1760 - val_loss: 2.7824 - val_mae: 1.1624\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0668 - mae: 0.1762 - val_loss: 2.7884 - val_mae: 1.1624\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0665 - mae: 0.1775 - val_loss: 2.7811 - val_mae: 1.1656\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0569 - mae: 0.1642 - val_loss: 2.8251 - val_mae: 1.1866\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0508 - mae: 0.1594 - val_loss: 2.8066 - val_mae: 1.1637\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0513 - mae: 0.1624 - val_loss: 2.7928 - val_mae: 1.1659\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0536 - mae: 0.1674 - val_loss: 2.7928 - val_mae: 1.1621\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0535 - mae: 0.1608 - val_loss: 2.8121 - val_mae: 1.1792\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0500 - mae: 0.1566 - val_loss: 2.8077 - val_mae: 1.1683\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0501 - mae: 0.1538 - val_loss: 2.8388 - val_mae: 1.1879\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0475 - mae: 0.1521 - val_loss: 2.7816 - val_mae: 1.1672\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0515 - mae: 0.1580 - val_loss: 2.7943 - val_mae: 1.1625\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0490 - mae: 0.1495 - val_loss: 2.8234 - val_mae: 1.1741\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0479 - mae: 0.1490 - val_loss: 2.8077 - val_mae: 1.1715\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0456 - mae: 0.1418 - val_loss: 2.7998 - val_mae: 1.1778\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0394 - mae: 0.1370 - val_loss: 2.7884 - val_mae: 1.1594\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0462 - mae: 0.1416 - val_loss: 2.8071 - val_mae: 1.1748\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0436 - mae: 0.1431 - val_loss: 2.7627 - val_mae: 1.1573\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0449 - mae: 0.1487 - val_loss: 2.7734 - val_mae: 1.1667\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0540 - mae: 0.1569 - val_loss: 2.7949 - val_mae: 1.1641\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0454 - mae: 0.1467 - val_loss: 2.7528 - val_mae: 1.1538\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0375 - mae: 0.1354 - val_loss: 2.7940 - val_mae: 1.1569\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0421 - mae: 0.1456 - val_loss: 2.7918 - val_mae: 1.1660\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0379 - mae: 0.1341 - val_loss: 2.7861 - val_mae: 1.1631\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0377 - mae: 0.1267 - val_loss: 2.7732 - val_mae: 1.1562\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0359 - mae: 0.1315 - val_loss: 2.7787 - val_mae: 1.1625\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0390 - mae: 0.1374 - val_loss: 2.7875 - val_mae: 1.1749\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0375 - mae: 0.1368 - val_loss: 2.7720 - val_mae: 1.1522\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0352 - mae: 0.1331 - val_loss: 2.7694 - val_mae: 1.1604\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0348 - mae: 0.1307 - val_loss: 2.7847 - val_mae: 1.1674\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0428 - mae: 0.1414 - val_loss: 2.7641 - val_mae: 1.1569\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0453 - mae: 0.1451 - val_loss: 2.7580 - val_mae: 1.1628\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0326 - mae: 0.1263 - val_loss: 2.7673 - val_mae: 1.1555\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0328 - mae: 0.1220 - val_loss: 2.7616 - val_mae: 1.1600\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0311 - mae: 0.1205 - val_loss: 2.7660 - val_mae: 1.1585\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0340 - mae: 0.1232 - val_loss: 2.7568 - val_mae: 1.1536\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0331 - mae: 0.1239 - val_loss: 2.7659 - val_mae: 1.1599\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0323 - mae: 0.1252 - val_loss: 2.7846 - val_mae: 1.1617\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0334 - mae: 0.1267 - val_loss: 2.7579 - val_mae: 1.1570\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0315 - mae: 0.1212 - val_loss: 2.7619 - val_mae: 1.1579\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0306 - mae: 0.1193 - val_loss: 2.8001 - val_mae: 1.1702\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0335 - mae: 0.1270 - val_loss: 2.7633 - val_mae: 1.1571\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0339 - mae: 0.1206 - val_loss: 2.7811 - val_mae: 1.1666\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0309 - mae: 0.1192 - val_loss: 2.7627 - val_mae: 1.1539\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0303 - mae: 0.1205 - val_loss: 2.7794 - val_mae: 1.1590\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0298 - mae: 0.1198 - val_loss: 2.7604 - val_mae: 1.1573\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0297 - mae: 0.1221 - val_loss: 2.7659 - val_mae: 1.1553\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0263 - mae: 0.1132 - val_loss: 2.7678 - val_mae: 1.1560\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0303 - mae: 0.1204 - val_loss: 2.7690 - val_mae: 1.1632\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0309 - mae: 0.1197 - val_loss: 2.7577 - val_mae: 1.1517\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0302 - mae: 0.1191 - val_loss: 2.7933 - val_mae: 1.1583\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0312 - mae: 0.1235 - val_loss: 2.7780 - val_mae: 1.1641\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0328 - mae: 0.1251 - val_loss: 2.7685 - val_mae: 1.1557\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0265 - mae: 0.1130 - val_loss: 2.7575 - val_mae: 1.1556\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0273 - mae: 0.1095 - val_loss: 2.7595 - val_mae: 1.1581\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0264 - mae: 0.1116 - val_loss: 2.7490 - val_mae: 1.1547\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0254 - mae: 0.1077 - val_loss: 2.7758 - val_mae: 1.1646\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0243 - mae: 0.1069 - val_loss: 2.7788 - val_mae: 1.1606\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0264 - mae: 0.1071 - val_loss: 2.7788 - val_mae: 1.1595\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0317 - mae: 0.1161 - val_loss: 2.7891 - val_mae: 1.1652\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0291 - mae: 0.1142 - val_loss: 2.7655 - val_mae: 1.1599\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0252 - mae: 0.1061 - val_loss: 2.7492 - val_mae: 1.1507\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0286 - mae: 0.1104 - val_loss: 2.7583 - val_mae: 1.1511\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0244 - mae: 0.1053 - val_loss: 2.7704 - val_mae: 1.1553\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0219 - mae: 0.1001 - val_loss: 2.7688 - val_mae: 1.1582\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0220 - mae: 0.1025 - val_loss: 2.7521 - val_mae: 1.1495\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0253 - mae: 0.1097 - val_loss: 2.7473 - val_mae: 1.1535\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0238 - mae: 0.1062 - val_loss: 2.7311 - val_mae: 1.1467\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0283 - mae: 0.1111 - val_loss: 2.7791 - val_mae: 1.1623\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0244 - mae: 0.1055 - val_loss: 2.7645 - val_mae: 1.1620\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0254 - mae: 0.1047 - val_loss: 2.7601 - val_mae: 1.1555\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0258 - mae: 0.1073 - val_loss: 2.7717 - val_mae: 1.1579\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0216 - mae: 0.0985 - val_loss: 2.7701 - val_mae: 1.1567\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0253 - mae: 0.1006 - val_loss: 2.7444 - val_mae: 1.1589\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0223 - mae: 0.0966 - val_loss: 2.7911 - val_mae: 1.1643\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0261 - mae: 0.1063 - val_loss: 2.7735 - val_mae: 1.1629\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0216 - mae: 0.1003 - val_loss: 2.7832 - val_mae: 1.1592\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0212 - mae: 0.0967 - val_loss: 2.7643 - val_mae: 1.1609\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0192 - mae: 0.0952 - val_loss: 2.7718 - val_mae: 1.1617\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0213 - mae: 0.0978 - val_loss: 2.7730 - val_mae: 1.1592\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0241 - mae: 0.0992 - val_loss: 2.7616 - val_mae: 1.1582\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0215 - mae: 0.0995 - val_loss: 2.7850 - val_mae: 1.1612\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0238 - mae: 0.1019 - val_loss: 2.7464 - val_mae: 1.1526\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0248 - mae: 0.1066 - val_loss: 2.7671 - val_mae: 1.1555\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0272 - mae: 0.1062 - val_loss: 2.7580 - val_mae: 1.1567\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0194 - mae: 0.0941 - val_loss: 2.7231 - val_mae: 1.1493\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0223 - mae: 0.0970 - val_loss: 2.7759 - val_mae: 1.1560\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0217 - mae: 0.0922 - val_loss: 2.7461 - val_mae: 1.1562\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0173 - mae: 0.0891 - val_loss: 2.7825 - val_mae: 1.1585\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0170 - mae: 0.0854 - val_loss: 2.7370 - val_mae: 1.1480\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0251 - mae: 0.1073 - val_loss: 2.7719 - val_mae: 1.1557\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0259 - mae: 0.1032 - val_loss: 2.7348 - val_mae: 1.1521\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0183 - mae: 0.0922 - val_loss: 2.7605 - val_mae: 1.1568\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0191 - mae: 0.0910 - val_loss: 2.7483 - val_mae: 1.1498\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0177 - mae: 0.0924 - val_loss: 2.7551 - val_mae: 1.1593\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0182 - mae: 0.0864 - val_loss: 2.7644 - val_mae: 1.1564\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0179 - mae: 0.0844 - val_loss: 2.7382 - val_mae: 1.1463\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0189 - mae: 0.0891 - val_loss: 2.7581 - val_mae: 1.1522\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0187 - mae: 0.0920 - val_loss: 2.7709 - val_mae: 1.1586\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0198 - mae: 0.0948 - val_loss: 2.7352 - val_mae: 1.1520\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0226 - mae: 0.0961 - val_loss: 2.7648 - val_mae: 1.1539\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0200 - mae: 0.0943 - val_loss: 2.7704 - val_mae: 1.1590\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0197 - mae: 0.0925 - val_loss: 2.7584 - val_mae: 1.1614\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0206 - mae: 0.0896 - val_loss: 2.7590 - val_mae: 1.1524\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0209 - mae: 0.0938 - val_loss: 2.7638 - val_mae: 1.1525\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0207 - mae: 0.0955 - val_loss: 2.7754 - val_mae: 1.1601\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0181 - mae: 0.0883 - val_loss: 2.7767 - val_mae: 1.1563\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0206 - mae: 0.0942 - val_loss: 2.7601 - val_mae: 1.1507\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0194 - mae: 0.0916 - val_loss: 2.7639 - val_mae: 1.1572\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0167 - mae: 0.0862 - val_loss: 2.7532 - val_mae: 1.1502\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0182 - mae: 0.0879 - val_loss: 2.7783 - val_mae: 1.1604\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0180 - mae: 0.0903 - val_loss: 2.7829 - val_mae: 1.1563\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0187 - mae: 0.0892 - val_loss: 2.7661 - val_mae: 1.1565\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0178 - mae: 0.0869 - val_loss: 2.7822 - val_mae: 1.1559\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0154 - mae: 0.0823 - val_loss: 2.7476 - val_mae: 1.1486\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0222 - mae: 0.0904 - val_loss: 2.7683 - val_mae: 1.1532\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0166 - mae: 0.0823 - val_loss: 2.7606 - val_mae: 1.1550\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0163 - mae: 0.0853 - val_loss: 2.7579 - val_mae: 1.1496\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0194 - mae: 0.0875 - val_loss: 2.7541 - val_mae: 1.1533\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0184 - mae: 0.0859 - val_loss: 2.7583 - val_mae: 1.1509\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0174 - mae: 0.0856 - val_loss: 2.7592 - val_mae: 1.1587\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0173 - mae: 0.0825 - val_loss: 2.7530 - val_mae: 1.1501\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0133 - mae: 0.0779 - val_loss: 2.7532 - val_mae: 1.1538\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0169 - mae: 0.0797 - val_loss: 2.7630 - val_mae: 1.1567\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0192 - mae: 0.0873 - val_loss: 2.7531 - val_mae: 1.1527\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0197 - mae: 0.0869 - val_loss: 2.7464 - val_mae: 1.1488\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0196 - mae: 0.0870 - val_loss: 2.7555 - val_mae: 1.1545\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0160 - mae: 0.0834 - val_loss: 2.7560 - val_mae: 1.1546\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0178 - mae: 0.0815 - val_loss: 2.7488 - val_mae: 1.1504\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0160 - mae: 0.0805 - val_loss: 2.7479 - val_mae: 1.1479\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0157 - mae: 0.0786 - val_loss: 2.7607 - val_mae: 1.1554\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0177 - mae: 0.0868 - val_loss: 2.7361 - val_mae: 1.1461\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0180 - mae: 0.0859 - val_loss: 2.7342 - val_mae: 1.1508\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0190 - mae: 0.0836 - val_loss: 2.7647 - val_mae: 1.1538\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0156 - mae: 0.0798 - val_loss: 2.7488 - val_mae: 1.1520\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0130 - mae: 0.0747 - val_loss: 2.7514 - val_mae: 1.1546\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0152 - mae: 0.0789 - val_loss: 2.7558 - val_mae: 1.1514\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0155 - mae: 0.0785 - val_loss: 2.7418 - val_mae: 1.1505\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0147 - mae: 0.0830 - val_loss: 2.7496 - val_mae: 1.1512\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0182 - mae: 0.0860 - val_loss: 2.7601 - val_mae: 1.1548\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0150 - mae: 0.0800 - val_loss: 2.7412 - val_mae: 1.1547\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0186 - mae: 0.0812 - val_loss: 2.7375 - val_mae: 1.1488\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4597 - mae: 1.1356\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 14.1613 - mae: 2.7532 - val_loss: 4.3639 - val_mae: 1.5012\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.5519 - mae: 1.2104 - val_loss: 3.6120 - val_mae: 1.3692\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.6598 - mae: 0.9636 - val_loss: 3.1862 - val_mae: 1.2698\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.2432 - mae: 0.8296 - val_loss: 3.2822 - val_mae: 1.2650\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.9254 - mae: 0.6980 - val_loss: 3.0477 - val_mae: 1.2349\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7785 - mae: 0.6187 - val_loss: 3.3340 - val_mae: 1.2593\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6443 - mae: 0.5636 - val_loss: 3.2248 - val_mae: 1.2900\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5750 - mae: 0.5322 - val_loss: 3.3001 - val_mae: 1.2285\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4842 - mae: 0.4781 - val_loss: 3.1616 - val_mae: 1.2250\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4154 - mae: 0.4395 - val_loss: 3.1101 - val_mae: 1.2155\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3582 - mae: 0.4108 - val_loss: 3.0378 - val_mae: 1.2170\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3268 - mae: 0.3944 - val_loss: 3.0683 - val_mae: 1.1917\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3135 - mae: 0.3761 - val_loss: 2.9182 - val_mae: 1.1967\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2653 - mae: 0.3632 - val_loss: 2.9749 - val_mae: 1.1874\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2948 - mae: 0.3656 - val_loss: 2.9512 - val_mae: 1.1993\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2810 - mae: 0.3585 - val_loss: 2.9704 - val_mae: 1.1771\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2726 - mae: 0.3613 - val_loss: 3.0127 - val_mae: 1.1943\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2824 - mae: 0.3600 - val_loss: 2.9454 - val_mae: 1.1735\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2751 - mae: 0.3590 - val_loss: 2.9221 - val_mae: 1.1861\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.2213 - mae: 0.3243 - val_loss: 2.9056 - val_mae: 1.1724\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2363 - mae: 0.3280 - val_loss: 2.8912 - val_mae: 1.1615\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2084 - mae: 0.3177 - val_loss: 2.8984 - val_mae: 1.1520\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2088 - mae: 0.3102 - val_loss: 2.9046 - val_mae: 1.1643\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2527 - mae: 0.3202 - val_loss: 2.8391 - val_mae: 1.1711\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1924 - mae: 0.3032 - val_loss: 2.9034 - val_mae: 1.1684\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1813 - mae: 0.2878 - val_loss: 2.7425 - val_mae: 1.1485\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1760 - mae: 0.2900 - val_loss: 2.8049 - val_mae: 1.1538\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1993 - mae: 0.3029 - val_loss: 2.8681 - val_mae: 1.1668\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2274 - mae: 0.3152 - val_loss: 2.8019 - val_mae: 1.1473\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1840 - mae: 0.2911 - val_loss: 2.7268 - val_mae: 1.1272\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1473 - mae: 0.2555 - val_loss: 2.8477 - val_mae: 1.1423\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1322 - mae: 0.2494 - val_loss: 2.7665 - val_mae: 1.1396\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1431 - mae: 0.2508 - val_loss: 2.8954 - val_mae: 1.1451\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1421 - mae: 0.2589 - val_loss: 2.8658 - val_mae: 1.1422\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1368 - mae: 0.2533 - val_loss: 2.7812 - val_mae: 1.1408\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1545 - mae: 0.2670 - val_loss: 2.8439 - val_mae: 1.1394\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1476 - mae: 0.2655 - val_loss: 2.8223 - val_mae: 1.1390\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1488 - mae: 0.2685 - val_loss: 2.6925 - val_mae: 1.1217\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1341 - mae: 0.2482 - val_loss: 2.7695 - val_mae: 1.1454\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1495 - mae: 0.2464 - val_loss: 2.7678 - val_mae: 1.1346\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1215 - mae: 0.2295 - val_loss: 2.6683 - val_mae: 1.1203\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1128 - mae: 0.2253 - val_loss: 2.7326 - val_mae: 1.1212\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1165 - mae: 0.2248 - val_loss: 2.7242 - val_mae: 1.1213\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1071 - mae: 0.2269 - val_loss: 2.7250 - val_mae: 1.1300\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1098 - mae: 0.2290 - val_loss: 2.6879 - val_mae: 1.1329\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1105 - mae: 0.2229 - val_loss: 2.7071 - val_mae: 1.1239\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1134 - mae: 0.2316 - val_loss: 2.6843 - val_mae: 1.1165\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0976 - mae: 0.2139 - val_loss: 2.7848 - val_mae: 1.1203\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1109 - mae: 0.2177 - val_loss: 2.6358 - val_mae: 1.1086\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0826 - mae: 0.2005 - val_loss: 2.6558 - val_mae: 1.1067\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0879 - mae: 0.2033 - val_loss: 2.7023 - val_mae: 1.1116\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0863 - mae: 0.2000 - val_loss: 2.8068 - val_mae: 1.1273\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0929 - mae: 0.2078 - val_loss: 2.7357 - val_mae: 1.1159\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0758 - mae: 0.1874 - val_loss: 2.6418 - val_mae: 1.1057\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0838 - mae: 0.1929 - val_loss: 2.6196 - val_mae: 1.1010\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0761 - mae: 0.1882 - val_loss: 2.6914 - val_mae: 1.1267\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0849 - mae: 0.1956 - val_loss: 2.7082 - val_mae: 1.1158\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0928 - mae: 0.2062 - val_loss: 2.6932 - val_mae: 1.1218\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0849 - mae: 0.2002 - val_loss: 2.7188 - val_mae: 1.1233\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0783 - mae: 0.1883 - val_loss: 2.7440 - val_mae: 1.1162\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0796 - mae: 0.1865 - val_loss: 2.7545 - val_mae: 1.1226\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0752 - mae: 0.1867 - val_loss: 2.7020 - val_mae: 1.1139\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0809 - mae: 0.1862 - val_loss: 2.7044 - val_mae: 1.1193\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0665 - mae: 0.1696 - val_loss: 2.6380 - val_mae: 1.1171\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0619 - mae: 0.1654 - val_loss: 2.6660 - val_mae: 1.1224\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0655 - mae: 0.1736 - val_loss: 2.7365 - val_mae: 1.1210\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0694 - mae: 0.1763 - val_loss: 2.6509 - val_mae: 1.1080\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0614 - mae: 0.1709 - val_loss: 2.6401 - val_mae: 1.1062\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0723 - mae: 0.1738 - val_loss: 2.6604 - val_mae: 1.1050\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0763 - mae: 0.1824 - val_loss: 2.7046 - val_mae: 1.1050\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0809 - mae: 0.1940 - val_loss: 2.6914 - val_mae: 1.1151\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0835 - mae: 0.1916 - val_loss: 2.6920 - val_mae: 1.1079\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0691 - mae: 0.1752 - val_loss: 2.6555 - val_mae: 1.0976\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0542 - mae: 0.1554 - val_loss: 2.6620 - val_mae: 1.1083\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0542 - mae: 0.1557 - val_loss: 2.6560 - val_mae: 1.1109\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0611 - mae: 0.1594 - val_loss: 2.5993 - val_mae: 1.0911\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0554 - mae: 0.1538 - val_loss: 2.6570 - val_mae: 1.0982\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0536 - mae: 0.1580 - val_loss: 2.6708 - val_mae: 1.0985\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0508 - mae: 0.1501 - val_loss: 2.6328 - val_mae: 1.1033\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0528 - mae: 0.1507 - val_loss: 2.6612 - val_mae: 1.0957\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0586 - mae: 0.1568 - val_loss: 2.6381 - val_mae: 1.0945\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0554 - mae: 0.1578 - val_loss: 2.6457 - val_mae: 1.1097\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0598 - mae: 0.1609 - val_loss: 2.6659 - val_mae: 1.1012\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0589 - mae: 0.1563 - val_loss: 2.6784 - val_mae: 1.1083\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0512 - mae: 0.1521 - val_loss: 2.6899 - val_mae: 1.1092\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0468 - mae: 0.1473 - val_loss: 2.5950 - val_mae: 1.0961\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0636 - mae: 0.1611 - val_loss: 2.6382 - val_mae: 1.1001\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0482 - mae: 0.1438 - val_loss: 2.6337 - val_mae: 1.0892\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0472 - mae: 0.1400 - val_loss: 2.6328 - val_mae: 1.1002\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0399 - mae: 0.1350 - val_loss: 2.6102 - val_mae: 1.0917\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0455 - mae: 0.1459 - val_loss: 2.6587 - val_mae: 1.1016\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0493 - mae: 0.1456 - val_loss: 2.6474 - val_mae: 1.1078\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0484 - mae: 0.1464 - val_loss: 2.6880 - val_mae: 1.1028\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0512 - mae: 0.1514 - val_loss: 2.6305 - val_mae: 1.0878\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0539 - mae: 0.1551 - val_loss: 2.6490 - val_mae: 1.0979\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0422 - mae: 0.1419 - val_loss: 2.6930 - val_mae: 1.1061\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0421 - mae: 0.1376 - val_loss: 2.6102 - val_mae: 1.1084\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0396 - mae: 0.1386 - val_loss: 2.6483 - val_mae: 1.0977\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0545 - mae: 0.1455 - val_loss: 2.6433 - val_mae: 1.0972\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0533 - mae: 0.1522 - val_loss: 2.5992 - val_mae: 1.0894\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0442 - mae: 0.1361 - val_loss: 2.7231 - val_mae: 1.1073\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0597 - mae: 0.1521 - val_loss: 2.6244 - val_mae: 1.0982\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0501 - mae: 0.1527 - val_loss: 2.6506 - val_mae: 1.0962\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0503 - mae: 0.1494 - val_loss: 2.6223 - val_mae: 1.0881\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0463 - mae: 0.1429 - val_loss: 2.6331 - val_mae: 1.0961\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0352 - mae: 0.1288 - val_loss: 2.7004 - val_mae: 1.0957\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0457 - mae: 0.1371 - val_loss: 2.6603 - val_mae: 1.1002\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0413 - mae: 0.1340 - val_loss: 2.5802 - val_mae: 1.0785\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0386 - mae: 0.1281 - val_loss: 2.6465 - val_mae: 1.0923\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0465 - mae: 0.1336 - val_loss: 2.6255 - val_mae: 1.0953\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0357 - mae: 0.1292 - val_loss: 2.6089 - val_mae: 1.1018\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0489 - mae: 0.1395 - val_loss: 2.6411 - val_mae: 1.0935\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - mae: 0.1265 - val_loss: 2.5717 - val_mae: 1.0829\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0363 - mae: 0.1251 - val_loss: 2.6258 - val_mae: 1.0974\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0399 - mae: 0.1259 - val_loss: 2.6345 - val_mae: 1.0934\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0381 - mae: 0.1262 - val_loss: 2.6112 - val_mae: 1.0868\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0347 - mae: 0.1283 - val_loss: 2.6310 - val_mae: 1.0996\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0464 - mae: 0.1357 - val_loss: 2.5870 - val_mae: 1.0823\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0495 - mae: 0.1435 - val_loss: 2.6116 - val_mae: 1.0943\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0422 - mae: 0.1369 - val_loss: 2.6460 - val_mae: 1.0986\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0453 - mae: 0.1329 - val_loss: 2.5972 - val_mae: 1.0847\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0327 - mae: 0.1202 - val_loss: 2.6208 - val_mae: 1.0957\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0377 - mae: 0.1236 - val_loss: 2.6271 - val_mae: 1.0932\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.1164 - val_loss: 2.6100 - val_mae: 1.0851\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0287 - mae: 0.1118 - val_loss: 2.6172 - val_mae: 1.0898\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0334 - mae: 0.1153 - val_loss: 2.6112 - val_mae: 1.0907\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0382 - mae: 0.1266 - val_loss: 2.6031 - val_mae: 1.0955\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0327 - mae: 0.1249 - val_loss: 2.5954 - val_mae: 1.0814\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0334 - mae: 0.1197 - val_loss: 2.6194 - val_mae: 1.0934\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0327 - mae: 0.1170 - val_loss: 2.6196 - val_mae: 1.0943\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0348 - mae: 0.1174 - val_loss: 2.5823 - val_mae: 1.0880\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0314 - mae: 0.1168 - val_loss: 2.5935 - val_mae: 1.0802\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0320 - mae: 0.1211 - val_loss: 2.6172 - val_mae: 1.0810\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0382 - mae: 0.1259 - val_loss: 2.5708 - val_mae: 1.0796\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0379 - mae: 0.1240 - val_loss: 2.5996 - val_mae: 1.0843\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0446 - mae: 0.1308 - val_loss: 2.5829 - val_mae: 1.0834\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0313 - mae: 0.1144 - val_loss: 2.5782 - val_mae: 1.0828\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0292 - mae: 0.1130 - val_loss: 2.5840 - val_mae: 1.0882\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0364 - mae: 0.1170 - val_loss: 2.5917 - val_mae: 1.0809\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - mae: 0.1068 - val_loss: 2.5675 - val_mae: 1.0764\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0300 - mae: 0.1152 - val_loss: 2.5741 - val_mae: 1.0871\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0260 - mae: 0.1131 - val_loss: 2.6087 - val_mae: 1.0832\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0332 - mae: 0.1156 - val_loss: 2.6123 - val_mae: 1.0879\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.1103 - val_loss: 2.5913 - val_mae: 1.0806\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0265 - mae: 0.1094 - val_loss: 2.5544 - val_mae: 1.0736\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.1079 - val_loss: 2.6413 - val_mae: 1.0905\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0285 - mae: 0.1103 - val_loss: 2.5916 - val_mae: 1.0843\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0377 - mae: 0.1277 - val_loss: 2.5939 - val_mae: 1.0772\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0387 - mae: 0.1254 - val_loss: 2.5935 - val_mae: 1.0961\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0343 - mae: 0.1190 - val_loss: 2.5858 - val_mae: 1.0787\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0311 - mae: 0.1074 - val_loss: 2.6204 - val_mae: 1.0833\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0236 - mae: 0.1003 - val_loss: 2.6387 - val_mae: 1.0885\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - mae: 0.1043 - val_loss: 2.6570 - val_mae: 1.0900\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.1056 - val_loss: 2.5999 - val_mae: 1.0793\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0286 - mae: 0.1067 - val_loss: 2.6064 - val_mae: 1.0843\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0254 - mae: 0.1058 - val_loss: 2.5841 - val_mae: 1.0767\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0315 - mae: 0.1138 - val_loss: 2.5953 - val_mae: 1.0826\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.1096 - val_loss: 2.5886 - val_mae: 1.0744\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0237 - mae: 0.1040 - val_loss: 2.5900 - val_mae: 1.0861\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.1110 - val_loss: 2.5916 - val_mae: 1.0892\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0275 - mae: 0.1127 - val_loss: 2.5945 - val_mae: 1.0867\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0366 - mae: 0.1205 - val_loss: 2.5876 - val_mae: 1.0826\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0283 - mae: 0.1091 - val_loss: 2.5843 - val_mae: 1.0798\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0223 - mae: 0.0973 - val_loss: 2.5925 - val_mae: 1.0777\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0228 - mae: 0.0942 - val_loss: 2.5765 - val_mae: 1.0771\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0238 - mae: 0.0999 - val_loss: 2.5977 - val_mae: 1.0840\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0261 - mae: 0.1081 - val_loss: 2.5643 - val_mae: 1.0787\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0258 - mae: 0.1060 - val_loss: 2.5983 - val_mae: 1.0815\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.1057 - val_loss: 2.5487 - val_mae: 1.0784\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - mae: 0.1031 - val_loss: 2.5761 - val_mae: 1.0764\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0221 - mae: 0.0958 - val_loss: 2.5948 - val_mae: 1.0777\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0257 - mae: 0.0955 - val_loss: 2.5473 - val_mae: 1.0742\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0288 - mae: 0.1087 - val_loss: 2.6078 - val_mae: 1.0770\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0230 - mae: 0.1033 - val_loss: 2.5635 - val_mae: 1.0739\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - mae: 0.1044 - val_loss: 2.5945 - val_mae: 1.0823\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0279 - mae: 0.1084 - val_loss: 2.5824 - val_mae: 1.0847\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0271 - mae: 0.1031 - val_loss: 2.5719 - val_mae: 1.0718\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0273 - mae: 0.1077 - val_loss: 2.5795 - val_mae: 1.0814\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0253 - mae: 0.1061 - val_loss: 2.5628 - val_mae: 1.0750\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0287 - mae: 0.1036 - val_loss: 2.5823 - val_mae: 1.0798\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0243 - mae: 0.1006 - val_loss: 2.5641 - val_mae: 1.0793\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0941 - val_loss: 2.5893 - val_mae: 1.0884\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0215 - mae: 0.0972 - val_loss: 2.5925 - val_mae: 1.0781\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0232 - mae: 0.0987 - val_loss: 2.6149 - val_mae: 1.0863\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.1052 - val_loss: 2.6015 - val_mae: 1.0819\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0281 - mae: 0.1040 - val_loss: 2.5961 - val_mae: 1.0803\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0232 - mae: 0.0989 - val_loss: 2.6450 - val_mae: 1.0958\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0209 - mae: 0.0959 - val_loss: 2.5700 - val_mae: 1.0780\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0218 - mae: 0.0941 - val_loss: 2.5437 - val_mae: 1.0737\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0233 - mae: 0.0991 - val_loss: 2.5848 - val_mae: 1.0737\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - mae: 0.1004 - val_loss: 2.5743 - val_mae: 1.0729\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0242 - mae: 0.0978 - val_loss: 2.6295 - val_mae: 1.0839\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0214 - mae: 0.0949 - val_loss: 2.6174 - val_mae: 1.0850\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0900 - val_loss: 2.5445 - val_mae: 1.0753\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - mae: 0.0947 - val_loss: 2.5816 - val_mae: 1.0820\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0887 - val_loss: 2.5824 - val_mae: 1.0889\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1059 - val_loss: 2.5620 - val_mae: 1.0664\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0913 - val_loss: 2.5705 - val_mae: 1.0784\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0934 - val_loss: 2.5578 - val_mae: 1.0708\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197 - mae: 0.0930 - val_loss: 2.5656 - val_mae: 1.0767\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3684 - mae: 1.0835\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 12.1672 - mae: 2.6387 - val_loss: 4.4855 - val_mae: 1.5253\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.5486 - mae: 1.2198 - val_loss: 3.6870 - val_mae: 1.3606\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.7741 - mae: 0.9857 - val_loss: 3.6635 - val_mae: 1.3326\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.1182 - mae: 0.7792 - val_loss: 3.4816 - val_mae: 1.3214\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.9083 - mae: 0.6830 - val_loss: 3.2964 - val_mae: 1.3144\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.6838 - mae: 0.5803 - val_loss: 3.2534 - val_mae: 1.2704\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6837 - mae: 0.5532 - val_loss: 3.2861 - val_mae: 1.2659\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5199 - mae: 0.4956 - val_loss: 3.0644 - val_mae: 1.2221\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4456 - mae: 0.4485 - val_loss: 3.1912 - val_mae: 1.2231\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4692 - mae: 0.4368 - val_loss: 3.0453 - val_mae: 1.2160\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3816 - mae: 0.4138 - val_loss: 3.1831 - val_mae: 1.2463\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3470 - mae: 0.3914 - val_loss: 3.0949 - val_mae: 1.1873\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3898 - mae: 0.4102 - val_loss: 3.0618 - val_mae: 1.2104\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3064 - mae: 0.3622 - val_loss: 3.1859 - val_mae: 1.1960\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2738 - mae: 0.3584 - val_loss: 3.0031 - val_mae: 1.1940\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2534 - mae: 0.3448 - val_loss: 3.0017 - val_mae: 1.1722\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2555 - mae: 0.3388 - val_loss: 3.0314 - val_mae: 1.1872\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2679 - mae: 0.3591 - val_loss: 3.0377 - val_mae: 1.2036\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2954 - mae: 0.3597 - val_loss: 2.9951 - val_mae: 1.2142\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2388 - mae: 0.3394 - val_loss: 2.8280 - val_mae: 1.1587\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2075 - mae: 0.3099 - val_loss: 3.0051 - val_mae: 1.1831\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1941 - mae: 0.3000 - val_loss: 2.8656 - val_mae: 1.1594\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2011 - mae: 0.3107 - val_loss: 2.9116 - val_mae: 1.1767\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2069 - mae: 0.3147 - val_loss: 2.8302 - val_mae: 1.1439\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1870 - mae: 0.2904 - val_loss: 2.8078 - val_mae: 1.1394\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1594 - mae: 0.2772 - val_loss: 2.8759 - val_mae: 1.1675\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1824 - mae: 0.2847 - val_loss: 2.9118 - val_mae: 1.1548\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1393 - mae: 0.2460 - val_loss: 2.8506 - val_mae: 1.1525\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1701 - mae: 0.2784 - val_loss: 2.8912 - val_mae: 1.1660\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1872 - mae: 0.2967 - val_loss: 2.7647 - val_mae: 1.1391\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1607 - mae: 0.2770 - val_loss: 2.8573 - val_mae: 1.1405\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1608 - mae: 0.2675 - val_loss: 2.7907 - val_mae: 1.1286\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1496 - mae: 0.2612 - val_loss: 2.7653 - val_mae: 1.1346\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1437 - mae: 0.2502 - val_loss: 2.7122 - val_mae: 1.1195\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1231 - mae: 0.2320 - val_loss: 2.7810 - val_mae: 1.1235\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1226 - mae: 0.2294 - val_loss: 2.7676 - val_mae: 1.1293\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1233 - mae: 0.2267 - val_loss: 2.7765 - val_mae: 1.1421\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1182 - mae: 0.2290 - val_loss: 2.7292 - val_mae: 1.1338\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1076 - mae: 0.2204 - val_loss: 2.7601 - val_mae: 1.1121\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1375 - mae: 0.2497 - val_loss: 2.7152 - val_mae: 1.1166\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1301 - mae: 0.2380 - val_loss: 2.8021 - val_mae: 1.1214\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1355 - mae: 0.2504 - val_loss: 2.7071 - val_mae: 1.1267\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1228 - mae: 0.2299 - val_loss: 2.7460 - val_mae: 1.1220\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1169 - mae: 0.2218 - val_loss: 2.7644 - val_mae: 1.1163\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0929 - mae: 0.2056 - val_loss: 2.6935 - val_mae: 1.1132\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0905 - mae: 0.2048 - val_loss: 2.7319 - val_mae: 1.1140\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1047 - mae: 0.2144 - val_loss: 2.6887 - val_mae: 1.1151\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1075 - mae: 0.2084 - val_loss: 2.6944 - val_mae: 1.1109\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1045 - mae: 0.2118 - val_loss: 2.6865 - val_mae: 1.1023\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0931 - mae: 0.2020 - val_loss: 2.6914 - val_mae: 1.1081\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0799 - mae: 0.1889 - val_loss: 2.6914 - val_mae: 1.1014\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0766 - mae: 0.1869 - val_loss: 2.7227 - val_mae: 1.1018\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0732 - mae: 0.1817 - val_loss: 2.6639 - val_mae: 1.0956\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0772 - mae: 0.1831 - val_loss: 2.7107 - val_mae: 1.1166\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0775 - mae: 0.1846 - val_loss: 2.6652 - val_mae: 1.1019\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0737 - mae: 0.1882 - val_loss: 2.6615 - val_mae: 1.1019\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0847 - mae: 0.1908 - val_loss: 2.7090 - val_mae: 1.1115\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0737 - mae: 0.1870 - val_loss: 2.6255 - val_mae: 1.1041\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0847 - mae: 0.1899 - val_loss: 2.6827 - val_mae: 1.1011\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0797 - mae: 0.1914 - val_loss: 2.6657 - val_mae: 1.1042\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0841 - mae: 0.1876 - val_loss: 2.6803 - val_mae: 1.1048\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0722 - mae: 0.1754 - val_loss: 2.6726 - val_mae: 1.1000\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0651 - mae: 0.1681 - val_loss: 2.6710 - val_mae: 1.0938\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0597 - mae: 0.1639 - val_loss: 2.6552 - val_mae: 1.0922\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0603 - mae: 0.1637 - val_loss: 2.6287 - val_mae: 1.0855\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0674 - mae: 0.1702 - val_loss: 2.6372 - val_mae: 1.1007\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0668 - mae: 0.1717 - val_loss: 2.6195 - val_mae: 1.0834\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0544 - mae: 0.1596 - val_loss: 2.6594 - val_mae: 1.1031\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0694 - mae: 0.1768 - val_loss: 2.6218 - val_mae: 1.0847\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0590 - mae: 0.1582 - val_loss: 2.6547 - val_mae: 1.0928\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0492 - mae: 0.1484 - val_loss: 2.6448 - val_mae: 1.0890\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0548 - mae: 0.1589 - val_loss: 2.6235 - val_mae: 1.0873\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0577 - mae: 0.1600 - val_loss: 2.6744 - val_mae: 1.0898\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0621 - mae: 0.1629 - val_loss: 2.6577 - val_mae: 1.0852\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0629 - mae: 0.1565 - val_loss: 2.6613 - val_mae: 1.0880\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0580 - mae: 0.1640 - val_loss: 2.6304 - val_mae: 1.0822\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0518 - mae: 0.1542 - val_loss: 2.6211 - val_mae: 1.0881\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0460 - mae: 0.1478 - val_loss: 2.6544 - val_mae: 1.0848\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0548 - mae: 0.1529 - val_loss: 2.6457 - val_mae: 1.0828\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0480 - mae: 0.1471 - val_loss: 2.6418 - val_mae: 1.0882\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0459 - mae: 0.1427 - val_loss: 2.6483 - val_mae: 1.0864\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0489 - mae: 0.1402 - val_loss: 2.6502 - val_mae: 1.0838\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0486 - mae: 0.1436 - val_loss: 2.6658 - val_mae: 1.0854\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0442 - mae: 0.1382 - val_loss: 2.6423 - val_mae: 1.0794\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0448 - mae: 0.1391 - val_loss: 2.6691 - val_mae: 1.0923\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0541 - mae: 0.1543 - val_loss: 2.6528 - val_mae: 1.0821\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0427 - mae: 0.1404 - val_loss: 2.7476 - val_mae: 1.0964\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0539 - mae: 0.1518 - val_loss: 2.5976 - val_mae: 1.0713\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0490 - mae: 0.1408 - val_loss: 2.6495 - val_mae: 1.0754\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0390 - mae: 0.1350 - val_loss: 2.6369 - val_mae: 1.0865\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - mae: 0.1291 - val_loss: 2.6630 - val_mae: 1.0772\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0379 - mae: 0.1299 - val_loss: 2.6436 - val_mae: 1.0819\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0408 - mae: 0.1334 - val_loss: 2.6649 - val_mae: 1.0797\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0460 - mae: 0.1422 - val_loss: 2.6387 - val_mae: 1.0815\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0399 - mae: 0.1340 - val_loss: 2.6226 - val_mae: 1.0733\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0385 - mae: 0.1350 - val_loss: 2.6176 - val_mae: 1.0788\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0412 - mae: 0.1324 - val_loss: 2.6106 - val_mae: 1.0817\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0423 - mae: 0.1388 - val_loss: 2.6610 - val_mae: 1.0918\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0473 - mae: 0.1383 - val_loss: 2.6724 - val_mae: 1.0937\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0421 - mae: 0.1371 - val_loss: 2.6392 - val_mae: 1.0875\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0404 - mae: 0.1320 - val_loss: 2.6343 - val_mae: 1.0814\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0355 - mae: 0.1234 - val_loss: 2.6323 - val_mae: 1.0812\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0414 - mae: 0.1360 - val_loss: 2.6192 - val_mae: 1.0815\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.1236 - val_loss: 2.6179 - val_mae: 1.0825\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0358 - mae: 0.1208 - val_loss: 2.5934 - val_mae: 1.0808\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0310 - mae: 0.1220 - val_loss: 2.6234 - val_mae: 1.0782\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0292 - mae: 0.1148 - val_loss: 2.5991 - val_mae: 1.0810\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0386 - mae: 0.1262 - val_loss: 2.6295 - val_mae: 1.0815\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - mae: 0.1253 - val_loss: 2.6522 - val_mae: 1.0762\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0379 - mae: 0.1255 - val_loss: 2.5967 - val_mae: 1.0746\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0378 - mae: 0.1240 - val_loss: 2.6095 - val_mae: 1.0733\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0422 - mae: 0.1272 - val_loss: 2.5880 - val_mae: 1.0797\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0333 - mae: 0.1203 - val_loss: 2.6362 - val_mae: 1.0928\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0287 - mae: 0.1131 - val_loss: 2.6175 - val_mae: 1.0742\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0273 - mae: 0.1114 - val_loss: 2.6267 - val_mae: 1.0832\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0272 - mae: 0.1079 - val_loss: 2.6021 - val_mae: 1.0781\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0277 - mae: 0.1158 - val_loss: 2.6756 - val_mae: 1.0869\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0337 - mae: 0.1273 - val_loss: 2.6434 - val_mae: 1.0832\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0340 - mae: 0.1231 - val_loss: 2.6302 - val_mae: 1.0846\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0445 - mae: 0.1325 - val_loss: 2.6114 - val_mae: 1.0880\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - mae: 0.1251 - val_loss: 2.6440 - val_mae: 1.0830\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0266 - mae: 0.1076 - val_loss: 2.6111 - val_mae: 1.0724\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0282 - mae: 0.1136 - val_loss: 2.6035 - val_mae: 1.0803\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - mae: 0.1089 - val_loss: 2.5951 - val_mae: 1.0855\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0331 - mae: 0.1132 - val_loss: 2.6387 - val_mae: 1.0742\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1124 - val_loss: 2.5945 - val_mae: 1.0708\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0338 - mae: 0.1210 - val_loss: 2.5955 - val_mae: 1.0858\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0261 - mae: 0.1121 - val_loss: 2.6226 - val_mae: 1.0746\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0312 - mae: 0.1171 - val_loss: 2.6028 - val_mae: 1.0724\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0281 - mae: 0.1121 - val_loss: 2.5969 - val_mae: 1.0803\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0306 - mae: 0.1144 - val_loss: 2.5982 - val_mae: 1.0765\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0384 - mae: 0.1194 - val_loss: 2.6003 - val_mae: 1.0738\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0324 - mae: 0.1146 - val_loss: 2.5978 - val_mae: 1.0742\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0294 - mae: 0.1103 - val_loss: 2.6170 - val_mae: 1.0802\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - mae: 0.1006 - val_loss: 2.5924 - val_mae: 1.0747\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0945 - val_loss: 2.6131 - val_mae: 1.0839\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0290 - mae: 0.1170 - val_loss: 2.5895 - val_mae: 1.0774\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0264 - mae: 0.1098 - val_loss: 2.5826 - val_mae: 1.0713\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0241 - mae: 0.1062 - val_loss: 2.6172 - val_mae: 1.0783\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0241 - mae: 0.1051 - val_loss: 2.6241 - val_mae: 1.0778\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - mae: 0.1040 - val_loss: 2.5771 - val_mae: 1.0770\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0339 - mae: 0.1141 - val_loss: 2.6290 - val_mae: 1.0810\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.1108 - val_loss: 2.6301 - val_mae: 1.0846\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0371 - mae: 0.1172 - val_loss: 2.6029 - val_mae: 1.0727\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0302 - mae: 0.1102 - val_loss: 2.6212 - val_mae: 1.0831\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0258 - mae: 0.1041 - val_loss: 2.6174 - val_mae: 1.0837\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0252 - mae: 0.1056 - val_loss: 2.6189 - val_mae: 1.0816\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0229 - mae: 0.0984 - val_loss: 2.5907 - val_mae: 1.0796\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0258 - mae: 0.1069 - val_loss: 2.6473 - val_mae: 1.0782\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0289 - mae: 0.1055 - val_loss: 2.6268 - val_mae: 1.0803\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0272 - mae: 0.1034 - val_loss: 2.6320 - val_mae: 1.0784\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - mae: 0.1022 - val_loss: 2.6073 - val_mae: 1.0818\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0245 - mae: 0.1018 - val_loss: 2.6237 - val_mae: 1.0753\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0199 - mae: 0.0964 - val_loss: 2.6104 - val_mae: 1.0822\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0223 - mae: 0.1016 - val_loss: 2.6003 - val_mae: 1.0717\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0222 - mae: 0.1012 - val_loss: 2.5963 - val_mae: 1.0732\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0256 - mae: 0.1057 - val_loss: 2.6109 - val_mae: 1.0736\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0267 - mae: 0.1027 - val_loss: 2.5943 - val_mae: 1.0839\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0211 - mae: 0.0974 - val_loss: 2.6177 - val_mae: 1.0736\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0232 - mae: 0.1010 - val_loss: 2.6356 - val_mae: 1.0773\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0197 - mae: 0.0953 - val_loss: 2.6347 - val_mae: 1.0725\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0249 - mae: 0.1074 - val_loss: 2.5719 - val_mae: 1.0696\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0218 - mae: 0.1014 - val_loss: 2.6158 - val_mae: 1.0761\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0325 - mae: 0.1103 - val_loss: 2.5984 - val_mae: 1.0727\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - mae: 0.1039 - val_loss: 2.5870 - val_mae: 1.0746\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0962 - val_loss: 2.5920 - val_mae: 1.0722\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - mae: 0.0959 - val_loss: 2.6154 - val_mae: 1.0812\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0217 - mae: 0.0926 - val_loss: 2.6097 - val_mae: 1.0732\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0233 - mae: 0.1004 - val_loss: 2.6321 - val_mae: 1.0716\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0232 - mae: 0.1017 - val_loss: 2.5847 - val_mae: 1.0722\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0200 - mae: 0.0965 - val_loss: 2.5793 - val_mae: 1.0730\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0263 - mae: 0.1051 - val_loss: 2.6035 - val_mae: 1.0751\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180 - mae: 0.0914 - val_loss: 2.5834 - val_mae: 1.0725\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182 - mae: 0.0899 - val_loss: 2.5953 - val_mae: 1.0829\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196 - mae: 0.0929 - val_loss: 2.5996 - val_mae: 1.0795\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186 - mae: 0.0899 - val_loss: 2.6139 - val_mae: 1.0767\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0230 - mae: 0.1013 - val_loss: 2.5882 - val_mae: 1.0693\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0230 - mae: 0.0976 - val_loss: 2.5908 - val_mae: 1.0690\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0169 - mae: 0.0887 - val_loss: 2.5715 - val_mae: 1.0689\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175 - mae: 0.0879 - val_loss: 2.5965 - val_mae: 1.0729\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0904 - val_loss: 2.5706 - val_mae: 1.0639\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0160 - mae: 0.0855 - val_loss: 2.6076 - val_mae: 1.0695\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0241 - mae: 0.1086 - val_loss: 2.5908 - val_mae: 1.0698\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0249 - mae: 0.1046 - val_loss: 2.5982 - val_mae: 1.0721\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0945 - val_loss: 2.6247 - val_mae: 1.0784\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196 - mae: 0.0895 - val_loss: 2.5990 - val_mae: 1.0810\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0924 - val_loss: 2.5790 - val_mae: 1.0719\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0890 - val_loss: 2.5903 - val_mae: 1.0687\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0907 - val_loss: 2.5748 - val_mae: 1.0716\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0201 - mae: 0.0890 - val_loss: 2.6043 - val_mae: 1.0813\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0217 - mae: 0.0926 - val_loss: 2.6027 - val_mae: 1.0810\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0205 - mae: 0.0924 - val_loss: 2.5969 - val_mae: 1.0795\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - mae: 0.0868 - val_loss: 2.5669 - val_mae: 1.0714\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181 - mae: 0.0890 - val_loss: 2.5893 - val_mae: 1.0717\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0882 - val_loss: 2.5952 - val_mae: 1.0728\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0864 - val_loss: 2.6114 - val_mae: 1.0734\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183 - mae: 0.0883 - val_loss: 2.5656 - val_mae: 1.0705\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0893 - val_loss: 2.6056 - val_mae: 1.0749\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0261 - mae: 0.1061 - val_loss: 2.5859 - val_mae: 1.0741\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178 - mae: 0.0919 - val_loss: 2.6122 - val_mae: 1.0787\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4275 - mae: 1.0850\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 14.3042 - mae: 2.8761 - val_loss: 4.3590 - val_mae: 1.5693\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.6847 - mae: 1.2600 - val_loss: 3.7129 - val_mae: 1.4121\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.7187 - mae: 0.9846 - val_loss: 3.6609 - val_mae: 1.3614\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.2950 - mae: 0.8252 - val_loss: 3.8122 - val_mae: 1.3582\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0609 - mae: 0.7301 - val_loss: 3.6613 - val_mae: 1.3616\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.8537 - mae: 0.6469 - val_loss: 3.5240 - val_mae: 1.3654\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.7488 - mae: 0.6017 - val_loss: 3.7385 - val_mae: 1.3432\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6822 - mae: 0.5590 - val_loss: 3.6276 - val_mae: 1.3214\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.5204 - mae: 0.4895 - val_loss: 3.4268 - val_mae: 1.3009\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4195 - mae: 0.4287 - val_loss: 3.4259 - val_mae: 1.2969\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3623 - mae: 0.4008 - val_loss: 3.3446 - val_mae: 1.2864\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3554 - mae: 0.3935 - val_loss: 3.2845 - val_mae: 1.2702\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3185 - mae: 0.3743 - val_loss: 3.3367 - val_mae: 1.2619\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3083 - mae: 0.3740 - val_loss: 3.3821 - val_mae: 1.2803\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3267 - mae: 0.3804 - val_loss: 3.4997 - val_mae: 1.2811\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3486 - mae: 0.4015 - val_loss: 3.2930 - val_mae: 1.2620\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2814 - mae: 0.3697 - val_loss: 3.3951 - val_mae: 1.2950\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3081 - mae: 0.3721 - val_loss: 3.2448 - val_mae: 1.2463\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2496 - mae: 0.3366 - val_loss: 3.2714 - val_mae: 1.2522\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3783 - mae: 0.3722 - val_loss: 3.1880 - val_mae: 1.2602\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2605 - mae: 0.3481 - val_loss: 3.1374 - val_mae: 1.2464\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2292 - mae: 0.3098 - val_loss: 3.0571 - val_mae: 1.2168\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1790 - mae: 0.2817 - val_loss: 3.2021 - val_mae: 1.2519\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1773 - mae: 0.2851 - val_loss: 3.1718 - val_mae: 1.2063\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2067 - mae: 0.2953 - val_loss: 3.1794 - val_mae: 1.2325\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2869 - mae: 0.3029 - val_loss: 3.0999 - val_mae: 1.2223\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2269 - mae: 0.3135 - val_loss: 3.0616 - val_mae: 1.2109\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1672 - mae: 0.2819 - val_loss: 3.0090 - val_mae: 1.2088\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1516 - mae: 0.2592 - val_loss: 3.0299 - val_mae: 1.2197\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1735 - mae: 0.2791 - val_loss: 3.0958 - val_mae: 1.2005\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1439 - mae: 0.2572 - val_loss: 2.9755 - val_mae: 1.2065\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1505 - mae: 0.2531 - val_loss: 3.0218 - val_mae: 1.1918\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1347 - mae: 0.2605 - val_loss: 3.0504 - val_mae: 1.2013\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1209 - mae: 0.2383 - val_loss: 2.9921 - val_mae: 1.1949\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1307 - mae: 0.2473 - val_loss: 2.9954 - val_mae: 1.1784\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1260 - mae: 0.2419 - val_loss: 3.0295 - val_mae: 1.1843\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1184 - mae: 0.2381 - val_loss: 2.9165 - val_mae: 1.1938\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1194 - mae: 0.2260 - val_loss: 2.9921 - val_mae: 1.1749\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1217 - mae: 0.2370 - val_loss: 2.9667 - val_mae: 1.1844\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1383 - mae: 0.2478 - val_loss: 2.9049 - val_mae: 1.1568\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1164 - mae: 0.2335 - val_loss: 2.9252 - val_mae: 1.1540\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1128 - mae: 0.2278 - val_loss: 2.8772 - val_mae: 1.1660\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1158 - mae: 0.2256 - val_loss: 2.9242 - val_mae: 1.1601\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1336 - mae: 0.2402 - val_loss: 2.9565 - val_mae: 1.1666\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1086 - mae: 0.2261 - val_loss: 2.8683 - val_mae: 1.1493\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1081 - mae: 0.2204 - val_loss: 2.8436 - val_mae: 1.1624\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0899 - mae: 0.2035 - val_loss: 2.9047 - val_mae: 1.1504\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0989 - mae: 0.2112 - val_loss: 2.9021 - val_mae: 1.1540\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0913 - mae: 0.2025 - val_loss: 2.8154 - val_mae: 1.1482\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0943 - mae: 0.2036 - val_loss: 2.8595 - val_mae: 1.1469\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0821 - mae: 0.1990 - val_loss: 2.7741 - val_mae: 1.1428\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0710 - mae: 0.1837 - val_loss: 2.8245 - val_mae: 1.1503\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0884 - mae: 0.1972 - val_loss: 2.8460 - val_mae: 1.1674\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0813 - mae: 0.1917 - val_loss: 2.8090 - val_mae: 1.1452\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0798 - mae: 0.1949 - val_loss: 2.7708 - val_mae: 1.1395\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0722 - mae: 0.1838 - val_loss: 2.8100 - val_mae: 1.1338\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0764 - mae: 0.1841 - val_loss: 2.7821 - val_mae: 1.1504\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0886 - mae: 0.1998 - val_loss: 2.7453 - val_mae: 1.1489\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0840 - mae: 0.1963 - val_loss: 2.7797 - val_mae: 1.1304\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0710 - mae: 0.1822 - val_loss: 2.7790 - val_mae: 1.1346\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0733 - mae: 0.1781 - val_loss: 2.7566 - val_mae: 1.1400\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0617 - mae: 0.1739 - val_loss: 2.8021 - val_mae: 1.1413\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0569 - mae: 0.1659 - val_loss: 2.7452 - val_mae: 1.1349\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0500 - mae: 0.1564 - val_loss: 2.8390 - val_mae: 1.1325\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0635 - mae: 0.1717 - val_loss: 2.7699 - val_mae: 1.1412\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0624 - mae: 0.1723 - val_loss: 2.7503 - val_mae: 1.1404\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0617 - mae: 0.1693 - val_loss: 2.8341 - val_mae: 1.1388\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0615 - mae: 0.1718 - val_loss: 2.7788 - val_mae: 1.1337\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0743 - mae: 0.1806 - val_loss: 2.8424 - val_mae: 1.1320\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0628 - mae: 0.1744 - val_loss: 2.7806 - val_mae: 1.1418\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0580 - mae: 0.1663 - val_loss: 2.7237 - val_mae: 1.1265\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0495 - mae: 0.1560 - val_loss: 2.8165 - val_mae: 1.1394\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0584 - mae: 0.1605 - val_loss: 2.7515 - val_mae: 1.1346\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0637 - mae: 0.1636 - val_loss: 2.7527 - val_mae: 1.1274\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0590 - mae: 0.1660 - val_loss: 2.7249 - val_mae: 1.1200\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0485 - mae: 0.1542 - val_loss: 2.7213 - val_mae: 1.1224\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0449 - mae: 0.1458 - val_loss: 2.7472 - val_mae: 1.1285\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0393 - mae: 0.1358 - val_loss: 2.7530 - val_mae: 1.1255\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0383 - mae: 0.1333 - val_loss: 2.7553 - val_mae: 1.1254\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0421 - mae: 0.1415 - val_loss: 2.7719 - val_mae: 1.1263\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0468 - mae: 0.1464 - val_loss: 2.8104 - val_mae: 1.1340\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0440 - mae: 0.1466 - val_loss: 2.7404 - val_mae: 1.1273\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0532 - mae: 0.1581 - val_loss: 2.7861 - val_mae: 1.1241\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0459 - mae: 0.1487 - val_loss: 2.8081 - val_mae: 1.1281\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0500 - mae: 0.1541 - val_loss: 2.8044 - val_mae: 1.1356\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0461 - mae: 0.1473 - val_loss: 2.7379 - val_mae: 1.1205\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0500 - mae: 0.1508 - val_loss: 2.7588 - val_mae: 1.1224\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0360 - mae: 0.1326 - val_loss: 2.7619 - val_mae: 1.1232\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0373 - mae: 0.1343 - val_loss: 2.7624 - val_mae: 1.1347\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0408 - mae: 0.1422 - val_loss: 2.7832 - val_mae: 1.1258\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0448 - mae: 0.1433 - val_loss: 2.7962 - val_mae: 1.1327\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0388 - mae: 0.1359 - val_loss: 2.7356 - val_mae: 1.1307\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0413 - mae: 0.1438 - val_loss: 2.7340 - val_mae: 1.1167\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0347 - mae: 0.1296 - val_loss: 2.7246 - val_mae: 1.1230\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0395 - mae: 0.1395 - val_loss: 2.7280 - val_mae: 1.1187\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - mae: 0.1332 - val_loss: 2.7238 - val_mae: 1.1300\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0354 - mae: 0.1306 - val_loss: 2.7214 - val_mae: 1.1278\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0373 - mae: 0.1303 - val_loss: 2.7239 - val_mae: 1.1208\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0361 - mae: 0.1299 - val_loss: 2.7161 - val_mae: 1.1185\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0325 - mae: 0.1250 - val_loss: 2.7125 - val_mae: 1.1160\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0321 - mae: 0.1246 - val_loss: 2.7299 - val_mae: 1.1194\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0339 - mae: 0.1222 - val_loss: 2.7624 - val_mae: 1.1286\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0343 - mae: 0.1290 - val_loss: 2.7349 - val_mae: 1.1200\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0364 - mae: 0.1326 - val_loss: 2.7075 - val_mae: 1.1177\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0419 - mae: 0.1365 - val_loss: 2.7777 - val_mae: 1.1263\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0368 - mae: 0.1306 - val_loss: 2.7157 - val_mae: 1.1206\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0296 - mae: 0.1196 - val_loss: 2.7482 - val_mae: 1.1158\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0377 - mae: 0.1238 - val_loss: 2.7311 - val_mae: 1.1335\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0300 - mae: 0.1239 - val_loss: 2.7393 - val_mae: 1.1221\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0276 - mae: 0.1186 - val_loss: 2.7389 - val_mae: 1.1246\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0264 - mae: 0.1145 - val_loss: 2.7069 - val_mae: 1.1157\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0260 - mae: 0.1124 - val_loss: 2.7246 - val_mae: 1.1345\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0302 - mae: 0.1223 - val_loss: 2.6908 - val_mae: 1.1091\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0285 - mae: 0.1204 - val_loss: 2.6874 - val_mae: 1.1187\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0357 - mae: 0.1287 - val_loss: 2.6975 - val_mae: 1.1175\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0311 - mae: 0.1238 - val_loss: 2.7435 - val_mae: 1.1228\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0332 - mae: 0.1266 - val_loss: 2.7542 - val_mae: 1.1387\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0330 - mae: 0.1255 - val_loss: 2.7530 - val_mae: 1.1188\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0281 - mae: 0.1172 - val_loss: 2.7132 - val_mae: 1.1185\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0238 - mae: 0.1080 - val_loss: 2.7233 - val_mae: 1.1159\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0227 - mae: 0.1044 - val_loss: 2.7246 - val_mae: 1.1090\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0215 - mae: 0.1025 - val_loss: 2.7271 - val_mae: 1.1186\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0229 - mae: 0.1054 - val_loss: 2.7144 - val_mae: 1.1142\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0252 - mae: 0.1089 - val_loss: 2.7082 - val_mae: 1.1180\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0304 - mae: 0.1224 - val_loss: 2.6869 - val_mae: 1.1187\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1158 - val_loss: 2.6875 - val_mae: 1.1129\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0239 - mae: 0.1093 - val_loss: 2.7280 - val_mae: 1.1139\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0245 - mae: 0.1089 - val_loss: 2.6990 - val_mae: 1.1095\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0230 - mae: 0.1061 - val_loss: 2.6969 - val_mae: 1.1175\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0202 - mae: 0.1009 - val_loss: 2.6884 - val_mae: 1.1104\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0226 - mae: 0.1060 - val_loss: 2.6906 - val_mae: 1.1137\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0267 - mae: 0.1123 - val_loss: 2.7150 - val_mae: 1.1136\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0232 - mae: 0.1068 - val_loss: 2.7139 - val_mae: 1.1156\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0245 - mae: 0.1101 - val_loss: 2.6843 - val_mae: 1.1170\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0275 - mae: 0.1126 - val_loss: 2.7164 - val_mae: 1.1134\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0254 - mae: 0.1104 - val_loss: 2.7181 - val_mae: 1.1155\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0274 - mae: 0.1109 - val_loss: 2.6626 - val_mae: 1.1113\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0236 - mae: 0.1062 - val_loss: 2.6916 - val_mae: 1.1103\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0227 - mae: 0.1061 - val_loss: 2.6913 - val_mae: 1.1119\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0213 - mae: 0.1033 - val_loss: 2.6991 - val_mae: 1.1114\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194 - mae: 0.0969 - val_loss: 2.7002 - val_mae: 1.1078\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0228 - mae: 0.1051 - val_loss: 2.7423 - val_mae: 1.1191\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191 - mae: 0.0994 - val_loss: 2.6722 - val_mae: 1.1178\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0213 - mae: 0.1060 - val_loss: 2.7279 - val_mae: 1.1122\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.1006 - val_loss: 2.6977 - val_mae: 1.1172\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0199 - mae: 0.0970 - val_loss: 2.6942 - val_mae: 1.1086\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0204 - mae: 0.1008 - val_loss: 2.7239 - val_mae: 1.1121\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0973 - val_loss: 2.7008 - val_mae: 1.1177\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0209 - mae: 0.1012 - val_loss: 2.7065 - val_mae: 1.1170\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0981 - val_loss: 2.7042 - val_mae: 1.1144\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0978 - val_loss: 2.6767 - val_mae: 1.1073\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0218 - mae: 0.1049 - val_loss: 2.6867 - val_mae: 1.1117\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0959 - val_loss: 2.6679 - val_mae: 1.1148\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184 - mae: 0.0961 - val_loss: 2.6757 - val_mae: 1.1126\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192 - mae: 0.0972 - val_loss: 2.7016 - val_mae: 1.1142\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0216 - mae: 0.0999 - val_loss: 2.6800 - val_mae: 1.1187\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.1013 - val_loss: 2.6735 - val_mae: 1.1124\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174 - mae: 0.0925 - val_loss: 2.7008 - val_mae: 1.1126\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0159 - mae: 0.0872 - val_loss: 2.6873 - val_mae: 1.1125\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0941 - val_loss: 2.7180 - val_mae: 1.1313\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0247 - mae: 0.1075 - val_loss: 2.6913 - val_mae: 1.1070\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0235 - mae: 0.1048 - val_loss: 2.7133 - val_mae: 1.1160\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193 - mae: 0.0973 - val_loss: 2.6706 - val_mae: 1.1043\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0958 - val_loss: 2.6916 - val_mae: 1.1160\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175 - mae: 0.0903 - val_loss: 2.7106 - val_mae: 1.1213\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177 - mae: 0.0933 - val_loss: 2.6808 - val_mae: 1.1083\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0948 - val_loss: 2.6792 - val_mae: 1.1104\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0908 - val_loss: 2.6963 - val_mae: 1.1158\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179 - mae: 0.0960 - val_loss: 2.6949 - val_mae: 1.1232\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185 - mae: 0.0975 - val_loss: 2.6735 - val_mae: 1.1087\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162 - mae: 0.0899 - val_loss: 2.7178 - val_mae: 1.1180\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175 - mae: 0.0918 - val_loss: 2.6884 - val_mae: 1.1172\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0221 - mae: 0.0958 - val_loss: 2.7145 - val_mae: 1.1183\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176 - mae: 0.0946 - val_loss: 2.7080 - val_mae: 1.1160\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0155 - mae: 0.0892 - val_loss: 2.6727 - val_mae: 1.1154\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0156 - mae: 0.0879 - val_loss: 2.6778 - val_mae: 1.1095\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0141 - mae: 0.0814 - val_loss: 2.6589 - val_mae: 1.1041\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0149 - mae: 0.0844 - val_loss: 2.7003 - val_mae: 1.1210\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0207 - mae: 0.0988 - val_loss: 2.7002 - val_mae: 1.1084\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186 - mae: 0.0958 - val_loss: 2.6622 - val_mae: 1.1053\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188 - mae: 0.0963 - val_loss: 2.6935 - val_mae: 1.1117\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0166 - mae: 0.0884 - val_loss: 2.6953 - val_mae: 1.1112\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0144 - mae: 0.0824 - val_loss: 2.7359 - val_mae: 1.1157\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0212 - mae: 0.0929 - val_loss: 2.6956 - val_mae: 1.1096\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0150 - mae: 0.0842 - val_loss: 2.6676 - val_mae: 1.1067\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0153 - mae: 0.0859 - val_loss: 2.6889 - val_mae: 1.1075\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176 - mae: 0.0941 - val_loss: 2.6917 - val_mae: 1.1134\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167 - mae: 0.0926 - val_loss: 2.7121 - val_mae: 1.1107\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0156 - mae: 0.0861 - val_loss: 2.6700 - val_mae: 1.1073\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0829 - val_loss: 2.6765 - val_mae: 1.1124\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0840 - val_loss: 2.6739 - val_mae: 1.1054\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0816 - val_loss: 2.6700 - val_mae: 1.1023\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - mae: 0.0922 - val_loss: 2.6708 - val_mae: 1.1082\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0160 - mae: 0.0892 - val_loss: 2.6736 - val_mae: 1.1057\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0168 - mae: 0.0926 - val_loss: 2.7103 - val_mae: 1.1074\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183 - mae: 0.0905 - val_loss: 2.6946 - val_mae: 1.1093\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190 - mae: 0.0965 - val_loss: 2.6681 - val_mae: 1.1102\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0154 - mae: 0.0863 - val_loss: 2.6805 - val_mae: 1.1007\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0155 - mae: 0.0847 - val_loss: 2.6820 - val_mae: 1.1068\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0113 - mae: 0.0742 - val_loss: 2.6804 - val_mae: 1.1094\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5886 - mae: 1.1465\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 12.5613 - mae: 2.7116 - val_loss: 4.0211 - val_mae: 1.4577\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.3223 - mae: 1.1464 - val_loss: 3.5035 - val_mae: 1.3408\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 1.4742 - mae: 0.9087 - val_loss: 3.3745 - val_mae: 1.3197\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.0946 - mae: 0.7694 - val_loss: 3.2418 - val_mae: 1.3001\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.8682 - mae: 0.6774 - val_loss: 3.0903 - val_mae: 1.2717\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.7355 - mae: 0.6108 - val_loss: 3.0347 - val_mae: 1.2237\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.6142 - mae: 0.5491 - val_loss: 3.0797 - val_mae: 1.2704\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.6176 - mae: 0.5330 - val_loss: 3.0982 - val_mae: 1.2092\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.4328 - mae: 0.4584 - val_loss: 3.1036 - val_mae: 1.2290\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.4089 - mae: 0.4418 - val_loss: 3.2039 - val_mae: 1.1945\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3389 - mae: 0.4090 - val_loss: 2.9806 - val_mae: 1.1967\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3277 - mae: 0.3915 - val_loss: 2.9198 - val_mae: 1.1898\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3067 - mae: 0.3816 - val_loss: 2.8864 - val_mae: 1.1697\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.3132 - mae: 0.3883 - val_loss: 2.9731 - val_mae: 1.1774\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2789 - mae: 0.3655 - val_loss: 2.8891 - val_mae: 1.1657\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2889 - mae: 0.3714 - val_loss: 2.8908 - val_mae: 1.1685\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2953 - mae: 0.3640 - val_loss: 2.9336 - val_mae: 1.1573\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2805 - mae: 0.3533 - val_loss: 2.8664 - val_mae: 1.1716\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2448 - mae: 0.3405 - val_loss: 2.8507 - val_mae: 1.1484\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2273 - mae: 0.3359 - val_loss: 2.8267 - val_mae: 1.1653\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2448 - mae: 0.3325 - val_loss: 2.9576 - val_mae: 1.1597\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2133 - mae: 0.3227 - val_loss: 2.8739 - val_mae: 1.1403\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2242 - mae: 0.3171 - val_loss: 2.8168 - val_mae: 1.1357\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2094 - mae: 0.3120 - val_loss: 2.7895 - val_mae: 1.1395\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1779 - mae: 0.2925 - val_loss: 2.8684 - val_mae: 1.1339\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1840 - mae: 0.2947 - val_loss: 2.8214 - val_mae: 1.1243\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2154 - mae: 0.3106 - val_loss: 2.7139 - val_mae: 1.1182\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1815 - mae: 0.2811 - val_loss: 2.7501 - val_mae: 1.1173\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1539 - mae: 0.2586 - val_loss: 2.8597 - val_mae: 1.1306\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1510 - mae: 0.2599 - val_loss: 2.7274 - val_mae: 1.1122\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1225 - mae: 0.2363 - val_loss: 2.7645 - val_mae: 1.1211\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1404 - mae: 0.2506 - val_loss: 2.7502 - val_mae: 1.1159\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1250 - mae: 0.2434 - val_loss: 2.7097 - val_mae: 1.1449\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1473 - mae: 0.2744 - val_loss: 2.7014 - val_mae: 1.1278\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1677 - mae: 0.2811 - val_loss: 2.7419 - val_mae: 1.1236\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1380 - mae: 0.2549 - val_loss: 2.7479 - val_mae: 1.1076\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1368 - mae: 0.2436 - val_loss: 2.6809 - val_mae: 1.1070\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1244 - mae: 0.2380 - val_loss: 2.7418 - val_mae: 1.1077\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1126 - mae: 0.2267 - val_loss: 2.6881 - val_mae: 1.0967\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1062 - mae: 0.2179 - val_loss: 2.7640 - val_mae: 1.1005\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1264 - mae: 0.2292 - val_loss: 2.6501 - val_mae: 1.0840\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1391 - mae: 0.2325 - val_loss: 2.6706 - val_mae: 1.0898\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1085 - mae: 0.2215 - val_loss: 2.6696 - val_mae: 1.0906\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1074 - mae: 0.2234 - val_loss: 2.6963 - val_mae: 1.0922\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0989 - mae: 0.2134 - val_loss: 2.6480 - val_mae: 1.0821\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0853 - mae: 0.1933 - val_loss: 2.6167 - val_mae: 1.0795\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0874 - mae: 0.1918 - val_loss: 2.6695 - val_mae: 1.0808\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0909 - mae: 0.2113 - val_loss: 2.6732 - val_mae: 1.0758\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0915 - mae: 0.2070 - val_loss: 2.7422 - val_mae: 1.0812\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0944 - mae: 0.2105 - val_loss: 2.6388 - val_mae: 1.0689\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1010 - mae: 0.2112 - val_loss: 2.5918 - val_mae: 1.0896\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0925 - mae: 0.2050 - val_loss: 2.6255 - val_mae: 1.0731\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0913 - mae: 0.1957 - val_loss: 2.6254 - val_mae: 1.0890\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0842 - mae: 0.1855 - val_loss: 2.6419 - val_mae: 1.0839\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1140 - mae: 0.2093 - val_loss: 2.6095 - val_mae: 1.0578\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0809 - mae: 0.1860 - val_loss: 2.6191 - val_mae: 1.0630\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0726 - mae: 0.1757 - val_loss: 2.6500 - val_mae: 1.0663\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0762 - mae: 0.1812 - val_loss: 2.5944 - val_mae: 1.0574\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0678 - mae: 0.1770 - val_loss: 2.6277 - val_mae: 1.0899\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0802 - mae: 0.1906 - val_loss: 2.5913 - val_mae: 1.0602\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0772 - mae: 0.1846 - val_loss: 2.6466 - val_mae: 1.0656\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0617 - mae: 0.1700 - val_loss: 2.6542 - val_mae: 1.0685\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0701 - mae: 0.1707 - val_loss: 2.6045 - val_mae: 1.0673\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0622 - mae: 0.1651 - val_loss: 2.5809 - val_mae: 1.0619\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0668 - mae: 0.1697 - val_loss: 2.6623 - val_mae: 1.0744\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0685 - mae: 0.1753 - val_loss: 2.5981 - val_mae: 1.0647\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0578 - mae: 0.1632 - val_loss: 2.6285 - val_mae: 1.0729\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0573 - mae: 0.1626 - val_loss: 2.5415 - val_mae: 1.0681\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0598 - mae: 0.1651 - val_loss: 2.6289 - val_mae: 1.0673\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0627 - mae: 0.1651 - val_loss: 2.5440 - val_mae: 1.0555\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0556 - mae: 0.1557 - val_loss: 2.6007 - val_mae: 1.0604\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0568 - mae: 0.1626 - val_loss: 2.5608 - val_mae: 1.0603\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0694 - mae: 0.1734 - val_loss: 2.6509 - val_mae: 1.0668\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0572 - mae: 0.1584 - val_loss: 2.5875 - val_mae: 1.0622\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0611 - mae: 0.1605 - val_loss: 2.5833 - val_mae: 1.0613\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0720 - mae: 0.1617 - val_loss: 2.6012 - val_mae: 1.0676\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0614 - mae: 0.1576 - val_loss: 2.5829 - val_mae: 1.0621\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0520 - mae: 0.1461 - val_loss: 2.6259 - val_mae: 1.0608\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0548 - mae: 0.1533 - val_loss: 2.5899 - val_mae: 1.0557\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0561 - mae: 0.1488 - val_loss: 2.5845 - val_mae: 1.0563\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0511 - mae: 0.1486 - val_loss: 2.6085 - val_mae: 1.0596\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0530 - mae: 0.1486 - val_loss: 2.5837 - val_mae: 1.0579\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0597 - mae: 0.1527 - val_loss: 2.5613 - val_mae: 1.0536\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0500 - mae: 0.1429 - val_loss: 2.6414 - val_mae: 1.0598\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0450 - mae: 0.1427 - val_loss: 2.5617 - val_mae: 1.0487\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0383 - mae: 0.1335 - val_loss: 2.5985 - val_mae: 1.0582\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0421 - mae: 0.1398 - val_loss: 2.5823 - val_mae: 1.0517\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0479 - mae: 0.1397 - val_loss: 2.6104 - val_mae: 1.0573\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0489 - mae: 0.1381 - val_loss: 2.5760 - val_mae: 1.0602\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0454 - mae: 0.1443 - val_loss: 2.5727 - val_mae: 1.0533\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0504 - mae: 0.1426 - val_loss: 2.5621 - val_mae: 1.0556\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0388 - mae: 0.1348 - val_loss: 2.5582 - val_mae: 1.0460\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0402 - mae: 0.1314 - val_loss: 2.6213 - val_mae: 1.0580\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0449 - mae: 0.1372 - val_loss: 2.5674 - val_mae: 1.0573\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0425 - mae: 0.1337 - val_loss: 2.5712 - val_mae: 1.0571\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0420 - mae: 0.1376 - val_loss: 2.5709 - val_mae: 1.0510\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0431 - mae: 0.1395 - val_loss: 2.5926 - val_mae: 1.0544\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0567 - mae: 0.1501 - val_loss: 2.5389 - val_mae: 1.0419\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0414 - mae: 0.1363 - val_loss: 2.5734 - val_mae: 1.0544\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0402 - mae: 0.1340 - val_loss: 2.5661 - val_mae: 1.0423\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0471 - mae: 0.1361 - val_loss: 2.5792 - val_mae: 1.0488\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0307 - mae: 0.1168 - val_loss: 2.5938 - val_mae: 1.0468\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0391 - mae: 0.1259 - val_loss: 2.5997 - val_mae: 1.0573\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0345 - mae: 0.1167 - val_loss: 2.5559 - val_mae: 1.0505\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0406 - mae: 0.1240 - val_loss: 2.5500 - val_mae: 1.0411\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0353 - mae: 0.1227 - val_loss: 2.5947 - val_mae: 1.0459\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0371 - mae: 0.1235 - val_loss: 2.5577 - val_mae: 1.0460\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0365 - mae: 0.1237 - val_loss: 2.5661 - val_mae: 1.0407\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0400 - mae: 0.1249 - val_loss: 2.5710 - val_mae: 1.0399\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0341 - mae: 0.1209 - val_loss: 2.5820 - val_mae: 1.0436\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0333 - mae: 0.1220 - val_loss: 2.5875 - val_mae: 1.0487\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0311 - mae: 0.1176 - val_loss: 2.5626 - val_mae: 1.0449\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0450 - mae: 0.1323 - val_loss: 2.5478 - val_mae: 1.0448\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0327 - mae: 0.1247 - val_loss: 2.5730 - val_mae: 1.0460\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0326 - mae: 0.1186 - val_loss: 2.5754 - val_mae: 1.0467\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0338 - mae: 0.1230 - val_loss: 2.5576 - val_mae: 1.0410\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0346 - mae: 0.1184 - val_loss: 2.5929 - val_mae: 1.0482\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0354 - mae: 0.1162 - val_loss: 2.5523 - val_mae: 1.0453\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0318 - mae: 0.1179 - val_loss: 2.5388 - val_mae: 1.0387\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0347 - mae: 0.1233 - val_loss: 2.5968 - val_mae: 1.0465\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0310 - mae: 0.1173 - val_loss: 2.5827 - val_mae: 1.0419\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0363 - mae: 0.1209 - val_loss: 2.5796 - val_mae: 1.0494\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0320 - mae: 0.1152 - val_loss: 2.6029 - val_mae: 1.0495\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0287 - mae: 0.1085 - val_loss: 2.5853 - val_mae: 1.0571\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0313 - mae: 0.1183 - val_loss: 2.5618 - val_mae: 1.0414\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0298 - mae: 0.1138 - val_loss: 2.6166 - val_mae: 1.0571\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0295 - mae: 0.1110 - val_loss: 2.5632 - val_mae: 1.0473\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0438 - mae: 0.1184 - val_loss: 2.5981 - val_mae: 1.0493\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0290 - mae: 0.1140 - val_loss: 2.5946 - val_mae: 1.0488\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0260 - mae: 0.1081 - val_loss: 2.5711 - val_mae: 1.0534\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0424 - mae: 0.1280 - val_loss: 2.5526 - val_mae: 1.0392\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0307 - mae: 0.1120 - val_loss: 2.5683 - val_mae: 1.0451\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0367 - mae: 0.1233 - val_loss: 2.5862 - val_mae: 1.0504\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0374 - mae: 0.1213 - val_loss: 2.5594 - val_mae: 1.0384\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0261 - mae: 0.1033 - val_loss: 2.5612 - val_mae: 1.0489\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0235 - mae: 0.1014 - val_loss: 2.5639 - val_mae: 1.0466\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0262 - mae: 0.1063 - val_loss: 2.5632 - val_mae: 1.0460\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0312 - mae: 0.1071 - val_loss: 2.5960 - val_mae: 1.0510\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0281 - mae: 0.1109 - val_loss: 2.5515 - val_mae: 1.0424\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0228 - mae: 0.1033 - val_loss: 2.6242 - val_mae: 1.0512\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0257 - mae: 0.1080 - val_loss: 2.5320 - val_mae: 1.0416\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0296 - mae: 0.1106 - val_loss: 2.5816 - val_mae: 1.0447\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0233 - mae: 0.1042 - val_loss: 2.5788 - val_mae: 1.0408\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0359 - mae: 0.1210 - val_loss: 2.5909 - val_mae: 1.0497\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0278 - mae: 0.1070 - val_loss: 2.5643 - val_mae: 1.0458\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0352 - mae: 0.1148 - val_loss: 2.5923 - val_mae: 1.0501\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0246 - mae: 0.1032 - val_loss: 2.5576 - val_mae: 1.0436\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0261 - mae: 0.1044 - val_loss: 2.5870 - val_mae: 1.0464\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0316 - mae: 0.1076 - val_loss: 2.5356 - val_mae: 1.0429\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0244 - mae: 0.0976 - val_loss: 2.5675 - val_mae: 1.0489\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0195 - mae: 0.0929 - val_loss: 2.5870 - val_mae: 1.0455\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0231 - mae: 0.0985 - val_loss: 2.5623 - val_mae: 1.0462\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0224 - mae: 0.1016 - val_loss: 2.5940 - val_mae: 1.0511\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0296 - mae: 0.1071 - val_loss: 2.5879 - val_mae: 1.0527\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0285 - mae: 0.1067 - val_loss: 2.5365 - val_mae: 1.0378\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0245 - mae: 0.1024 - val_loss: 2.6014 - val_mae: 1.0456\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0246 - mae: 0.1082 - val_loss: 2.5621 - val_mae: 1.0437\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0271 - mae: 0.1059 - val_loss: 2.5556 - val_mae: 1.0367\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0246 - mae: 0.0999 - val_loss: 2.5718 - val_mae: 1.0426\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0240 - mae: 0.0986 - val_loss: 2.5618 - val_mae: 1.0437\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0237 - mae: 0.0918 - val_loss: 2.5939 - val_mae: 1.0407\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0209 - mae: 0.0970 - val_loss: 2.5741 - val_mae: 1.0472\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0279 - mae: 0.1105 - val_loss: 2.5694 - val_mae: 1.0445\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0258 - mae: 0.0991 - val_loss: 2.5584 - val_mae: 1.0442\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0331 - mae: 0.1204 - val_loss: 2.5571 - val_mae: 1.0440\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0259 - mae: 0.1015 - val_loss: 2.5896 - val_mae: 1.0493\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0262 - mae: 0.0955 - val_loss: 2.5518 - val_mae: 1.0446\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0198 - mae: 0.0902 - val_loss: 2.5591 - val_mae: 1.0476\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0209 - mae: 0.0905 - val_loss: 2.5345 - val_mae: 1.0443\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0210 - mae: 0.0898 - val_loss: 2.5414 - val_mae: 1.0392\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0238 - mae: 0.0957 - val_loss: 2.5782 - val_mae: 1.0476\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0215 - mae: 0.0897 - val_loss: 2.5618 - val_mae: 1.0448\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0230 - mae: 0.0934 - val_loss: 2.5743 - val_mae: 1.0426\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0226 - mae: 0.0961 - val_loss: 2.5767 - val_mae: 1.0484\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0226 - mae: 0.0967 - val_loss: 2.5763 - val_mae: 1.0438\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0234 - mae: 0.0984 - val_loss: 2.5921 - val_mae: 1.0482\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0242 - mae: 0.0976 - val_loss: 2.5743 - val_mae: 1.0453\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0262 - mae: 0.1011 - val_loss: 2.5825 - val_mae: 1.0472\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0300 - mae: 0.0970 - val_loss: 2.5553 - val_mae: 1.0539\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0188 - mae: 0.0899 - val_loss: 2.5685 - val_mae: 1.0469\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0201 - mae: 0.0927 - val_loss: 2.5834 - val_mae: 1.0478\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0160 - mae: 0.0871 - val_loss: 2.5442 - val_mae: 1.0391\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0247 - mae: 0.0946 - val_loss: 2.5384 - val_mae: 1.0477\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0181 - mae: 0.0912 - val_loss: 2.5761 - val_mae: 1.0504\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0226 - mae: 0.0962 - val_loss: 2.5736 - val_mae: 1.0453\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0223 - mae: 0.0924 - val_loss: 2.5847 - val_mae: 1.0454\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0244 - mae: 0.0919 - val_loss: 2.5632 - val_mae: 1.0461\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0236 - mae: 0.0933 - val_loss: 2.5639 - val_mae: 1.0466\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0200 - mae: 0.0907 - val_loss: 2.5554 - val_mae: 1.0476\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0253 - mae: 0.0974 - val_loss: 2.5980 - val_mae: 1.0528\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0287 - mae: 0.1015 - val_loss: 2.5808 - val_mae: 1.0431\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0175 - mae: 0.0870 - val_loss: 2.5430 - val_mae: 1.0444\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0177 - mae: 0.0858 - val_loss: 2.5496 - val_mae: 1.0431\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0267 - mae: 0.0951 - val_loss: 2.5318 - val_mae: 1.0493\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0166 - mae: 0.0843 - val_loss: 2.5607 - val_mae: 1.0467\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0143 - mae: 0.0811 - val_loss: 2.5803 - val_mae: 1.0492\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0198 - mae: 0.0907 - val_loss: 2.5489 - val_mae: 1.0432\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0203 - mae: 0.0934 - val_loss: 2.5712 - val_mae: 1.0469\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0339 - mae: 0.1040 - val_loss: 2.5529 - val_mae: 1.0500\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0205 - mae: 0.0956 - val_loss: 2.5613 - val_mae: 1.0426\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2454 - mae: 1.0501\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 13.5129 - mae: 2.6948 - val_loss: 4.1054 - val_mae: 1.5189\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.2328 - mae: 1.1376 - val_loss: 3.6828 - val_mae: 1.3944\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3833 - mae: 0.8743 - val_loss: 3.4046 - val_mae: 1.3276\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.0002 - mae: 0.7355 - val_loss: 3.4597 - val_mae: 1.3299\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.7955 - mae: 0.6406 - val_loss: 3.3933 - val_mae: 1.3003\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.7234 - mae: 0.5894 - val_loss: 3.2675 - val_mae: 1.2850\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.5458 - mae: 0.5094 - val_loss: 3.3055 - val_mae: 1.2572\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.5061 - mae: 0.4830 - val_loss: 3.4300 - val_mae: 1.3167\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4904 - mae: 0.4730 - val_loss: 3.3458 - val_mae: 1.2730\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4358 - mae: 0.4409 - val_loss: 3.2323 - val_mae: 1.2615\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3381 - mae: 0.3936 - val_loss: 3.4474 - val_mae: 1.2775\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4044 - mae: 0.4276 - val_loss: 3.2336 - val_mae: 1.2472\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3247 - mae: 0.3841 - val_loss: 3.1700 - val_mae: 1.2461\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2806 - mae: 0.3636 - val_loss: 3.1402 - val_mae: 1.2312\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2446 - mae: 0.3385 - val_loss: 3.1518 - val_mae: 1.2164\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2948 - mae: 0.3530 - val_loss: 3.0858 - val_mae: 1.2066\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2718 - mae: 0.3458 - val_loss: 3.0982 - val_mae: 1.2224\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2911 - mae: 0.3532 - val_loss: 3.1934 - val_mae: 1.2296\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2389 - mae: 0.3397 - val_loss: 3.0267 - val_mae: 1.1906\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2349 - mae: 0.3233 - val_loss: 2.9951 - val_mae: 1.1940\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2001 - mae: 0.3050 - val_loss: 2.9873 - val_mae: 1.1994\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2014 - mae: 0.3034 - val_loss: 3.0007 - val_mae: 1.1988\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1759 - mae: 0.2877 - val_loss: 2.9502 - val_mae: 1.1974\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2021 - mae: 0.2956 - val_loss: 2.9093 - val_mae: 1.1820\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1698 - mae: 0.2875 - val_loss: 3.0712 - val_mae: 1.1950\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1966 - mae: 0.3001 - val_loss: 2.9827 - val_mae: 1.1971\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1570 - mae: 0.2762 - val_loss: 2.9925 - val_mae: 1.1733\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1484 - mae: 0.2670 - val_loss: 2.9910 - val_mae: 1.2013\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1845 - mae: 0.2894 - val_loss: 2.8735 - val_mae: 1.1674\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1607 - mae: 0.2787 - val_loss: 3.0674 - val_mae: 1.1939\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1738 - mae: 0.2800 - val_loss: 2.8768 - val_mae: 1.1462\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1368 - mae: 0.2531 - val_loss: 2.9164 - val_mae: 1.1579\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1299 - mae: 0.2443 - val_loss: 2.8558 - val_mae: 1.1470\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1322 - mae: 0.2489 - val_loss: 2.8485 - val_mae: 1.1399\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1408 - mae: 0.2517 - val_loss: 2.8685 - val_mae: 1.1646\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1420 - mae: 0.2566 - val_loss: 2.8162 - val_mae: 1.1430\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1262 - mae: 0.2355 - val_loss: 2.8805 - val_mae: 1.1493\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1233 - mae: 0.2354 - val_loss: 2.8157 - val_mae: 1.1474\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1108 - mae: 0.2308 - val_loss: 2.8419 - val_mae: 1.1608\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1164 - mae: 0.2338 - val_loss: 2.7936 - val_mae: 1.1332\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0998 - mae: 0.2130 - val_loss: 2.7842 - val_mae: 1.1303\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1042 - mae: 0.2156 - val_loss: 2.8142 - val_mae: 1.1343\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1145 - mae: 0.2247 - val_loss: 2.8282 - val_mae: 1.1342\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1010 - mae: 0.2231 - val_loss: 2.7637 - val_mae: 1.1199\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0950 - mae: 0.2103 - val_loss: 2.7179 - val_mae: 1.1171\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0993 - mae: 0.2117 - val_loss: 2.8682 - val_mae: 1.1362\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0820 - mae: 0.1941 - val_loss: 2.8154 - val_mae: 1.1353\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0854 - mae: 0.1999 - val_loss: 2.8080 - val_mae: 1.1414\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0929 - mae: 0.2044 - val_loss: 2.7271 - val_mae: 1.1181\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0875 - mae: 0.1997 - val_loss: 2.8046 - val_mae: 1.1355\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0856 - mae: 0.1973 - val_loss: 2.7666 - val_mae: 1.1099\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1071 - mae: 0.2005 - val_loss: 2.7771 - val_mae: 1.1266\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0801 - mae: 0.1891 - val_loss: 2.7966 - val_mae: 1.1227\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0759 - mae: 0.1848 - val_loss: 2.7794 - val_mae: 1.1243\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0763 - mae: 0.1823 - val_loss: 2.7578 - val_mae: 1.1176\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0754 - mae: 0.1910 - val_loss: 2.7403 - val_mae: 1.1188\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0787 - mae: 0.1883 - val_loss: 2.7930 - val_mae: 1.1338\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0689 - mae: 0.1838 - val_loss: 2.7220 - val_mae: 1.1046\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0787 - mae: 0.1887 - val_loss: 2.7754 - val_mae: 1.1237\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0765 - mae: 0.1843 - val_loss: 2.7349 - val_mae: 1.1188\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0675 - mae: 0.1732 - val_loss: 2.7611 - val_mae: 1.1132\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0724 - mae: 0.1773 - val_loss: 2.7249 - val_mae: 1.1089\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0819 - mae: 0.1698 - val_loss: 2.7293 - val_mae: 1.1195\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0548 - mae: 0.1626 - val_loss: 2.7446 - val_mae: 1.1170\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0573 - mae: 0.1649 - val_loss: 2.7443 - val_mae: 1.1124\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0603 - mae: 0.1651 - val_loss: 2.7654 - val_mae: 1.1140\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0590 - mae: 0.1647 - val_loss: 2.7099 - val_mae: 1.1070\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0516 - mae: 0.1551 - val_loss: 2.7470 - val_mae: 1.1157\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0521 - mae: 0.1558 - val_loss: 2.7235 - val_mae: 1.1123\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0513 - mae: 0.1558 - val_loss: 2.6989 - val_mae: 1.1090\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0514 - mae: 0.1493 - val_loss: 2.7484 - val_mae: 1.1156\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0558 - mae: 0.1577 - val_loss: 2.7362 - val_mae: 1.1174\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0578 - mae: 0.1581 - val_loss: 2.7363 - val_mae: 1.1137\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0517 - mae: 0.1554 - val_loss: 2.7331 - val_mae: 1.1179\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0519 - mae: 0.1521 - val_loss: 2.7117 - val_mae: 1.1060\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0544 - mae: 0.1580 - val_loss: 2.8025 - val_mae: 1.1199\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0532 - mae: 0.1578 - val_loss: 2.6852 - val_mae: 1.1033\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0566 - mae: 0.1504 - val_loss: 2.7387 - val_mae: 1.1104\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0547 - mae: 0.1505 - val_loss: 2.6913 - val_mae: 1.1028\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0602 - mae: 0.1552 - val_loss: 2.7024 - val_mae: 1.1163\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0465 - mae: 0.1451 - val_loss: 2.7216 - val_mae: 1.1065\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0508 - mae: 0.1427 - val_loss: 2.7050 - val_mae: 1.1005\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0394 - mae: 0.1249 - val_loss: 2.6703 - val_mae: 1.1054\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0432 - mae: 0.1348 - val_loss: 2.6865 - val_mae: 1.0958\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0393 - mae: 0.1356 - val_loss: 2.6622 - val_mae: 1.0954\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0416 - mae: 0.1363 - val_loss: 2.7020 - val_mae: 1.1034\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0506 - mae: 0.1449 - val_loss: 2.6958 - val_mae: 1.1055\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0458 - mae: 0.1484 - val_loss: 2.6945 - val_mae: 1.1058\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0542 - mae: 0.1517 - val_loss: 2.6897 - val_mae: 1.1006\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0432 - mae: 0.1388 - val_loss: 2.7205 - val_mae: 1.1005\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0441 - mae: 0.1325 - val_loss: 2.6514 - val_mae: 1.0971\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0338 - mae: 0.1286 - val_loss: 2.6485 - val_mae: 1.0953\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0448 - mae: 0.1320 - val_loss: 2.7280 - val_mae: 1.1034\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0337 - mae: 0.1258 - val_loss: 2.6467 - val_mae: 1.0918\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0446 - mae: 0.1307 - val_loss: 2.7268 - val_mae: 1.1030\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0384 - mae: 0.1293 - val_loss: 2.7079 - val_mae: 1.0970\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0380 - mae: 0.1306 - val_loss: 2.7035 - val_mae: 1.1037\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0453 - mae: 0.1367 - val_loss: 2.6647 - val_mae: 1.1015\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0356 - mae: 0.1273 - val_loss: 2.7332 - val_mae: 1.1064\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0427 - mae: 0.1292 - val_loss: 2.7575 - val_mae: 1.1106\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0389 - mae: 0.1308 - val_loss: 2.6626 - val_mae: 1.1047\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0376 - mae: 0.1287 - val_loss: 2.6902 - val_mae: 1.0954\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0369 - mae: 0.1252 - val_loss: 2.6972 - val_mae: 1.1013\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0325 - mae: 0.1194 - val_loss: 2.7551 - val_mae: 1.1067\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0343 - mae: 0.1234 - val_loss: 2.6831 - val_mae: 1.0960\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0364 - mae: 0.1185 - val_loss: 2.6932 - val_mae: 1.0961\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0383 - mae: 0.1277 - val_loss: 2.6734 - val_mae: 1.1079\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0417 - mae: 0.1297 - val_loss: 2.6819 - val_mae: 1.0971\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0330 - mae: 0.1194 - val_loss: 2.6957 - val_mae: 1.1009\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0322 - mae: 0.1166 - val_loss: 2.7272 - val_mae: 1.1088\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0293 - mae: 0.1138 - val_loss: 2.6421 - val_mae: 1.0897\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0273 - mae: 0.1105 - val_loss: 2.6625 - val_mae: 1.0914\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0347 - mae: 0.1172 - val_loss: 2.7309 - val_mae: 1.1061\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0361 - mae: 0.1199 - val_loss: 2.6845 - val_mae: 1.0960\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0337 - mae: 0.1231 - val_loss: 2.6517 - val_mae: 1.0912\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0313 - mae: 0.1160 - val_loss: 2.6709 - val_mae: 1.0915\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0373 - mae: 0.1244 - val_loss: 2.7010 - val_mae: 1.1004\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0356 - mae: 0.1238 - val_loss: 2.6384 - val_mae: 1.0842\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0271 - mae: 0.1096 - val_loss: 2.6776 - val_mae: 1.0992\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0299 - mae: 0.1134 - val_loss: 2.6299 - val_mae: 1.0895\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0360 - mae: 0.1185 - val_loss: 2.6770 - val_mae: 1.0953\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0267 - mae: 0.1082 - val_loss: 2.6030 - val_mae: 1.0868\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0253 - mae: 0.1064 - val_loss: 2.6608 - val_mae: 1.0925\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0260 - mae: 0.1039 - val_loss: 2.6650 - val_mae: 1.0950\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0323 - mae: 0.1168 - val_loss: 2.6583 - val_mae: 1.1002\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0332 - mae: 0.1194 - val_loss: 2.6681 - val_mae: 1.1033\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0269 - mae: 0.1118 - val_loss: 2.6679 - val_mae: 1.0939\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0337 - mae: 0.1174 - val_loss: 2.6607 - val_mae: 1.0980\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0237 - mae: 0.1015 - val_loss: 2.6255 - val_mae: 1.0883\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0259 - mae: 0.1041 - val_loss: 2.6745 - val_mae: 1.0976\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0268 - mae: 0.1053 - val_loss: 2.6727 - val_mae: 1.0988\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0278 - mae: 0.1082 - val_loss: 2.6389 - val_mae: 1.0877\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0269 - mae: 0.1063 - val_loss: 2.6469 - val_mae: 1.0900\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0246 - mae: 0.1069 - val_loss: 2.6554 - val_mae: 1.0980\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0270 - mae: 0.1066 - val_loss: 2.6504 - val_mae: 1.0925\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0234 - mae: 0.1006 - val_loss: 2.6287 - val_mae: 1.0915\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0219 - mae: 0.0994 - val_loss: 2.6765 - val_mae: 1.0948\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0269 - mae: 0.1077 - val_loss: 2.6471 - val_mae: 1.0944\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0239 - mae: 0.1041 - val_loss: 2.6599 - val_mae: 1.0939\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0278 - mae: 0.1087 - val_loss: 2.6655 - val_mae: 1.0981\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0313 - mae: 0.1173 - val_loss: 2.6543 - val_mae: 1.0897\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0210 - mae: 0.0987 - val_loss: 2.6616 - val_mae: 1.0929\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0191 - mae: 0.0923 - val_loss: 2.6412 - val_mae: 1.0926\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0196 - mae: 0.0920 - val_loss: 2.6439 - val_mae: 1.0909\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0289 - mae: 0.1031 - val_loss: 2.6557 - val_mae: 1.0986\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0316 - mae: 0.1156 - val_loss: 2.6540 - val_mae: 1.0923\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0381 - mae: 0.1242 - val_loss: 2.6784 - val_mae: 1.0983\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0208 - mae: 0.0980 - val_loss: 2.6627 - val_mae: 1.0934\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0201 - mae: 0.0905 - val_loss: 2.6483 - val_mae: 1.0864\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0164 - mae: 0.0858 - val_loss: 2.6550 - val_mae: 1.0929\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0170 - mae: 0.0862 - val_loss: 2.6678 - val_mae: 1.0933\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0173 - mae: 0.0875 - val_loss: 2.6853 - val_mae: 1.0972\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0274 - mae: 0.1007 - val_loss: 2.6718 - val_mae: 1.0969\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0214 - mae: 0.0975 - val_loss: 2.6472 - val_mae: 1.0881\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0194 - mae: 0.0944 - val_loss: 2.6837 - val_mae: 1.1022\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.0224 - mae: 0.1002 - val_loss: 2.6765 - val_mae: 1.0961\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.0212 - mae: 0.0957 - val_loss: 2.6892 - val_mae: 1.1032\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0217 - mae: 0.0956 - val_loss: 2.6711 - val_mae: 1.0962\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0184 - mae: 0.0921 - val_loss: 2.6459 - val_mae: 1.0874\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0212 - mae: 0.0999 - val_loss: 2.6565 - val_mae: 1.0932\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0214 - mae: 0.1010 - val_loss: 2.6736 - val_mae: 1.0981\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0206 - mae: 0.0963 - val_loss: 2.6347 - val_mae: 1.0872\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0199 - mae: 0.0943 - val_loss: 2.6506 - val_mae: 1.0930\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0337 - mae: 0.1062 - val_loss: 2.7214 - val_mae: 1.1032\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0252 - mae: 0.1037 - val_loss: 2.6230 - val_mae: 1.0869\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0205 - mae: 0.0968 - val_loss: 2.7073 - val_mae: 1.1027\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0194 - mae: 0.0927 - val_loss: 2.6764 - val_mae: 1.0965\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0227 - mae: 0.0959 - val_loss: 2.6732 - val_mae: 1.0923\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0193 - mae: 0.0911 - val_loss: 2.6578 - val_mae: 1.0993\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0266 - mae: 0.0956 - val_loss: 2.6337 - val_mae: 1.0873\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0175 - mae: 0.0888 - val_loss: 2.6491 - val_mae: 1.0949\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0180 - mae: 0.0884 - val_loss: 2.6645 - val_mae: 1.0962\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0157 - mae: 0.0839 - val_loss: 2.6363 - val_mae: 1.0934\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0178 - mae: 0.0904 - val_loss: 2.6537 - val_mae: 1.0899\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0176 - mae: 0.0884 - val_loss: 2.6638 - val_mae: 1.0946\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0188 - mae: 0.0920 - val_loss: 2.6503 - val_mae: 1.0873\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0190 - mae: 0.0906 - val_loss: 2.6635 - val_mae: 1.0956\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0238 - mae: 0.0957 - val_loss: 2.6452 - val_mae: 1.0930\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0210 - mae: 0.0970 - val_loss: 2.6506 - val_mae: 1.0838\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0178 - mae: 0.0896 - val_loss: 2.6278 - val_mae: 1.0878\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0211 - mae: 0.0959 - val_loss: 2.6849 - val_mae: 1.0933\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0247 - mae: 0.1024 - val_loss: 2.6389 - val_mae: 1.0926\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0195 - mae: 0.0922 - val_loss: 2.6774 - val_mae: 1.0955\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0160 - mae: 0.0816 - val_loss: 2.6421 - val_mae: 1.0871\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0151 - mae: 0.0820 - val_loss: 2.6526 - val_mae: 1.0898\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0137 - mae: 0.0767 - val_loss: 2.6272 - val_mae: 1.0893\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0141 - mae: 0.0799 - val_loss: 2.6348 - val_mae: 1.0883\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0139 - mae: 0.0796 - val_loss: 2.6201 - val_mae: 1.0846\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0161 - mae: 0.0842 - val_loss: 2.6245 - val_mae: 1.0886\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0148 - mae: 0.0846 - val_loss: 2.6305 - val_mae: 1.0917\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0180 - mae: 0.0943 - val_loss: 2.6675 - val_mae: 1.0952\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0199 - mae: 0.0959 - val_loss: 2.6384 - val_mae: 1.0909\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0179 - mae: 0.0916 - val_loss: 2.6524 - val_mae: 1.0932\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0178 - mae: 0.0895 - val_loss: 2.6144 - val_mae: 1.0833\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0184 - mae: 0.0887 - val_loss: 2.6364 - val_mae: 1.0857\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0165 - mae: 0.0868 - val_loss: 2.6674 - val_mae: 1.0919\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0200 - mae: 0.0927 - val_loss: 2.6639 - val_mae: 1.0929\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0200 - mae: 0.0925 - val_loss: 2.6465 - val_mae: 1.0906\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0157 - mae: 0.0813 - val_loss: 2.6438 - val_mae: 1.0916\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0837 - val_loss: 2.6420 - val_mae: 1.0859\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3584 - mae: 1.0820\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 13.2094 - mae: 2.8001 - val_loss: 4.0261 - val_mae: 1.5404\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.5298 - mae: 1.1882 - val_loss: 3.8200 - val_mae: 1.3943\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5534 - mae: 0.9335 - val_loss: 3.5621 - val_mae: 1.3779\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1339 - mae: 0.7735 - val_loss: 3.5330 - val_mae: 1.3412\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.8449 - mae: 0.6431 - val_loss: 3.4041 - val_mae: 1.3411\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.7710 - mae: 0.5944 - val_loss: 3.4574 - val_mae: 1.3126\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.6286 - mae: 0.5342 - val_loss: 3.3792 - val_mae: 1.3106\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4679 - mae: 0.4599 - val_loss: 3.3612 - val_mae: 1.3197\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4764 - mae: 0.4511 - val_loss: 3.2122 - val_mae: 1.2733\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.4687 - mae: 0.4456 - val_loss: 3.2320 - val_mae: 1.2693\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3766 - mae: 0.4029 - val_loss: 3.2444 - val_mae: 1.2736\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3405 - mae: 0.3773 - val_loss: 3.2254 - val_mae: 1.2698\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3227 - mae: 0.3897 - val_loss: 3.1945 - val_mae: 1.2443\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.3031 - mae: 0.3704 - val_loss: 3.2653 - val_mae: 1.2340\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2883 - mae: 0.3650 - val_loss: 3.1626 - val_mae: 1.2320\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2563 - mae: 0.3313 - val_loss: 3.1010 - val_mae: 1.2458\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2728 - mae: 0.3371 - val_loss: 3.1309 - val_mae: 1.2327\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2594 - mae: 0.3439 - val_loss: 3.0970 - val_mae: 1.2339\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2597 - mae: 0.3428 - val_loss: 3.1921 - val_mae: 1.2257\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2377 - mae: 0.3338 - val_loss: 3.0881 - val_mae: 1.2001\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1861 - mae: 0.2932 - val_loss: 3.1468 - val_mae: 1.2092\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2035 - mae: 0.3109 - val_loss: 3.0144 - val_mae: 1.2194\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2125 - mae: 0.3131 - val_loss: 3.0011 - val_mae: 1.1827\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1983 - mae: 0.3049 - val_loss: 2.9814 - val_mae: 1.2249\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.2012 - mae: 0.3036 - val_loss: 2.9569 - val_mae: 1.1894\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1840 - mae: 0.2835 - val_loss: 2.8827 - val_mae: 1.1635\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1770 - mae: 0.2817 - val_loss: 2.9131 - val_mae: 1.1745\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1717 - mae: 0.2811 - val_loss: 2.8850 - val_mae: 1.1745\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1735 - mae: 0.2781 - val_loss: 2.9755 - val_mae: 1.1922\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1899 - mae: 0.2884 - val_loss: 2.9276 - val_mae: 1.1702\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1554 - mae: 0.2662 - val_loss: 2.9023 - val_mae: 1.1655\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1516 - mae: 0.2558 - val_loss: 2.7835 - val_mae: 1.1515\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1378 - mae: 0.2475 - val_loss: 2.8741 - val_mae: 1.1734\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1218 - mae: 0.2267 - val_loss: 2.7880 - val_mae: 1.1472\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1181 - mae: 0.2294 - val_loss: 2.8850 - val_mae: 1.1647\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1249 - mae: 0.2320 - val_loss: 2.8249 - val_mae: 1.1630\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1224 - mae: 0.2362 - val_loss: 2.8329 - val_mae: 1.1547\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1096 - mae: 0.2238 - val_loss: 2.8229 - val_mae: 1.1606\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1123 - mae: 0.2317 - val_loss: 2.8248 - val_mae: 1.1456\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1149 - mae: 0.2316 - val_loss: 2.7743 - val_mae: 1.1473\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1155 - mae: 0.2281 - val_loss: 2.7978 - val_mae: 1.1527\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0977 - mae: 0.2084 - val_loss: 2.8332 - val_mae: 1.1514\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1181 - mae: 0.2266 - val_loss: 2.8398 - val_mae: 1.1536\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1034 - mae: 0.2190 - val_loss: 2.8024 - val_mae: 1.1316\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1008 - mae: 0.2155 - val_loss: 2.7983 - val_mae: 1.1405\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0860 - mae: 0.1966 - val_loss: 2.8244 - val_mae: 1.1373\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0880 - mae: 0.2033 - val_loss: 2.7558 - val_mae: 1.1306\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0865 - mae: 0.1965 - val_loss: 2.7611 - val_mae: 1.1422\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0825 - mae: 0.1958 - val_loss: 2.7666 - val_mae: 1.1446\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0783 - mae: 0.1911 - val_loss: 2.7585 - val_mae: 1.1196\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0854 - mae: 0.2008 - val_loss: 2.8007 - val_mae: 1.1437\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0892 - mae: 0.1961 - val_loss: 2.7038 - val_mae: 1.1241\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0800 - mae: 0.1869 - val_loss: 2.7421 - val_mae: 1.1235\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0741 - mae: 0.1860 - val_loss: 2.7397 - val_mae: 1.1255\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0930 - mae: 0.1970 - val_loss: 2.7395 - val_mae: 1.1156\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0665 - mae: 0.1757 - val_loss: 2.6915 - val_mae: 1.1228\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0734 - mae: 0.1820 - val_loss: 2.6884 - val_mae: 1.1228\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0667 - mae: 0.1698 - val_loss: 2.7420 - val_mae: 1.1273\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0658 - mae: 0.1761 - val_loss: 2.6639 - val_mae: 1.1031\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0680 - mae: 0.1726 - val_loss: 2.6643 - val_mae: 1.1118\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0622 - mae: 0.1664 - val_loss: 2.6835 - val_mae: 1.1161\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0598 - mae: 0.1627 - val_loss: 2.6601 - val_mae: 1.1060\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0599 - mae: 0.1655 - val_loss: 2.6721 - val_mae: 1.1029\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0608 - mae: 0.1653 - val_loss: 2.7200 - val_mae: 1.1029\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0598 - mae: 0.1625 - val_loss: 2.6867 - val_mae: 1.1014\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0593 - mae: 0.1625 - val_loss: 2.7655 - val_mae: 1.1009\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0629 - mae: 0.1659 - val_loss: 2.6981 - val_mae: 1.1150\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0644 - mae: 0.1697 - val_loss: 2.6831 - val_mae: 1.1032\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0745 - mae: 0.1754 - val_loss: 2.7156 - val_mae: 1.1077\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0598 - mae: 0.1614 - val_loss: 2.7083 - val_mae: 1.1027\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0512 - mae: 0.1499 - val_loss: 2.7235 - val_mae: 1.1066\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0446 - mae: 0.1424 - val_loss: 2.6775 - val_mae: 1.0938\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0451 - mae: 0.1422 - val_loss: 2.6634 - val_mae: 1.0929\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0497 - mae: 0.1493 - val_loss: 2.6785 - val_mae: 1.1114\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0438 - mae: 0.1450 - val_loss: 2.6893 - val_mae: 1.0974\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0453 - mae: 0.1452 - val_loss: 2.6985 - val_mae: 1.0974\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0508 - mae: 0.1504 - val_loss: 2.6886 - val_mae: 1.0952\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0480 - mae: 0.1502 - val_loss: 2.6770 - val_mae: 1.1051\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0479 - mae: 0.1458 - val_loss: 2.6368 - val_mae: 1.0864\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0406 - mae: 0.1390 - val_loss: 2.6757 - val_mae: 1.0960\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0379 - mae: 0.1374 - val_loss: 2.6849 - val_mae: 1.0866\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0397 - mae: 0.1349 - val_loss: 2.6877 - val_mae: 1.0868\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0499 - mae: 0.1459 - val_loss: 2.6579 - val_mae: 1.0905\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0414 - mae: 0.1361 - val_loss: 2.6698 - val_mae: 1.0903\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0398 - mae: 0.1372 - val_loss: 2.6052 - val_mae: 1.0924\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0408 - mae: 0.1365 - val_loss: 2.6673 - val_mae: 1.0953\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0346 - mae: 0.1258 - val_loss: 2.6129 - val_mae: 1.0883\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.1354 - val_loss: 2.6727 - val_mae: 1.0905\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0422 - mae: 0.1354 - val_loss: 2.6299 - val_mae: 1.0931\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0447 - mae: 0.1447 - val_loss: 2.6230 - val_mae: 1.0890\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0433 - mae: 0.1401 - val_loss: 2.6448 - val_mae: 1.0974\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0355 - mae: 0.1320 - val_loss: 2.6391 - val_mae: 1.0914\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0343 - mae: 0.1251 - val_loss: 2.6585 - val_mae: 1.0865\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0275 - mae: 0.1115 - val_loss: 2.6172 - val_mae: 1.0822\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0344 - mae: 0.1241 - val_loss: 2.6726 - val_mae: 1.0899\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0341 - mae: 0.1274 - val_loss: 2.6651 - val_mae: 1.0953\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0346 - mae: 0.1276 - val_loss: 2.6576 - val_mae: 1.0841\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0316 - mae: 0.1228 - val_loss: 2.6606 - val_mae: 1.0878\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0341 - mae: 0.1271 - val_loss: 2.6073 - val_mae: 1.0817\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0367 - mae: 0.1285 - val_loss: 2.6160 - val_mae: 1.0802\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0553 - mae: 0.1283 - val_loss: 2.6135 - val_mae: 1.0857\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0318 - mae: 0.1229 - val_loss: 2.6333 - val_mae: 1.0992\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0355 - mae: 0.1293 - val_loss: 2.6455 - val_mae: 1.0854\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0282 - mae: 0.1155 - val_loss: 2.6450 - val_mae: 1.0845\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0259 - mae: 0.1101 - val_loss: 2.6459 - val_mae: 1.0894\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0264 - mae: 0.1106 - val_loss: 2.6502 - val_mae: 1.0961\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0282 - mae: 0.1156 - val_loss: 2.6460 - val_mae: 1.0885\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0266 - mae: 0.1115 - val_loss: 2.6220 - val_mae: 1.0801\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0271 - mae: 0.1132 - val_loss: 2.6509 - val_mae: 1.0920\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0288 - mae: 0.1153 - val_loss: 2.6383 - val_mae: 1.0800\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0353 - mae: 0.1208 - val_loss: 2.6079 - val_mae: 1.0862\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0319 - mae: 0.1234 - val_loss: 2.6248 - val_mae: 1.0814\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0251 - mae: 0.1087 - val_loss: 2.5882 - val_mae: 1.0710\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0241 - mae: 0.1067 - val_loss: 2.6121 - val_mae: 1.0838\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0242 - mae: 0.1063 - val_loss: 2.6319 - val_mae: 1.0805\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0272 - mae: 0.1115 - val_loss: 2.6269 - val_mae: 1.0811\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0276 - mae: 0.1138 - val_loss: 2.5876 - val_mae: 1.0878\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0290 - mae: 0.1195 - val_loss: 2.6397 - val_mae: 1.0813\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0290 - mae: 0.1194 - val_loss: 2.6030 - val_mae: 1.0762\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0230 - mae: 0.1063 - val_loss: 2.6144 - val_mae: 1.0721\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0242 - mae: 0.1052 - val_loss: 2.6366 - val_mae: 1.0874\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0266 - mae: 0.1110 - val_loss: 2.5962 - val_mae: 1.0842\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0287 - mae: 0.1136 - val_loss: 2.6235 - val_mae: 1.0829\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0263 - mae: 0.1095 - val_loss: 2.5969 - val_mae: 1.0678\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0214 - mae: 0.0997 - val_loss: 2.6531 - val_mae: 1.0903\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0214 - mae: 0.1000 - val_loss: 2.6155 - val_mae: 1.0872\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0202 - mae: 0.0980 - val_loss: 2.6189 - val_mae: 1.0840\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0230 - mae: 0.1025 - val_loss: 2.6139 - val_mae: 1.0751\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0211 - mae: 0.0990 - val_loss: 2.6382 - val_mae: 1.0857\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0215 - mae: 0.1027 - val_loss: 2.6225 - val_mae: 1.0818\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0203 - mae: 0.1025 - val_loss: 2.6275 - val_mae: 1.0787\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0231 - mae: 0.1070 - val_loss: 2.6303 - val_mae: 1.0800\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0269 - mae: 0.1151 - val_loss: 2.6041 - val_mae: 1.0831\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0245 - mae: 0.1065 - val_loss: 2.6139 - val_mae: 1.0816\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0270 - mae: 0.1108 - val_loss: 2.6471 - val_mae: 1.0804\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0273 - mae: 0.1043 - val_loss: 2.6223 - val_mae: 1.0857\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0207 - mae: 0.0960 - val_loss: 2.6364 - val_mae: 1.0878\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0874 - val_loss: 2.6112 - val_mae: 1.0906\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0190 - mae: 0.0929 - val_loss: 2.6090 - val_mae: 1.0810\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0195 - mae: 0.0974 - val_loss: 2.6249 - val_mae: 1.0798\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0206 - mae: 0.1001 - val_loss: 2.6380 - val_mae: 1.0757\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0213 - mae: 0.0998 - val_loss: 2.6219 - val_mae: 1.0830\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0199 - mae: 0.0978 - val_loss: 2.6177 - val_mae: 1.0818\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0195 - mae: 0.0966 - val_loss: 2.6405 - val_mae: 1.0836\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0174 - mae: 0.0928 - val_loss: 2.6293 - val_mae: 1.0840\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0202 - mae: 0.0966 - val_loss: 2.6405 - val_mae: 1.0802\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0211 - mae: 0.0979 - val_loss: 2.6204 - val_mae: 1.0782\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0212 - mae: 0.0974 - val_loss: 2.6415 - val_mae: 1.0892\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0203 - mae: 0.0984 - val_loss: 2.6233 - val_mae: 1.0804\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0184 - mae: 0.0931 - val_loss: 2.6484 - val_mae: 1.0812\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0201 - mae: 0.0981 - val_loss: 2.6350 - val_mae: 1.0854\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0200 - mae: 0.0966 - val_loss: 2.6654 - val_mae: 1.0950\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0206 - mae: 0.0952 - val_loss: 2.6388 - val_mae: 1.0823\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0200 - mae: 0.0960 - val_loss: 2.6162 - val_mae: 1.0925\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0278 - mae: 0.1110 - val_loss: 2.6307 - val_mae: 1.0822\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0204 - mae: 0.0974 - val_loss: 2.6451 - val_mae: 1.0802\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0191 - mae: 0.0954 - val_loss: 2.6182 - val_mae: 1.0856\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0162 - mae: 0.0860 - val_loss: 2.6365 - val_mae: 1.0849\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0192 - mae: 0.0920 - val_loss: 2.6337 - val_mae: 1.0835\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0188 - mae: 0.0911 - val_loss: 2.6200 - val_mae: 1.0760\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0219 - mae: 0.0983 - val_loss: 2.6195 - val_mae: 1.0798\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0167 - mae: 0.0885 - val_loss: 2.6371 - val_mae: 1.0806\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0183 - mae: 0.0901 - val_loss: 2.6358 - val_mae: 1.0828\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0164 - mae: 0.0843 - val_loss: 2.6195 - val_mae: 1.0763\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0835 - val_loss: 2.6386 - val_mae: 1.0780\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0185 - mae: 0.0936 - val_loss: 2.6247 - val_mae: 1.0823\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0169 - mae: 0.0902 - val_loss: 2.6471 - val_mae: 1.0815\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0160 - mae: 0.0905 - val_loss: 2.6299 - val_mae: 1.0817\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0199 - mae: 0.0947 - val_loss: 2.6438 - val_mae: 1.0845\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0189 - mae: 0.0940 - val_loss: 2.6360 - val_mae: 1.0851\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0865 - val_loss: 2.6347 - val_mae: 1.0819\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0138 - mae: 0.0802 - val_loss: 2.6183 - val_mae: 1.0750\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0154 - mae: 0.0850 - val_loss: 2.6340 - val_mae: 1.0842\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0169 - mae: 0.0892 - val_loss: 2.6351 - val_mae: 1.0888\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0171 - mae: 0.0907 - val_loss: 2.6120 - val_mae: 1.0765\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0167 - mae: 0.0887 - val_loss: 2.6293 - val_mae: 1.0814\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0188 - mae: 0.0928 - val_loss: 2.6372 - val_mae: 1.0781\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0171 - mae: 0.0896 - val_loss: 2.6215 - val_mae: 1.0779\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0148 - mae: 0.0839 - val_loss: 2.6073 - val_mae: 1.0773\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0149 - mae: 0.0824 - val_loss: 2.6336 - val_mae: 1.0790\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0182 - mae: 0.0932 - val_loss: 2.6392 - val_mae: 1.0834\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0159 - mae: 0.0878 - val_loss: 2.6481 - val_mae: 1.0859\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0156 - mae: 0.0866 - val_loss: 2.6582 - val_mae: 1.0837\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0143 - mae: 0.0822 - val_loss: 2.6276 - val_mae: 1.0750\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0140 - mae: 0.0822 - val_loss: 2.6449 - val_mae: 1.0806\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0142 - mae: 0.0818 - val_loss: 2.6706 - val_mae: 1.0800\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0144 - mae: 0.0806 - val_loss: 2.6289 - val_mae: 1.0856\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0157 - mae: 0.0846 - val_loss: 2.6365 - val_mae: 1.0784\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0146 - mae: 0.0836 - val_loss: 2.6094 - val_mae: 1.0780\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0198 - mae: 0.0953 - val_loss: 2.6560 - val_mae: 1.0883\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0181 - mae: 0.0926 - val_loss: 2.6375 - val_mae: 1.0788\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0161 - mae: 0.0871 - val_loss: 2.6145 - val_mae: 1.0754\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0171 - mae: 0.0877 - val_loss: 2.6378 - val_mae: 1.0836\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0132 - mae: 0.0780 - val_loss: 2.6496 - val_mae: 1.0768\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0143 - mae: 0.0804 - val_loss: 2.6198 - val_mae: 1.0752\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0119 - mae: 0.0750 - val_loss: 2.6417 - val_mae: 1.0765\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0136 - mae: 0.0799 - val_loss: 2.6268 - val_mae: 1.0784\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0856 - val_loss: 2.6263 - val_mae: 1.0738\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0143 - mae: 0.0844 - val_loss: 2.6241 - val_mae: 1.0797\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0143 - mae: 0.0811 - val_loss: 2.6354 - val_mae: 1.0796\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3623 - mae: 1.0913\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 14.1394 - mae: 2.8065 - val_loss: 4.1623 - val_mae: 1.5145\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 2.2759 - mae: 1.1194 - val_loss: 3.6578 - val_mae: 1.3280\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 1.2742 - mae: 0.8233 - val_loss: 3.4167 - val_mae: 1.2863\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.9727 - mae: 0.7026 - val_loss: 3.2377 - val_mae: 1.2543\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8370 - mae: 0.6352 - val_loss: 3.4310 - val_mae: 1.3116\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.7056 - mae: 0.5962 - val_loss: 3.3435 - val_mae: 1.2545\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.6042 - mae: 0.5422 - val_loss: 3.3346 - val_mae: 1.3117\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.7953 - mae: 0.5881 - val_loss: 3.2905 - val_mae: 1.2595\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.4914 - mae: 0.4813 - val_loss: 3.2924 - val_mae: 1.2496\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3808 - mae: 0.4217 - val_loss: 3.2737 - val_mae: 1.2225\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3613 - mae: 0.4129 - val_loss: 3.3817 - val_mae: 1.2452\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3615 - mae: 0.4129 - val_loss: 3.2503 - val_mae: 1.2443\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3692 - mae: 0.4022 - val_loss: 3.1339 - val_mae: 1.2204\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.3861 - mae: 0.4021 - val_loss: 3.2062 - val_mae: 1.2391\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2915 - mae: 0.3661 - val_loss: 3.0076 - val_mae: 1.1906\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2419 - mae: 0.3397 - val_loss: 3.0789 - val_mae: 1.2007\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2705 - mae: 0.3582 - val_loss: 3.1300 - val_mae: 1.2091\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2756 - mae: 0.3655 - val_loss: 3.3062 - val_mae: 1.2577\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2764 - mae: 0.3613 - val_loss: 3.0564 - val_mae: 1.1889\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2070 - mae: 0.3195 - val_loss: 3.0612 - val_mae: 1.1962\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2212 - mae: 0.3129 - val_loss: 3.1625 - val_mae: 1.1870\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2014 - mae: 0.3087 - val_loss: 3.0452 - val_mae: 1.1751\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2144 - mae: 0.3134 - val_loss: 3.0537 - val_mae: 1.1894\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2191 - mae: 0.3249 - val_loss: 3.0333 - val_mae: 1.1779\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2283 - mae: 0.3267 - val_loss: 3.1131 - val_mae: 1.1765\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1946 - mae: 0.3010 - val_loss: 3.0264 - val_mae: 1.1773\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1841 - mae: 0.2864 - val_loss: 3.0674 - val_mae: 1.1737\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1930 - mae: 0.2934 - val_loss: 2.9870 - val_mae: 1.1746\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1634 - mae: 0.2724 - val_loss: 3.0250 - val_mae: 1.1770\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1530 - mae: 0.2717 - val_loss: 3.0337 - val_mae: 1.2200\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1866 - mae: 0.2969 - val_loss: 2.9332 - val_mae: 1.1682\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1665 - mae: 0.2713 - val_loss: 2.9340 - val_mae: 1.1609\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1442 - mae: 0.2574 - val_loss: 2.9566 - val_mae: 1.1777\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1196 - mae: 0.2432 - val_loss: 2.9808 - val_mae: 1.1637\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1385 - mae: 0.2463 - val_loss: 2.9906 - val_mae: 1.1545\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1424 - mae: 0.2531 - val_loss: 2.8914 - val_mae: 1.1528\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1492 - mae: 0.2490 - val_loss: 2.9590 - val_mae: 1.1593\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1613 - mae: 0.2567 - val_loss: 2.9452 - val_mae: 1.1722\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1352 - mae: 0.2472 - val_loss: 2.9113 - val_mae: 1.1711\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1245 - mae: 0.2472 - val_loss: 2.9794 - val_mae: 1.1697\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1163 - mae: 0.2361 - val_loss: 2.9485 - val_mae: 1.1501\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1428 - mae: 0.2460 - val_loss: 2.8792 - val_mae: 1.1393\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1168 - mae: 0.2245 - val_loss: 2.9919 - val_mae: 1.1503\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1543 - mae: 0.2452 - val_loss: 2.9167 - val_mae: 1.1574\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1208 - mae: 0.2247 - val_loss: 2.8889 - val_mae: 1.1421\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1117 - mae: 0.2161 - val_loss: 2.8657 - val_mae: 1.1374\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0981 - mae: 0.2048 - val_loss: 2.9341 - val_mae: 1.1598\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1040 - mae: 0.2166 - val_loss: 2.9326 - val_mae: 1.1455\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1138 - mae: 0.2151 - val_loss: 2.8659 - val_mae: 1.1620\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1228 - mae: 0.2264 - val_loss: 2.8783 - val_mae: 1.1326\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1025 - mae: 0.2142 - val_loss: 2.9199 - val_mae: 1.1491\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0955 - mae: 0.2052 - val_loss: 2.8200 - val_mae: 1.1348\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1001 - mae: 0.1973 - val_loss: 2.9237 - val_mae: 1.1424\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0793 - mae: 0.1883 - val_loss: 2.8320 - val_mae: 1.1410\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0834 - mae: 0.1928 - val_loss: 2.7765 - val_mae: 1.1234\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0836 - mae: 0.1889 - val_loss: 2.8742 - val_mae: 1.1356\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0836 - mae: 0.1935 - val_loss: 2.8786 - val_mae: 1.1254\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0859 - mae: 0.1887 - val_loss: 2.8529 - val_mae: 1.1259\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0728 - mae: 0.1821 - val_loss: 2.8470 - val_mae: 1.1317\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0802 - mae: 0.1850 - val_loss: 2.8453 - val_mae: 1.1238\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0806 - mae: 0.1830 - val_loss: 2.8931 - val_mae: 1.1323\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0761 - mae: 0.1813 - val_loss: 2.8310 - val_mae: 1.1233\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0737 - mae: 0.1762 - val_loss: 2.7855 - val_mae: 1.1201\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0704 - mae: 0.1803 - val_loss: 2.8147 - val_mae: 1.1239\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0619 - mae: 0.1672 - val_loss: 2.7912 - val_mae: 1.1204\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0726 - mae: 0.1704 - val_loss: 2.7761 - val_mae: 1.1161\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0775 - mae: 0.1750 - val_loss: 2.7102 - val_mae: 1.1109\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0683 - mae: 0.1753 - val_loss: 2.8803 - val_mae: 1.1239\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0673 - mae: 0.1756 - val_loss: 2.7993 - val_mae: 1.1166\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0728 - mae: 0.1689 - val_loss: 2.8099 - val_mae: 1.1090\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0659 - mae: 0.1737 - val_loss: 2.8760 - val_mae: 1.1179\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0760 - mae: 0.1797 - val_loss: 2.7841 - val_mae: 1.1153\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0620 - mae: 0.1602 - val_loss: 2.8286 - val_mae: 1.1120\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0530 - mae: 0.1536 - val_loss: 2.8792 - val_mae: 1.1217\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0660 - mae: 0.1599 - val_loss: 2.8232 - val_mae: 1.1143\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0640 - mae: 0.1650 - val_loss: 2.8134 - val_mae: 1.1043\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0590 - mae: 0.1596 - val_loss: 2.7881 - val_mae: 1.1180\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0529 - mae: 0.1566 - val_loss: 2.7388 - val_mae: 1.1091\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0482 - mae: 0.1514 - val_loss: 2.7772 - val_mae: 1.1098\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0513 - mae: 0.1463 - val_loss: 2.7896 - val_mae: 1.1119\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0573 - mae: 0.1574 - val_loss: 2.7950 - val_mae: 1.1079\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0560 - mae: 0.1529 - val_loss: 2.8096 - val_mae: 1.1134\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0584 - mae: 0.1601 - val_loss: 2.7815 - val_mae: 1.1202\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0600 - mae: 0.1584 - val_loss: 2.8119 - val_mae: 1.1147\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0548 - mae: 0.1550 - val_loss: 2.7373 - val_mae: 1.1066\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0567 - mae: 0.1540 - val_loss: 2.7495 - val_mae: 1.1216\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0566 - mae: 0.1553 - val_loss: 2.7765 - val_mae: 1.1113\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0495 - mae: 0.1420 - val_loss: 2.7515 - val_mae: 1.1031\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0530 - mae: 0.1463 - val_loss: 2.7606 - val_mae: 1.1148\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0473 - mae: 0.1448 - val_loss: 2.7781 - val_mae: 1.1093\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0434 - mae: 0.1385 - val_loss: 2.7812 - val_mae: 1.1167\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0409 - mae: 0.1396 - val_loss: 2.7489 - val_mae: 1.1119\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0534 - mae: 0.1457 - val_loss: 2.7733 - val_mae: 1.1014\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0471 - mae: 0.1423 - val_loss: 2.8001 - val_mae: 1.1101\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0471 - mae: 0.1396 - val_loss: 2.7665 - val_mae: 1.1122\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0527 - mae: 0.1408 - val_loss: 2.7449 - val_mae: 1.1022\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0474 - mae: 0.1451 - val_loss: 2.7869 - val_mae: 1.1109\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0500 - mae: 0.1439 - val_loss: 2.7830 - val_mae: 1.1067\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0502 - mae: 0.1443 - val_loss: 2.7977 - val_mae: 1.1271\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0381 - mae: 0.1302 - val_loss: 2.7331 - val_mae: 1.1125\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0501 - mae: 0.1401 - val_loss: 2.7611 - val_mae: 1.1072\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0377 - mae: 0.1292 - val_loss: 2.7578 - val_mae: 1.1158\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0443 - mae: 0.1338 - val_loss: 2.7965 - val_mae: 1.1039\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0370 - mae: 0.1304 - val_loss: 2.7770 - val_mae: 1.1118\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0388 - mae: 0.1324 - val_loss: 2.7719 - val_mae: 1.1004\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0351 - mae: 0.1251 - val_loss: 2.7714 - val_mae: 1.1188\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0435 - mae: 0.1343 - val_loss: 2.8164 - val_mae: 1.1088\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0372 - mae: 0.1238 - val_loss: 2.7472 - val_mae: 1.1023\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0425 - mae: 0.1292 - val_loss: 2.7521 - val_mae: 1.1127\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0480 - mae: 0.1405 - val_loss: 2.7559 - val_mae: 1.1149\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0402 - mae: 0.1305 - val_loss: 2.7411 - val_mae: 1.1099\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0355 - mae: 0.1265 - val_loss: 2.7693 - val_mae: 1.1080\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0444 - mae: 0.1309 - val_loss: 2.7485 - val_mae: 1.1112\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0357 - mae: 0.1227 - val_loss: 2.7280 - val_mae: 1.1021\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0327 - mae: 0.1196 - val_loss: 2.7565 - val_mae: 1.1100\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0398 - mae: 0.1218 - val_loss: 2.7128 - val_mae: 1.1003\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0365 - mae: 0.1245 - val_loss: 2.7737 - val_mae: 1.1070\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0400 - mae: 0.1261 - val_loss: 2.7216 - val_mae: 1.1011\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0290 - mae: 0.1164 - val_loss: 2.7395 - val_mae: 1.1047\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0391 - mae: 0.1244 - val_loss: 2.7687 - val_mae: 1.1067\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0427 - mae: 0.1253 - val_loss: 2.7327 - val_mae: 1.0966\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0394 - mae: 0.1242 - val_loss: 2.7849 - val_mae: 1.1085\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0319 - mae: 0.1223 - val_loss: 2.7563 - val_mae: 1.1067\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0314 - mae: 0.1155 - val_loss: 2.7480 - val_mae: 1.1062\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0427 - mae: 0.1235 - val_loss: 2.7438 - val_mae: 1.1020\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0289 - mae: 0.1140 - val_loss: 2.7721 - val_mae: 1.1048\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0299 - mae: 0.1130 - val_loss: 2.7463 - val_mae: 1.1039\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0241 - mae: 0.0982 - val_loss: 2.7260 - val_mae: 1.1177\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0306 - mae: 0.1209 - val_loss: 2.7512 - val_mae: 1.1066\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0327 - mae: 0.1170 - val_loss: 2.7550 - val_mae: 1.1088\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0399 - mae: 0.1270 - val_loss: 2.7500 - val_mae: 1.1056\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0396 - mae: 0.1242 - val_loss: 2.7336 - val_mae: 1.0971\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0342 - mae: 0.1192 - val_loss: 2.7664 - val_mae: 1.1016\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0352 - mae: 0.1184 - val_loss: 2.7330 - val_mae: 1.1021\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0264 - mae: 0.1103 - val_loss: 2.6915 - val_mae: 1.0906\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0401 - mae: 0.1222 - val_loss: 2.7425 - val_mae: 1.1005\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0381 - mae: 0.1181 - val_loss: 2.7171 - val_mae: 1.0970\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0299 - mae: 0.1129 - val_loss: 2.7606 - val_mae: 1.1003\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0307 - mae: 0.1063 - val_loss: 2.7685 - val_mae: 1.1023\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0351 - mae: 0.1090 - val_loss: 2.7273 - val_mae: 1.0973\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0286 - mae: 0.1114 - val_loss: 2.7330 - val_mae: 1.1033\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0250 - mae: 0.1037 - val_loss: 2.7594 - val_mae: 1.1076\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0364 - mae: 0.1068 - val_loss: 2.7411 - val_mae: 1.0979\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0249 - mae: 0.1020 - val_loss: 2.7322 - val_mae: 1.0935\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0253 - mae: 0.1034 - val_loss: 2.7597 - val_mae: 1.1016\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0333 - mae: 0.1169 - val_loss: 2.7157 - val_mae: 1.1015\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0311 - mae: 0.1135 - val_loss: 2.7148 - val_mae: 1.1033\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0308 - mae: 0.1155 - val_loss: 2.7551 - val_mae: 1.0993\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0278 - mae: 0.1053 - val_loss: 2.7586 - val_mae: 1.0984\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0322 - mae: 0.1072 - val_loss: 2.7452 - val_mae: 1.0973\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0245 - mae: 0.1043 - val_loss: 2.7306 - val_mae: 1.0966\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0330 - mae: 0.1108 - val_loss: 2.7193 - val_mae: 1.1016\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0309 - mae: 0.1081 - val_loss: 2.7403 - val_mae: 1.0998\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0264 - mae: 0.0993 - val_loss: 2.7211 - val_mae: 1.0954\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0268 - mae: 0.1019 - val_loss: 2.7267 - val_mae: 1.0947\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0249 - mae: 0.0966 - val_loss: 2.7357 - val_mae: 1.1034\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0256 - mae: 0.1012 - val_loss: 2.7165 - val_mae: 1.0938\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0236 - mae: 0.1012 - val_loss: 2.7555 - val_mae: 1.1042\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0291 - mae: 0.1085 - val_loss: 2.7876 - val_mae: 1.1003\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0228 - mae: 0.1022 - val_loss: 2.7215 - val_mae: 1.1003\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0271 - mae: 0.1032 - val_loss: 2.7069 - val_mae: 1.0985\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0240 - mae: 0.1029 - val_loss: 2.7449 - val_mae: 1.0985\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0230 - mae: 0.0997 - val_loss: 2.7305 - val_mae: 1.0940\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0219 - mae: 0.0934 - val_loss: 2.7300 - val_mae: 1.0976\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0229 - mae: 0.0934 - val_loss: 2.7053 - val_mae: 1.0926\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0194 - mae: 0.0912 - val_loss: 2.7448 - val_mae: 1.0988\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0257 - mae: 0.0989 - val_loss: 2.7214 - val_mae: 1.0975\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0304 - mae: 0.1107 - val_loss: 2.7318 - val_mae: 1.0888\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0268 - mae: 0.1009 - val_loss: 2.7323 - val_mae: 1.0990\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0236 - mae: 0.0970 - val_loss: 2.7268 - val_mae: 1.0939\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0273 - mae: 0.0984 - val_loss: 2.7083 - val_mae: 1.0890\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0200 - mae: 0.0923 - val_loss: 2.7060 - val_mae: 1.0885\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0215 - mae: 0.0959 - val_loss: 2.7498 - val_mae: 1.1010\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0200 - mae: 0.0916 - val_loss: 2.7644 - val_mae: 1.0976\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0276 - mae: 0.1052 - val_loss: 2.7151 - val_mae: 1.0902\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0279 - mae: 0.1026 - val_loss: 2.7016 - val_mae: 1.0886\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0244 - mae: 0.1006 - val_loss: 2.7368 - val_mae: 1.0968\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0219 - mae: 0.0946 - val_loss: 2.7036 - val_mae: 1.0920\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0246 - mae: 0.0956 - val_loss: 2.7107 - val_mae: 1.0922\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0214 - mae: 0.0916 - val_loss: 2.7026 - val_mae: 1.0867\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0194 - mae: 0.0895 - val_loss: 2.6940 - val_mae: 1.0919\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0232 - mae: 0.0953 - val_loss: 2.7069 - val_mae: 1.0952\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0198 - mae: 0.0911 - val_loss: 2.7104 - val_mae: 1.0912\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0295 - mae: 0.1025 - val_loss: 2.7437 - val_mae: 1.0987\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0196 - mae: 0.0934 - val_loss: 2.7165 - val_mae: 1.0927\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0200 - mae: 0.0960 - val_loss: 2.7499 - val_mae: 1.0971\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0271 - mae: 0.1000 - val_loss: 2.7470 - val_mae: 1.0938\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0221 - mae: 0.0933 - val_loss: 2.6914 - val_mae: 1.0882\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0225 - mae: 0.0953 - val_loss: 2.6954 - val_mae: 1.0930\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0192 - mae: 0.0880 - val_loss: 2.7048 - val_mae: 1.0934\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0259 - mae: 0.1004 - val_loss: 2.7092 - val_mae: 1.0910\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0239 - mae: 0.0994 - val_loss: 2.6728 - val_mae: 1.0831\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0245 - mae: 0.0933 - val_loss: 2.7177 - val_mae: 1.0861\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0222 - mae: 0.0865 - val_loss: 2.6969 - val_mae: 1.0867\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0175 - mae: 0.0844 - val_loss: 2.7183 - val_mae: 1.0915\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0235 - mae: 0.0915 - val_loss: 2.7149 - val_mae: 1.0891\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0223 - mae: 0.0914 - val_loss: 2.7077 - val_mae: 1.0894\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0186 - mae: 0.0876 - val_loss: 2.7256 - val_mae: 1.0977\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0234 - mae: 0.0973 - val_loss: 2.7319 - val_mae: 1.0951\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0269 - mae: 0.1036 - val_loss: 2.6631 - val_mae: 1.0852\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4465 - mae: 1.1118\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 14.4340 - mae: 2.8544 - val_loss: 4.3111 - val_mae: 1.5321\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 2.4093 - mae: 1.1577 - val_loss: 3.5045 - val_mae: 1.3559\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 1.3122 - mae: 0.8373 - val_loss: 3.5827 - val_mae: 1.3197\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.9100 - mae: 0.6737 - val_loss: 3.5071 - val_mae: 1.3250\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.6604 - mae: 0.5655 - val_loss: 3.3845 - val_mae: 1.3226\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.6094 - mae: 0.5458 - val_loss: 3.6684 - val_mae: 1.3382\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.5699 - mae: 0.5050 - val_loss: 3.5645 - val_mae: 1.3328\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.5274 - mae: 0.4824 - val_loss: 3.4897 - val_mae: 1.3118\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.5335 - mae: 0.4798 - val_loss: 3.6455 - val_mae: 1.3078\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.4626 - mae: 0.4767 - val_loss: 3.4536 - val_mae: 1.2940\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3844 - mae: 0.3974 - val_loss: 3.3700 - val_mae: 1.2772\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3377 - mae: 0.3947 - val_loss: 3.3331 - val_mae: 1.3087\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.3114 - mae: 0.3883 - val_loss: 3.2845 - val_mae: 1.2589\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2991 - mae: 0.3717 - val_loss: 3.2689 - val_mae: 1.2508\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2605 - mae: 0.3497 - val_loss: 3.2755 - val_mae: 1.2516\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.3222 - mae: 0.3683 - val_loss: 3.4023 - val_mae: 1.2476\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.2886 - mae: 0.3723 - val_loss: 3.3203 - val_mae: 1.2469\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.2759 - mae: 0.3526 - val_loss: 3.2290 - val_mae: 1.2524\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.6309 - mae: 0.3789 - val_loss: 3.4355 - val_mae: 1.2324\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2670 - mae: 0.3535 - val_loss: 3.1937 - val_mae: 1.2260\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.2680 - mae: 0.3391 - val_loss: 3.1963 - val_mae: 1.2140\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2073 - mae: 0.3041 - val_loss: 3.1738 - val_mae: 1.2155\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1894 - mae: 0.2905 - val_loss: 3.0986 - val_mae: 1.2160\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1735 - mae: 0.2825 - val_loss: 3.1436 - val_mae: 1.2015\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.1909 - mae: 0.2942 - val_loss: 3.1051 - val_mae: 1.2359\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1810 - mae: 0.2951 - val_loss: 3.0179 - val_mae: 1.2209\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2215 - mae: 0.3137 - val_loss: 3.0162 - val_mae: 1.2107\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1690 - mae: 0.2705 - val_loss: 2.9371 - val_mae: 1.1704\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1896 - mae: 0.2956 - val_loss: 3.0036 - val_mae: 1.1867\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1700 - mae: 0.2725 - val_loss: 2.9877 - val_mae: 1.1811\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1855 - mae: 0.2757 - val_loss: 3.1150 - val_mae: 1.1961\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1694 - mae: 0.2778 - val_loss: 3.1039 - val_mae: 1.2157\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1596 - mae: 0.2670 - val_loss: 2.9715 - val_mae: 1.1859\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1395 - mae: 0.2502 - val_loss: 2.9529 - val_mae: 1.1875\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1267 - mae: 0.2378 - val_loss: 3.0773 - val_mae: 1.1844\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1387 - mae: 0.2502 - val_loss: 2.9923 - val_mae: 1.1793\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.1444 - mae: 0.2680 - val_loss: 2.9133 - val_mae: 1.1722\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1188 - mae: 0.2461 - val_loss: 3.0080 - val_mae: 1.1677\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1195 - mae: 0.2299 - val_loss: 2.9773 - val_mae: 1.1629\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1090 - mae: 0.2203 - val_loss: 2.8352 - val_mae: 1.1653\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1237 - mae: 0.2440 - val_loss: 2.9607 - val_mae: 1.1929\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1391 - mae: 0.2486 - val_loss: 2.9259 - val_mae: 1.1685\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1067 - mae: 0.2223 - val_loss: 2.9735 - val_mae: 1.1733\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1066 - mae: 0.2189 - val_loss: 2.9241 - val_mae: 1.1820\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1065 - mae: 0.2120 - val_loss: 2.9168 - val_mae: 1.1645\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0996 - mae: 0.2144 - val_loss: 2.8998 - val_mae: 1.1555\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0961 - mae: 0.2125 - val_loss: 2.8693 - val_mae: 1.1465\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1045 - mae: 0.2107 - val_loss: 2.9042 - val_mae: 1.1484\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1057 - mae: 0.2180 - val_loss: 2.9122 - val_mae: 1.1448\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0912 - mae: 0.2073 - val_loss: 2.9045 - val_mae: 1.1561\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0776 - mae: 0.1872 - val_loss: 2.8318 - val_mae: 1.1442\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0820 - mae: 0.1892 - val_loss: 2.8708 - val_mae: 1.1596\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0863 - mae: 0.2009 - val_loss: 2.8254 - val_mae: 1.1493\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0821 - mae: 0.1910 - val_loss: 2.8370 - val_mae: 1.1450\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0783 - mae: 0.1941 - val_loss: 2.8738 - val_mae: 1.1393\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0765 - mae: 0.1879 - val_loss: 2.8555 - val_mae: 1.1429\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0844 - mae: 0.1919 - val_loss: 2.8569 - val_mae: 1.1723\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0867 - mae: 0.2065 - val_loss: 2.8533 - val_mae: 1.1485\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0861 - mae: 0.1990 - val_loss: 2.8073 - val_mae: 1.1473\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0795 - mae: 0.1887 - val_loss: 2.8476 - val_mae: 1.1458\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0689 - mae: 0.1733 - val_loss: 2.7891 - val_mae: 1.1385\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0721 - mae: 0.1752 - val_loss: 2.8378 - val_mae: 1.1392\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0642 - mae: 0.1734 - val_loss: 2.8443 - val_mae: 1.1426\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0757 - mae: 0.1867 - val_loss: 2.8885 - val_mae: 1.1479\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0827 - mae: 0.1880 - val_loss: 2.8457 - val_mae: 1.1407\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0609 - mae: 0.1640 - val_loss: 2.7946 - val_mae: 1.1357\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0601 - mae: 0.1626 - val_loss: 2.8265 - val_mae: 1.1458\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0675 - mae: 0.1726 - val_loss: 2.8218 - val_mae: 1.1386\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0741 - mae: 0.1788 - val_loss: 2.9359 - val_mae: 1.1388\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0716 - mae: 0.1772 - val_loss: 2.7780 - val_mae: 1.1284\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0602 - mae: 0.1638 - val_loss: 2.7935 - val_mae: 1.1330\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0617 - mae: 0.1599 - val_loss: 2.7796 - val_mae: 1.1337\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0528 - mae: 0.1510 - val_loss: 2.8347 - val_mae: 1.1392\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0515 - mae: 0.1506 - val_loss: 2.8271 - val_mae: 1.1318\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0558 - mae: 0.1584 - val_loss: 2.8068 - val_mae: 1.1279\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0616 - mae: 0.1652 - val_loss: 2.7871 - val_mae: 1.1328\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0523 - mae: 0.1541 - val_loss: 2.8275 - val_mae: 1.1339\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0561 - mae: 0.1576 - val_loss: 2.7776 - val_mae: 1.1331\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0682 - mae: 0.1718 - val_loss: 2.7686 - val_mae: 1.1306\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0523 - mae: 0.1538 - val_loss: 2.8423 - val_mae: 1.1257\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0522 - mae: 0.1522 - val_loss: 2.7776 - val_mae: 1.1198\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0481 - mae: 0.1477 - val_loss: 2.8082 - val_mae: 1.1218\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0450 - mae: 0.1404 - val_loss: 2.7311 - val_mae: 1.1217\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0446 - mae: 0.1405 - val_loss: 2.7963 - val_mae: 1.1318\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 0.0613 - mae: 0.1542 - val_loss: 2.7887 - val_mae: 1.1195\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0479 - mae: 0.1478 - val_loss: 2.8127 - val_mae: 1.1348\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0464 - mae: 0.1390 - val_loss: 2.7585 - val_mae: 1.1275\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0413 - mae: 0.1371 - val_loss: 2.7830 - val_mae: 1.1264\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0439 - mae: 0.1426 - val_loss: 2.7649 - val_mae: 1.1299\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0460 - mae: 0.1381 - val_loss: 2.7769 - val_mae: 1.1270\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0507 - mae: 0.1362 - val_loss: 2.8159 - val_mae: 1.1334\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0419 - mae: 0.1387 - val_loss: 2.7347 - val_mae: 1.1232\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0367 - mae: 0.1296 - val_loss: 2.7385 - val_mae: 1.1228\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0469 - mae: 0.1386 - val_loss: 2.7700 - val_mae: 1.1174\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0399 - mae: 0.1345 - val_loss: 2.7765 - val_mae: 1.1155\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0417 - mae: 0.1317 - val_loss: 2.7790 - val_mae: 1.1226\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0395 - mae: 0.1320 - val_loss: 2.7630 - val_mae: 1.1207\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0426 - mae: 0.1343 - val_loss: 2.7675 - val_mae: 1.1262\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0443 - mae: 0.1385 - val_loss: 2.7715 - val_mae: 1.1215\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0449 - mae: 0.1421 - val_loss: 2.7583 - val_mae: 1.1332\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0530 - mae: 0.1579 - val_loss: 2.7830 - val_mae: 1.1256\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0354 - mae: 0.1305 - val_loss: 2.7491 - val_mae: 1.1129\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0434 - mae: 0.1329 - val_loss: 2.7939 - val_mae: 1.1195\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0398 - mae: 0.1324 - val_loss: 2.7934 - val_mae: 1.1156\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0360 - mae: 0.1260 - val_loss: 2.7506 - val_mae: 1.1200\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0362 - mae: 0.1219 - val_loss: 2.7573 - val_mae: 1.1187\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0315 - mae: 0.1162 - val_loss: 2.7445 - val_mae: 1.1127\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0377 - mae: 0.1236 - val_loss: 2.7479 - val_mae: 1.1145\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0338 - mae: 0.1186 - val_loss: 2.8101 - val_mae: 1.1260\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0439 - mae: 0.1313 - val_loss: 2.7625 - val_mae: 1.1162\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0368 - mae: 0.1278 - val_loss: 2.7292 - val_mae: 1.1174\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0356 - mae: 0.1245 - val_loss: 2.7498 - val_mae: 1.1123\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0364 - mae: 0.1231 - val_loss: 2.7330 - val_mae: 1.1224\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0365 - mae: 0.1257 - val_loss: 2.7391 - val_mae: 1.1204\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0294 - mae: 0.1157 - val_loss: 2.7569 - val_mae: 1.1132\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0340 - mae: 0.1144 - val_loss: 2.7559 - val_mae: 1.1211\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0291 - mae: 0.1126 - val_loss: 2.7456 - val_mae: 1.1085\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0360 - mae: 0.1181 - val_loss: 2.7234 - val_mae: 1.1046\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0312 - mae: 0.1173 - val_loss: 2.7561 - val_mae: 1.1111\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0407 - mae: 0.1282 - val_loss: 2.7680 - val_mae: 1.1187\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0411 - mae: 0.1216 - val_loss: 2.7739 - val_mae: 1.1148\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0372 - mae: 0.1207 - val_loss: 2.7579 - val_mae: 1.1118\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0307 - mae: 0.1123 - val_loss: 2.7317 - val_mae: 1.1073\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0393 - mae: 0.1187 - val_loss: 2.7256 - val_mae: 1.1135\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0304 - mae: 0.1163 - val_loss: 2.7581 - val_mae: 1.1164\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0295 - mae: 0.1117 - val_loss: 2.7854 - val_mae: 1.1171\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0301 - mae: 0.1083 - val_loss: 2.7245 - val_mae: 1.1092\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0228 - mae: 0.1006 - val_loss: 2.7743 - val_mae: 1.1178\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0301 - mae: 0.1121 - val_loss: 2.7240 - val_mae: 1.1140\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0345 - mae: 0.1219 - val_loss: 2.7356 - val_mae: 1.1041\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0267 - mae: 0.1118 - val_loss: 2.7173 - val_mae: 1.1119\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0304 - mae: 0.1125 - val_loss: 2.7516 - val_mae: 1.1180\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0296 - mae: 0.1117 - val_loss: 2.7330 - val_mae: 1.1058\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0299 - mae: 0.1041 - val_loss: 2.7204 - val_mae: 1.1146\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0269 - mae: 0.1059 - val_loss: 2.7421 - val_mae: 1.1064\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0312 - mae: 0.1092 - val_loss: 2.7373 - val_mae: 1.1036\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0418 - mae: 0.1157 - val_loss: 2.7094 - val_mae: 1.1054\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 2.7167 - val_mae: 1.1116\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0269 - mae: 0.1077 - val_loss: 2.7273 - val_mae: 1.1086\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0280 - mae: 0.1072 - val_loss: 2.7544 - val_mae: 1.1026\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0280 - mae: 0.1052 - val_loss: 2.7422 - val_mae: 1.1039\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0278 - mae: 0.1068 - val_loss: 2.7287 - val_mae: 1.1011\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0297 - mae: 0.1058 - val_loss: 2.7487 - val_mae: 1.1027\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0251 - mae: 0.1008 - val_loss: 2.7453 - val_mae: 1.0995\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0258 - mae: 0.1070 - val_loss: 2.7098 - val_mae: 1.1071\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0228 - mae: 0.1004 - val_loss: 2.7103 - val_mae: 1.0993\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0229 - mae: 0.1014 - val_loss: 2.7377 - val_mae: 1.1094\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0269 - mae: 0.1023 - val_loss: 2.6850 - val_mae: 1.0980\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0250 - mae: 0.0999 - val_loss: 2.7515 - val_mae: 1.1047\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0220 - mae: 0.0990 - val_loss: 2.7499 - val_mae: 1.1051\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0269 - mae: 0.1092 - val_loss: 2.7089 - val_mae: 1.0994\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0326 - mae: 0.1046 - val_loss: 2.7256 - val_mae: 1.1010\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0263 - mae: 0.0965 - val_loss: 2.7133 - val_mae: 1.1013\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0192 - mae: 0.0860 - val_loss: 2.7288 - val_mae: 1.1003\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0234 - mae: 0.0958 - val_loss: 2.7346 - val_mae: 1.1015\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0236 - mae: 0.0952 - val_loss: 2.7203 - val_mae: 1.1030\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0268 - mae: 0.0994 - val_loss: 2.7584 - val_mae: 1.1071\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0232 - mae: 0.1022 - val_loss: 2.7291 - val_mae: 1.1019\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0261 - mae: 0.1014 - val_loss: 2.7152 - val_mae: 1.1059\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0265 - mae: 0.1008 - val_loss: 2.7306 - val_mae: 1.1072\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0237 - mae: 0.0973 - val_loss: 2.7451 - val_mae: 1.1077\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0232 - mae: 0.0956 - val_loss: 2.7332 - val_mae: 1.1015\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0323 - mae: 0.1005 - val_loss: 2.7384 - val_mae: 1.1070\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0203 - mae: 0.0934 - val_loss: 2.7230 - val_mae: 1.1058\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0203 - mae: 0.0910 - val_loss: 2.7594 - val_mae: 1.1021\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0224 - mae: 0.0984 - val_loss: 2.7013 - val_mae: 1.1054\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0221 - mae: 0.0984 - val_loss: 2.7160 - val_mae: 1.1013\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0234 - mae: 0.0967 - val_loss: 2.7461 - val_mae: 1.1009\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0239 - mae: 0.0955 - val_loss: 2.7248 - val_mae: 1.0963\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0211 - mae: 0.0911 - val_loss: 2.7272 - val_mae: 1.1087\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0254 - mae: 0.0969 - val_loss: 2.6912 - val_mae: 1.0987\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0238 - mae: 0.0925 - val_loss: 2.7224 - val_mae: 1.0990\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0249 - mae: 0.0917 - val_loss: 2.7158 - val_mae: 1.0988\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0261 - mae: 0.0932 - val_loss: 2.7237 - val_mae: 1.0993\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0201 - mae: 0.0882 - val_loss: 2.6923 - val_mae: 1.0975\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0186 - mae: 0.0891 - val_loss: 2.6681 - val_mae: 1.0964\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0235 - mae: 0.0918 - val_loss: 2.6925 - val_mae: 1.0962\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0154 - mae: 0.0799 - val_loss: 2.7138 - val_mae: 1.1000\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0272 - mae: 0.0939 - val_loss: 2.6953 - val_mae: 1.0961\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0173 - mae: 0.0864 - val_loss: 2.7085 - val_mae: 1.0913\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0232 - mae: 0.0949 - val_loss: 2.7247 - val_mae: 1.0993\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0197 - mae: 0.0880 - val_loss: 2.6857 - val_mae: 1.0915\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0192 - mae: 0.0878 - val_loss: 2.6953 - val_mae: 1.1014\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0177 - mae: 0.0852 - val_loss: 2.7221 - val_mae: 1.1001\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0187 - mae: 0.0856 - val_loss: 2.7081 - val_mae: 1.0962\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0197 - mae: 0.0929 - val_loss: 2.6845 - val_mae: 1.0906\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0207 - mae: 0.0908 - val_loss: 2.7001 - val_mae: 1.0978\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0215 - mae: 0.0902 - val_loss: 2.7150 - val_mae: 1.0942\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0224 - mae: 0.0912 - val_loss: 2.6799 - val_mae: 1.0945\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0204 - mae: 0.0896 - val_loss: 2.7003 - val_mae: 1.0957\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0190 - mae: 0.0885 - val_loss: 2.6809 - val_mae: 1.0940\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0177 - mae: 0.0852 - val_loss: 2.6716 - val_mae: 1.0927\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0184 - mae: 0.0847 - val_loss: 2.6945 - val_mae: 1.0939\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0217 - mae: 0.0898 - val_loss: 2.7107 - val_mae: 1.0933\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0170 - mae: 0.0834 - val_loss: 2.7115 - val_mae: 1.0966\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0198 - mae: 0.0857 - val_loss: 2.6842 - val_mae: 1.0947\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0243 - mae: 0.0961 - val_loss: 2.7012 - val_mae: 1.0906\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0190 - mae: 0.0896 - val_loss: 2.6845 - val_mae: 1.0970\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0173 - mae: 0.0845 - val_loss: 2.6734 - val_mae: 1.1013\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0169 - mae: 0.0839 - val_loss: 2.7041 - val_mae: 1.0973\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4735 - mae: 1.1079\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berna\\anaconda3\\envs\\saedc_ml\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 13.2361 - mae: 2.7059 - val_loss: 4.3199 - val_mae: 1.5360\n",
      "Epoch 2/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 2.2211 - mae: 1.1078 - val_loss: 3.8116 - val_mae: 1.4156\n",
      "Epoch 3/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 1.2234 - mae: 0.8090 - val_loss: 3.5044 - val_mae: 1.3313\n",
      "Epoch 4/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.9071 - mae: 0.6598 - val_loss: 3.4522 - val_mae: 1.3207\n",
      "Epoch 5/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.7528 - mae: 0.5958 - val_loss: 3.3728 - val_mae: 1.2872\n",
      "Epoch 6/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.6326 - mae: 0.5409 - val_loss: 3.4277 - val_mae: 1.3027\n",
      "Epoch 7/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.5887 - mae: 0.5050 - val_loss: 3.3296 - val_mae: 1.3061\n",
      "Epoch 8/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.5088 - mae: 0.4835 - val_loss: 3.4508 - val_mae: 1.2974\n",
      "Epoch 9/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.4961 - mae: 0.4705 - val_loss: 3.3356 - val_mae: 1.2837\n",
      "Epoch 10/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.4145 - mae: 0.4353 - val_loss: 3.3278 - val_mae: 1.2886\n",
      "Epoch 11/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.3796 - mae: 0.4201 - val_loss: 3.2841 - val_mae: 1.2886\n",
      "Epoch 12/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.3728 - mae: 0.4104 - val_loss: 3.3322 - val_mae: 1.3004\n",
      "Epoch 13/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.3528 - mae: 0.3781 - val_loss: 3.1654 - val_mae: 1.2487\n",
      "Epoch 14/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.3055 - mae: 0.3721 - val_loss: 3.2491 - val_mae: 1.2800\n",
      "Epoch 15/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2702 - mae: 0.3537 - val_loss: 3.1827 - val_mae: 1.2486\n",
      "Epoch 16/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2660 - mae: 0.3547 - val_loss: 3.1316 - val_mae: 1.2809\n",
      "Epoch 17/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2898 - mae: 0.3735 - val_loss: 3.1394 - val_mae: 1.2628\n",
      "Epoch 18/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2590 - mae: 0.3518 - val_loss: 3.0191 - val_mae: 1.1967\n",
      "Epoch 19/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2219 - mae: 0.3273 - val_loss: 3.0675 - val_mae: 1.2256\n",
      "Epoch 20/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2087 - mae: 0.3137 - val_loss: 2.9828 - val_mae: 1.1914\n",
      "Epoch 21/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2075 - mae: 0.3049 - val_loss: 3.0768 - val_mae: 1.1959\n",
      "Epoch 22/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1955 - mae: 0.3011 - val_loss: 2.9352 - val_mae: 1.2130\n",
      "Epoch 23/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2100 - mae: 0.3150 - val_loss: 3.0089 - val_mae: 1.1931\n",
      "Epoch 24/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2190 - mae: 0.3082 - val_loss: 2.9214 - val_mae: 1.1922\n",
      "Epoch 25/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.2333 - mae: 0.3305 - val_loss: 2.9318 - val_mae: 1.1760\n",
      "Epoch 26/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1630 - mae: 0.2857 - val_loss: 2.9293 - val_mae: 1.1913\n",
      "Epoch 27/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1740 - mae: 0.2849 - val_loss: 2.9290 - val_mae: 1.1510\n",
      "Epoch 28/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1621 - mae: 0.2695 - val_loss: 2.8251 - val_mae: 1.1719\n",
      "Epoch 29/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1379 - mae: 0.2549 - val_loss: 2.8741 - val_mae: 1.1527\n",
      "Epoch 30/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1659 - mae: 0.2745 - val_loss: 2.8718 - val_mae: 1.1565\n",
      "Epoch 31/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1471 - mae: 0.2647 - val_loss: 2.9290 - val_mae: 1.1696\n",
      "Epoch 32/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1621 - mae: 0.2807 - val_loss: 2.8435 - val_mae: 1.1519\n",
      "Epoch 33/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.1395 - mae: 0.2519 - val_loss: 2.8339 - val_mae: 1.1420\n",
      "Epoch 34/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1133 - mae: 0.2322 - val_loss: 2.8134 - val_mae: 1.1378\n",
      "Epoch 35/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1138 - mae: 0.2339 - val_loss: 2.8037 - val_mae: 1.1514\n",
      "Epoch 36/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1048 - mae: 0.2213 - val_loss: 2.8686 - val_mae: 1.1561\n",
      "Epoch 37/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1243 - mae: 0.2381 - val_loss: 2.7480 - val_mae: 1.1223\n",
      "Epoch 38/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1334 - mae: 0.2443 - val_loss: 2.7631 - val_mae: 1.1402\n",
      "Epoch 39/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1208 - mae: 0.2314 - val_loss: 2.7410 - val_mae: 1.1261\n",
      "Epoch 40/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1010 - mae: 0.2193 - val_loss: 2.7503 - val_mae: 1.1326\n",
      "Epoch 41/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1104 - mae: 0.2198 - val_loss: 2.7026 - val_mae: 1.1248\n",
      "Epoch 42/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1066 - mae: 0.2212 - val_loss: 2.7128 - val_mae: 1.1287\n",
      "Epoch 43/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1094 - mae: 0.2241 - val_loss: 2.6905 - val_mae: 1.1207\n",
      "Epoch 44/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0999 - mae: 0.2145 - val_loss: 2.7399 - val_mae: 1.1206\n",
      "Epoch 45/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1159 - mae: 0.2311 - val_loss: 2.7421 - val_mae: 1.1109\n",
      "Epoch 46/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1018 - mae: 0.2140 - val_loss: 2.7049 - val_mae: 1.1099\n",
      "Epoch 47/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0993 - mae: 0.2081 - val_loss: 2.6969 - val_mae: 1.1225\n",
      "Epoch 48/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.1061 - mae: 0.2134 - val_loss: 2.7598 - val_mae: 1.1216\n",
      "Epoch 49/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0841 - mae: 0.1950 - val_loss: 2.7122 - val_mae: 1.1275\n",
      "Epoch 50/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0844 - mae: 0.1934 - val_loss: 2.7114 - val_mae: 1.1242\n",
      "Epoch 51/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0689 - mae: 0.1790 - val_loss: 2.6640 - val_mae: 1.1118\n",
      "Epoch 52/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0741 - mae: 0.1776 - val_loss: 2.7062 - val_mae: 1.1074\n",
      "Epoch 53/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0764 - mae: 0.1743 - val_loss: 2.6774 - val_mae: 1.1057\n",
      "Epoch 54/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0638 - mae: 0.1665 - val_loss: 2.7148 - val_mae: 1.1094\n",
      "Epoch 55/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0666 - mae: 0.1754 - val_loss: 2.6520 - val_mae: 1.1055\n",
      "Epoch 56/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0688 - mae: 0.1762 - val_loss: 2.6921 - val_mae: 1.1058\n",
      "Epoch 57/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0723 - mae: 0.1783 - val_loss: 2.7030 - val_mae: 1.1509\n",
      "Epoch 58/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0764 - mae: 0.1904 - val_loss: 2.6558 - val_mae: 1.1030\n",
      "Epoch 59/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0692 - mae: 0.1780 - val_loss: 2.6404 - val_mae: 1.0980\n",
      "Epoch 60/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0747 - mae: 0.1802 - val_loss: 2.7186 - val_mae: 1.1034\n",
      "Epoch 61/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0629 - mae: 0.1730 - val_loss: 2.6171 - val_mae: 1.0974\n",
      "Epoch 62/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0581 - mae: 0.1654 - val_loss: 2.6300 - val_mae: 1.1003\n",
      "Epoch 63/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0560 - mae: 0.1604 - val_loss: 2.6435 - val_mae: 1.0948\n",
      "Epoch 64/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0603 - mae: 0.1651 - val_loss: 2.6520 - val_mae: 1.1032\n",
      "Epoch 65/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0638 - mae: 0.1729 - val_loss: 2.6121 - val_mae: 1.0908\n",
      "Epoch 66/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0595 - mae: 0.1670 - val_loss: 2.6070 - val_mae: 1.0898\n",
      "Epoch 67/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0592 - mae: 0.1616 - val_loss: 2.6302 - val_mae: 1.0940\n",
      "Epoch 68/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0493 - mae: 0.1518 - val_loss: 2.6376 - val_mae: 1.0914\n",
      "Epoch 69/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0519 - mae: 0.1458 - val_loss: 2.5842 - val_mae: 1.0954\n",
      "Epoch 70/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0493 - mae: 0.1547 - val_loss: 2.6326 - val_mae: 1.0817\n",
      "Epoch 71/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0574 - mae: 0.1553 - val_loss: 2.5625 - val_mae: 1.0838\n",
      "Epoch 72/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0465 - mae: 0.1481 - val_loss: 2.6539 - val_mae: 1.0977\n",
      "Epoch 73/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0506 - mae: 0.1470 - val_loss: 2.6394 - val_mae: 1.0832\n",
      "Epoch 74/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0497 - mae: 0.1509 - val_loss: 2.6090 - val_mae: 1.0897\n",
      "Epoch 75/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0543 - mae: 0.1567 - val_loss: 2.5942 - val_mae: 1.0969\n",
      "Epoch 76/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0468 - mae: 0.1493 - val_loss: 2.5895 - val_mae: 1.0787\n",
      "Epoch 77/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0485 - mae: 0.1452 - val_loss: 2.6124 - val_mae: 1.0827\n",
      "Epoch 78/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0408 - mae: 0.1340 - val_loss: 2.6178 - val_mae: 1.0790\n",
      "Epoch 79/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0391 - mae: 0.1327 - val_loss: 2.5891 - val_mae: 1.0792\n",
      "Epoch 80/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0391 - mae: 0.1302 - val_loss: 2.6048 - val_mae: 1.0803\n",
      "Epoch 81/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0383 - mae: 0.1312 - val_loss: 2.5867 - val_mae: 1.0833\n",
      "Epoch 82/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0413 - mae: 0.1385 - val_loss: 2.6238 - val_mae: 1.0790\n",
      "Epoch 83/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0507 - mae: 0.1488 - val_loss: 2.5559 - val_mae: 1.0735\n",
      "Epoch 84/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0422 - mae: 0.1401 - val_loss: 2.5934 - val_mae: 1.0829\n",
      "Epoch 85/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0395 - mae: 0.1357 - val_loss: 2.5719 - val_mae: 1.0849\n",
      "Epoch 86/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0369 - mae: 0.1323 - val_loss: 2.6231 - val_mae: 1.0838\n",
      "Epoch 87/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0391 - mae: 0.1335 - val_loss: 2.5907 - val_mae: 1.0923\n",
      "Epoch 88/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0369 - mae: 0.1309 - val_loss: 2.5446 - val_mae: 1.0725\n",
      "Epoch 89/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0325 - mae: 0.1265 - val_loss: 2.6027 - val_mae: 1.0849\n",
      "Epoch 90/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0349 - mae: 0.1298 - val_loss: 2.5604 - val_mae: 1.0749\n",
      "Epoch 91/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0348 - mae: 0.1281 - val_loss: 2.5894 - val_mae: 1.0774\n",
      "Epoch 92/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0297 - mae: 0.1173 - val_loss: 2.5898 - val_mae: 1.0738\n",
      "Epoch 93/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0409 - mae: 0.1349 - val_loss: 2.5599 - val_mae: 1.0672\n",
      "Epoch 94/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0359 - mae: 0.1315 - val_loss: 2.5415 - val_mae: 1.0771\n",
      "Epoch 95/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0316 - mae: 0.1253 - val_loss: 2.6032 - val_mae: 1.0714\n",
      "Epoch 96/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0319 - mae: 0.1235 - val_loss: 2.5630 - val_mae: 1.0693\n",
      "Epoch 97/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0328 - mae: 0.1226 - val_loss: 2.5769 - val_mae: 1.0690\n",
      "Epoch 98/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0313 - mae: 0.1203 - val_loss: 2.5567 - val_mae: 1.0726\n",
      "Epoch 99/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0331 - mae: 0.1269 - val_loss: 2.5636 - val_mae: 1.0818\n",
      "Epoch 100/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0353 - mae: 0.1309 - val_loss: 2.5383 - val_mae: 1.0711\n",
      "Epoch 101/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0289 - mae: 0.1185 - val_loss: 2.5544 - val_mae: 1.0702\n",
      "Epoch 102/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0377 - mae: 0.1213 - val_loss: 2.5691 - val_mae: 1.0659\n",
      "Epoch 103/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0277 - mae: 0.1105 - val_loss: 2.5559 - val_mae: 1.0666\n",
      "Epoch 104/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 0.0240 - mae: 0.1049 - val_loss: 2.5743 - val_mae: 1.0725\n",
      "Epoch 105/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0272 - mae: 0.1136 - val_loss: 2.5444 - val_mae: 1.0595\n",
      "Epoch 106/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0247 - mae: 0.1076 - val_loss: 2.5546 - val_mae: 1.0662\n",
      "Epoch 107/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0241 - mae: 0.1070 - val_loss: 2.5573 - val_mae: 1.0814\n",
      "Epoch 108/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0288 - mae: 0.1173 - val_loss: 2.5565 - val_mae: 1.0712\n",
      "Epoch 109/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0277 - mae: 0.1152 - val_loss: 2.5495 - val_mae: 1.0748\n",
      "Epoch 110/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0302 - mae: 0.1183 - val_loss: 2.5753 - val_mae: 1.0713\n",
      "Epoch 111/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0281 - mae: 0.1149 - val_loss: 2.5282 - val_mae: 1.0593\n",
      "Epoch 112/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0250 - mae: 0.1098 - val_loss: 2.5576 - val_mae: 1.0647\n",
      "Epoch 113/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0242 - mae: 0.1083 - val_loss: 2.5578 - val_mae: 1.0666\n",
      "Epoch 114/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0318 - mae: 0.1208 - val_loss: 2.5317 - val_mae: 1.0713\n",
      "Epoch 115/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0304 - mae: 0.1228 - val_loss: 2.5205 - val_mae: 1.0632\n",
      "Epoch 116/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0252 - mae: 0.1097 - val_loss: 2.5775 - val_mae: 1.0682\n",
      "Epoch 117/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0236 - mae: 0.1039 - val_loss: 2.5177 - val_mae: 1.0632\n",
      "Epoch 118/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0219 - mae: 0.0991 - val_loss: 2.5450 - val_mae: 1.0711\n",
      "Epoch 119/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0249 - mae: 0.1044 - val_loss: 2.5183 - val_mae: 1.0663\n",
      "Epoch 120/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0254 - mae: 0.1098 - val_loss: 2.5554 - val_mae: 1.0627\n",
      "Epoch 121/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0203 - mae: 0.0992 - val_loss: 2.5412 - val_mae: 1.0663\n",
      "Epoch 122/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0274 - mae: 0.1100 - val_loss: 2.5886 - val_mae: 1.0724\n",
      "Epoch 123/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0273 - mae: 0.1139 - val_loss: 2.5456 - val_mae: 1.0763\n",
      "Epoch 124/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0293 - mae: 0.1129 - val_loss: 2.5584 - val_mae: 1.0740\n",
      "Epoch 125/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0215 - mae: 0.1005 - val_loss: 2.5938 - val_mae: 1.0670\n",
      "Epoch 126/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0228 - mae: 0.1023 - val_loss: 2.5606 - val_mae: 1.0676\n",
      "Epoch 127/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0206 - mae: 0.0976 - val_loss: 2.5325 - val_mae: 1.0581\n",
      "Epoch 128/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0206 - mae: 0.0996 - val_loss: 2.5495 - val_mae: 1.0620\n",
      "Epoch 129/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0213 - mae: 0.1004 - val_loss: 2.5395 - val_mae: 1.0610\n",
      "Epoch 130/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0232 - mae: 0.1006 - val_loss: 2.5404 - val_mae: 1.0586\n",
      "Epoch 131/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0233 - mae: 0.1030 - val_loss: 2.5371 - val_mae: 1.0632\n",
      "Epoch 132/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0228 - mae: 0.1004 - val_loss: 2.5488 - val_mae: 1.0658\n",
      "Epoch 133/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0245 - mae: 0.1004 - val_loss: 2.5431 - val_mae: 1.0622\n",
      "Epoch 134/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0210 - mae: 0.0995 - val_loss: 2.5490 - val_mae: 1.0644\n",
      "Epoch 135/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0228 - mae: 0.1033 - val_loss: 2.5513 - val_mae: 1.0608\n",
      "Epoch 136/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0213 - mae: 0.1018 - val_loss: 2.5469 - val_mae: 1.0612\n",
      "Epoch 137/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0191 - mae: 0.0945 - val_loss: 2.5329 - val_mae: 1.0651\n",
      "Epoch 138/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0201 - mae: 0.0984 - val_loss: 2.5498 - val_mae: 1.0662\n",
      "Epoch 139/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0220 - mae: 0.1034 - val_loss: 2.5497 - val_mae: 1.0713\n",
      "Epoch 140/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0238 - mae: 0.1040 - val_loss: 2.5675 - val_mae: 1.0652\n",
      "Epoch 141/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0196 - mae: 0.0954 - val_loss: 2.5399 - val_mae: 1.0564\n",
      "Epoch 142/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0215 - mae: 0.1003 - val_loss: 2.5418 - val_mae: 1.0592\n",
      "Epoch 143/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0212 - mae: 0.0990 - val_loss: 2.5460 - val_mae: 1.0659\n",
      "Epoch 144/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0194 - mae: 0.0958 - val_loss: 2.5389 - val_mae: 1.0584\n",
      "Epoch 145/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0209 - mae: 0.0993 - val_loss: 2.5679 - val_mae: 1.0651\n",
      "Epoch 146/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0226 - mae: 0.1048 - val_loss: 2.5799 - val_mae: 1.0660\n",
      "Epoch 147/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0187 - mae: 0.0926 - val_loss: 2.5496 - val_mae: 1.0656\n",
      "Epoch 148/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0213 - mae: 0.0964 - val_loss: 2.5539 - val_mae: 1.0618\n",
      "Epoch 149/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0178 - mae: 0.0885 - val_loss: 2.5351 - val_mae: 1.0608\n",
      "Epoch 150/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0159 - mae: 0.0860 - val_loss: 2.5671 - val_mae: 1.0621\n",
      "Epoch 151/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0189 - mae: 0.0933 - val_loss: 2.5359 - val_mae: 1.0690\n",
      "Epoch 152/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0182 - mae: 0.0917 - val_loss: 2.5414 - val_mae: 1.0625\n",
      "Epoch 153/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0210 - mae: 0.0950 - val_loss: 2.5612 - val_mae: 1.0649\n",
      "Epoch 154/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0177 - mae: 0.0908 - val_loss: 2.5426 - val_mae: 1.0638\n",
      "Epoch 155/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0186 - mae: 0.0922 - val_loss: 2.5303 - val_mae: 1.0561\n",
      "Epoch 156/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0165 - mae: 0.0865 - val_loss: 2.5548 - val_mae: 1.0602\n",
      "Epoch 157/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0164 - mae: 0.0893 - val_loss: 2.5626 - val_mae: 1.0621\n",
      "Epoch 158/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0156 - mae: 0.0865 - val_loss: 2.5692 - val_mae: 1.0678\n",
      "Epoch 159/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0206 - mae: 0.0976 - val_loss: 2.5385 - val_mae: 1.0623\n",
      "Epoch 160/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0181 - mae: 0.0920 - val_loss: 2.5591 - val_mae: 1.0643\n",
      "Epoch 161/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0171 - mae: 0.0886 - val_loss: 2.5495 - val_mae: 1.0637\n",
      "Epoch 162/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0169 - mae: 0.0894 - val_loss: 2.5383 - val_mae: 1.0649\n",
      "Epoch 163/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0169 - mae: 0.0878 - val_loss: 2.5648 - val_mae: 1.0661\n",
      "Epoch 164/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0202 - mae: 0.0900 - val_loss: 2.5670 - val_mae: 1.0651\n",
      "Epoch 165/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0155 - mae: 0.0861 - val_loss: 2.5479 - val_mae: 1.0651\n",
      "Epoch 166/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0163 - mae: 0.0844 - val_loss: 2.5281 - val_mae: 1.0593\n",
      "Epoch 167/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0191 - mae: 0.0920 - val_loss: 2.5562 - val_mae: 1.0628\n",
      "Epoch 168/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0156 - mae: 0.0861 - val_loss: 2.5398 - val_mae: 1.0648\n",
      "Epoch 169/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0164 - mae: 0.0876 - val_loss: 2.5213 - val_mae: 1.0618\n",
      "Epoch 170/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0179 - mae: 0.0856 - val_loss: 2.5459 - val_mae: 1.0671\n",
      "Epoch 171/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0158 - mae: 0.0828 - val_loss: 2.5435 - val_mae: 1.0603\n",
      "Epoch 172/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0160 - mae: 0.0853 - val_loss: 2.5627 - val_mae: 1.0637\n",
      "Epoch 173/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0163 - mae: 0.0849 - val_loss: 2.5338 - val_mae: 1.0545\n",
      "Epoch 174/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0180 - mae: 0.0916 - val_loss: 2.5391 - val_mae: 1.0617\n",
      "Epoch 175/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0147 - mae: 0.0807 - val_loss: 2.5681 - val_mae: 1.0619\n",
      "Epoch 176/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0136 - mae: 0.0804 - val_loss: 2.5217 - val_mae: 1.0580\n",
      "Epoch 177/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0149 - mae: 0.0813 - val_loss: 2.5422 - val_mae: 1.0562\n",
      "Epoch 178/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0168 - mae: 0.0890 - val_loss: 2.5469 - val_mae: 1.0606\n",
      "Epoch 179/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0158 - mae: 0.0852 - val_loss: 2.5325 - val_mae: 1.0553\n",
      "Epoch 180/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0128 - mae: 0.0779 - val_loss: 2.5485 - val_mae: 1.0628\n",
      "Epoch 181/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0141 - mae: 0.0791 - val_loss: 2.5417 - val_mae: 1.0621\n",
      "Epoch 182/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0172 - mae: 0.0859 - val_loss: 2.5540 - val_mae: 1.0610\n",
      "Epoch 183/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0166 - mae: 0.0848 - val_loss: 2.5342 - val_mae: 1.0684\n",
      "Epoch 184/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0154 - mae: 0.0829 - val_loss: 2.5743 - val_mae: 1.0647\n",
      "Epoch 185/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0182 - mae: 0.0854 - val_loss: 2.5262 - val_mae: 1.0654\n",
      "Epoch 186/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.0135 - mae: 0.0823 - val_loss: 2.5522 - val_mae: 1.0636\n",
      "Epoch 187/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0136 - mae: 0.0789 - val_loss: 2.5399 - val_mae: 1.0616\n",
      "Epoch 188/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0131 - mae: 0.0793 - val_loss: 2.5453 - val_mae: 1.0641\n",
      "Epoch 189/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0149 - mae: 0.0828 - val_loss: 2.5342 - val_mae: 1.0601\n",
      "Epoch 190/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0146 - mae: 0.0837 - val_loss: 2.5323 - val_mae: 1.0604\n",
      "Epoch 191/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0137 - mae: 0.0813 - val_loss: 2.5441 - val_mae: 1.0597\n",
      "Epoch 192/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0145 - mae: 0.0829 - val_loss: 2.5329 - val_mae: 1.0650\n",
      "Epoch 193/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0168 - mae: 0.0887 - val_loss: 2.5487 - val_mae: 1.0577\n",
      "Epoch 194/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0133 - mae: 0.0788 - val_loss: 2.5434 - val_mae: 1.0655\n",
      "Epoch 195/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0124 - mae: 0.0722 - val_loss: 2.5397 - val_mae: 1.0608\n",
      "Epoch 196/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0124 - mae: 0.0748 - val_loss: 2.5553 - val_mae: 1.0593\n",
      "Epoch 197/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0117 - mae: 0.0735 - val_loss: 2.5317 - val_mae: 1.0606\n",
      "Epoch 198/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0105 - mae: 0.0697 - val_loss: 2.5432 - val_mae: 1.0560\n",
      "Epoch 199/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0116 - mae: 0.0756 - val_loss: 2.5308 - val_mae: 1.0561\n",
      "Epoch 200/200\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.0132 - mae: 0.0786 - val_loss: 2.5296 - val_mae: 1.0603\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2466 - mae: 1.0587\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\n",
    "    'use_count_option', 'fpSize_option', 'radius_option',\n",
    "    'train', 'test', 'loss', 'mae', 'r-squared', 'error'\n",
    "                          ])\n",
    "\n",
    "# Obtem os dados\n",
    "df_rat_vo = pd.read_csv('dados/rat_vo.csv', usecols=['rat_vo', 'smiles'])\n",
    "\n",
    "# Converter valores da coluna 'valor' para float\n",
    "df_rat_vo['rat_vo'] = pd.to_numeric(df_rat_vo['rat_vo'], errors='coerce')\n",
    "\n",
    "# Remove NaN\n",
    "df_rat_vo.dropna(subset=['rat_vo', 'smiles'], inplace=True, ignore_index=True)\n",
    "\n",
    "# Normaliza LD50\n",
    "df_rat_vo['log_ld50'] = -np.log(df_rat_vo['rat_vo'])\n",
    "\n",
    "# Realiza a limpeza dos dados\n",
    "limpeza = Limpeza(dataframe=df_rat_vo)\n",
    "df_rat_vo = limpeza.dados_limpos(col_smiles='smiles', col_valor='rat_vo', sanitize=True, cutoff=.05, fragmento=False)\n",
    "\n",
    "for c in use_count_option:\n",
    "    for d in fpSize_option:\n",
    "        for e in radius_option:\n",
    "\n",
    "            try:\n",
    "\n",
    "                rat_vo = df_rat_vo.copy()\n",
    "\n",
    "                # Define a representação fingerprint\n",
    "                representacao = Representacao(dataframe=rat_vo)\n",
    "                rat_vo = representacao.fingerprint(col_smiles='smiles', fingerprint='morgan', use_count=c, fpSize=d, radius=e)\n",
    "                \n",
    "                # Define os conjuntos de treinamento e teste\n",
    "                X = np.array(rat_vo['Features'].to_list())\n",
    "                y = rat_vo['log_ld50'].values\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "                # Aplica ANN\n",
    "                model = ANN(fpSize=d)\n",
    "                model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "                history = model.fit(X_train, y_train, validation_split=0.1, epochs=200, batch_size=32)\n",
    "                \n",
    "                # Obtem as métricas do modelo\n",
    "                loss, mae = model.evaluate(X_test, y_test)\n",
    "                \n",
    "                # R-squared\n",
    "                predictions = model.predict(X_test)\n",
    "                y_true = np.array(y_test)\n",
    "                y_pred = np.array(predictions)\n",
    "                \n",
    "                r2 = r2_score(y_true, y_pred)\n",
    "                \n",
    "                df_ann = pd.DataFrame([{\n",
    "                    'use_count_option' : c, 'fpSize_option' : d, 'radius_option' : e,\n",
    "                    'train' : len(X_train), 'test' : len(X_test), 'loss' : loss, 'mae' : mae, 'r-squared' : r2, 'error' : np.nan\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n",
    "\n",
    "                df.to_excel('rat_vo_modelos.xlsx', index=False)\n",
    "\n",
    "            except Exception as err:\n",
    "                \n",
    "                df_ann = pd.DataFrame([{\n",
    "                    'use_count_option' : c, 'fpSize_option' : d, 'radius_option' : e,\n",
    "                    'train' : np.nan, 'test' : np.nan, 'loss' : np.nan, 'mae' : np.nan, 'r-squared' : np.nan, 'error' : str(err)\n",
    "                }])\n",
    "\n",
    "                df = pd.concat([df, df_ann], ignore_index=True, sort=False)\n",
    "\n",
    "                df.to_excel('rat_vo_modelos.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
